From 536fed53b0722f4e74236a42f771667fb9618f50 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 13:04:43 -0400
Subject: [PATCH 001/309] bcachefs: Fix UAF by journal write path

Previously, we handled synchronization with shutdown vs. the journal
write path by holding the journal lock until we were done, after marking
the write as completed.

But we don't want to be kicking off discards under the journal lock, so
we need an actual ref - just set the journal write closure's parent to
bch_fs.cl.

Fixes: b4d6e204f892 ("bcachefs: Fix triggering of discard by the journal path")
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c    | 3 +++
 fs/bcachefs/journal_io.c | 2 ++
 2 files changed, 5 insertions(+)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index ddfeb0dafc9d..014adbcb404b 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -189,6 +189,8 @@ journal_error_check_stuck(struct journal *j, int error, unsigned flags)
 
 void bch2_journal_do_writes(struct journal *j)
 {
+	struct bch_fs *c = container_of(j, struct bch_fs, journal);
+
 	for (u64 seq = journal_last_unwritten_seq(j);
 	     seq <= journal_cur_seq(j);
 	     seq++) {
@@ -203,6 +205,7 @@ void bch2_journal_do_writes(struct journal *j)
 		if (!journal_state_seq_count(j, j->reservations, seq)) {
 			j->seq_write_started = seq;
 			w->write_started = true;
+			closure_get(&c->cl);
 			closure_call(&w->io, bch2_journal_write, j->wq, NULL);
 		}
 
diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 9e028dbcc3d0..343f1daf5da7 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -1819,6 +1819,8 @@ static CLOSURE_CALLBACK(journal_write_done)
 
 	if (do_discards)
 		bch2_do_discards(c);
+
+	closure_put(&c->cl);
 }
 
 static void journal_write_endio(struct bio *bio)
-- 
2.51.0


From b1e781fc7ba499f5ef75748330626b727ff3d363 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 10 Jul 2025 16:27:15 -0400
Subject: [PATCH 002/309] bcachefs: async_objs: update iter pos after obj
 printed

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/async_objs.c | 3 +--
 1 file changed, 1 insertion(+), 2 deletions(-)

diff --git a/fs/bcachefs/async_objs.c b/fs/bcachefs/async_objs.c
index a7cd1f0f0964..e368c765eb46 100644
--- a/fs/bcachefs/async_objs.c
+++ b/fs/bcachefs/async_objs.c
@@ -80,12 +80,11 @@ static ssize_t bch2_async_obj_list_read(struct file *file, char __user *buf,
 			break;
 
 		list->obj_to_text(&i->buf, obj);
+		i->iter = iter.pos;
 	}
 
 	if (i->buf.allocation_failure)
 		ret = -ENOMEM;
-	else
-		i->iter = iter.pos;
 
 	if (!ret)
 		ret = bch2_debugfs_flush_buf(i);
-- 
2.51.0


From a862a8b3c3961776478a039163889aeec20f39f9 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 16 Jun 2025 16:17:49 -0400
Subject: [PATCH 003/309] bcachefs: fsck: dir_loop, subvol_loop now autofix

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-errors_format.h | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/sb-errors_format.h b/fs/bcachefs/sb-errors_format.h
index d154b7651d28..6cdb07a721e9 100644
--- a/fs/bcachefs/sb-errors_format.h
+++ b/fs/bcachefs/sb-errors_format.h
@@ -279,7 +279,7 @@ enum bch_fsck_flags {
 	x(root_subvol_missing,					238,	0)		\
 	x(root_dir_missing,					239,	0)		\
 	x(root_inode_not_dir,					240,	0)		\
-	x(dir_loop,						241,	0)		\
+	x(dir_loop,						241,	FSCK_AUTOFIX)	\
 	x(hash_table_key_duplicate,				242,	FSCK_AUTOFIX)	\
 	x(hash_table_key_wrong_offset,				243,	FSCK_AUTOFIX)	\
 	x(unlinked_inode_not_on_deleted_list,			244,	FSCK_AUTOFIX)	\
@@ -296,7 +296,7 @@ enum bch_fsck_flags {
 	x(subvol_root_fs_path_parent_nonzero,			255,	0)		\
 	x(subvol_children_not_set,				256,	0)		\
 	x(subvol_children_bad,					257,	0)		\
-	x(subvol_loop,						258,	0)		\
+	x(subvol_loop,						258,	FSCK_AUTOFIX)	\
 	x(subvol_unreachable,					259,	FSCK_AUTOFIX)	\
 	x(btree_node_bkey_bad_u64s,				260,	0)		\
 	x(btree_node_topology_empty_interior_node,		261,	0)		\
-- 
2.51.0


From 7903e03c2d65ee52f239d297dde5a6235d74ed6c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 7 Jun 2025 19:33:46 -0400
Subject: [PATCH 004/309] bcachefs: kill darray_u32_has()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 10 +---------
 1 file changed, 1 insertion(+), 9 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 15c1e890d299..9e3180fab553 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -2570,14 +2570,6 @@ int bch2_check_root(struct bch_fs *c)
 	return ret;
 }
 
-static bool darray_u32_has(darray_u32 *d, u32 v)
-{
-	darray_for_each(*d, i)
-		if (*i == v)
-			return true;
-	return false;
-}
-
 static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter, struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
@@ -2610,7 +2602,7 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 
 		u32 parent = le32_to_cpu(s.v->fs_path_parent);
 
-		if (darray_u32_has(&subvol_path, parent)) {
+		if (darray_find(subvol_path, parent)) {
 			printbuf_reset(&buf);
 			prt_printf(&buf, "subvolume loop: ");
 
-- 
2.51.0


From e8f8a2987820e244a59706ba183a442d56b64b47 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 26 May 2025 14:07:17 -0400
Subject: [PATCH 005/309] bcachefs: Reduce __bch2_btree_node_alloc() stack
 usage

Kill some temporaries on the stack that were completely unnecessary.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update_interior.c | 31 ++++++++++-------------------
 1 file changed, 11 insertions(+), 20 deletions(-)

diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 553059b33bfd..a26911d4d3bf 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -290,8 +290,6 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 	struct bch_fs *c = trans->c;
 	struct write_point *wp;
 	struct btree *b;
-	BKEY_PADDED_ONSTACK(k, BKEY_BTREE_PTR_VAL_U64s_MAX) tmp;
-	struct open_buckets obs = { .nr = 0 };
 	struct bch_devs_list devs_have = (struct bch_devs_list) { 0 };
 	enum bch_watermark watermark = flags & BCH_WATERMARK_MASK;
 	unsigned nr_reserve = watermark < BCH_WATERMARK_reclaim
@@ -310,8 +308,8 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 		struct btree_alloc *a =
 			&c->btree_reserve_cache[--c->btree_reserve_cache_nr];
 
-		obs = a->ob;
-		bkey_copy(&tmp.k, &a->k);
+		bkey_copy(&b->key, &a->k);
+		b->ob = a->ob;
 		mutex_unlock(&c->btree_reserve_cache_lock);
 		goto out;
 	}
@@ -345,14 +343,12 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 		goto retry;
 	}
 
-	bkey_btree_ptr_v2_init(&tmp.k);
-	bch2_alloc_sectors_append_ptrs(c, wp, &tmp.k, btree_sectors(c), false);
+	bkey_btree_ptr_v2_init(&b->key);
+	bch2_alloc_sectors_append_ptrs(c, wp, &b->key, btree_sectors(c), false);
 
-	bch2_open_bucket_get(c, wp, &obs);
+	bch2_open_bucket_get(c, wp, &b->ob);
 	bch2_alloc_sectors_done(c, wp);
 out:
-	bkey_copy(&b->key, &tmp.k);
-	b->ob = obs;
 	six_unlock_write(&b->c.lock);
 	six_unlock_intent(&b->c.lock);
 
@@ -513,30 +509,25 @@ static int bch2_btree_reserve_get(struct btree_trans *trans,
 				  unsigned flags,
 				  struct closure *cl)
 {
-	struct btree *b;
-	unsigned interior;
-	int ret = 0;
-
 	BUG_ON(nr_nodes[0] + nr_nodes[1] > BTREE_RESERVE_MAX);
 
 	/*
 	 * Protects reaping from the btree node cache and using the btree node
 	 * open bucket reserve:
 	 */
-	ret = bch2_btree_cache_cannibalize_lock(trans, cl);
+	int ret = bch2_btree_cache_cannibalize_lock(trans, cl);
 	if (ret)
 		return ret;
 
-	for (interior = 0; interior < 2; interior++) {
+	for (unsigned interior = 0; interior < 2; interior++) {
 		struct prealloc_nodes *p = as->prealloc_nodes + interior;
 
 		while (p->nr < nr_nodes[interior]) {
-			b = __bch2_btree_node_alloc(trans, &as->disk_res, cl,
-						    interior, target, flags);
-			if (IS_ERR(b)) {
-				ret = PTR_ERR(b);
+			struct btree *b = __bch2_btree_node_alloc(trans, &as->disk_res,
+							cl, interior, target, flags);
+			ret = PTR_ERR_OR_ZERO(b);
+			if (ret)
 				goto err;
-			}
 
 			p->b[p->nr++] = b;
 		}
-- 
2.51.0


From a39d7120253e8cb768f111f3a01747928002fc8a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 3 Jun 2025 15:53:44 -0400
Subject: [PATCH 006/309] bcachefs: Allow CONFIG_UNICODE=m

Fix the CONFIG_UNICODE checks - IS_ENABLED() is required when unicode is
bulit as a module.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h | 2 +-
 fs/bcachefs/dirent.c   | 4 ++--
 fs/bcachefs/dirent.h   | 2 +-
 fs/bcachefs/fs.c       | 2 +-
 fs/bcachefs/inode.c    | 2 +-
 fs/bcachefs/super.c    | 4 ++--
 6 files changed, 8 insertions(+), 8 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index ddfacad0f70c..f4edbe2a14fd 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -1285,7 +1285,7 @@ static inline bool bch2_discard_opt_enabled(struct bch_fs *c, struct bch_dev *ca
 
 static inline bool bch2_fs_casefold_enabled(struct bch_fs *c)
 {
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 	return !c->opts.casefold_disabled;
 #else
 	return false;
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index 28875c5c86ad..b06951673d49 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -13,7 +13,7 @@
 
 #include <linux/dcache.h>
 
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 int bch2_casefold(struct btree_trans *trans, const struct bch_hash_info *info,
 		  const struct qstr *str, struct qstr *out_cf)
 {
@@ -256,7 +256,7 @@ int bch2_dirent_init_name(struct bch_fs *c,
 		if (!bch2_fs_casefold_enabled(c))
 			return -EOPNOTSUPP;
 
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 		memcpy(&dirent->v.d_cf_name_block.d_names[0], name->name, name->len);
 
 		char *cf_out = &dirent->v.d_cf_name_block.d_names[name->len];
diff --git a/fs/bcachefs/dirent.h b/fs/bcachefs/dirent.h
index 0417608c18d5..2675da3e3860 100644
--- a/fs/bcachefs/dirent.h
+++ b/fs/bcachefs/dirent.h
@@ -23,7 +23,7 @@ struct bch_fs;
 struct bch_hash_info;
 struct bch_inode_info;
 
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 int bch2_casefold(struct btree_trans *, const struct bch_hash_info *,
 		  const struct qstr *, struct qstr *);
 #else
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index e54e4f255b22..cd8347063e80 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -2563,7 +2563,7 @@ static int bch2_fs_get_tree(struct fs_context *fc)
 
 	sb->s_shrink->seeks = 0;
 
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 	if (bch2_fs_casefold_enabled(c))
 		sb->s_encoding = c->cf_encoding;
 	generic_set_sb_d_ops(sb);
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index ef4cc7395b86..6e08c7a26f4d 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1265,7 +1265,7 @@ int bch2_inode_set_casefold(struct btree_trans *trans, subvol_inum inum,
 {
 	struct bch_fs *c = trans->c;
 
-#ifndef CONFIG_UNICODE
+#if !IS_ENABLED(CONFIG_UNICODE)
 	bch_err(c, "Cannot use casefolding on a kernel without CONFIG_UNICODE");
 	return -EOPNOTSUPP;
 #endif
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index c46b1053a02c..5e90f64bd5f4 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -585,7 +585,7 @@ static void __bch2_fs_free(struct bch_fs *c)
 	for (unsigned i = 0; i < BCH_TIME_STAT_NR; i++)
 		bch2_time_stats_exit(&c->times[i]);
 
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 	utf8_unload(c->cf_encoding);
 #endif
 
@@ -1024,7 +1024,7 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 			goto err;
 	}
 
-#ifdef CONFIG_UNICODE
+#if IS_ENABLED(CONFIG_UNICODE)
 	if (bch2_fs_casefold_enabled(c)) {
 		/* Default encoding until we can potentially have more as an option. */
 		c->cf_encoding = utf8_load(BCH_FS_DEFAULT_UTF8_ENCODING);
-- 
2.51.0


From 13e65bffc10a818080851b7734e071dedc328192 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 25 May 2025 01:01:19 -0400
Subject: [PATCH 007/309] bcachefs: use scoped_guard() in fast_list.c

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fast_list.c | 15 +++++++--------
 1 file changed, 7 insertions(+), 8 deletions(-)

diff --git a/fs/bcachefs/fast_list.c b/fs/bcachefs/fast_list.c
index 2faec143eb31..b52f264318d8 100644
--- a/fs/bcachefs/fast_list.c
+++ b/fs/bcachefs/fast_list.c
@@ -115,22 +115,21 @@ int fast_list_add(struct fast_list *l, void *item)
 void fast_list_remove(struct fast_list *l, unsigned idx)
 {
 	u32 entries[16], nr = 0;
-	unsigned long flags;
 
 	if (!idx)
 		return;
 
 	*genradix_ptr_inlined(&l->items, idx) = NULL;
 
-	local_irq_save(flags);
-	struct fast_list_pcpu *lp = this_cpu_ptr(l->buffer);
+	scoped_guard(irqsave) {
+		struct fast_list_pcpu *lp = this_cpu_ptr(l->buffer);
 
-	if (unlikely(lp->nr == ARRAY_SIZE(lp->entries)))
-		while (nr < ARRAY_SIZE(entries))
-			entries[nr++] = lp->entries[--lp->nr];
+		if (unlikely(lp->nr == ARRAY_SIZE(lp->entries)))
+			while (nr < ARRAY_SIZE(entries))
+				entries[nr++] = lp->entries[--lp->nr];
 
-	lp->entries[lp->nr++] = idx;
-	local_irq_restore(flags);
+		lp->entries[lp->nr++] = idx;
+	}
 
 	if (unlikely(nr))
 		while (nr)
-- 
2.51.0


From d273e6594cda8a05d11fc669cb057d1289d7c291 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 13 Jun 2025 22:34:35 -0400
Subject: [PATCH 008/309] bcachefs: DEFINE_CLASS()es for dev refcounts

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-members.h | 16 ++++++++++++++++
 1 file changed, 16 insertions(+)

diff --git a/fs/bcachefs/sb-members.h b/fs/bcachefs/sb-members.h
index 8d8a8a857648..5dcc2017f85b 100644
--- a/fs/bcachefs/sb-members.h
+++ b/fs/bcachefs/sb-members.h
@@ -240,6 +240,10 @@ static inline struct bch_dev *bch2_dev_tryget_noerror(struct bch_fs *c, unsigned
 	return ca;
 }
 
+DEFINE_CLASS(bch2_dev_tryget_noerror, struct bch_dev *,
+	     bch2_dev_put(_T), bch2_dev_tryget_noerror(c, dev),
+	     struct bch_fs *c, unsigned dev);
+
 static inline struct bch_dev *bch2_dev_tryget(struct bch_fs *c, unsigned dev)
 {
 	struct bch_dev *ca = bch2_dev_tryget_noerror(c, dev);
@@ -248,6 +252,10 @@ static inline struct bch_dev *bch2_dev_tryget(struct bch_fs *c, unsigned dev)
 	return ca;
 }
 
+DEFINE_CLASS(bch2_dev_tryget, struct bch_dev *,
+	     bch2_dev_put(_T), bch2_dev_tryget(c, dev),
+	     struct bch_fs *c, unsigned dev);
+
 static inline struct bch_dev *bch2_dev_bucket_tryget_noerror(struct bch_fs *c, struct bpos bucket)
 {
 	struct bch_dev *ca = bch2_dev_tryget_noerror(c, bucket.inode);
@@ -258,6 +266,10 @@ static inline struct bch_dev *bch2_dev_bucket_tryget_noerror(struct bch_fs *c, s
 	return ca;
 }
 
+DEFINE_CLASS(bch2_dev_bucket_tryget_noerror, struct bch_dev *,
+	     bch2_dev_put(_T), bch2_dev_bucket_tryget_noerror(c, bucket),
+	     struct bch_fs *c, struct bpos bucket);
+
 void bch2_dev_bucket_missing(struct bch_dev *, u64);
 
 static inline struct bch_dev *bch2_dev_bucket_tryget(struct bch_fs *c, struct bpos bucket)
@@ -271,6 +283,10 @@ static inline struct bch_dev *bch2_dev_bucket_tryget(struct bch_fs *c, struct bp
 	return ca;
 }
 
+DEFINE_CLASS(bch2_dev_bucket_tryget, struct bch_dev *,
+	     bch2_dev_put(_T), bch2_dev_bucket_tryget(c, bucket),
+	     struct bch_fs *c, struct bpos bucket);
+
 static inline struct bch_dev *bch2_dev_iterate_noerror(struct bch_fs *c, struct bch_dev *ca, unsigned dev_idx)
 {
 	if (ca && ca->dev_idx == dev_idx)
-- 
2.51.0


From ba73deef908d5e58cf1aea734f02e06cc739ee6d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 17 Jun 2025 10:52:13 -0400
Subject: [PATCH 009/309] bcachefs: More errcode conversions

Convert standard errcodes to private error codes, and return them with
bch_err_throw(), for better debugging.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h | 12 ++++++------
 fs/bcachefs/dirent.c   | 12 +++++++-----
 fs/bcachefs/errcode.h  |  7 +++++++
 fs/bcachefs/fs-io.c    |  2 +-
 fs/bcachefs/fs.c       | 22 ++++++++++++++--------
 fs/bcachefs/inode.c    | 15 ++++++---------
 fs/bcachefs/super.c    |  2 +-
 7 files changed, 42 insertions(+), 30 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index f4edbe2a14fd..004044e105ea 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -1283,13 +1283,13 @@ static inline bool bch2_discard_opt_enabled(struct bch_fs *c, struct bch_dev *ca
 		: ca->mi.discard;
 }
 
-static inline bool bch2_fs_casefold_enabled(struct bch_fs *c)
+static inline int bch2_fs_casefold_enabled(struct bch_fs *c)
 {
-#if IS_ENABLED(CONFIG_UNICODE)
-	return !c->opts.casefold_disabled;
-#else
-	return false;
-#endif
+	if (!IS_ENABLED(CONFIG_UNICODE))
+		return bch_err_throw(c, no_casefolding_without_utf8);
+	if (!c->opts.casefold_disabled)
+		return bch_err_throw(c, casefolding_disabled);
+	return 0;
 }
 
 #endif /* _BCACHEFS_H */
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index b06951673d49..216ab5f4f59e 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -19,11 +19,12 @@ int bch2_casefold(struct btree_trans *trans, const struct bch_hash_info *info,
 {
 	*out_cf = (struct qstr) QSTR_INIT(NULL, 0);
 
-	if (!bch2_fs_casefold_enabled(trans->c))
-		return -EOPNOTSUPP;
+	int ret = bch2_fs_casefold_enabled(trans->c);
+	if (ret)
+		return ret;
 
 	unsigned char *buf = bch2_trans_kmalloc(trans, BCH_NAME_MAX + 1);
-	int ret = PTR_ERR_OR_ZERO(buf);
+	ret = PTR_ERR_OR_ZERO(buf);
 	if (ret)
 		return ret;
 
@@ -253,8 +254,9 @@ int bch2_dirent_init_name(struct bch_fs *c,
 		       offsetof(struct bch_dirent, d_name) -
 		       name->len);
 	} else {
-		if (!bch2_fs_casefold_enabled(c))
-			return -EOPNOTSUPP;
+		int ret = bch2_fs_casefold_enabled(c);
+		if (ret)
+			return ret;
 
 #if IS_ENABLED(CONFIG_UNICODE)
 		memcpy(&dirent->v.d_cf_name_block.d_names[0], name->name, name->len);
diff --git a/fs/bcachefs/errcode.h b/fs/bcachefs/errcode.h
index acc3b7b67704..2de0dc91a69e 100644
--- a/fs/bcachefs/errcode.h
+++ b/fs/bcachefs/errcode.h
@@ -5,6 +5,7 @@
 #define BCH_ERRCODES()								\
 	x(ERANGE,			ERANGE_option_too_small)		\
 	x(ERANGE,			ERANGE_option_too_big)			\
+	x(ERANGE,			projid_too_big)				\
 	x(EINVAL,			injected)				\
 	x(BCH_ERR_injected,		injected_fs_start)			\
 	x(EINVAL,			mount_option)				\
@@ -216,6 +217,12 @@
 	x(EINVAL,			erasure_coding_found_btree_node)	\
 	x(EINVAL,			option_negative)			\
 	x(EOPNOTSUPP,			may_not_use_incompat_feature)		\
+	x(EOPNOTSUPP,			no_casefolding_without_utf8)		\
+	x(EOPNOTSUPP,			casefolding_disabled)		\
+	x(EOPNOTSUPP,			casefold_opt_is_dir_only)		\
+	x(EOPNOTSUPP,			unsupported_fsx_flag)			\
+	x(EOPNOTSUPP,			unsupported_fa_flag)			\
+	x(EOPNOTSUPP,			unsupported_fallocate_mode)		\
 	x(EROFS,			erofs_trans_commit)			\
 	x(EROFS,			erofs_no_writes)			\
 	x(EROFS,			erofs_journal_err)			\
diff --git a/fs/bcachefs/fs-io.c b/fs/bcachefs/fs-io.c
index a233f45875e9..dc5f713e209c 100644
--- a/fs/bcachefs/fs-io.c
+++ b/fs/bcachefs/fs-io.c
@@ -841,7 +841,7 @@ long bch2_fallocate_dispatch(struct file *file, int mode,
 	else if (mode == FALLOC_FL_COLLAPSE_RANGE)
 		ret = bchfs_fcollapse_finsert(inode, offset, len, false);
 	else
-		ret = -EOPNOTSUPP;
+		ret = bch_err_throw(c, unsupported_fallocate_mode);
 err:
 	bch2_pagecache_block_put(inode);
 	inode_unlock(&inode->v);
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index cd8347063e80..3b0783f117ae 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -1692,11 +1692,15 @@ static int bch2_fileattr_set(struct mnt_idmap *idmap,
 
 		s.mask = map_defined(bch_flags_to_xflags);
 		s.flags |= map_flags_rev(bch_flags_to_xflags, fa->fsx_xflags);
-		if (fa->fsx_xflags)
-			return -EOPNOTSUPP;
+		if (fa->fsx_xflags) {
+			ret = bch_err_throw(c, unsupported_fsx_flag);
+			goto err;
+		}
 
-		if (fa->fsx_projid >= U32_MAX)
-			return -EINVAL;
+		if (fa->fsx_projid >= U32_MAX) {
+			ret = bch_err_throw(c, projid_too_big);
+			goto err;
+		}
 
 		/*
 		 * inode fields accessible via the xattr interface are stored with a +1
@@ -1718,8 +1722,10 @@ static int bch2_fileattr_set(struct mnt_idmap *idmap,
 		fa->flags &= ~FS_CASEFOLD_FL;
 
 		s.flags |= map_flags_rev(bch_flags_to_uflags, fa->flags);
-		if (fa->flags)
-			return -EOPNOTSUPP;
+		if (fa->flags) {
+			ret = bch_err_throw(c, unsupported_fa_flag);
+			goto err;
+		}
 	}
 
 	mutex_lock(&inode->ei_update_lock);
@@ -1730,7 +1736,7 @@ static int bch2_fileattr_set(struct mnt_idmap *idmap,
 		bch2_write_inode(c, inode, fssetxattr_inode_update_fn, &s,
 			       ATTR_CTIME);
 	mutex_unlock(&inode->ei_update_lock);
-
+err:
 	return bch2_err_class(ret);
 }
 
@@ -2564,7 +2570,7 @@ static int bch2_fs_get_tree(struct fs_context *fc)
 	sb->s_shrink->seeks = 0;
 
 #if IS_ENABLED(CONFIG_UNICODE)
-	if (bch2_fs_casefold_enabled(c))
+	if (!bch2_fs_casefold_enabled(c))
 		sb->s_encoding = c->cf_encoding;
 	generic_set_sb_d_ops(sb);
 #endif
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 6e08c7a26f4d..99cd2a47f853 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1265,18 +1265,15 @@ int bch2_inode_set_casefold(struct btree_trans *trans, subvol_inum inum,
 {
 	struct bch_fs *c = trans->c;
 
-#if !IS_ENABLED(CONFIG_UNICODE)
-	bch_err(c, "Cannot use casefolding on a kernel without CONFIG_UNICODE");
-	return -EOPNOTSUPP;
-#endif
-
-	if (c->opts.casefold_disabled)
-		return -EOPNOTSUPP;
+	int ret = bch2_fs_casefold_enabled(c);
+	if (ret) {
+		bch_err_ratelimited(c, "Cannot enable casefolding: %s", bch2_err_str(ret));
+		return ret;
+	}
 
-	int ret = 0;
 	/* Not supported on individual files. */
 	if (!S_ISDIR(bi->bi_mode))
-		return -EOPNOTSUPP;
+		return bch_err_throw(c, casefold_opt_is_dir_only);
 
 	/*
 	 * Make sure the dir is empty, as otherwise we'd need to
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 5e90f64bd5f4..6980cd5b0ca8 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1025,7 +1025,7 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 	}
 
 #if IS_ENABLED(CONFIG_UNICODE)
-	if (bch2_fs_casefold_enabled(c)) {
+	if (!bch2_fs_casefold_enabled(c)) {
 		/* Default encoding until we can potentially have more as an option. */
 		c->cf_encoding = utf8_load(BCH_FS_DEFAULT_UTF8_ENCODING);
 		if (IS_ERR(c->cf_encoding)) {
-- 
2.51.0


From 3472b6bb63bb6e36a4249163f618a34d5cf2c121 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 17 Jun 2025 18:24:57 -0400
Subject: [PATCH 010/309] bcachefs: add an unlikely() to trans_begin()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index f8829b667ad3..d7dc7a25b95d 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -3323,7 +3323,7 @@ u32 bch2_trans_begin(struct btree_trans *trans)
 	trans->restart_count++;
 	trans->mem_top			= 0;
 
-	if (trans->restarted == BCH_ERR_transaction_restart_mem_realloced) {
+	if (unlikely(trans->restarted == BCH_ERR_transaction_restart_mem_realloced)) {
 		EBUG_ON(!trans->mem || !trans->mem_bytes);
 		unsigned new_bytes = trans->realloc_bytes_required;
 		void *new_mem = krealloc(trans->mem, new_bytes, GFP_NOWAIT|__GFP_NOWARN);
-- 
2.51.0


From cfcaead907c1e29d1f424d26fb9f0e2ed36033dd Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 17 Jun 2025 21:06:58 -0400
Subject: [PATCH 011/309] bcachefs: Plumb trans_kmalloc ip to trans_log_msg

the 'ip' parameter to bch2_trans_kmalloc() is used for bump allocator
tracing: when we exceed the bump allocator limit, it dumps a list of
allocations and what function did them.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update.c | 15 ++++++++-------
 fs/bcachefs/btree_update.h | 26 ++++++++++++++++++++------
 2 files changed, 28 insertions(+), 13 deletions(-)

diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index ee657b9f4b96..192c1e5e3ed9 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -546,7 +546,7 @@ int bch2_btree_insert_clone_trans(struct btree_trans *trans,
 
 void *__bch2_trans_subbuf_alloc(struct btree_trans *trans,
 				struct btree_trans_subbuf *buf,
-				unsigned u64s)
+				unsigned u64s, ulong ip)
 {
 	unsigned new_top = buf->u64s + u64s;
 	unsigned new_size = buf->size;
@@ -556,7 +556,7 @@ void *__bch2_trans_subbuf_alloc(struct btree_trans *trans,
 	if (new_top > new_size)
 		new_size = roundup_pow_of_two(new_top);
 
-	void *n = bch2_trans_kmalloc_nomemzero(trans, new_size * sizeof(u64));
+	void *n = bch2_trans_kmalloc_nomemzero_ip(trans, new_size * sizeof(u64), ip);
 	if (IS_ERR(n))
 		return n;
 
@@ -813,11 +813,11 @@ int bch2_btree_bit_mod_buffered(struct btree_trans *trans, enum btree_id btree,
 	return bch2_trans_update_buffered(trans, btree, &k);
 }
 
-static int __bch2_trans_log_str(struct btree_trans *trans, const char *str, unsigned len)
+static int __bch2_trans_log_str(struct btree_trans *trans, const char *str, unsigned len, ulong ip)
 {
 	unsigned u64s = DIV_ROUND_UP(len, sizeof(u64));
 
-	struct jset_entry *e = bch2_trans_jset_entry_alloc(trans, jset_u64s(u64s));
+	struct jset_entry *e = bch2_trans_jset_entry_alloc_ip(trans, jset_u64s(u64s), ip);
 	int ret = PTR_ERR_OR_ZERO(e);
 	if (ret)
 		return ret;
@@ -830,7 +830,7 @@ static int __bch2_trans_log_str(struct btree_trans *trans, const char *str, unsi
 
 int bch2_trans_log_str(struct btree_trans *trans, const char *str)
 {
-	return __bch2_trans_log_str(trans, str, strlen(str));
+	return __bch2_trans_log_str(trans, str, strlen(str), _RET_IP_);
 }
 
 int bch2_trans_log_msg(struct btree_trans *trans, struct printbuf *buf)
@@ -839,13 +839,14 @@ int bch2_trans_log_msg(struct btree_trans *trans, struct printbuf *buf)
 	if (ret)
 		return ret;
 
-	return __bch2_trans_log_str(trans, buf->buf, buf->pos);
+	return __bch2_trans_log_str(trans, buf->buf, buf->pos, _RET_IP_);
 }
 
 int bch2_trans_log_bkey(struct btree_trans *trans, enum btree_id btree,
 			unsigned level, struct bkey_i *k)
 {
-	struct jset_entry *e = bch2_trans_jset_entry_alloc(trans, jset_u64s(k->k.u64s));
+	struct jset_entry *e = bch2_trans_jset_entry_alloc_ip(trans,
+						jset_u64s(k->k.u64s), _RET_IP_);
 	int ret = PTR_ERR_OR_ZERO(e);
 	if (ret)
 		return ret;
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 0b98ab959719..17a6abd7d9cb 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -137,21 +137,29 @@ static inline void *btree_trans_subbuf_top(struct btree_trans *trans,
 
 void *__bch2_trans_subbuf_alloc(struct btree_trans *,
 				struct btree_trans_subbuf *,
-				unsigned);
+				unsigned, ulong);
 
 static inline void *
-bch2_trans_subbuf_alloc(struct btree_trans *trans,
-			struct btree_trans_subbuf *buf,
-			unsigned u64s)
+bch2_trans_subbuf_alloc_ip(struct btree_trans *trans,
+			   struct btree_trans_subbuf *buf,
+			   unsigned u64s, ulong ip)
 {
 	if (buf->u64s + u64s > buf->size)
-		return __bch2_trans_subbuf_alloc(trans, buf, u64s);
+		return __bch2_trans_subbuf_alloc(trans, buf, u64s, ip);
 
 	void *p = btree_trans_subbuf_top(trans, buf);
 	buf->u64s += u64s;
 	return p;
 }
 
+static inline void *
+bch2_trans_subbuf_alloc(struct btree_trans *trans,
+			struct btree_trans_subbuf *buf,
+			unsigned u64s)
+{
+	return bch2_trans_subbuf_alloc_ip(trans, buf, u64s, _THIS_IP_);
+}
+
 static inline struct jset_entry *btree_trans_journal_entries_start(struct btree_trans *trans)
 {
 	return btree_trans_subbuf_base(trans, &trans->journal_entries);
@@ -162,10 +170,16 @@ static inline struct jset_entry *btree_trans_journal_entries_top(struct btree_tr
 	return btree_trans_subbuf_top(trans, &trans->journal_entries);
 }
 
+static inline struct jset_entry *
+bch2_trans_jset_entry_alloc_ip(struct btree_trans *trans, unsigned u64s, ulong ip)
+{
+	return bch2_trans_subbuf_alloc_ip(trans, &trans->journal_entries, u64s, ip);
+}
+
 static inline struct jset_entry *
 bch2_trans_jset_entry_alloc(struct btree_trans *trans, unsigned u64s)
 {
-	return bch2_trans_subbuf_alloc(trans, &trans->journal_entries, u64s);
+	return bch2_trans_jset_entry_alloc_ip(trans, u64s, _THIS_IP_);
 }
 
 int bch2_btree_insert_clone_trans(struct btree_trans *, enum btree_id, struct bkey_i *);
-- 
2.51.0


From df5c47a04eb2ac130300e134452de8054f133552 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 19 Jun 2025 13:00:02 -0400
Subject: [PATCH 012/309] bcachefs: Don't log error twice in allocator async
 repair

Add a new fsck flag, FSCK_ERR_SILENT, to suppress logging the error in
dmesg.

Use this for allocator async repair.

Also, make sure that we _do_ still log silent error correction in the
journal.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 18 +++++++++---------
 fs/bcachefs/alloc_background.h |  9 ++++++++-
 fs/bcachefs/alloc_foreground.c |  2 +-
 fs/bcachefs/error.c            | 15 +++++++++------
 fs/bcachefs/sb-errors_format.h |  1 +
 5 files changed, 28 insertions(+), 17 deletions(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index 66de46318620..d64839c756bc 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -1381,7 +1381,7 @@ static int bch2_recheck_discard_freespace_key(struct btree_trans *trans, struct
 
 	u8 gen;
 	ret = k.k->type != KEY_TYPE_set
-		? bch2_check_discard_freespace_key(trans, &iter, &gen, false)
+		? __bch2_check_discard_freespace_key(trans, &iter, &gen, FSCK_ERR_SILENT)
 		: 0;
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
@@ -1397,8 +1397,8 @@ static void check_discard_freespace_key_work(struct work_struct *work)
 	kfree(w);
 }
 
-int bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_iter *iter, u8 *gen,
-				     bool async_repair)
+int __bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_iter *iter, u8 *gen,
+				       enum bch_fsck_flags fsck_flags)
 {
 	struct bch_fs *c = trans->c;
 	enum bch_data_type state = iter->btree_id == BTREE_ID_need_discard
@@ -1406,8 +1406,8 @@ int bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_ite
 		: BCH_DATA_free;
 	struct printbuf buf = PRINTBUF;
 
-	unsigned fsck_flags = (async_repair ? FSCK_ERR_NO_LOG : 0)|
-		FSCK_CAN_FIX|FSCK_CAN_IGNORE;
+	bool async_repair = fsck_flags & FSCK_ERR_NO_LOG;
+	fsck_flags |= FSCK_CAN_FIX|FSCK_CAN_IGNORE;
 
 	struct bpos bucket = iter->pos;
 	bucket.offset &= ~(~0ULL << 56);
@@ -1490,10 +1490,10 @@ int bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_ite
 	}
 }
 
-static int bch2_check_discard_freespace_key_fsck(struct btree_trans *trans, struct btree_iter *iter)
+static int bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_iter *iter)
 {
 	u8 gen;
-	int ret = bch2_check_discard_freespace_key(trans, iter, &gen, false);
+	int ret = __bch2_check_discard_freespace_key(trans, iter, &gen, 0);
 	return ret < 0 ? ret : 0;
 }
 
@@ -1651,7 +1651,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 	ret = for_each_btree_key(trans, iter,
 			BTREE_ID_need_discard, POS_MIN,
 			BTREE_ITER_prefetch, k,
-		bch2_check_discard_freespace_key_fsck(trans, &iter));
+		bch2_check_discard_freespace_key(trans, &iter));
 	if (ret)
 		goto err;
 
@@ -1664,7 +1664,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 			break;
 
 		ret = bkey_err(k) ?:
-			bch2_check_discard_freespace_key_fsck(trans, &iter);
+			bch2_check_discard_freespace_key(trans, &iter);
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart)) {
 			ret = 0;
 			continue;
diff --git a/fs/bcachefs/alloc_background.h b/fs/bcachefs/alloc_background.h
index 0cc5adc55b6f..c2e8482fbbe6 100644
--- a/fs/bcachefs/alloc_background.h
+++ b/fs/bcachefs/alloc_background.h
@@ -309,7 +309,14 @@ int bch2_trigger_alloc(struct btree_trans *, enum btree_id, unsigned,
 		       struct bkey_s_c, struct bkey_s,
 		       enum btree_iter_update_trigger_flags);
 
-int bch2_check_discard_freespace_key(struct btree_trans *, struct btree_iter *, u8 *, bool);
+int __bch2_check_discard_freespace_key(struct btree_trans *, struct btree_iter *, u8 *,
+				       enum bch_fsck_flags);
+
+static inline int bch2_check_discard_freespace_key_async(struct btree_trans *trans, struct btree_iter *iter, u8 *gen)
+{
+	return __bch2_check_discard_freespace_key(trans, iter, gen, FSCK_ERR_NO_LOG);
+}
+
 int bch2_check_alloc_info(struct bch_fs *);
 int bch2_check_alloc_to_lru_refs(struct bch_fs *);
 void bch2_dev_do_discards(struct bch_dev *);
diff --git a/fs/bcachefs/alloc_foreground.c b/fs/bcachefs/alloc_foreground.c
index b58525ec7b4d..77406394127c 100644
--- a/fs/bcachefs/alloc_foreground.c
+++ b/fs/bcachefs/alloc_foreground.c
@@ -269,7 +269,7 @@ static struct open_bucket *try_alloc_bucket(struct btree_trans *trans,
 		return NULL;
 
 	u8 gen;
-	int ret = bch2_check_discard_freespace_key(trans, freespace_iter, &gen, true);
+	int ret = bch2_check_discard_freespace_key_async(trans, freespace_iter, &gen);
 	if (ret < 0)
 		return ERR_PTR(ret);
 	if (ret)
diff --git a/fs/bcachefs/error.c b/fs/bcachefs/error.c
index 267e73d9d7e6..f2bffe2140d3 100644
--- a/fs/bcachefs/error.c
+++ b/fs/bcachefs/error.c
@@ -472,10 +472,13 @@ int __bch2_fsck_err(struct bch_fs *c,
 		!trans &&
 		bch2_current_has_btree_trans(c));
 
-	if (test_bit(err, c->sb.errors_silent))
-		return flags & FSCK_CAN_FIX
+	if ((flags & FSCK_ERR_SILENT) ||
+	    test_bit(err, c->sb.errors_silent)) {
+		ret = flags & FSCK_CAN_FIX
 			? bch_err_throw(c, fsck_fix)
 			: bch_err_throw(c, fsck_ignore);
+		goto err;
+	}
 
 	printbuf_indent_add_nextline(out, 2);
 
@@ -620,14 +623,14 @@ int __bch2_fsck_err(struct bch_fs *c,
 
 	if (s)
 		s->ret = ret;
-
+err_unlock:
+	mutex_unlock(&c->fsck_error_msgs_lock);
+err:
 	if (trans &&
 	    !(flags & FSCK_ERR_NO_LOG) &&
 	    ret == -BCH_ERR_fsck_fix)
 		ret = bch2_trans_log_str(trans, bch2_sb_error_strs[err]) ?: ret;
-err_unlock:
-	mutex_unlock(&c->fsck_error_msgs_lock);
-err:
+
 	/*
 	 * We don't yet track whether the filesystem currently has errors, for
 	 * log_fsck_err()s: that would require us to track for every error type
diff --git a/fs/bcachefs/sb-errors_format.h b/fs/bcachefs/sb-errors_format.h
index 6cdb07a721e9..3ecac2524118 100644
--- a/fs/bcachefs/sb-errors_format.h
+++ b/fs/bcachefs/sb-errors_format.h
@@ -7,6 +7,7 @@ enum bch_fsck_flags {
 	FSCK_CAN_IGNORE		= BIT(1),
 	FSCK_AUTOFIX		= BIT(2),
 	FSCK_ERR_NO_LOG		= BIT(3),
+	FSCK_ERR_SILENT		= BIT(4),
 };
 
 #define BCH_SB_ERRS()									\
-- 
2.51.0


From a38688539f21ae830f5a51aee56fd5b9a524f735 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Fri, 20 Jun 2025 01:33:17 +0800
Subject: [PATCH 013/309] bcachefs: Don't memcpy more than needed

buf->u64s is all we used.

Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 192c1e5e3ed9..5d5394db3965 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -566,7 +566,7 @@ void *__bch2_trans_subbuf_alloc(struct btree_trans *trans,
 	if (buf->u64s)
 		memcpy(n,
 		       btree_trans_subbuf_base(trans, buf),
-		       buf->size * sizeof(u64));
+		       buf->u64s * sizeof(u64));
 	buf->base = (u64 *) n - (u64 *) trans->mem;
 	buf->size = new_size;
 
-- 
2.51.0


From d335b3d53741c32183b19258e012d926adc9becd Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 19 Jun 2025 14:17:07 -0400
Subject: [PATCH 014/309] bcachefs: bch2_trans_has_updates()

new helper

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_gc.c           | 2 +-
 fs/bcachefs/btree_trans_commit.c | 4 +---
 fs/bcachefs/btree_update.h       | 7 +++++++
 3 files changed, 9 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index bac108e93823..7269490a5d9a 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -693,7 +693,7 @@ static int bch2_gc_mark_key(struct btree_trans *trans, enum btree_id btree_id,
 	if (ret)
 		goto out;
 
-	if (trans->nr_updates) {
+	if (bch2_trans_has_updates(trans)) {
 		ret = bch2_trans_commit(trans, NULL, NULL, 0) ?:
 			-BCH_ERR_transaction_restart_nested;
 		goto out;
diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index 639ef75b3dbd..454b4c5c1808 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -1015,9 +1015,7 @@ int __bch2_trans_commit(struct btree_trans *trans, unsigned flags)
 	if (unlikely(ret))
 		goto out_reset;
 
-	if (!trans->nr_updates &&
-	    !trans->journal_entries.u64s &&
-	    !trans->accounting.u64s)
+	if (!bch2_trans_has_updates(trans))
 		goto out_reset;
 
 	ret = bch2_trans_commit_run_triggers(trans);
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 17a6abd7d9cb..2c6f9b44d888 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -271,6 +271,13 @@ static inline int bch2_trans_commit(struct btree_trans *trans,
 	     (_i) < (_trans)->updates + (_trans)->nr_updates;		\
 	     (_i)++)
 
+static inline bool bch2_trans_has_updates(struct btree_trans *trans)
+{
+	return trans->nr_updates ||
+		trans->journal_entries.u64s ||
+		trans->accounting.u64s;
+}
+
 static inline void bch2_trans_reset_updates(struct btree_trans *trans)
 {
 	trans_for_each_update(trans, i)
-- 
2.51.0


From 9caf59327840efc5e3c13e875f338f6111e7222c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 24 Jun 2025 14:07:32 -0400
Subject: [PATCH 015/309] bcachefs: Improve inode deletion

Don't delete dirents or extents if it's the wrong type of inode.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/inode.c | 36 ++++++++++++++++++++----------------
 1 file changed, 20 insertions(+), 16 deletions(-)

diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 99cd2a47f853..a0621006aee5 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -38,7 +38,7 @@ static const char * const bch2_inode_flag_strs[] = {
 #undef  x
 
 static int delete_ancestor_snapshot_inodes(struct btree_trans *, struct bpos);
-static int may_delete_deleted_inum(struct btree_trans *, subvol_inum);
+static int may_delete_deleted_inum(struct btree_trans *, subvol_inum, struct bch_inode_unpacked *);
 
 static const u8 byte_table[8] = { 1, 2, 3, 4, 6, 8, 10, 13 };
 
@@ -1128,10 +1128,11 @@ int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 	struct btree_trans *trans = bch2_trans_get(c);
 	struct btree_iter iter = {};
 	struct bkey_s_c k;
+	struct bch_inode_unpacked inode;
 	u32 snapshot;
 	int ret;
 
-	ret = lockrestart_do(trans, may_delete_deleted_inum(trans, inum));
+	ret = lockrestart_do(trans, may_delete_deleted_inum(trans, inum, &inode));
 	if (ret)
 		goto err2;
 
@@ -1143,9 +1144,10 @@ int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 	 * XXX: the dirent code ideally would delete whiteouts when they're no
 	 * longer needed
 	 */
-	ret   = bch2_inode_delete_keys(trans, inum, BTREE_ID_extents) ?:
-		bch2_inode_delete_keys(trans, inum, BTREE_ID_xattrs) ?:
-		bch2_inode_delete_keys(trans, inum, BTREE_ID_dirents);
+	ret   = (!S_ISDIR(inode.bi_mode)
+		 ? bch2_inode_delete_keys(trans, inum, BTREE_ID_extents)
+		 : bch2_inode_delete_keys(trans, inum, BTREE_ID_dirents)) ?:
+		bch2_inode_delete_keys(trans, inum, BTREE_ID_xattrs);
 	if (ret)
 		goto err2;
 retry:
@@ -1398,12 +1400,12 @@ int bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum, u32 snapshot)
 }
 
 static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
+				    struct bch_inode_unpacked *inode,
 				    bool from_deleted_inodes)
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter inode_iter;
 	struct bkey_s_c k;
-	struct bch_inode_unpacked inode;
 	struct printbuf buf = PRINTBUF;
 	int ret;
 
@@ -1421,11 +1423,11 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 	if (ret)
 		goto out;
 
-	ret = bch2_inode_unpack(k, &inode);
+	ret = bch2_inode_unpack(k, inode);
 	if (ret)
 		goto out;
 
-	if (S_ISDIR(inode.bi_mode)) {
+	if (S_ISDIR(inode->bi_mode)) {
 		ret = bch2_empty_dir_snapshot(trans, pos.offset, 0, pos.snapshot);
 		if (fsck_err_on(from_deleted_inodes &&
 				bch2_err_matches(ret, ENOTEMPTY),
@@ -1437,7 +1439,7 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 			goto out;
 	}
 
-	ret = inode.bi_flags & BCH_INODE_unlinked ? 0 : bch_err_throw(c, inode_not_unlinked);
+	ret = inode->bi_flags & BCH_INODE_unlinked ? 0 : bch_err_throw(c, inode_not_unlinked);
 	if (fsck_err_on(from_deleted_inodes && ret,
 			trans, deleted_inode_not_unlinked,
 			"non-deleted inode %llu:%u in deleted_inodes btree",
@@ -1446,7 +1448,7 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 	if (ret)
 		goto out;
 
-	ret = !(inode.bi_flags & BCH_INODE_has_child_snapshot)
+	ret = !(inode->bi_flags & BCH_INODE_has_child_snapshot)
 		? 0 : bch_err_throw(c, inode_has_child_snapshot);
 
 	if (fsck_err_on(from_deleted_inodes && ret,
@@ -1465,10 +1467,10 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 		if (fsck_err(trans, inode_has_child_snapshots_wrong,
 			     "inode has_child_snapshots flag wrong (should be set)\n%s",
 			     (printbuf_reset(&buf),
-			      bch2_inode_unpacked_to_text(&buf, &inode),
+			      bch2_inode_unpacked_to_text(&buf, inode),
 			      buf.buf))) {
-			inode.bi_flags |= BCH_INODE_has_child_snapshot;
-			ret = __bch2_fsck_write_inode(trans, &inode);
+			inode->bi_flags |= BCH_INODE_has_child_snapshot;
+			ret = __bch2_fsck_write_inode(trans, inode);
 			if (ret)
 				goto out;
 		}
@@ -1504,12 +1506,13 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 	goto out;
 }
 
-static int may_delete_deleted_inum(struct btree_trans *trans, subvol_inum inum)
+static int may_delete_deleted_inum(struct btree_trans *trans, subvol_inum inum,
+				   struct bch_inode_unpacked *inode)
 {
 	u32 snapshot;
 
 	return bch2_subvolume_get_snapshot(trans, inum.subvol, &snapshot) ?:
-		may_delete_deleted_inode(trans, SPOS(0, inum.inum, snapshot), false);
+		may_delete_deleted_inode(trans, SPOS(0, inum.inum, snapshot), inode, false);
 }
 
 int bch2_delete_dead_inodes(struct bch_fs *c)
@@ -1535,7 +1538,8 @@ int bch2_delete_dead_inodes(struct bch_fs *c)
 	ret = for_each_btree_key_commit(trans, iter, BTREE_ID_deleted_inodes, POS_MIN,
 					BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 					NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
-		ret = may_delete_deleted_inode(trans, k.k->p, true);
+		struct bch_inode_unpacked inode;
+		ret = may_delete_deleted_inode(trans, k.k->p, &inode, true);
 		if (ret > 0) {
 			bch_verbose_ratelimited(c, "deleting unlinked inode %llu:%u",
 						k.k->p.offset, k.k->p.snapshot);
-- 
2.51.0


From ad84f89a49d802302a632c967c4a3a327391cd8e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 24 Jun 2025 15:55:40 -0400
Subject: [PATCH 016/309] bcachefs: Don't peek key cache unless we have a real
 key

We require that if a key exists in the key cache it also be present in
the underlying btree, for cache coherency reasons.

So checking the key cache on whiteout is unnecessary. This is part of
fixing a major performance bug when doing many unlinks all in a row -
we end up scanning through a ton of key cache whiteouts before peek()
can return a real key.

Reported-by: John Schoenick <johns@valvesoftware.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 18 ++++++++++--------
 1 file changed, 10 insertions(+), 8 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index d7dc7a25b95d..87d98a5cb02a 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2288,6 +2288,7 @@ static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct
 
 		if (unlikely(iter->flags & BTREE_ITER_with_key_cache) &&
 		    k.k &&
+		    !bkey_deleted(k.k) &&
 		    (k2 = btree_trans_peek_key_cache(trans, iter, k.k->p)).k) {
 			k = k2;
 			if (bkey_err(k)) {
@@ -2580,6 +2581,7 @@ static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_trans *trans, st
 
 		if (unlikely(iter->flags & BTREE_ITER_with_key_cache) &&
 		    k.k &&
+		    !bkey_deleted(k.k) &&
 		    (k2 = btree_trans_peek_key_cache(trans, iter, k.k->p)).k) {
 			k = k2;
 			if (bkey_err(k2)) {
@@ -2795,7 +2797,7 @@ struct bkey_s_c bch2_btree_iter_prev(struct btree_trans *trans, struct btree_ite
 struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btree_iter *iter)
 {
 	struct bpos search_key;
-	struct bkey_s_c k;
+	struct bkey_s_c k, k2;
 	int ret;
 
 	bch2_trans_verify_not_unlocked_or_in_restart(trans);
@@ -2854,18 +2856,18 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 		    (k = btree_trans_peek_slot_journal(trans, iter)).k)
 			goto out;
 
+		k = bch2_btree_path_peek_slot(btree_iter_path(trans, iter), &iter->k);
+		if (unlikely(!k.k))
+			goto out;
+
 		if (unlikely(iter->flags & BTREE_ITER_with_key_cache) &&
-		    (k = btree_trans_peek_key_cache(trans, iter, iter->pos)).k) {
+		    !bkey_deleted(k.k) &&
+		    (k2 = btree_trans_peek_key_cache(trans, iter, iter->pos)).k) {
+			k = k2;
 			if (!bkey_err(k))
 				iter->k = *k.k;
-			/* We're not returning a key from iter->path: */
-			goto out;
 		}
 
-		k = bch2_btree_path_peek_slot(btree_iter_path(trans, iter), &iter->k);
-		if (unlikely(!k.k))
-			goto out;
-
 		if (unlikely(k.k->type == KEY_TYPE_whiteout &&
 			     (iter->flags & BTREE_ITER_filter_snapshots) &&
 			     !(iter->flags & BTREE_ITER_key_cache_fill)))
-- 
2.51.0


From cb3370dd22cd4f2679f0814c42d51886b804b04f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 24 Jun 2025 16:01:33 -0400
Subject: [PATCH 017/309] bcachefs: Evict/bypass key cache when deleting

Fix a performance bug when doing many unlinks.

The btree has optimizations to ensure we don't have too many whiteouts
to scan in peek() before we find a real key to return, but unflushed key
cache deletions break this.

To fix this, tweak the existing code for redirecting updates that create
a key to the underlying btree so that we can use it for deletions as
well.

Reported-by: John Schoenick <johns@valvesoftware.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c         |   1 +
 fs/bcachefs/btree_key_cache.c    |   1 +
 fs/bcachefs/btree_trans_commit.c |   6 ++
 fs/bcachefs/btree_types.h        |   8 ++-
 fs/bcachefs/btree_update.c       | 105 ++++++++++++++++++-------------
 5 files changed, 73 insertions(+), 48 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 87d98a5cb02a..0b856c72389c 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -645,6 +645,7 @@ static void bch2_trans_revalidate_updates_in_node(struct btree_trans *trans, str
 
 	trans_for_each_update(trans, i)
 		if (!i->cached &&
+		    !i->key_cache_flushing &&
 		    i->level	== b->c.level &&
 		    i->btree_id	== b->c.btree_id &&
 		    bpos_cmp(i->k->k.p, b->data->min_key) >= 0 &&
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index d96188b92db2..f68265f9969c 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -580,6 +580,7 @@ bool bch2_btree_insert_key_cached(struct btree_trans *trans,
 	bool kick_reclaim = false;
 
 	BUG_ON(insert->k.u64s > ck->u64s);
+	BUG_ON(bkey_deleted(&insert->k));
 
 	bkey_copy(ck->k, insert);
 
diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index 454b4c5c1808..7fcf248a9a76 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -46,6 +46,9 @@ void bch2_trans_commit_flags_to_text(struct printbuf *out, enum bch_trans_commit
 static void verify_update_old_key(struct btree_trans *trans, struct btree_insert_entry *i)
 {
 #ifdef CONFIG_BCACHEFS_DEBUG
+	if (i->key_cache_flushing)
+		return;
+
 	struct bch_fs *c = trans->c;
 	struct bkey u;
 	struct bkey_s_c k = bch2_btree_path_peek_slot_exact(trans->paths + i->path, &u);
@@ -337,6 +340,9 @@ static inline void btree_insert_entry_checks(struct btree_trans *trans,
 
 	BUG_ON(!bpos_eq(i->k->k.p, path->pos));
 	BUG_ON(i->cached	!= path->cached);
+	BUG_ON(i->cached &&
+	       !i->key_cache_already_flushed  &&
+	       bkey_deleted(&i->k->k));;
 	BUG_ON(i->level		!= path->level);
 	BUG_ON(i->btree_id	!= path->btree_id);
 	BUG_ON(i->bkey_type	!= __btree_node_type(path->level, path->btree_id));
diff --git a/fs/bcachefs/btree_types.h b/fs/bcachefs/btree_types.h
index 112170fd9c8f..76adf75617aa 100644
--- a/fs/bcachefs/btree_types.h
+++ b/fs/bcachefs/btree_types.h
@@ -422,14 +422,16 @@ struct btree_insert_entry {
 	u8			sort_order;
 	u8			bkey_type;
 	enum btree_id		btree_id:8;
-	u8			level:4;
+	u8			level:3;
 	bool			cached:1;
 	bool			insert_trigger_run:1;
 	bool			overwrite_trigger_run:1;
 	bool			key_cache_already_flushed:1;
+	bool			key_cache_flushing:1;
 	/*
-	 * @old_k may be a key from the journal; @old_btree_u64s always refers
-	 * to the size of the key being overwritten in the btree:
+	 * @old_k may be a key from the journal or the key cache;
+	 * @old_btree_u64s always refers to the size of the key being
+	 * overwritten in the btree:
 	 */
 	u8			old_btree_u64s;
 	btree_path_idx_t	path;
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 5d5394db3965..5d9e02370aff 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -325,47 +325,11 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 	return ret;
 }
 
-static noinline int flush_new_cached_update(struct btree_trans *trans,
-					    struct btree_insert_entry *i,
-					    enum btree_iter_update_trigger_flags flags,
-					    unsigned long ip)
-{
-	struct bkey k;
-	int ret;
-
-	btree_path_idx_t path_idx =
-		bch2_path_get(trans, i->btree_id, i->old_k.p, 1, 0,
-			      BTREE_ITER_intent, _THIS_IP_);
-	ret = bch2_btree_path_traverse(trans, path_idx, 0);
-	if (ret)
-		goto out;
-
-	struct btree_path *btree_path = trans->paths + path_idx;
-
-	/*
-	 * The old key in the insert entry might actually refer to an existing
-	 * key in the btree that has been deleted from cache and not yet
-	 * flushed. Check for this and skip the flush so we don't run triggers
-	 * against a stale key.
-	 */
-	bch2_btree_path_peek_slot_exact(btree_path, &k);
-	if (!bkey_deleted(&k))
-		goto out;
-
-	i->key_cache_already_flushed = true;
-	i->flags |= BTREE_TRIGGER_norun;
-
-	btree_path_set_should_be_locked(trans, btree_path);
-	ret = bch2_trans_update_by_path(trans, path_idx, i->k, flags, ip);
-out:
-	bch2_path_put(trans, path_idx, true);
-	return ret;
-}
-
-static int __must_check
-bch2_trans_update_by_path(struct btree_trans *trans, btree_path_idx_t path_idx,
-			  struct bkey_i *k, enum btree_iter_update_trigger_flags flags,
-			  unsigned long ip)
+static inline struct btree_insert_entry *
+__btree_trans_update_by_path(struct btree_trans *trans,
+			     btree_path_idx_t path_idx,
+			     struct bkey_i *k, enum btree_iter_update_trigger_flags flags,
+			     unsigned long ip)
 {
 	struct bch_fs *c = trans->c;
 	struct btree_insert_entry *i, n;
@@ -436,6 +400,58 @@ bch2_trans_update_by_path(struct btree_trans *trans, btree_path_idx_t path_idx,
 	__btree_path_get(trans, trans->paths + i->path, true);
 
 	trace_update_by_path(trans, path, i, overwrite);
+	return i;
+}
+
+static noinline int flush_new_cached_update(struct btree_trans *trans,
+					    struct btree_insert_entry *i,
+					    enum btree_iter_update_trigger_flags flags,
+					    unsigned long ip)
+{
+	btree_path_idx_t path_idx =
+		bch2_path_get(trans, i->btree_id, i->old_k.p, 1, 0,
+			      BTREE_ITER_intent, _THIS_IP_);
+	int ret = bch2_btree_path_traverse(trans, path_idx, 0);
+	if (ret)
+		goto out;
+
+	struct btree_path *btree_path = trans->paths + path_idx;
+
+	btree_path_set_should_be_locked(trans, btree_path);
+#if 0
+	/*
+	 * The old key in the insert entry might actually refer to an existing
+	 * key in the btree that has been deleted from cache and not yet
+	 * flushed. Check for this and skip the flush so we don't run triggers
+	 * against a stale key.
+	 */
+	struct bkey k;
+	bch2_btree_path_peek_slot_exact(btree_path, &k);
+	if (!bkey_deleted(&k))
+		goto out;
+#endif
+	i->key_cache_already_flushed = true;
+	i->flags |= BTREE_TRIGGER_norun;
+
+	struct bkey old_k		= i->old_k;
+	const struct bch_val *old_v	= i->old_v;
+
+	i = __btree_trans_update_by_path(trans, path_idx, i->k, flags, _THIS_IP_);
+
+	i->old_k		= old_k;
+	i->old_v		= old_v;
+	i->key_cache_flushing	= true;
+out:
+	bch2_path_put(trans, path_idx, true);
+	return ret;
+}
+
+static int __must_check
+bch2_trans_update_by_path(struct btree_trans *trans, btree_path_idx_t path_idx,
+			  struct bkey_i *k, enum btree_iter_update_trigger_flags flags,
+			  unsigned long ip)
+{
+	struct btree_insert_entry *i = __btree_trans_update_by_path(trans, path_idx, k, flags, ip);
 
 	/*
 	 * If a key is present in the key cache, it must also exist in the
@@ -444,10 +460,9 @@ bch2_trans_update_by_path(struct btree_trans *trans, btree_path_idx_t path_idx,
 	 * the key cache - but the key has to exist in the btree for that to
 	 * work:
 	 */
-	if (path->cached && !i->old_btree_u64s)
-		return flush_new_cached_update(trans, i, flags, ip);
-
-	return 0;
+	return i->cached && (!i->old_btree_u64s || bkey_deleted(&k->k))
+		? flush_new_cached_update(trans, i, flags, ip)
+		: 0;
 }
 
 static noinline int bch2_trans_update_get_key_cache(struct btree_trans *trans,
-- 
2.51.0


From 77a6cbb9ae08760e893ef5dd07b973e7a5e20535 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Fri, 20 Jun 2025 03:00:16 +0800
Subject: [PATCH 018/309] bcachefs: Refactor trans->mem allocation

Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 65 ++++++++++++++++++++--------------------
 fs/bcachefs/btree_iter.h | 14 +++++++++
 2 files changed, 46 insertions(+), 33 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 0b856c72389c..bdb69b4b406f 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -3241,32 +3241,30 @@ void *__bch2_trans_kmalloc(struct btree_trans *trans, size_t size, unsigned long
 	}
 
 	EBUG_ON(trans->mem);
+	EBUG_ON(trans->mem_bytes);
+	EBUG_ON(trans->mem_top);
+	EBUG_ON(new_bytes > BTREE_TRANS_MEM_MAX);
+	
+	bool lock_dropped = false;
+	new_mem = allocate_dropping_locks_norelock(trans, lock_dropped, kmalloc(new_bytes, _gfp));
+	if (!new_mem) {
+		new_mem = mempool_alloc(&c->btree_trans_mem_pool, GFP_KERNEL);
+		new_bytes = BTREE_TRANS_MEM_MAX;
+		trans->used_mempool = true;
+	}
 
-	new_mem = kmalloc(new_bytes, GFP_NOWAIT|__GFP_NOWARN);
-	if (unlikely(!new_mem)) {
-		bch2_trans_unlock(trans);
-
-		new_mem = kmalloc(new_bytes, GFP_KERNEL);
-		if (!new_mem && new_bytes <= BTREE_TRANS_MEM_MAX) {
-			new_mem = mempool_alloc(&c->btree_trans_mem_pool, GFP_KERNEL);
-			new_bytes = BTREE_TRANS_MEM_MAX;
-			trans->used_mempool = true;
-		}
-
-		EBUG_ON(!new_mem);
+	EBUG_ON(!new_mem);
 
-		trans->mem = new_mem;
-		trans->mem_bytes = new_bytes;
+	trans->mem = new_mem;
+	trans->mem_bytes = new_bytes;
 
+	if (unlikely(lock_dropped)) {
 		ret = bch2_trans_relock(trans);
 		if (ret)
 			return ERR_PTR(ret);
 	}
 
-	trans->mem = new_mem;
-	trans->mem_bytes = new_bytes;
-
-	p = trans->mem + trans->mem_top;
+	p = trans->mem;
 	trans->mem_top += size;
 	memset(p, 0, size);
 	return p;
@@ -3327,22 +3325,23 @@ u32 bch2_trans_begin(struct btree_trans *trans)
 	trans->mem_top			= 0;
 
 	if (unlikely(trans->restarted == BCH_ERR_transaction_restart_mem_realloced)) {
-		EBUG_ON(!trans->mem || !trans->mem_bytes);
 		unsigned new_bytes = trans->realloc_bytes_required;
-		void *new_mem = krealloc(trans->mem, new_bytes, GFP_NOWAIT|__GFP_NOWARN);
-		if (unlikely(!new_mem)) {
-			bch2_trans_unlock(trans);
-			new_mem = krealloc(trans->mem, new_bytes, GFP_KERNEL);
-
-			EBUG_ON(new_bytes > BTREE_TRANS_MEM_MAX);
-
-			if (!new_mem) {
-				new_mem = mempool_alloc(&trans->c->btree_trans_mem_pool, GFP_KERNEL);
-				new_bytes = BTREE_TRANS_MEM_MAX;
-				trans->used_mempool = true;
-				kfree(trans->mem);
-			}
-                }
+		EBUG_ON(new_bytes > BTREE_TRANS_MEM_MAX);
+		EBUG_ON(!trans->mem);
+		EBUG_ON(!trans->mem_bytes);
+
+		bool lock_dropped = false;
+		void *new_mem = allocate_dropping_locks_norelock(trans, lock_dropped,
+					krealloc(trans->mem, new_bytes, _gfp));
+		if (!new_mem) {
+			new_mem = mempool_alloc(&trans->c->btree_trans_mem_pool, GFP_KERNEL);
+			new_bytes = BTREE_TRANS_MEM_MAX;
+			trans->used_mempool = true;
+			kfree(trans->mem);
+		}
+
+		EBUG_ON(!new_mem);
+
 		trans->mem = new_mem;
 		trans->mem_bytes = new_bytes;
 	}
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 09dd3e52622e..cc2c6bb6b6a8 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -963,6 +963,20 @@ struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_trans *,
 	_p;								\
 })
 
+#define allocate_dropping_locks_norelock(_trans, _lock_dropped, _do)	\
+({									\
+	gfp_t _gfp = GFP_NOWAIT|__GFP_NOWARN;				\
+	typeof(_do) _p = _do;						\
+	_lock_dropped = false;						\
+	if (unlikely(!_p)) {						\
+		bch2_trans_unlock(_trans);				\
+		_lock_dropped = true;					\
+		_gfp = GFP_KERNEL;					\
+		_p = _do;						\
+	}								\
+	_p;								\
+})
+
 struct btree_trans *__bch2_trans_get(struct bch_fs *, unsigned);
 void bch2_trans_put(struct btree_trans *);
 
-- 
2.51.0


From ae71ad08ad311db2aaf7e1047aad71e07dd6705b Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Thu, 26 Jun 2025 11:04:45 +0800
Subject: [PATCH 019/309] bcachefs: Shut up clang warning

Reported-by: kernel test robot <lkp@intel.com>
Closes: https://lore.kernel.org/oe-kbuild-all/202506261026.ZxtJ7yeV-lkp@intel.com/
Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index bdb69b4b406f..7463946898c0 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -3333,6 +3333,8 @@ u32 bch2_trans_begin(struct btree_trans *trans)
 		bool lock_dropped = false;
 		void *new_mem = allocate_dropping_locks_norelock(trans, lock_dropped,
 					krealloc(trans->mem, new_bytes, _gfp));
+		(void)lock_dropped;
+
 		if (!new_mem) {
 			new_mem = mempool_alloc(&trans->c->btree_trans_mem_pool, GFP_KERNEL);
 			new_bytes = BTREE_TRANS_MEM_MAX;
-- 
2.51.0


From a4df7c805ac8519811f7db76f4941448dd26a8c2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 26 Jun 2025 19:52:42 -0400
Subject: [PATCH 020/309] bcachefs: -o fix_errors may now be used without -o
 fsck

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/error.c | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/error.c b/fs/bcachefs/error.c
index f2bffe2140d3..c7ee81b7d45c 100644
--- a/fs/bcachefs/error.c
+++ b/fs/bcachefs/error.c
@@ -401,7 +401,8 @@ int bch2_fsck_err_opt(struct bch_fs *c,
 	if (!WARN_ON(err >= ARRAY_SIZE(fsck_flags_extra)))
 		flags |= fsck_flags_extra[err];
 
-	if (test_bit(BCH_FS_in_fsck, &c->flags)) {
+	if (test_bit(BCH_FS_in_fsck, &c->flags) ||
+	    test_bit(BCH_FS_in_recovery, &c->flags)) {
 		if (!(flags & (FSCK_CAN_FIX|FSCK_CAN_IGNORE)))
 			return bch_err_throw(c, fsck_repair_unimplemented);
 
-- 
2.51.0


From 9ca8c16b0fa7c7535362b2a0b8e1a6427985abdf Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 26 Jun 2025 15:35:17 -0400
Subject: [PATCH 021/309] bcachefs: Improved btree node tracepoints

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_cache.c           |   3 +-
 fs/bcachefs/btree_cache.h           |  11 +++
 fs/bcachefs/btree_io.c              |  14 ++-
 fs/bcachefs/btree_update_interior.c |  16 ++--
 fs/bcachefs/trace.h                 | 127 +++++++---------------------
 5 files changed, 63 insertions(+), 108 deletions(-)

diff --git a/fs/bcachefs/btree_cache.c b/fs/bcachefs/btree_cache.c
index 83c9860e6b82..021580a5e7cc 100644
--- a/fs/bcachefs/btree_cache.c
+++ b/fs/bcachefs/btree_cache.c
@@ -440,7 +440,8 @@ static int __btree_node_reclaim(struct bch_fs *c, struct btree *b, bool flush)
 	}
 
 	if (b->hash_val && !ret)
-		trace_and_count(c, btree_cache_reap, c, b);
+		trace_btree_node(c, b, btree_cache_reap);
+
 	return 0;
 }
 
diff --git a/fs/bcachefs/btree_cache.h b/fs/bcachefs/btree_cache.h
index be275f87a60e..649e9dfd178a 100644
--- a/fs/bcachefs/btree_cache.h
+++ b/fs/bcachefs/btree_cache.h
@@ -154,4 +154,15 @@ void bch2_btree_pos_to_text(struct printbuf *, struct bch_fs *, const struct btr
 void bch2_btree_node_to_text(struct printbuf *, struct bch_fs *, const struct btree *);
 void bch2_btree_cache_to_text(struct printbuf *, const struct btree_cache *);
 
+#define trace_btree_node(_c, _b, event)				\
+do {								\
+	if (trace_##event##_enabled()) {			\
+		CLASS(printbuf, buf)();				\
+		printbuf_indent_add(&buf, 2);			\
+		bch2_btree_pos_to_text(&buf, c, b);		\
+		trace_##event(c, buf.buf);			\
+	}							\
+	count_event(c, event);					\
+} while (0);
+
 #endif /* _BCACHEFS_BTREE_CACHE_H */
diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index 590cd29f3e86..aa18c1c25e8a 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -1796,7 +1796,7 @@ void bch2_btree_node_read(struct btree_trans *trans, struct btree *b,
 	struct bio *bio;
 	int ret;
 
-	trace_and_count(c, btree_node_read, trans, b);
+	trace_btree_node(c, b, btree_node_read);
 
 	if (static_branch_unlikely(&bch2_verify_all_btree_replicas) &&
 	    !btree_node_read_all_replicas(c, b, sync))
@@ -2530,7 +2530,17 @@ void __bch2_btree_node_write(struct bch_fs *c, struct btree *b, unsigned flags)
 	    c->opts.nochanges)
 		goto err;
 
-	trace_and_count(c, btree_node_write, b, bytes_to_write, sectors_to_write);
+	if (trace_btree_node_write_enabled()) {
+		CLASS(printbuf, buf)();
+		printbuf_indent_add(&buf, 2);
+		prt_printf(&buf, "offset %u sectors %u bytes %u\n",
+			   b->written,
+			   sectors_to_write,
+			   bytes_to_write);
+		bch2_btree_pos_to_text(&buf, c, b);
+		trace_btree_node_write(c, buf.buf);
+	}
+	count_event(c, btree_node_write);
 
 	wbio = container_of(bio_alloc_bioset(NULL,
 				buf_pages(data, sectors_to_write << 9),
diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index a26911d4d3bf..8e3d3db2c53b 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -217,7 +217,7 @@ static void __btree_node_free(struct btree_trans *trans, struct btree *b)
 {
 	struct bch_fs *c = trans->c;
 
-	trace_and_count(c, btree_node_free, trans, b);
+	trace_btree_node(c, b, btree_node_free);
 
 	BUG_ON(btree_node_write_blocked(b));
 	BUG_ON(btree_node_dirty(b));
@@ -406,7 +406,7 @@ static struct btree *bch2_btree_node_alloc(struct btree_update *as,
 	ret = bch2_btree_node_hash_insert(&c->btree_cache, b, level, as->btree_id);
 	BUG_ON(ret);
 
-	trace_and_count(c, btree_node_alloc, trans, b);
+	trace_btree_node(c, b, btree_node_alloc);
 	bch2_increment_clock(c, btree_sectors(c), WRITE);
 	return b;
 }
@@ -1331,7 +1331,7 @@ static int bch2_btree_set_root(struct btree_update *as,
 {
 	struct bch_fs *c = as->c;
 
-	trace_and_count(c, btree_node_set_root, trans, b);
+	trace_btree_node(c, b, btree_node_set_root);
 
 	struct btree *old = btree_node_root(c, b);
 
@@ -1641,7 +1641,7 @@ static int btree_split(struct btree_update *as, struct btree_trans *trans,
 	if (b->nr.live_u64s > BTREE_SPLIT_THRESHOLD(c)) {
 		struct btree *n[2];
 
-		trace_and_count(c, btree_node_split, trans, b);
+		trace_btree_node(c, b, btree_node_split);
 
 		n[0] = n1 = bch2_btree_node_alloc(as, trans, b->c.level);
 		n[1] = n2 = bch2_btree_node_alloc(as, trans, b->c.level);
@@ -1703,7 +1703,7 @@ static int btree_split(struct btree_update *as, struct btree_trans *trans,
 				goto err;
 		}
 	} else {
-		trace_and_count(c, btree_node_compact, trans, b);
+		trace_btree_node(c, b, btree_node_compact);
 
 		n1 = bch2_btree_node_alloc_replacement(as, trans, b);
 
@@ -2119,7 +2119,7 @@ int __bch2_foreground_maybe_merge(struct btree_trans *trans,
 	as->node_start	= prev->data->min_key;
 	as->node_end	= next->data->max_key;
 
-	trace_and_count(c, btree_node_merge, trans, b);
+	trace_btree_node(c, b, btree_node_merge);
 
 	n = bch2_btree_node_alloc(as, trans, b->c.level);
 
@@ -2251,8 +2251,6 @@ int bch2_btree_node_rewrite(struct btree_trans *trans,
 	mark_btree_node_locked(trans, trans->paths + new_path, n->c.level, BTREE_NODE_INTENT_LOCKED);
 	bch2_btree_path_level_init(trans, trans->paths + new_path, n);
 
-	trace_and_count(c, btree_node_rewrite, trans, b);
-
 	if (parent) {
 		bch2_keylist_add(&as->parent_keys, &n->key);
 		ret = bch2_btree_insert_node(as, trans, iter->path, parent, &as->parent_keys);
@@ -2263,6 +2261,8 @@ int bch2_btree_node_rewrite(struct btree_trans *trans,
 	if (ret)
 		goto err;
 
+	trace_btree_node(c, b, btree_node_rewrite);
+
 	bch2_btree_interior_update_will_free_node(as, b);
 
 	bch2_btree_update_get_open_buckets(as, n);
diff --git a/fs/bcachefs/trace.h b/fs/bcachefs/trace.h
index 9c5a9c551f03..b5dae1145afa 100644
--- a/fs/bcachefs/trace.h
+++ b/fs/bcachefs/trace.h
@@ -92,58 +92,6 @@ DECLARE_EVENT_CLASS(trans_str_nocaller,
 		  __entry->trans_fn, __get_str(str))
 );
 
-DECLARE_EVENT_CLASS(btree_node_nofs,
-	TP_PROTO(struct bch_fs *c, struct btree *b),
-	TP_ARGS(c, b),
-
-	TP_STRUCT__entry(
-		__field(dev_t,		dev			)
-		__field(u8,		level			)
-		__field(u8,		btree_id		)
-		TRACE_BPOS_entries(pos)
-	),
-
-	TP_fast_assign(
-		__entry->dev		= c->dev;
-		__entry->level		= b->c.level;
-		__entry->btree_id	= b->c.btree_id;
-		TRACE_BPOS_assign(pos, b->key.k.p);
-	),
-
-	TP_printk("%d,%d %u %s %llu:%llu:%u",
-		  MAJOR(__entry->dev), MINOR(__entry->dev),
-		  __entry->level,
-		  bch2_btree_id_str(__entry->btree_id),
-		  __entry->pos_inode, __entry->pos_offset, __entry->pos_snapshot)
-);
-
-DECLARE_EVENT_CLASS(btree_node,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b),
-
-	TP_STRUCT__entry(
-		__field(dev_t,		dev			)
-		__array(char,		trans_fn, 32		)
-		__field(u8,		level			)
-		__field(u8,		btree_id		)
-		TRACE_BPOS_entries(pos)
-	),
-
-	TP_fast_assign(
-		__entry->dev		= trans->c->dev;
-		strscpy(__entry->trans_fn, trans->fn, sizeof(__entry->trans_fn));
-		__entry->level		= b->c.level;
-		__entry->btree_id	= b->c.btree_id;
-		TRACE_BPOS_assign(pos, b->key.k.p);
-	),
-
-	TP_printk("%d,%d %s %u %s %llu:%llu:%u",
-		  MAJOR(__entry->dev), MINOR(__entry->dev), __entry->trans_fn,
-		  __entry->level,
-		  bch2_btree_id_str(__entry->btree_id),
-		  __entry->pos_inode, __entry->pos_offset, __entry->pos_snapshot)
-);
-
 DECLARE_EVENT_CLASS(bch_fs,
 	TP_PROTO(struct bch_fs *c),
 	TP_ARGS(c),
@@ -527,9 +475,9 @@ TRACE_EVENT(btree_cache_scan,
 		  __entry->nr_to_scan, __entry->can_free, __entry->ret)
 );
 
-DEFINE_EVENT(btree_node_nofs, btree_cache_reap,
-	TP_PROTO(struct bch_fs *c, struct btree *b),
-	TP_ARGS(c, b)
+DEFINE_EVENT(fs_str, btree_cache_reap,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
 DEFINE_EVENT(btree_trans, btree_cache_cannibalize_lock_fail,
@@ -554,39 +502,24 @@ DEFINE_EVENT(btree_trans, btree_cache_cannibalize_unlock,
 
 /* Btree */
 
-DEFINE_EVENT(btree_node, btree_node_read,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_read,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-TRACE_EVENT(btree_node_write,
-	TP_PROTO(struct btree *b, unsigned bytes, unsigned sectors),
-	TP_ARGS(b, bytes, sectors),
-
-	TP_STRUCT__entry(
-		__field(enum btree_node_type,	type)
-		__field(unsigned,	bytes			)
-		__field(unsigned,	sectors			)
-	),
-
-	TP_fast_assign(
-		__entry->type	= btree_node_type(b);
-		__entry->bytes	= bytes;
-		__entry->sectors = sectors;
-	),
-
-	TP_printk("bkey type %u bytes %u sectors %u",
-		  __entry->type , __entry->bytes, __entry->sectors)
+DEFINE_EVENT(fs_str, btree_node_write,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-DEFINE_EVENT(btree_node, btree_node_alloc,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_alloc,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-DEFINE_EVENT(btree_node, btree_node_free,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_free,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
 TRACE_EVENT(btree_reserve_get_fail,
@@ -617,29 +550,29 @@ TRACE_EVENT(btree_reserve_get_fail,
 		  __entry->ret)
 );
 
-DEFINE_EVENT(btree_node, btree_node_compact,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_set_root,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-DEFINE_EVENT(btree_node, btree_node_merge,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_rewrite,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-DEFINE_EVENT(btree_node, btree_node_split,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_merge,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-DEFINE_EVENT(btree_node, btree_node_rewrite,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_compact,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
-DEFINE_EVENT(btree_node, btree_node_set_root,
-	TP_PROTO(struct btree_trans *trans, struct btree *b),
-	TP_ARGS(trans, b)
+DEFINE_EVENT(fs_str, btree_node_split,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
 TRACE_EVENT(btree_path_relock_fail,
-- 
2.51.0


From 86cf5b626ea5af8a5097f34d6be14600233436da Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 26 Jun 2025 20:43:41 -0400
Subject: [PATCH 022/309] bcachefs: Finish error_throw tracepoints

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h  | 2 +-
 fs/bcachefs/dirent.h    | 2 +-
 fs/bcachefs/ec.c        | 4 ++--
 fs/bcachefs/inode.c     | 4 ++--
 fs/bcachefs/namei.c     | 2 +-
 fs/bcachefs/rebalance.c | 2 +-
 fs/bcachefs/reflink.c   | 4 ++--
 fs/bcachefs/snapshot.h  | 2 +-
 fs/bcachefs/str_hash.c  | 6 +++---
 fs/bcachefs/str_hash.h  | 4 ++--
 fs/bcachefs/subvolume.c | 4 ++--
 11 files changed, 18 insertions(+), 18 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index 004044e105ea..c74d48e9d3c4 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -1287,7 +1287,7 @@ static inline int bch2_fs_casefold_enabled(struct bch_fs *c)
 {
 	if (!IS_ENABLED(CONFIG_UNICODE))
 		return bch_err_throw(c, no_casefolding_without_utf8);
-	if (!c->opts.casefold_disabled)
+	if (c->opts.casefold_disabled)
 		return bch_err_throw(c, casefolding_disabled);
 	return 0;
 }
diff --git a/fs/bcachefs/dirent.h b/fs/bcachefs/dirent.h
index 2675da3e3860..efb58d2dcf68 100644
--- a/fs/bcachefs/dirent.h
+++ b/fs/bcachefs/dirent.h
@@ -30,7 +30,7 @@ int bch2_casefold(struct btree_trans *, const struct bch_hash_info *,
 static inline int bch2_casefold(struct btree_trans *trans, const struct bch_hash_info *info,
 				const struct qstr *str, struct qstr *out_cf)
 {
-	return -EOPNOTSUPP;
+	return bch_err_throw(trans->c, no_casefolding_without_utf8);
 }
 #endif
 
diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index 543dbba9b14f..687c3ba98095 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -1683,7 +1683,7 @@ __bch2_ec_stripe_head_get(struct btree_trans *trans,
 		return ERR_PTR(ret);
 
 	if (test_bit(BCH_FS_going_ro, &c->flags)) {
-		h = ERR_PTR(-BCH_ERR_erofs_no_writes);
+		h = ERR_PTR(bch_err_throw(c, erofs_no_writes));
 		goto err;
 	}
 
@@ -1702,7 +1702,7 @@ __bch2_ec_stripe_head_get(struct btree_trans *trans,
 
 	h = ec_new_stripe_head_alloc(c, disk_label, algo, redundancy, watermark);
 	if (!h) {
-		h = ERR_PTR(-BCH_ERR_ENOMEM_stripe_head_alloc);
+		h = ERR_PTR(bch_err_throw(c, ENOMEM_stripe_head_alloc));
 		goto err;
 	}
 found:
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index a0621006aee5..1c1b6e4533fc 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1319,7 +1319,7 @@ static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum
 						      SPOS(inum, 0, snapshot),
 						      SPOS(inum, U64_MAX, snapshot),
 						      0, NULL);
-	} while (ret == -BCH_ERR_transaction_restart_nested);
+	} while (bch2_err_matches(ret, BCH_ERR_transaction_restart));
 	if (ret)
 		goto err;
 retry:
@@ -1357,7 +1357,7 @@ static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 
-	return ret ?: -BCH_ERR_transaction_restart_nested;
+	return ret ?: bch_err_throw(c, transaction_restart_nested);
 }
 
 /*
diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index c3f87c59922d..3e2b41babc26 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -1027,7 +1027,7 @@ int bch2_check_inode_has_case_insensitive(struct btree_trans *trans,
 
 	if (repairing_parents) {
 		return bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
-			-BCH_ERR_transaction_restart_nested;
+			bch_err_throw(trans->c, transaction_restart_nested);
 	}
 
 	return 0;
diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index 1c345b86b1c0..73b463c94966 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -220,7 +220,7 @@ int bch2_get_update_rebalance_opts(struct btree_trans *trans,
 	return bch2_bkey_set_needs_rebalance(trans->c, io_opts, n) ?:
 		bch2_trans_update(trans, iter, n, BTREE_UPDATE_internal_snapshot_node) ?:
 		bch2_trans_commit(trans, NULL, NULL, 0) ?:
-		-BCH_ERR_transaction_restart_nested;
+		bch_err_throw(trans->c, transaction_restart_nested);
 }
 
 #define REBALANCE_WORK_SCAN_OFFSET	(U64_MAX - 1)
diff --git a/fs/bcachefs/reflink.c b/fs/bcachefs/reflink.c
index 92b90cfe622b..8d8e045b6bd5 100644
--- a/fs/bcachefs/reflink.c
+++ b/fs/bcachefs/reflink.c
@@ -167,7 +167,7 @@ static int bch2_indirect_extent_not_missing(struct btree_trans *trans, struct bk
 		return 0;
 
 	return bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
-		-BCH_ERR_transaction_restart_nested;
+		bch_err_throw(trans->c, transaction_restart_nested);
 }
 
 static int bch2_indirect_extent_missing_error(struct btree_trans *trans,
@@ -242,7 +242,7 @@ static int bch2_indirect_extent_missing_error(struct btree_trans *trans,
 
 		if (should_commit)
 			ret =   bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
-				-BCH_ERR_transaction_restart_nested;
+				bch_err_throw(c, transaction_restart_nested);
 	}
 err:
 fsck_err:
diff --git a/fs/bcachefs/snapshot.h b/fs/bcachefs/snapshot.h
index 6766bf673ed9..6dcb118b0fbd 100644
--- a/fs/bcachefs/snapshot.h
+++ b/fs/bcachefs/snapshot.h
@@ -128,7 +128,7 @@ static inline int bch2_snapshot_is_internal_node(struct bch_fs *c, u32 id)
 {
 	guard(rcu)();
 	const struct snapshot_t *s = snapshot_t(c, id);
-	return s ? s->children[0] : -BCH_ERR_invalid_snapshot_node;
+	return s ? s->children[0] : bch_err_throw(c, invalid_snapshot_node);
 }
 
 static inline int bch2_snapshot_is_leaf(struct bch_fs *c, u32 id)
diff --git a/fs/bcachefs/str_hash.c b/fs/bcachefs/str_hash.c
index 3e9f59226bdf..d39fd4261e1b 100644
--- a/fs/bcachefs/str_hash.c
+++ b/fs/bcachefs/str_hash.c
@@ -204,7 +204,7 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 	}
 
 	ret = bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
-		-BCH_ERR_transaction_restart_nested;
+		bch_err_throw(c, transaction_restart_nested);
 err:
 fsck_err:
 	printbuf_exit(&buf);
@@ -292,7 +292,7 @@ int bch2_str_hash_repair_key(struct btree_trans *trans,
 					    BTREE_UPDATE_internal_snapshot_node) ?:
 			bch2_fsck_update_backpointers(trans, s, *desc, hash_info, new) ?:
 			bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
-			-BCH_ERR_transaction_restart_commit;
+			bch_err_throw(c, transaction_restart_commit);
 	} else {
 duplicate_entries:
 		ret = hash_pick_winner(trans, *desc, hash_info, k, dup_k);
@@ -326,7 +326,7 @@ int bch2_str_hash_repair_key(struct btree_trans *trans,
 		}
 
 		ret = bch2_trans_commit(trans, NULL, NULL, 0) ?:
-			-BCH_ERR_transaction_restart_commit;
+			bch_err_throw(c, transaction_restart_commit);
 	}
 out:
 fsck_err:
diff --git a/fs/bcachefs/str_hash.h b/fs/bcachefs/str_hash.h
index 8979ac2d7a3b..353a927857f1 100644
--- a/fs/bcachefs/str_hash.h
+++ b/fs/bcachefs/str_hash.h
@@ -175,7 +175,7 @@ bch2_hash_lookup_in_snapshot(struct btree_trans *trans,
 	}
 	bch2_trans_iter_exit(trans, iter);
 
-	return bkey_s_c_err(ret ?: -BCH_ERR_ENOENT_str_hash_lookup);
+	return bkey_s_c_err(ret ?: bch_err_throw(trans->c, ENOENT_str_hash_lookup));
 }
 
 static __always_inline struct bkey_s_c
@@ -217,7 +217,7 @@ bch2_hash_hole(struct btree_trans *trans,
 			return 0;
 	bch2_trans_iter_exit(trans, iter);
 
-	return ret ?: -BCH_ERR_ENOSPC_str_hash_create;
+	return ret ?: bch_err_throw(trans->c, ENOSPC_str_hash_create);
 }
 
 static __always_inline
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index 020587449123..353df662a9b5 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -70,7 +70,7 @@ static int check_subvol(struct btree_trans *trans,
 	if (BCH_SUBVOLUME_UNLINKED(subvol.v)) {
 		ret = bch2_subvolume_delete(trans, iter->pos.offset);
 		bch_err_msg(c, ret, "deleting subvolume %llu", iter->pos.offset);
-		return ret ?: -BCH_ERR_transaction_restart_nested;
+		return ret ?: bch_err_throw(c, transaction_restart_nested);
 	}
 
 	if (fsck_err_on(subvol.k->p.offset == BCACHEFS_ROOT_SUBVOL &&
@@ -310,7 +310,7 @@ int bch2_subvol_has_children(struct btree_trans *trans, u32 subvol)
 	bch2_trans_iter_exit(trans, &iter);
 
 	return bkey_err(k) ?: k.k && k.k->p.inode == subvol
-		? -BCH_ERR_ENOTEMPTY_subvol_not_empty
+		? bch_err_throw(trans->c, ENOTEMPTY_subvol_not_empty)
 		: 0;
 }
 
-- 
2.51.0


From 12f0d5c5d31542438105c7af8f76169b91a5b864 Mon Sep 17 00:00:00 2001
From: Youling Tang <tangyouling@kylinos.cn>
Date: Thu, 5 Jun 2025 10:06:38 +0800
Subject: [PATCH 023/309] bcachefs: Simplify bch2_bio_map()

For the part of directly mapping the kernel virtual address, there is no
need to increase to bio page-by-page. It can be directly replaced by
bio_add_virt_nofail().

For the address part of the vmalloc region, its physical address is
discontinuous and needs to be increased page-by-page to bio. The helper
function bio_add_vmalloc() can be used to simplify the implementation of
bch2_bio_map().

Signed-off-by: Youling Tang <tangyouling@kylinos.cn>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/util.c | 15 ++++-----------
 1 file changed, 4 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/util.c b/fs/bcachefs/util.c
index df9a6071fe18..05b40debf211 100644
--- a/fs/bcachefs/util.c
+++ b/fs/bcachefs/util.c
@@ -617,17 +617,10 @@ void bch2_pd_controller_debug_to_text(struct printbuf *out, struct bch_pd_contro
 
 void bch2_bio_map(struct bio *bio, void *base, size_t size)
 {
-	while (size) {
-		struct page *page = is_vmalloc_addr(base)
-				? vmalloc_to_page(base)
-				: virt_to_page(base);
-		unsigned offset = offset_in_page(base);
-		unsigned len = min_t(size_t, PAGE_SIZE - offset, size);
-
-		BUG_ON(!bio_add_page(bio, page, len, offset));
-		size -= len;
-		base += len;
-	}
+	if (is_vmalloc_addr(base))
+		bio_add_vmalloc(bio, base, size);
+	else
+		bio_add_virt_nofail(bio, base, size);
 }
 
 int bch2_bio_alloc_pages(struct bio *bio, size_t size, gfp_t gfp_mask)
-- 
2.51.0


From efbe7bac03b0574f32e96695729be157c7544a76 Mon Sep 17 00:00:00 2001
From: Youling Tang <tangyouling@kylinos.cn>
Date: Thu, 5 Jun 2025 10:06:39 +0800
Subject: [PATCH 024/309] bcachefs: Use bio_add_folio_nofail() for unfailable
 operations

Use bio_add_folio_nofail() to replace the unfailable bio_add_folio()
operation.

Signed-off-by: Youling Tang <tangyouling@kylinos.cn>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 10 +++++-----
 1 file changed, 5 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index 66bacdd49f78..dad48d44f47b 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -145,7 +145,7 @@ static int readpage_bio_extend(struct btree_trans *trans,
 
 		BUG_ON(folio_sector(folio) != bio_end_sector(bio));
 
-		BUG_ON(!bio_add_folio(bio, folio, folio_size(folio), 0));
+		bio_add_folio_nofail(bio, folio, folio_size(folio), 0);
 	}
 
 	return bch2_trans_relock(trans);
@@ -311,7 +311,7 @@ void bch2_readahead(struct readahead_control *ractl)
 		readpage_iter_advance(&readpages_iter);
 
 		rbio->bio.bi_iter.bi_sector = folio_sector(folio);
-		BUG_ON(!bio_add_folio(&rbio->bio, folio, folio_size(folio), 0));
+		bio_add_folio_nofail(&rbio->bio, folio, folio_size(folio), 0);
 
 		bchfs_read(trans, rbio, inode_inum(inode),
 			   &readpages_iter);
@@ -354,7 +354,7 @@ int bch2_read_single_folio(struct folio *folio, struct address_space *mapping)
 	rbio->bio.bi_private = &done;
 	rbio->bio.bi_opf = REQ_OP_READ|REQ_SYNC;
 	rbio->bio.bi_iter.bi_sector = folio_sector(folio);
-	BUG_ON(!bio_add_folio(&rbio->bio, folio, folio_size(folio), 0));
+	bio_add_folio_nofail(&rbio->bio, folio, folio_size(folio), 0);
 
 	blk_start_plug(&plug);
 	bch2_trans_run(c, (bchfs_read(trans, rbio, inode_inum(inode), NULL), 0));
@@ -639,8 +639,8 @@ static int __bch2_writepage(struct folio *folio,
 		atomic_inc(&s->write_count);
 
 		BUG_ON(inode != w->io->inode);
-		BUG_ON(!bio_add_folio(&w->io->op.wbio.bio, folio,
-				     sectors << 9, offset << 9));
+		bio_add_folio_nofail(&w->io->op.wbio.bio, folio,
+				     sectors << 9, offset << 9);
 
 		w->io->op.res.sectors += reserved_sectors;
 		w->io->op.i_sectors_delta -= dirty_sectors;
-- 
2.51.0


From d75e07635a4cc0b181192cac111bc0feac693eb7 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 26 Jun 2025 19:55:40 -0400
Subject: [PATCH 025/309] bcachefs: Improve inode_create behaviour on old
 filesystems

On filesystems that predate persistent cursors, inode_generation keys
will be present (no longer needed because the cursor tracks the current
generation).

But the new inode allocation code skipped allocating slots with
inode_generation keys, which led to a lot of unnecessary scanning, which
this patch fixes.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/inode.c | 9 ++++++++-
 1 file changed, 8 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 1c1b6e4533fc..307fb0c95656 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1018,6 +1018,7 @@ int bch2_inode_create(struct btree_trans *trans,
 
 	u64 start = le64_to_cpu(cursor->v.idx);
 	u64 pos = start;
+	u64 gen = 0;
 
 	bch2_trans_iter_init(trans, iter, BTREE_ID_inodes, POS(0, pos),
 			     BTREE_ITER_all_snapshots|
@@ -1030,6 +1031,12 @@ int bch2_inode_create(struct btree_trans *trans,
 		if (pos < iter->pos.offset)
 			goto found_slot;
 
+		if (bch2_snapshot_is_ancestor(trans->c, snapshot, k.k->p.snapshot) &&
+		    k.k->type == KEY_TYPE_inode_generation) {
+			gen = le32_to_cpu(bkey_s_c_to_inode_generation(k).v->bi_generation);
+			goto found_slot;
+		}
+
 		/*
 		 * We don't need to iterate over keys in every snapshot once
 		 * we've found just one:
@@ -1064,7 +1071,7 @@ int bch2_inode_create(struct btree_trans *trans,
 	}
 
 	inode_u->bi_inum	= k.k->p.offset;
-	inode_u->bi_generation	= le64_to_cpu(cursor->v.gen);
+	inode_u->bi_generation	= max(gen, le64_to_cpu(cursor->v.gen));
 	cursor->v.idx		= cpu_to_le64(k.k->p.offset + 1);
 	return 0;
 }
-- 
2.51.0


From fc6047aba8e85ef9e458d3fc38861a9256e3259b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 30 Jun 2025 17:07:31 -0400
Subject: [PATCH 026/309] bcachefs: Before removing dangling dirents, check for
 contents

If we find a dirent pointing to a missing inode, check for
dirents/extents assocatiated with that inode number: if present,
reconstruct the inode insead of deleting the dirent.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c             | 45 ++++++++++++++++++++++++++++++++++
 fs/bcachefs/sb-errors_format.h |  3 ++-
 2 files changed, 47 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 9e3180fab553..c36ce7e8c32d 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1573,6 +1573,44 @@ static int check_key_has_inode(struct btree_trans *trans,
 	goto out;
 }
 
+static int maybe_reconstruct_inum_btree(struct btree_trans *trans,
+					u64 inum, u32 snapshot,
+					enum btree_id btree)
+{
+	struct btree_iter iter;
+	struct bkey_s_c k;
+	int ret = 0;
+
+	for_each_btree_key_max_norestart(trans, iter, btree,
+					 SPOS(inum, 0, snapshot),
+					 POS(inum, U64_MAX),
+					 0, k, ret) {
+		ret = 1;
+		break;
+	}
+	bch2_trans_iter_exit(trans, &iter);
+
+	if (ret <= 0)
+		return ret;
+
+	if (fsck_err(trans, missing_inode_with_contents,
+		     "inode %llu:%u type %s missing, but contents found: reconstruct?",
+		     inum, snapshot,
+		     btree == BTREE_ID_extents ? "reg" : "dir"))
+		return  reconstruct_inode(trans, btree, snapshot, inum) ?:
+			bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
+			bch_err_throw(trans->c, transaction_restart_commit);
+fsck_err:
+	return ret;
+}
+
+static int maybe_reconstruct_inum(struct btree_trans *trans,
+				  u64 inum, u32 snapshot)
+{
+	return  maybe_reconstruct_inum_btree(trans, inum, snapshot, BTREE_ID_extents) ?:
+		maybe_reconstruct_inum_btree(trans, inum, snapshot, BTREE_ID_dirents);
+}
+
 static int check_i_sectors_notnested(struct btree_trans *trans, struct inode_walker *w)
 {
 	struct bch_fs *c = trans->c;
@@ -2346,6 +2384,13 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 		if (ret)
 			goto err;
 
+		if (!target->inodes.nr) {
+			ret = maybe_reconstruct_inum(trans, le64_to_cpu(d.v->d_inum),
+						     d.k->p.snapshot);
+			if (ret)
+				return ret;
+		}
+
 		if (fsck_err_on(!target->inodes.nr,
 				trans, dirent_to_missing_inode,
 				"dirent points to missing inode:\n%s",
diff --git a/fs/bcachefs/sb-errors_format.h b/fs/bcachefs/sb-errors_format.h
index 3ecac2524118..02605976a114 100644
--- a/fs/bcachefs/sb-errors_format.h
+++ b/fs/bcachefs/sb-errors_format.h
@@ -291,6 +291,7 @@ enum bch_fsck_flags {
 	x(inode_points_to_missing_dirent,			249,	FSCK_AUTOFIX)	\
 	x(inode_points_to_wrong_dirent,				250,	FSCK_AUTOFIX)	\
 	x(inode_bi_parent_nonzero,				251,	0)		\
+	x(missing_inode_with_contents,				321,	FSCK_AUTOFIX)	\
 	x(dirent_to_missing_parent_subvol,			252,	0)		\
 	x(dirent_not_visible_in_parent_subvol,			253,	0)		\
 	x(subvol_fs_path_parent_wrong,				254,	0)		\
@@ -332,7 +333,7 @@ enum bch_fsck_flags {
 	x(dirent_stray_data_after_cf_name,			305,	0)		\
 	x(rebalance_work_incorrectly_set,			309,	FSCK_AUTOFIX)	\
 	x(rebalance_work_incorrectly_unset,			310,	FSCK_AUTOFIX)	\
-	x(MAX,							321,	0)
+	x(MAX,							322,	0)
 
 enum bch_sb_error_id {
 #define x(t, n, ...) BCH_FSCK_ERR_##t = n,
-- 
2.51.0


From b25948a7b17ba519c868c1e6281a0b6af99f01f7 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 30 Jun 2025 17:10:51 -0400
Subject: [PATCH 027/309] bcachefs: check_key_has_inode() reconstructs more
 aggressively

For regular files: reconstruct if more than three extents are found
found

For directories: reconstruct if a single dirent is found.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index c36ce7e8c32d..bf2cfa40702b 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1501,6 +1501,10 @@ static int check_key_has_inode(struct btree_trans *trans,
 					 SPOS(k.k->p.inode, 0, k.k->p.snapshot),
 					 POS(k.k->p.inode, U64_MAX),
 					 0, k2, ret) {
+		if (k.k->type == KEY_TYPE_error ||
+		    k.k->type == KEY_TYPE_hash_whiteout)
+			continue;
+
 		nr_keys++;
 		if (nr_keys <= 10) {
 			bch2_bkey_val_to_text(&buf, c, k2);
@@ -1513,9 +1517,11 @@ static int check_key_has_inode(struct btree_trans *trans,
 	if (ret)
 		goto err;
 
+	unsigned reconstruct_limit = iter->btree_id == BTREE_ID_extents ? 3 : 0;
+
 	if (nr_keys > 100)
 		prt_printf(&buf, "found > %u keys for this missing inode\n", nr_keys);
-	else if (nr_keys > 10)
+	else if (nr_keys > reconstruct_limit)
 		prt_printf(&buf, "found %u keys for this missing inode\n", nr_keys);
 
 	if (!have_inode) {
-- 
2.51.0


From ce1f1a70162b54dbf22d10acb70f8c588e5cfbd9 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 30 Jun 2025 20:55:14 -0400
Subject: [PATCH 028/309] bcachefs: bch_fs.devs_removed

Add a bitmask of device slots that have been marked as removed: this
will be used in the next patch for differentiating, in error messages
and counters, between references to invalid devices and references to
removed devices.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h   |  1 +
 fs/bcachefs/recovery.c   |  3 ++-
 fs/bcachefs/sb-members.c | 16 ++++++++++++++++
 fs/bcachefs/sb-members.h |  1 +
 fs/bcachefs/super-io.c   |  5 +----
 5 files changed, 21 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index c74d48e9d3c4..fb3156ed7f0b 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -819,6 +819,7 @@ struct bch_fs {
 	struct work_struct	read_only_work;
 
 	struct bch_dev __rcu	*devs[BCH_SB_MEMBERS_MAX];
+	struct bch_devs_mask	devs_removed;
 
 	struct bch_accounting_mem accounting;
 
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index c94debb12d2f..0def4ecb7f88 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -1188,9 +1188,10 @@ int bch2_fs_initialize(struct bch_fs *c)
 	for_each_member_device(c, ca) {
 		m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
 		SET_BCH_MEMBER_FREESPACE_INITIALIZED(m, false);
-		ca->mi = bch2_mi_to_cpu(m);
 	}
 
+	bch2_sb_members_to_cpu(c);
+
 	bch2_write_super(c);
 	mutex_unlock(&c->sb_lock);
 
diff --git a/fs/bcachefs/sb-members.c b/fs/bcachefs/sb-members.c
index 6245e342a8a8..96f98f111f48 100644
--- a/fs/bcachefs/sb-members.c
+++ b/fs/bcachefs/sb-members.c
@@ -413,6 +413,22 @@ void bch2_sb_members_from_cpu(struct bch_fs *c)
 	}
 }
 
+void bch2_sb_members_to_cpu(struct bch_fs *c)
+{
+	for_each_member_device(c, ca) {
+		struct bch_member m = bch2_sb_member_get(c->disk_sb.sb, ca->dev_idx);
+		ca->mi = bch2_mi_to_cpu(&m);
+	}
+
+	struct bch_sb_field_members_v2 *mi2 = bch2_sb_field_get(c->disk_sb.sb, members_v2);
+	if (mi2)
+		for (unsigned i = 0; i < c->sb.nr_devices; i++) {
+			struct bch_member m = members_v2_get(mi2, i);
+			bool removed = uuid_equal(&m.uuid, &BCH_SB_MEMBER_DELETED_UUID);
+			mod_bit(i, c->devs_removed.d, removed);
+		}
+}
+
 void bch2_dev_io_errors_to_text(struct printbuf *out, struct bch_dev *ca)
 {
 	struct bch_fs *c = ca->fs;
diff --git a/fs/bcachefs/sb-members.h b/fs/bcachefs/sb-members.h
index 5dcc2017f85b..0d363a1cdd47 100644
--- a/fs/bcachefs/sb-members.h
+++ b/fs/bcachefs/sb-members.h
@@ -365,6 +365,7 @@ static inline struct bch_member_cpu bch2_mi_to_cpu(struct bch_member *mi)
 }
 
 void bch2_sb_members_from_cpu(struct bch_fs *);
+void bch2_sb_members_to_cpu(struct bch_fs *);
 
 void bch2_dev_io_errors_to_text(struct printbuf *, struct bch_dev *);
 void bch2_dev_errors_reset(struct bch_dev *);
diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index 6c2e1d647403..85e460d10e9d 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -632,10 +632,7 @@ static void bch2_sb_update(struct bch_fs *c)
 		c->sb.btrees_lost_data = le64_to_cpu(ext->btrees_lost_data);
 	}
 
-	for_each_member_device(c, ca) {
-		struct bch_member m = bch2_sb_member_get(src, ca->dev_idx);
-		ca->mi = bch2_mi_to_cpu(&m);
-	}
+	bch2_sb_members_to_cpu(c);
 }
 
 static int __copy_super(struct bch_sb_handle *dst_handle, struct bch_sb *src)
-- 
2.51.0


From 89b403d70a77b2de8ec2c6978ab6148d779dd486 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 30 Jun 2025 19:40:55 -0400
Subject: [PATCH 029/309] bcachefs: ptr_to_removed_device

Differentiate between pointers to invalid devices and pointers to
removed devices in log messages and superblock error counters.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-errors_format.h |  3 ++-
 fs/bcachefs/sb-members.c       | 13 ++++++++++---
 2 files changed, 12 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/sb-errors_format.h b/fs/bcachefs/sb-errors_format.h
index 02605976a114..dd4ee46606d7 100644
--- a/fs/bcachefs/sb-errors_format.h
+++ b/fs/bcachefs/sb-errors_format.h
@@ -158,6 +158,7 @@ enum bch_fsck_flags {
 	x(extent_ptrs_unwritten,				140,	0)		\
 	x(extent_ptrs_written_and_unwritten,			141,	0)		\
 	x(ptr_to_invalid_device,				142,	0)		\
+	x(ptr_to_removed_device,				322,	0)		\
 	x(ptr_to_duplicate_device,				143,	0)		\
 	x(ptr_after_last_bucket,				144,	0)		\
 	x(ptr_before_first_bucket,				145,	0)		\
@@ -333,7 +334,7 @@ enum bch_fsck_flags {
 	x(dirent_stray_data_after_cf_name,			305,	0)		\
 	x(rebalance_work_incorrectly_set,			309,	FSCK_AUTOFIX)	\
 	x(rebalance_work_incorrectly_unset,			310,	FSCK_AUTOFIX)	\
-	x(MAX,							322,	0)
+	x(MAX,							323,	0)
 
 enum bch_sb_error_id {
 #define x(t, n, ...) BCH_FSCK_ERR_##t = n,
diff --git a/fs/bcachefs/sb-members.c b/fs/bcachefs/sb-members.c
index 96f98f111f48..f2abe92ca130 100644
--- a/fs/bcachefs/sb-members.c
+++ b/fs/bcachefs/sb-members.c
@@ -15,10 +15,15 @@ int bch2_dev_missing_bkey(struct bch_fs *c, struct bkey_s_c k, unsigned dev)
 	struct printbuf buf = PRINTBUF;
 	bch2_log_msg_start(c, &buf);
 
-	prt_printf(&buf, "pointer to nonexistent device %u in key\n", dev);
+	bool removed = test_bit(dev, c->devs_removed.d);
+
+	prt_printf(&buf, "pointer to %s device %u in key\n",
+		   removed ? "removed" : "nonexistent", dev);
 	bch2_bkey_val_to_text(&buf, c, k);
 
-	bool print = bch2_count_fsck_err(c, ptr_to_invalid_device, &buf);
+	bool print = removed
+		? bch2_count_fsck_err(c, ptr_to_removed_device, &buf)
+		: bch2_count_fsck_err(c, ptr_to_invalid_device, &buf);
 
 	int ret = bch2_run_explicit_recovery_pass(c, &buf,
 					BCH_RECOVERY_PASS_check_allocations, 0);
@@ -32,7 +37,9 @@ int bch2_dev_missing_bkey(struct bch_fs *c, struct bkey_s_c k, unsigned dev)
 void bch2_dev_missing_atomic(struct bch_fs *c, unsigned dev)
 {
 	if (dev != BCH_SB_MEMBER_INVALID)
-		bch2_fs_inconsistent(c, "pointer to nonexistent device %u", dev);
+		bch2_fs_inconsistent(c, "pointer to %s device %u",
+				     test_bit(dev, c->devs_removed.d)
+				     ? "removed" : "nonexistent", dev);
 }
 
 void bch2_dev_bucket_missing(struct bch_dev *ca, u64 bucket)
-- 
2.51.0


From 2eb1a49515faca273c3e56d153ac3e4c0e716a60 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Tue, 1 Jul 2025 10:57:38 +0800
Subject: [PATCH 030/309] bcachefs: Don't lock exec_update_lock

exec_update_lock is used to check permissions, no need here.

Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/util.c | 5 -----
 1 file changed, 5 deletions(-)

diff --git a/fs/bcachefs/util.c b/fs/bcachefs/util.c
index 05b40debf211..7a4436fd4441 100644
--- a/fs/bcachefs/util.c
+++ b/fs/bcachefs/util.c
@@ -299,17 +299,12 @@ int bch2_save_backtrace(bch_stacktrace *stack, struct task_struct *task, unsigne
 	if (ret)
 		return ret;
 
-	if (!down_read_trylock(&task->signal->exec_update_lock))
-		return -1;
-
 	do {
 		nr_entries = stack_trace_save_tsk(task, stack->data, stack->size, skipnr + 1);
 	} while (nr_entries == stack->size &&
 		 !(ret = darray_make_room_gfp(stack, stack->size * 2, gfp)));
 
 	stack->nr = nr_entries;
-	up_read(&task->signal->exec_update_lock);
-
 	return ret;
 #else
 	return 0;
-- 
2.51.0


From dfb497fcb57d383fe102416e32b81043c2433a55 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 1 Jul 2025 13:54:33 -0400
Subject: [PATCH 031/309] bcachefs: bch2_journal_entry_missing_range()

Factor out a small common helper for userspace (bcachefs list_journal)
to use as well.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_io.c | 59 ++++++++++++++++++++++++++--------------
 fs/bcachefs/journal_io.h |  7 +++++
 2 files changed, 45 insertions(+), 21 deletions(-)

diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 343f1daf5da7..7cfe8ddf91da 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -1272,6 +1272,34 @@ static void bch2_journal_print_checksum_error(struct bch_fs *c, struct journal_r
 	printbuf_exit(&buf);
 }
 
+struct u64_range bch2_journal_entry_missing_range(struct bch_fs *c, u64 start, u64 end)
+{
+	BUG_ON(start > end);
+
+	if (start == end)
+		return (struct u64_range) {};
+
+	while (start < end &&
+	       bch2_journal_seq_is_blacklisted(c, start, false))
+		start++;
+
+	if (start == end)
+		return (struct u64_range) {};
+
+	struct u64_range missing = { .start = start };
+
+	while (start < end &&
+	       !bch2_journal_seq_is_blacklisted(c, start, false))
+		start++;
+
+	missing.end = start - 1;
+
+	if (missing.start == missing.end)
+		return (struct u64_range) {};
+
+	return missing;
+}
+
 noinline_for_stack
 static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 end_seq)
 {
@@ -1280,6 +1308,7 @@ static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 e
 
 	struct genradix_iter radix_iter;
 	struct journal_replay *i, **_i, *prev = NULL;
+	/* Sequence number we expect to find next, to check for missing entries */
 	u64 seq = start_seq;
 
 	genradix_for_each(&c->journal_entries, radix_iter, _i) {
@@ -1290,43 +1319,31 @@ static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 e
 
 		BUG_ON(seq > le64_to_cpu(i->j.seq));
 
-		while (seq < le64_to_cpu(i->j.seq)) {
-			while (seq < le64_to_cpu(i->j.seq) &&
-			       bch2_journal_seq_is_blacklisted(c, seq, false))
-				seq++;
-
-			if (seq == le64_to_cpu(i->j.seq))
-				break;
-
-			u64 missing_start = seq;
-
-			while (seq < le64_to_cpu(i->j.seq) &&
-			       !bch2_journal_seq_is_blacklisted(c, seq, false))
-				seq++;
-
-			u64 missing_end = seq - 1;
+		struct u64_range missing;
 
+		while ((missing = bch2_journal_entry_missing_range(c, seq, le64_to_cpu(i->j.seq))).start) {
 			printbuf_reset(&buf);
 			prt_printf(&buf, "journal entries %llu-%llu missing! (replaying %llu-%llu)",
-				   missing_start, missing_end,
+				   missing.start, missing.end,
 				   start_seq, end_seq);
 
-			prt_printf(&buf, "\nprev at ");
 			if (prev) {
+				prt_printf(&buf, "\n%llu at ", le64_to_cpu(prev->j.seq));
 				bch2_journal_ptrs_to_text(&buf, c, prev);
 				prt_printf(&buf, " size %zu", vstruct_sectors(&prev->j, c->block_bits));
-			} else
-				prt_printf(&buf, "(none)");
+			}
 
-			prt_printf(&buf, "\nnext at ");
+			prt_printf(&buf, "\n%llu at ", le64_to_cpu(i->j.seq));
 			bch2_journal_ptrs_to_text(&buf, c, i);
 			prt_printf(&buf, ", continue?");
 
 			fsck_err(c, journal_entries_missing, "%s", buf.buf);
+
+			seq = missing.end + 1;
 		}
 
 		prev = i;
-		seq++;
+		seq = le64_to_cpu(i->j.seq) + 1;
 	}
 fsck_err:
 	printbuf_exit(&buf);
diff --git a/fs/bcachefs/journal_io.h b/fs/bcachefs/journal_io.h
index 6fa82c4050fe..f53c5c81d137 100644
--- a/fs/bcachefs/journal_io.h
+++ b/fs/bcachefs/journal_io.h
@@ -71,6 +71,13 @@ void bch2_journal_entry_to_text(struct printbuf *, struct bch_fs *,
 void bch2_journal_ptrs_to_text(struct printbuf *, struct bch_fs *,
 			       struct journal_replay *);
 
+struct u64_range {
+	u64	start;
+	u64	end;
+};
+
+struct u64_range bch2_journal_entry_missing_range(struct bch_fs *, u64, u64);
+
 int bch2_journal_read(struct bch_fs *, u64 *, u64 *, u64 *);
 
 CLOSURE_CALLBACK(bch2_journal_write);
-- 
2.51.0


From 42ffa6990c546cfc3811e43d266c3d44381438da Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 2 Jul 2025 14:59:52 -0400
Subject: [PATCH 032/309] bcachefs: Faster checking for missing journal entries

Previously, we would do a linear search over journal entry gaps,
checking for entries that aren't actually missing beacuse the sequence
number was blacklisted.

But multi device filesystems can have massive gaps in journal entry
sequence numbers, and the linear search then becomes quite painful.

Fix this with two new helpers for iterating over the blacklist table:

  bch2_journal_seq_next_blacklisted()
  bch2_journal_seq_next_nonblacklisted()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_io.c            | 22 +++++---------
 fs/bcachefs/journal_seq_blacklist.c | 46 +++++++++++++++++++++++++++++
 fs/bcachefs/journal_seq_blacklist.h |  3 ++
 3 files changed, 57 insertions(+), 14 deletions(-)

diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 7cfe8ddf91da..322baa737e8e 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -1279,20 +1279,14 @@ struct u64_range bch2_journal_entry_missing_range(struct bch_fs *c, u64 start, u
 	if (start == end)
 		return (struct u64_range) {};
 
-	while (start < end &&
-	       bch2_journal_seq_is_blacklisted(c, start, false))
-		start++;
-
-	if (start == end)
+	start = bch2_journal_seq_next_nonblacklisted(c, start);
+	if (start >= end)
 		return (struct u64_range) {};
 
-	struct u64_range missing = { .start = start };
-
-	while (start < end &&
-	       !bch2_journal_seq_is_blacklisted(c, start, false))
-		start++;
-
-	missing.end = start - 1;
+	struct u64_range missing = {
+		.start	= start,
+		.end	= min(end, bch2_journal_seq_next_blacklisted(c, start)),
+	};
 
 	if (missing.start == missing.end)
 		return (struct u64_range) {};
@@ -1324,7 +1318,7 @@ static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 e
 		while ((missing = bch2_journal_entry_missing_range(c, seq, le64_to_cpu(i->j.seq))).start) {
 			printbuf_reset(&buf);
 			prt_printf(&buf, "journal entries %llu-%llu missing! (replaying %llu-%llu)",
-				   missing.start, missing.end,
+				   missing.start, missing.end - 1,
 				   start_seq, end_seq);
 
 			if (prev) {
@@ -1339,7 +1333,7 @@ static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 e
 
 			fsck_err(c, journal_entries_missing, "%s", buf.buf);
 
-			seq = missing.end + 1;
+			seq = missing.end;
 		}
 
 		prev = i;
diff --git a/fs/bcachefs/journal_seq_blacklist.c b/fs/bcachefs/journal_seq_blacklist.c
index af4fe416d9ec..6361809b5e2e 100644
--- a/fs/bcachefs/journal_seq_blacklist.c
+++ b/fs/bcachefs/journal_seq_blacklist.c
@@ -103,6 +103,52 @@ static int journal_seq_blacklist_table_cmp(const void *_l, const void *_r)
 	return cmp_int(l->start, r->start);
 }
 
+static int journal_seq_blacklist_table_end_cmp(const void *_l, const void *_r)
+{
+	const struct journal_seq_blacklist_table_entry *l = _l;
+	const struct journal_seq_blacklist_table_entry *r = _r;
+
+	return cmp_int(l->end, r->end);
+}
+
+u64 bch2_journal_seq_next_blacklisted(struct bch_fs *c, u64 seq)
+{
+	struct journal_seq_blacklist_table *t = c->journal_seq_blacklist_table;
+
+	if (!t)
+		return U64_MAX;
+
+	struct journal_seq_blacklist_table_entry search = { .end = seq };
+	int idx = eytzinger0_find_gt(t->entries, t->nr,
+				     sizeof(t->entries[0]),
+				     journal_seq_blacklist_table_end_cmp,
+				     &search);
+	if (idx < 0)
+		return U64_MAX;
+
+	return max(seq, t->entries[idx].start);
+}
+
+u64 bch2_journal_seq_next_nonblacklisted(struct bch_fs *c, u64 seq)
+{
+	struct journal_seq_blacklist_table *t = c->journal_seq_blacklist_table;
+
+	if (!t)
+		return seq;
+
+	while (true) {
+		struct journal_seq_blacklist_table_entry search = { .start = seq };
+		int idx = eytzinger0_find_le(t->entries, t->nr,
+					     sizeof(t->entries[0]),
+					     journal_seq_blacklist_table_cmp,
+					     &search);
+		if (idx < 0 || t->entries[idx].end <= seq)
+			return seq;
+
+		seq = t->entries[idx].end;
+	}
+}
+
 bool bch2_journal_seq_is_blacklisted(struct bch_fs *c, u64 seq,
 				     bool dirty)
 {
diff --git a/fs/bcachefs/journal_seq_blacklist.h b/fs/bcachefs/journal_seq_blacklist.h
index f06942ccfcdd..389b789b26f4 100644
--- a/fs/bcachefs/journal_seq_blacklist.h
+++ b/fs/bcachefs/journal_seq_blacklist.h
@@ -11,6 +11,9 @@ blacklist_nr_entries(struct bch_sb_field_journal_seq_blacklist *bl)
 		: 0;
 }
 
+u64 bch2_journal_seq_next_blacklisted(struct bch_fs *, u64);
+u64 bch2_journal_seq_next_nonblacklisted(struct bch_fs *, u64);
+
 bool bch2_journal_seq_is_blacklisted(struct bch_fs *, u64, bool);
 u64 bch2_journal_last_blacklisted_seq(struct bch_fs *);
 int bch2_journal_seq_blacklist_add(struct bch_fs *c, u64, u64);
-- 
2.51.0


From db13c74e37edcf7c47b5716086e57da7715c4706 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 2 Jul 2025 15:53:20 -0400
Subject: [PATCH 033/309] bcachefs: Add missing bch2_log_msg_start()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_io.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 322baa737e8e..798ad8789afc 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -1245,6 +1245,8 @@ noinline_for_stack
 static void bch2_journal_print_checksum_error(struct bch_fs *c, struct journal_replay *j)
 {
 	struct printbuf buf = PRINTBUF;
+	bch2_log_msg_start(c, &buf);
+
 	enum bch_csum_type csum_type = JSET_CSUM_TYPE(&j->j);
 	bool have_good = false;
 
-- 
2.51.0


From bb9b5b73f575a46410ff7c09bc282124f5cab3d8 Mon Sep 17 00:00:00 2001
From: Nikita Ofitserov <himikof@gmail.com>
Date: Thu, 3 Jul 2025 02:59:11 +0300
Subject: [PATCH 034/309] bcachefs: Suppress unnecessary inode_i_sectors_wrong
 fsck error

It is possible that fsck first miscounted the expected sector count (due
to applying other fixes at the same time, for example) and then
corrected itself using extents. No need to log an fsck error and
write the inode in this case.

Signed-off-by: Nikita Ofitserov <himikof@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index bf2cfa40702b..48e756cf48f2 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1638,7 +1638,8 @@ static int check_i_sectors_notnested(struct btree_trans *trans, struct inode_wal
 			i->count = count2;
 		}
 
-		if (fsck_err_on(!(i->inode.bi_flags & BCH_INODE_i_sectors_dirty),
+		if (fsck_err_on(!(i->inode.bi_flags & BCH_INODE_i_sectors_dirty) &&
+				i->inode.bi_sectors != i->count,
 				trans, inode_i_sectors_wrong,
 				"inode %llu:%u has incorrect i_sectors: got %llu, should be %llu",
 				w->last_pos.inode, i->inode.bi_snapshot,
-- 
2.51.0


From 64254250fd54c91047054975ddda3700257de299 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 3 Jul 2025 15:05:51 -0400
Subject: [PATCH 035/309] bcachefs: Print errcode when bch2_read_extent() sees
 error

This is not supposed to happen, so we WARN() - make the warning more
useful.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/io_read.h b/fs/bcachefs/io_read.h
index 9c5ddbf861b3..cfc8ef35b14d 100644
--- a/fs/bcachefs/io_read.h
+++ b/fs/bcachefs/io_read.h
@@ -147,7 +147,7 @@ static inline void bch2_read_extent(struct btree_trans *trans,
 	int ret = __bch2_read_extent(trans, rbio, rbio->bio.bi_iter, read_pos,
 				     data_btree, k, offset_into_extent, NULL, flags, -1);
 	/* __bch2_read_extent only returns errors if BCH_READ_in_retry is set */
-	WARN(ret, "unhandled error from __bch2_read_extent()");
+	WARN(ret, "unhandled error from __bch2_read_extent(): %s", bch2_err_str(ret));
 }
 
 int __bch2_read(struct btree_trans *, struct bch_read_bio *, struct bvec_iter,
-- 
2.51.0


From 85cffad99e7496c7cc4cdccb6d653a119dee8fb0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 3 Jul 2025 18:03:42 -0400
Subject: [PATCH 036/309] bcachefs: Fix error message in buffered read path

We should print error codes as strings, not numbers.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index dad48d44f47b..4e82dfa6c03f 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -257,7 +257,7 @@ static void bchfs_read(struct btree_trans *trans,
 		struct printbuf buf = PRINTBUF;
 		lockrestart_do(trans,
 			bch2_inum_offset_err_msg_trans(trans, &buf, inum, iter.pos.offset << 9));
-		prt_printf(&buf, "read error %i from btree lookup", ret);
+		prt_printf(&buf, "read error %s from btree lookup", bch2_err_str(ret));
 		bch_err_ratelimited(c, "%s", buf.buf);
 		printbuf_exit(&buf);
 
-- 
2.51.0


From 38369867813f728409ee5e4c8f2d607a6182afb4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 3 Jul 2025 19:22:45 -0400
Subject: [PATCH 037/309] bcachefs: Debug param for injecting btree node
 corruption on read

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 11 +++++++++++
 1 file changed, 11 insertions(+)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index aa18c1c25e8a..efe4183d3e13 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -26,6 +26,12 @@
 
 #include <linux/sched/mm.h>
 
+#ifdef CONFIG_BCACHEFS_DEBUG
+static unsigned bch2_btree_read_corrupt_ratio;
+module_param_named(btree_read_corrupt_ratio, bch2_btree_read_corrupt_ratio, uint, 0644);
+MODULE_PARM_DESC(btree_read_corrupt_ratio, "");
+#endif
+
 static void bch2_btree_node_header_to_text(struct printbuf *out, struct btree_node *bn)
 {
 	bch2_btree_id_level_to_text(out, BTREE_NODE_ID(bn), BTREE_NODE_LEVEL(bn));
@@ -1437,6 +1443,11 @@ static void btree_node_read_work(struct work_struct *work)
 			continue;
 		}
 
+		memset(&bio->bi_iter, 0, sizeof(bio->bi_iter));
+		bio->bi_iter.bi_size	= btree_buf_bytes(b);
+
+		bch2_maybe_corrupt_bio(bio, bch2_btree_read_corrupt_ratio);
+
 		ret = bch2_btree_node_read_done(c, ca, b, &failed, &buf);
 		if (ret == -BCH_ERR_btree_node_read_err_want_retry ||
 		    ret == -BCH_ERR_btree_node_read_err_must_retry)
-- 
2.51.0


From a3fa6b09f7b25bfee4f54174cddbae586a951e30 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 6 Jul 2025 13:27:32 -0400
Subject: [PATCH 038/309] bcachefs: device add now properly sets c->online_devs

State management for device online/offline is messy (perhaps inevitably
so), too many state machine combinations.o

c->online_devs is special; it's normally set in bch2_dev_attach_bdev(),
which device add does not use because it's attaching the new device in
stages.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 6980cd5b0ca8..54039f2a259c 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1974,11 +1974,15 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 	ca->disk_sb.sb->dev_idx	= dev_idx;
 	bch2_dev_attach(c, ca, dev_idx);
 
+	set_bit(ca->dev_idx, c->online_devs.d);
+
 	if (BCH_MEMBER_GROUP(&dev_mi)) {
 		ret = __bch2_dev_group_set(c, ca, label.buf);
 		bch_err_msg(c, ret, "creating new label");
-		if (ret)
-			goto err_unlock;
+		if (ret) {
+			mutex_unlock(&c->sb_lock);
+			goto err_late;
+		}
 	}
 
 	bch2_write_super(c);
-- 
2.51.0


From 5b18957c174ec50add77253f5fd60bd5c2061810 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 6 Jul 2025 13:33:19 -0400
Subject: [PATCH 039/309] bcachefs: silence userspace build warning

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 54039f2a259c..a3438b0dc0a9 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -2530,6 +2530,8 @@ static int bch2_param_get_static_key_t(char *buffer, const struct kernel_param *
 	return sprintf(buffer, "%c\n", static_key_enabled(key) ? 'N' : 'Y');
 }
 
+/* this is unused in userspace - silence the warning */
+__maybe_unused
 static const struct kernel_param_ops bch2_param_ops_static_key_t = {
 	.flags = KERNEL_PARAM_OPS_FL_NOARG,
 	.set = bch2_param_set_static_key_t,
-- 
2.51.0


From 7e53a53909879d804c9d3ab59f4b1f553f257c51 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 6 Jul 2025 13:45:13 -0400
Subject: [PATCH 040/309] bcachefs: Update path flags cleanups

Prefer the correct enum to 'unsigned flags'; also, we have a single enum
for iterator and update flags, so plumb that through delete_range (so we
can pass BTREE_ITER_all_snapshots).

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_trans_commit.c |  2 +-
 fs/bcachefs/btree_update.c       | 27 ++++++++++++++-------------
 fs/bcachefs/btree_update.h       | 21 +++++++++++++--------
 3 files changed, 28 insertions(+), 22 deletions(-)

diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index 7fcf248a9a76..a7e9d8916848 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -1008,7 +1008,7 @@ do_bch2_trans_commit_to_journal_replay(struct btree_trans *trans)
 	return 0;
 }
 
-int __bch2_trans_commit(struct btree_trans *trans, unsigned flags)
+int __bch2_trans_commit(struct btree_trans *trans, enum bch_trans_commit_flags flags)
 {
 	struct btree_insert_entry *errored_at = NULL;
 	struct bch_fs *c = trans->c;
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 5d9e02370aff..7983c4940b3b 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -661,21 +661,22 @@ int bch2_btree_insert_trans(struct btree_trans *trans, enum btree_id id,
  * @k:			key to insert
  * @disk_res:		must be non-NULL whenever inserting or potentially
  *			splitting data extents
- * @flags:		transaction commit flags
+ * @commit_flags:	transaction commit flags
  * @iter_flags:		btree iter update trigger flags
  *
  * Returns:		0 on success, error code on failure
  */
 int bch2_btree_insert(struct bch_fs *c, enum btree_id id, struct bkey_i *k,
-		      struct disk_reservation *disk_res, int flags,
+		      struct disk_reservation *disk_res,
+		      enum bch_trans_commit_flags commit_flags,
 		      enum btree_iter_update_trigger_flags iter_flags)
 {
-	return bch2_trans_commit_do(c, disk_res, NULL, flags,
+	return bch2_trans_commit_do(c, disk_res, NULL, commit_flags,
 			     bch2_btree_insert_trans(trans, id, k, iter_flags));
 }
 
-int bch2_btree_delete_at(struct btree_trans *trans,
-			 struct btree_iter *iter, unsigned update_flags)
+int bch2_btree_delete_at(struct btree_trans *trans, struct btree_iter *iter,
+			 enum btree_iter_update_trigger_flags flags)
 {
 	struct bkey_i *k = bch2_trans_kmalloc(trans, sizeof(*k));
 	int ret = PTR_ERR_OR_ZERO(k);
@@ -684,12 +685,12 @@ int bch2_btree_delete_at(struct btree_trans *trans,
 
 	bkey_init(&k->k);
 	k->k.p = iter->pos;
-	return bch2_trans_update(trans, iter, k, update_flags);
+	return bch2_trans_update(trans, iter, k, flags);
 }
 
 int bch2_btree_delete(struct btree_trans *trans,
 		      enum btree_id btree, struct bpos pos,
-		      unsigned update_flags)
+		      enum btree_iter_update_trigger_flags flags)
 {
 	struct btree_iter iter;
 	int ret;
@@ -698,7 +699,7 @@ int bch2_btree_delete(struct btree_trans *trans,
 			     BTREE_ITER_cached|
 			     BTREE_ITER_intent);
 	ret   = bch2_btree_iter_traverse(trans, &iter) ?:
-		bch2_btree_delete_at(trans, &iter, update_flags);
+		bch2_btree_delete_at(trans, &iter, flags);
 	bch2_trans_iter_exit(trans, &iter);
 
 	return ret;
@@ -706,7 +707,7 @@ int bch2_btree_delete(struct btree_trans *trans,
 
 int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
 				  struct bpos start, struct bpos end,
-				  unsigned update_flags,
+				  enum btree_iter_update_trigger_flags flags,
 				  u64 *journal_seq)
 {
 	u32 restart_count = trans->restart_count;
@@ -714,7 +715,7 @@ int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
 	struct bkey_s_c k;
 	int ret = 0;
 
-	bch2_trans_iter_init(trans, &iter, id, start, BTREE_ITER_intent);
+	bch2_trans_iter_init(trans, &iter, id, start, BTREE_ITER_intent|flags);
 	while ((k = bch2_btree_iter_peek_max(trans, &iter, end)).k) {
 		struct disk_reservation disk_res =
 			bch2_disk_reservation_init(trans->c, 0);
@@ -747,7 +748,7 @@ int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
 					bpos_min(end, k.k->p).offset -
 					iter.pos.offset);
 
-		ret   = bch2_trans_update(trans, &iter, &delete, update_flags) ?:
+		ret   = bch2_trans_update(trans, &iter, &delete, flags) ?:
 			bch2_trans_commit(trans, &disk_res, journal_seq,
 					  BCH_TRANS_COMMIT_no_enospc);
 		bch2_disk_reservation_put(trans->c, &disk_res);
@@ -777,12 +778,12 @@ int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
  */
 int bch2_btree_delete_range(struct bch_fs *c, enum btree_id id,
 			    struct bpos start, struct bpos end,
-			    unsigned update_flags,
+			    enum btree_iter_update_trigger_flags flags,
 			    u64 *journal_seq)
 {
 	int ret = bch2_trans_run(c,
 			bch2_btree_delete_range_trans(trans, id, start, end,
-						      update_flags, journal_seq));
+						      flags, journal_seq));
 	if (ret == -BCH_ERR_transaction_restart_nested)
 		ret = 0;
 	return ret;
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 2c6f9b44d888..222a9f8ffbd5 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -47,22 +47,27 @@ enum bch_trans_commit_flags {
 
 void bch2_trans_commit_flags_to_text(struct printbuf *, enum bch_trans_commit_flags);
 
-int bch2_btree_delete_at(struct btree_trans *, struct btree_iter *, unsigned);
-int bch2_btree_delete(struct btree_trans *, enum btree_id, struct bpos, unsigned);
+int bch2_btree_delete_at(struct btree_trans *, struct btree_iter *,
+			 enum btree_iter_update_trigger_flags);
+int bch2_btree_delete(struct btree_trans *, enum btree_id, struct bpos,
+		      enum btree_iter_update_trigger_flags);
 
 int bch2_btree_insert_nonextent(struct btree_trans *, enum btree_id,
 				struct bkey_i *, enum btree_iter_update_trigger_flags);
 
 int bch2_btree_insert_trans(struct btree_trans *, enum btree_id, struct bkey_i *,
 			enum btree_iter_update_trigger_flags);
-int bch2_btree_insert(struct bch_fs *, enum btree_id, struct bkey_i *, struct
-		disk_reservation *, int flags, enum
-		btree_iter_update_trigger_flags iter_flags);
+int bch2_btree_insert(struct bch_fs *, enum btree_id, struct bkey_i *,
+		      struct disk_reservation *,
+		      enum bch_trans_commit_flags,
+		      enum btree_iter_update_trigger_flags);
 
 int bch2_btree_delete_range_trans(struct btree_trans *, enum btree_id,
-				  struct bpos, struct bpos, unsigned, u64 *);
+				  struct bpos, struct bpos,
+				  enum btree_iter_update_trigger_flags, u64 *);
 int bch2_btree_delete_range(struct bch_fs *, enum btree_id,
-			    struct bpos, struct bpos, unsigned, u64 *);
+			    struct bpos, struct bpos,
+			    enum btree_iter_update_trigger_flags, u64 *);
 
 int bch2_btree_bit_mod_iter(struct btree_trans *, struct btree_iter *, bool);
 int bch2_btree_bit_mod(struct btree_trans *, enum btree_id, struct bpos, bool);
@@ -226,7 +231,7 @@ static inline int __must_check bch2_trans_update_buffered(struct btree_trans *tr
 
 void bch2_trans_commit_hook(struct btree_trans *,
 			    struct btree_trans_commit_hook *);
-int __bch2_trans_commit(struct btree_trans *, unsigned);
+int __bch2_trans_commit(struct btree_trans *, enum bch_trans_commit_flags);
 
 int bch2_trans_log_str(struct btree_trans *, const char *);
 int bch2_trans_log_msg(struct btree_trans *, struct printbuf *);
-- 
2.51.0


From e8c2932923c0766750bd2bb69f99e987beef7dc3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 6 Jul 2025 14:31:56 -0400
Subject: [PATCH 041/309] bcachefs: add missing log message newline

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-members.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/fs/bcachefs/sb-members.c b/fs/bcachefs/sb-members.c
index f2abe92ca130..340d4fb7f9b6 100644
--- a/fs/bcachefs/sb-members.c
+++ b/fs/bcachefs/sb-members.c
@@ -20,6 +20,7 @@ int bch2_dev_missing_bkey(struct bch_fs *c, struct bkey_s_c k, unsigned dev)
 	prt_printf(&buf, "pointer to %s device %u in key\n",
 		   removed ? "removed" : "nonexistent", dev);
 	bch2_bkey_val_to_text(&buf, c, k);
+	prt_newline(&buf);
 
 	bool print = removed
 		? bch2_count_fsck_err(c, ptr_to_removed_device, &buf)
-- 
2.51.0


From fbef71e48f56c80f9adbdb817fa0ee6595438e2c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 6 Jul 2025 14:43:56 -0400
Subject: [PATCH 042/309] bcachefs: add missing includes

Fix userspace debug build

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 1 +
 fs/bcachefs/io_write.c | 1 +
 2 files changed, 2 insertions(+)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index efe4183d3e13..064627a29883 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -24,6 +24,7 @@
 #include "super-io.h"
 #include "trace.h"
 
+#include <linux/moduleparam.h>
 #include <linux/sched/mm.h>
 
 #ifdef CONFIG_BCACHEFS_DEBUG
diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index 88b1eec8eff3..fa077341d2ef 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -32,6 +32,7 @@
 #include "trace.h"
 
 #include <linux/blkdev.h>
+#include <linux/moduleparam.h>
 #include <linux/prefetch.h>
 #include <linux/random.h>
 #include <linux/sched/mm.h>
-- 
2.51.0


From 021bd7cfc17c957ee980c56f6dca9afd9a5e1c3b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 6 Jul 2025 14:47:12 -0400
Subject: [PATCH 043/309] bcachefs: silence userspace build warning

printk won't crash if you feed it a null pointer for a %s argument, but
glibc printf will

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 77d93beb3c8f..bc277f42cf5f 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -144,7 +144,8 @@ static noinline int backpointer_mod_err(struct btree_trans *trans,
 	if (!will_check && __bch2_inconsistent_error(c, &buf))
 		ret = bch_err_throw(c, erofs_unfixed_errors);
 
-	bch_err(c, "%s", buf.buf);
+	if (buf.buf)
+		bch_err(c, "%s", buf.buf);
 	printbuf_exit(&buf);
 	return ret;
 }
-- 
2.51.0


From 9f44940ba17c8e2505f8bffef06cfc60ec2e63a1 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 20 Jun 2025 17:43:47 -0400
Subject: [PATCH 044/309] bcachefs: trace_data_update_done_no_rw_devs

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/data_update.c | 13 +++++++++++--
 fs/bcachefs/trace.h       |  5 +++++
 2 files changed, 16 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index e848e210a9bf..3968f3be7f3b 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -783,6 +783,9 @@ static int can_write_extent(struct bch_fs *c, struct data_update *m)
 	darray_for_each(m->op.devs_have, i)
 		__clear_bit(*i, devs.d);
 
+	CLASS(printbuf, buf)();
+	buf.atomic++;
+
 	guard(rcu)();
 
 	unsigned nr_replicas = 0, i;
@@ -794,7 +797,11 @@ static int can_write_extent(struct bch_fs *c, struct data_update *m)
 		struct bch_dev_usage usage;
 		bch2_dev_usage_read_fast(ca, &usage);
 
-		if (!dev_buckets_free(ca, usage, m->op.watermark))
+		u64 nr_free = dev_buckets_free(ca, usage, m->op.watermark);
+
+		prt_printf(&buf, "%s=%llu ", ca->name, nr_free);
+
+		if (!nr_free)
 			continue;
 
 		nr_replicas += ca->mi.durability;
@@ -802,8 +809,10 @@ static int can_write_extent(struct bch_fs *c, struct data_update *m)
 			break;
 	}
 
-	if (!nr_replicas)
+	if (!nr_replicas) {
+		trace_data_update_done_no_rw_devs(c, buf.buf);
 		return bch_err_throw(c, data_update_done_no_rw_devs);
+	}
 	if (nr_replicas < m->op.nr_replicas)
 		return bch_err_throw(c, insufficient_devices);
 	return 0;
diff --git a/fs/bcachefs/trace.h b/fs/bcachefs/trace.h
index b5dae1145afa..9324ef32903d 100644
--- a/fs/bcachefs/trace.h
+++ b/fs/bcachefs/trace.h
@@ -1330,6 +1330,11 @@ DEFINE_EVENT(fs_str, data_update,
 	TP_ARGS(c, str)
 );
 
+DEFINE_EVENT(fs_str, data_update_done_no_rw_devs,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
+);
+
 DEFINE_EVENT(fs_str, io_move_pred,
 	TP_PROTO(struct bch_fs *c, const char *str),
 	TP_ARGS(c, str)
-- 
2.51.0


From 0a5433f43076894575113eeb222ff1d2401ce20e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 7 Jul 2025 14:03:31 -0400
Subject: [PATCH 045/309] bcachefs: use kvzalloc() for journal bios
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

We can write quite large journal entries.

It's possible that JOURNAL_ENTRY_SIZE_MAX is far larger than it needs to
be and should be reduced to something more reasonable (1-2MB), but
performance can be sensitive to anything that affects journal
pipelining - we've had issues there in the past, so we shouldn't change
that without first doing performance testing.

For now, apply the simple fix to deal with the following, which caused a
mount to fail:

[43579.348135] mount.bcachefs: page allocation failure: order:5, mode:0x40dc0(GFP_KERNEL|__GFP_ZERO|__GFP_COMP), nodemask=(null),cpuset=openrc.sshd,mems_allowed=0
[43579.349792] CPU: 3 UID: 0 PID: 14702 Comm: mount.bcachefs Tainted: G     U              6.16.0-rc4 #18 VOLUNTARY
[43579.349798] Tainted: [U]=USER
[43579.349799] Hardware name: MSI MS-7982/B150M PRO-VDH (MS-7982), BIOS 3.H0 07/10/2018
[43579.349800] Call Trace:
[43579.349803]  <TASK>
[43579.349806] dump_stack_lvl (lib/dump_stack.c:122)
[43579.349814] warn_alloc (mm/page_alloc.c:3744)
[43579.349821] ? __alloc_pages_direct_compact (./arch/x86/include/asm/jump_label.h:36 ./include/linux/delayacct.h:211 mm/page_alloc.c:3882)
[43579.349827] __alloc_pages_slowpath.constprop.0 (mm/page_alloc.c:4699)
[43579.349833] __alloc_frozen_pages_noprof (mm/page_alloc.c:4972)
[43579.349838] __alloc_pages_noprof (mm/page_alloc.c:4994)
[43579.349843] ___kmalloc_large_node (./include/linux/gfp.h:284 ./include/linux/gfp.h:311 mm/slub.c:4272)
[43579.349848] __kmalloc_large_noprof (./arch/x86/include/asm/bitops.h:414 ./include/asm-generic/getorder.h:46 mm/slub.c:4292)
[43579.349852] bch2_dev_journal_init (fs/bcachefs/journal.c:1629 (discriminator 4))
[43579.349857] __bch2_dev_attach_bdev (fs/bcachefs/super.c:1588)
[43579.349861] ? kernfs_create_link (fs/kernfs/symlink.c:48)
[43579.349865] bch2_dev_attach_bdev (fs/bcachefs/super.c:1630)
[43579.349868] bch2_fs_open (fs/bcachefs/super.c:2440)
[43579.349874] bch2_fs_get_tree (fs/bcachefs/fs.c:2474)
[43579.349880] vfs_get_tree (fs/super.c:1805)

Reported-by: Marcin Mirosaw <marcin@mejor.pl>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c | 13 +++++++++++--
 1 file changed, 11 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index 014adbcb404b..ddbffd455c65 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -1593,7 +1593,7 @@ void bch2_dev_journal_exit(struct bch_dev *ca)
 	struct journal_device *ja = &ca->journal;
 
 	for (unsigned i = 0; i < ARRAY_SIZE(ja->bio); i++) {
-		kfree(ja->bio[i]);
+		kvfree(ja->bio[i]);
 		ja->bio[i] = NULL;
 	}
 
@@ -1630,7 +1630,16 @@ int bch2_dev_journal_init(struct bch_dev *ca, struct bch_sb *sb)
 	unsigned nr_bvecs = DIV_ROUND_UP(JOURNAL_ENTRY_SIZE_MAX, PAGE_SIZE);
 
 	for (unsigned i = 0; i < ARRAY_SIZE(ja->bio); i++) {
-		ja->bio[i] = kzalloc(struct_size(ja->bio[i], bio.bi_inline_vecs,
+		/*
+		 * kvzalloc() is not what we want to be using here:
+		 * JOURNAL_ENTRY_SIZE_MAX is probably quite a bit bigger than it
+		 * needs to be.
+		 *
+		 * But changing that will require performance testing -
+		 * performance can be sensitive to anything that affects journal
+		 * pipelining.
+		 */
+		ja->bio[i] = kvzalloc(struct_size(ja->bio[i], bio.bi_inline_vecs,
 				     nr_bvecs), GFP_KERNEL);
 		if (!ja->bio[i])
 			return bch_err_throw(c, ENOMEM_dev_journal_init);
-- 
2.51.0


From 6e22d849f2c5139fa8dc9ed68a5077b7d29e6d5d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 7 Jul 2025 14:42:04 -0400
Subject: [PATCH 046/309] bcachefs: Improve nopromote visibility

io_read_nopromote was missing a counter: generally speaking, every
tracepoint should have a matching persistent counter, and vice-versa.

Additionally, improve the tracepoint - switch it to the more modern
fs_str and generate the output with a printbuf, which is much easier to
extend later.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.c            | 11 ++++++++++-
 fs/bcachefs/sb-counters_format.h |  1 +
 fs/bcachefs/trace.h              | 20 +++-----------------
 3 files changed, 14 insertions(+), 18 deletions(-)

diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index e0874ad9a6cf..d07d28ab6724 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -350,7 +350,16 @@ static struct bch_read_bio *promote_alloc(struct btree_trans *trans,
 
 	return promote;
 nopromote:
-	trace_io_read_nopromote(c, ret);
+	if (trace_io_read_nopromote_enabled()) {
+		CLASS(printbuf, buf)();
+		printbuf_indent_add_nextline(&buf, 2);
+		prt_printf(&buf, "%s\n", bch2_err_str(ret));
+		bch2_bkey_val_to_text(&buf, c, k);
+
+		trace_io_read_nopromote(c, buf.buf);
+	}
+	count_event(c, io_read_nopromote);
+
 	return NULL;
 }
 
diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index b868702a431a..a59b2a10659e 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -12,6 +12,7 @@ enum counters_flags {
 	x(io_read_inline,				80,	TYPE_SECTORS)	\
 	x(io_read_hole,					81,	TYPE_SECTORS)	\
 	x(io_read_promote,				30,	TYPE_COUNTER)	\
+	x(io_read_nopromote,				85,	TYPE_COUNTER)	\
 	x(io_read_bounce,				31,	TYPE_COUNTER)	\
 	x(io_read_split,				33,	TYPE_COUNTER)	\
 	x(io_read_reuse_race,				34,	TYPE_COUNTER)	\
diff --git a/fs/bcachefs/trace.h b/fs/bcachefs/trace.h
index 9324ef32903d..3776a1403104 100644
--- a/fs/bcachefs/trace.h
+++ b/fs/bcachefs/trace.h
@@ -292,23 +292,9 @@ DEFINE_EVENT(bio, io_read_promote,
 	TP_ARGS(bio)
 );
 
-TRACE_EVENT(io_read_nopromote,
-	TP_PROTO(struct bch_fs *c, int ret),
-	TP_ARGS(c, ret),
-
-	TP_STRUCT__entry(
-		__field(dev_t,		dev		)
-		__array(char,		ret, 32		)
-	),
-
-	TP_fast_assign(
-		__entry->dev		= c->dev;
-		strscpy(__entry->ret, bch2_err_str(ret), sizeof(__entry->ret));
-	),
-
-	TP_printk("%d,%d ret %s",
-		  MAJOR(__entry->dev), MINOR(__entry->dev),
-		  __entry->ret)
+DEFINE_EVENT(fs_str, io_read_nopromote,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
 );
 
 DEFINE_EVENT(bio, io_read_bounce,
-- 
2.51.0


From 5b106f3c5bf158e1ed34879050cd7932022d1fde Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 7 Jul 2025 20:07:07 -0400
Subject: [PATCH 047/309] bcachefs: unsigned -> enum bch_trans_commit_flags

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update_interior.c | 15 +++++++++------
 fs/bcachefs/btree_update_interior.h | 12 ++++++++----
 2 files changed, 17 insertions(+), 10 deletions(-)

diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 8e3d3db2c53b..8084ca2dde3c 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -285,7 +285,7 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 					     struct closure *cl,
 					     bool interior_node,
 					     unsigned target,
-					     unsigned flags)
+					     enum bch_trans_commit_flags flags)
 {
 	struct bch_fs *c = trans->c;
 	struct write_point *wp;
@@ -1139,7 +1139,8 @@ static const char * const btree_node_reawrite_reason_strs[] = {
 static struct btree_update *
 bch2_btree_update_start(struct btree_trans *trans, struct btree_path *path,
 			unsigned level_start, bool split,
-			unsigned target, unsigned flags)
+			unsigned target,
+			enum bch_trans_commit_flags flags)
 {
 	struct bch_fs *c = trans->c;
 	struct btree_update *as;
@@ -2222,7 +2223,7 @@ int bch2_btree_node_rewrite(struct btree_trans *trans,
 			    struct btree_iter *iter,
 			    struct btree *b,
 			    unsigned target,
-			    unsigned flags)
+			    enum bch_trans_commit_flags flags)
 {
 	struct bch_fs *c = trans->c;
 	struct btree *n, *parent;
@@ -2287,7 +2288,8 @@ int bch2_btree_node_rewrite(struct btree_trans *trans,
 
 int bch2_btree_node_rewrite_key(struct btree_trans *trans,
 				enum btree_id btree, unsigned level,
-				struct bkey_i *k, unsigned flags)
+				struct bkey_i *k,
+				enum bch_trans_commit_flags flags)
 {
 	struct btree_iter iter;
 	bch2_trans_node_iter_init(trans, &iter,
@@ -2311,7 +2313,7 @@ int bch2_btree_node_rewrite_pos(struct btree_trans *trans,
 				enum btree_id btree, unsigned level,
 				struct bpos pos,
 				unsigned target,
-				unsigned flags)
+				enum bch_trans_commit_flags flags)
 {
 	BUG_ON(!level);
 
@@ -2330,7 +2332,8 @@ int bch2_btree_node_rewrite_pos(struct btree_trans *trans,
 }
 
 int bch2_btree_node_rewrite_key_get_iter(struct btree_trans *trans,
-					 struct btree *b, unsigned flags)
+					 struct btree *b,
+					 enum bch_trans_commit_flags flags)
 {
 	struct btree_iter iter;
 	int ret = get_iter_to_node(trans, &iter, b);
diff --git a/fs/bcachefs/btree_update_interior.h b/fs/bcachefs/btree_update_interior.h
index ac04e45a8515..6ed049f19a9a 100644
--- a/fs/bcachefs/btree_update_interior.h
+++ b/fs/bcachefs/btree_update_interior.h
@@ -175,15 +175,19 @@ static inline int bch2_foreground_maybe_merge(struct btree_trans *trans,
 }
 
 int bch2_btree_node_rewrite(struct btree_trans *, struct btree_iter *,
-			    struct btree *, unsigned, unsigned);
+			    struct btree *, unsigned,
+			    enum bch_trans_commit_flags);
 int bch2_btree_node_rewrite_key(struct btree_trans *,
 				enum btree_id, unsigned,
-				struct bkey_i *, unsigned);
+				struct bkey_i *,
+				enum bch_trans_commit_flags);
 int bch2_btree_node_rewrite_pos(struct btree_trans *,
 				enum btree_id, unsigned,
-				struct bpos, unsigned, unsigned);
+				struct bpos, unsigned,
+				enum bch_trans_commit_flags);
 int bch2_btree_node_rewrite_key_get_iter(struct btree_trans *,
-					 struct btree *, unsigned);
+					 struct btree *,
+					 enum bch_trans_commit_flags);
 
 void bch2_btree_node_rewrite_async(struct bch_fs *, struct btree *);
 
-- 
2.51.0


From 54da05446d2b4eaab1f3913d93e29c90c7787376 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 7 Jul 2025 20:07:37 -0400
Subject: [PATCH 048/309] bcachefs: __bch2_btree_node_alloc() now respects
 target

cmd_image in bcachefs-tools now requires that btree node allocation
strictly respects target when specified; allocating from the cache
wasn't obeying this.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update_interior.c | 19 ++++++++++++-------
 fs/bcachefs/extents.c               | 12 ++++++++++++
 fs/bcachefs/extents.h               |  1 +
 3 files changed, 25 insertions(+), 7 deletions(-)

diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 8084ca2dde3c..ebdb4d2f1be9 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -305,13 +305,18 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 
 	mutex_lock(&c->btree_reserve_cache_lock);
 	if (c->btree_reserve_cache_nr > nr_reserve) {
-		struct btree_alloc *a =
-			&c->btree_reserve_cache[--c->btree_reserve_cache_nr];
-
-		bkey_copy(&b->key, &a->k);
-		b->ob = a->ob;
-		mutex_unlock(&c->btree_reserve_cache_lock);
-		goto out;
+		for (struct btree_alloc *a = c->btree_reserve_cache;
+		     a < c->btree_reserve_cache + c->btree_reserve_cache_nr;
+		     a++) {
+			if (target && !bch2_bkey_in_target(c, bkey_i_to_s_c(&a->k), target))
+				continue;
+
+			bkey_copy(&b->key, &a->k);
+			b->ob = a->ob;
+			*a = c->btree_reserve_cache[--c->btree_reserve_cache_nr];
+			mutex_unlock(&c->btree_reserve_cache_lock);
+			goto out;
+		}
 	}
 	mutex_unlock(&c->btree_reserve_cache_lock);
 retry:
diff --git a/fs/bcachefs/extents.c b/fs/bcachefs/extents.c
index 83cbd77dcb9c..ec0951fbddea 100644
--- a/fs/bcachefs/extents.c
+++ b/fs/bcachefs/extents.c
@@ -1023,6 +1023,18 @@ bool bch2_bkey_has_target(struct bch_fs *c, struct bkey_s_c k, unsigned target)
 	return false;
 }
 
+bool bch2_bkey_in_target(struct bch_fs *c, struct bkey_s_c k, unsigned target)
+{
+	struct bkey_ptrs_c ptrs = bch2_bkey_ptrs_c(k);
+
+	guard(rcu)();
+	bkey_for_each_ptr(ptrs, ptr)
+		if (!bch2_dev_in_target(c, ptr->dev, target))
+			return false;
+
+	return true;
+}
+
 bool bch2_bkey_matches_ptr(struct bch_fs *c, struct bkey_s_c k,
 			   struct bch_extent_ptr m, u64 offset)
 {
diff --git a/fs/bcachefs/extents.h b/fs/bcachefs/extents.h
index b8590e51b76e..f212f91c278d 100644
--- a/fs/bcachefs/extents.h
+++ b/fs/bcachefs/extents.h
@@ -615,6 +615,7 @@ static inline struct bch_extent_ptr *bch2_bkey_has_device(struct bkey_s k, unsig
 }
 
 bool bch2_bkey_has_target(struct bch_fs *, struct bkey_s_c, unsigned);
+bool bch2_bkey_in_target(struct bch_fs *, struct bkey_s_c, unsigned);
 
 void bch2_bkey_extent_entry_drop(struct bkey_i *, union bch_extent_entry *);
 
-- 
2.51.0


From fa815a793db79b3a56f10ee11fd988cbdc6973e7 Mon Sep 17 00:00:00 2001
From: George Hu <integral@archlinux.org>
Date: Tue, 17 Jun 2025 15:00:36 +0800
Subject: [PATCH 049/309] bcachefs: use union for bch_compression_opt to make
 encode & decode easier

Eliminate redundant encode & decode function by using union for
bch_compression_opt, which reduces code complexity.

Signed-off-by: George Hu <integral@archlinux.org>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/compress.c | 17 +++++++++--------
 fs/bcachefs/compress.h | 36 +++++++++++-------------------------
 fs/bcachefs/extents.c  |  2 +-
 3 files changed, 21 insertions(+), 34 deletions(-)

diff --git a/fs/bcachefs/compress.c b/fs/bcachefs/compress.c
index b37b1f325f0a..5f74de920c92 100644
--- a/fs/bcachefs/compress.c
+++ b/fs/bcachefs/compress.c
@@ -336,7 +336,7 @@ static int attempt_compress(struct bch_fs *c,
 			    void *workspace,
 			    void *dst, size_t dst_len,
 			    void *src, size_t src_len,
-			    struct bch_compression_opt compression)
+			    union bch_compression_opt compression)
 {
 	enum bch_compression_type compression_type =
 		__bch2_compression_opt_to_type[compression.type];
@@ -426,7 +426,7 @@ static int attempt_compress(struct bch_fs *c,
 static unsigned __bio_compress(struct bch_fs *c,
 			       struct bio *dst, size_t *dst_len,
 			       struct bio *src, size_t *src_len,
-			       struct bch_compression_opt compression)
+			       union bch_compression_opt compression)
 {
 	struct bbuf src_data = { NULL }, dst_data = { NULL };
 	void *workspace;
@@ -553,7 +553,7 @@ unsigned bch2_bio_compress(struct bch_fs *c,
 
 	compression_type =
 		__bio_compress(c, dst, dst_len, src, src_len,
-			       bch2_compression_decode(compression_opt));
+			       (union bch_compression_opt){ .value = compression_opt });
 
 	dst->bi_iter.bi_size = orig_dst;
 	src->bi_iter.bi_size = orig_src;
@@ -602,7 +602,8 @@ static int __bch2_check_set_has_compressed_data(struct bch_fs *c, u64 f)
 int bch2_check_set_has_compressed_data(struct bch_fs *c,
 				       unsigned compression_opt)
 {
-	unsigned compression_type = bch2_compression_decode(compression_opt).type;
+	unsigned int compression_type = ((union bch_compression_opt){ .value = compression_opt })
+					.type;
 
 	BUG_ON(compression_type >= ARRAY_SIZE(bch2_compression_opt_to_feature));
 
@@ -683,7 +684,7 @@ static int __bch2_fs_compress_init(struct bch_fs *c, u64 features)
 
 static u64 compression_opt_to_feature(unsigned v)
 {
-	unsigned type = bch2_compression_decode(v).type;
+	unsigned int type = ((union bch_compression_opt){ .value = v }).type;
 
 	return BIT_ULL(bch2_compression_opt_to_feature[type]);
 }
@@ -703,7 +704,7 @@ int bch2_opt_compression_parse(struct bch_fs *c, const char *_val, u64 *res,
 {
 	char *val = kstrdup(_val, GFP_KERNEL);
 	char *p = val, *type_str, *level_str;
-	struct bch_compression_opt opt = { 0 };
+	union bch_compression_opt opt = { 0 };
 	int ret;
 
 	if (!val)
@@ -736,7 +737,7 @@ int bch2_opt_compression_parse(struct bch_fs *c, const char *_val, u64 *res,
 		opt.level = level;
 	}
 
-	*res = bch2_compression_encode(opt);
+	*res = opt.value;
 err:
 	kfree(val);
 	return ret;
@@ -744,7 +745,7 @@ int bch2_opt_compression_parse(struct bch_fs *c, const char *_val, u64 *res,
 
 void bch2_compression_opt_to_text(struct printbuf *out, u64 v)
 {
-	struct bch_compression_opt opt = bch2_compression_decode(v);
+	union bch_compression_opt opt = { .value = v };
 
 	if (opt.type < BCH_COMPRESSION_OPT_NR)
 		prt_str(out, bch2_compression_opts[opt.type]);
diff --git a/fs/bcachefs/compress.h b/fs/bcachefs/compress.h
index bec2f05bfd52..667ddb91d47a 100644
--- a/fs/bcachefs/compress.h
+++ b/fs/bcachefs/compress.h
@@ -10,41 +10,27 @@ static const unsigned __bch2_compression_opt_to_type[] = {
 #undef x
 };
 
-struct bch_compression_opt {
-	u8		type:4,
-			level:4;
-};
-
-static inline struct bch_compression_opt __bch2_compression_decode(unsigned v)
-{
-	return (struct bch_compression_opt) {
-		.type	= v & 15,
-		.level	= v >> 4,
+union bch_compression_opt {
+	u8 value;
+	struct {
+#if defined(__LITTLE_ENDIAN_BITFIELD)
+		u8 type:4, level:4;
+#elif defined(__BIG_ENDIAN_BITFIELD)
+		u8 level:4, type:4;
+#endif
 	};
-}
+};
 
 static inline bool bch2_compression_opt_valid(unsigned v)
 {
-	struct bch_compression_opt opt = __bch2_compression_decode(v);
+	union bch_compression_opt opt = { .value = v };
 
 	return opt.type < ARRAY_SIZE(__bch2_compression_opt_to_type) && !(!opt.type && opt.level);
 }
 
-static inline struct bch_compression_opt bch2_compression_decode(unsigned v)
-{
-	return bch2_compression_opt_valid(v)
-		? __bch2_compression_decode(v)
-		: (struct bch_compression_opt) { 0 };
-}
-
-static inline unsigned bch2_compression_encode(struct bch_compression_opt opt)
-{
-	return opt.type|(opt.level << 4);
-}
-
 static inline enum bch_compression_type bch2_compression_opt_to_type(unsigned v)
 {
-	return __bch2_compression_opt_to_type[bch2_compression_decode(v).type];
+	return __bch2_compression_opt_to_type[((union bch_compression_opt){ .value = v }).type];
 }
 
 struct bch_write_op;
diff --git a/fs/bcachefs/extents.c b/fs/bcachefs/extents.c
index ec0951fbddea..a286bd994101 100644
--- a/fs/bcachefs/extents.c
+++ b/fs/bcachefs/extents.c
@@ -1524,7 +1524,7 @@ int bch2_bkey_ptrs_validate(struct bch_fs *c, struct bkey_s_c k,
 			const struct bch_extent_rebalance *r = &entry->rebalance;
 
 			if (!bch2_compression_opt_valid(r->compression)) {
-				struct bch_compression_opt opt = __bch2_compression_decode(r->compression);
+				union bch_compression_opt opt = { .value = r->compression };
 				prt_printf(err, "invalid compression opt %u:%u",
 					   opt.type, opt.level);
 				return bch_err_throw(c, invalid_bkey);
-- 
2.51.0


From a2522c8f4e40627d3e9d3ba37f27d9591cfa9190 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 8 Jul 2025 21:27:59 -0400
Subject: [PATCH 050/309] bcachefs: bch2_btree_write_buffer_insert_checks()

Consolidate write buffer consistency checks.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update.h       | 24 +++++++++++++++++-------
 fs/bcachefs/btree_write_buffer.c |  5 ++---
 fs/bcachefs/btree_write_buffer.h |  6 ++----
 3 files changed, 21 insertions(+), 14 deletions(-)

diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 222a9f8ffbd5..8e91b9f143d8 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -191,19 +191,29 @@ int bch2_btree_insert_clone_trans(struct btree_trans *, enum btree_id, struct bk
 
 int bch2_btree_write_buffer_insert_err(struct bch_fs *, enum btree_id, struct bkey_i *);
 
+static inline int bch2_btree_write_buffer_insert_checks(struct bch_fs *c, enum btree_id btree,
+							struct bkey_i *k)
+{
+	if (unlikely(!btree_type_uses_write_buffer(btree) ||
+		     k->k.u64s > BTREE_WRITE_BUFERED_U64s_MAX)) {
+		int ret = bch2_btree_write_buffer_insert_err(c, btree, k);
+		dump_stack();
+		return ret;
+	}
+
+	return 0;
+}
+
 static inline int __must_check bch2_trans_update_buffered(struct btree_trans *trans,
 					    enum btree_id btree,
 					    struct bkey_i *k)
 {
 	kmsan_check_memory(k, bkey_bytes(&k->k));
 
-	EBUG_ON(k->k.u64s > BTREE_WRITE_BUFERED_U64s_MAX);
-
-	if (unlikely(!btree_type_uses_write_buffer(btree))) {
-		int ret = bch2_btree_write_buffer_insert_err(trans->c, btree, k);
-		dump_stack();
+	int ret = bch2_btree_write_buffer_insert_checks(trans->c, btree, k);
+	if (unlikely(ret))
 		return ret;
-	}
+
 	/*
 	 * Most updates skip the btree write buffer until journal replay is
 	 * finished because synchronization with journal replay relies on having
@@ -220,7 +230,7 @@ static inline int __must_check bch2_trans_update_buffered(struct btree_trans *tr
 		return bch2_btree_insert_clone_trans(trans, btree, k);
 
 	struct jset_entry *e = bch2_trans_jset_entry_alloc(trans, jset_u64s(k->k.u64s));
-	int ret = PTR_ERR_OR_ZERO(e);
+	ret = PTR_ERR_OR_ZERO(e);
 	if (ret)
 		return ret;
 
diff --git a/fs/bcachefs/btree_write_buffer.c b/fs/bcachefs/btree_write_buffer.c
index 4b095235a0d2..c897167820e4 100644
--- a/fs/bcachefs/btree_write_buffer.c
+++ b/fs/bcachefs/btree_write_buffer.c
@@ -330,10 +330,9 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 	darray_for_each(wb->sorted, i) {
 		struct btree_write_buffered_key *k = &wb->flushing.keys.data[i->idx];
 
-		if (unlikely(!btree_type_uses_write_buffer(k->btree))) {
-			ret = bch2_btree_write_buffer_insert_err(trans->c, k->btree, &k->k);
+		ret = bch2_btree_write_buffer_insert_checks(c, k->btree, &k->k);
+		if (unlikely(ret))
 			goto err;
-		}
 
 		for (struct wb_key_ref *n = i + 1; n < min(i + 4, &darray_top(wb->sorted)); n++)
 			prefetch(&wb->flushing.keys.data[n->idx]);
diff --git a/fs/bcachefs/btree_write_buffer.h b/fs/bcachefs/btree_write_buffer.h
index c351d21aca0b..e484cd6b90b0 100644
--- a/fs/bcachefs/btree_write_buffer.h
+++ b/fs/bcachefs/btree_write_buffer.h
@@ -89,11 +89,9 @@ static inline int bch2_journal_key_to_wb(struct bch_fs *c,
 			     struct journal_keys_to_wb *dst,
 			     enum btree_id btree, struct bkey_i *k)
 {
-	if (unlikely(!btree_type_uses_write_buffer(btree))) {
-		int ret = bch2_btree_write_buffer_insert_err(c, btree, k);
-		dump_stack();
+	int ret = bch2_btree_write_buffer_insert_checks(c, btree, k);
+	if (unlikely(ret))
 		return ret;
-	}
 
 	EBUG_ON(!dst->seq);
 
-- 
2.51.0


From b443fc25b1e1b3f8c765a6bbadcd70618a15e9f4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 9 Jul 2025 00:35:52 -0400
Subject: [PATCH 051/309] bcachefs: don't call get_update_rebalance_opts() on
 btree ptrs

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/move.c | 5 ++---
 1 file changed, 2 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index eec591e947bd..0739287a61fe 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -468,7 +468,7 @@ struct bch_io_opts *bch2_move_get_io_opts(struct btree_trans *trans,
 	struct bch_io_opts *opts_ret = &io_opts->fs_io_opts;
 	int ret = 0;
 
-	if (extent_iter->min_depth)
+	if (btree_iter_path(trans, extent_iter)->level)
 		return opts_ret;
 
 	if (extent_k.k->type == KEY_TYPE_reflink_v)
@@ -672,8 +672,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 
 		k = bkey_i_to_s_c(&b->key);
 
-		io_opts = bch2_move_get_io_opts(trans, &snapshot_io_opts,
-						iter.pos, &iter, k);
+		io_opts = &snapshot_io_opts.fs_io_opts;
 		ret = PTR_ERR_OR_ZERO(io_opts);
 		if (ret)
 			goto root_err;
-- 
2.51.0


From 79adb746d98cb54f1b43dcdb8f01510b68ff26b4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 10 Jul 2025 16:20:36 -0400
Subject: [PATCH 052/309] bcachefs: kill bch2_err_str() BUG_ON()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/errcode.c | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/errcode.c b/fs/bcachefs/errcode.c
index c39cf304c681..86264b8c343c 100644
--- a/fs/bcachefs/errcode.c
+++ b/fs/bcachefs/errcode.c
@@ -26,7 +26,8 @@ const char *bch2_err_str(int err)
 
 	err = abs(err);
 
-	BUG_ON(err >= BCH_ERR_MAX);
+	if (err >= BCH_ERR_MAX)
+		return "(Invalid error)";
 
 	if (err >= BCH_ERR_START)
 		errstr = bch2_errcode_strs[err - BCH_ERR_START];
-- 
2.51.0


From 312a12c580c9067a924b996bda20648c11747bb4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 9 Jul 2025 23:31:19 -0400
Subject: [PATCH 053/309] bcachefs: bch2_read_bio_to_text(): tabstops

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.c | 7 +++++--
 1 file changed, 5 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index d07d28ab6724..af5b91d85999 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -1488,9 +1488,12 @@ static const char * const bch2_read_bio_flags[] = {
 
 void bch2_read_bio_to_text(struct printbuf *out, struct bch_read_bio *rbio)
 {
+	if (!out->nr_tabstops)
+		printbuf_tabstop_push(out, 20);
+
 	u64 now = local_clock();
-	prt_printf(out, "start_time:\t%llu\n", rbio->start_time ? now - rbio->start_time : 0);
-	prt_printf(out, "submit_time:\t%llu\n", rbio->submit_time ? now - rbio->submit_time : 0);
+	prt_printf(out, "start_time:\t%llu\n", (rbio->start_time ? now - rbio->start_time : 0) / NSEC_PER_MSEC);
+	prt_printf(out, "submit_time:\t%llu ms ago\n", (rbio->submit_time ? now - rbio->submit_time : 0) / NSEC_PER_MSEC);
 
 	if (!rbio->split)
 		prt_printf(out, "end_io:\t%ps\n", rbio->end_io);
-- 
2.51.0


From d1f983975cdedeaf4bf499b8474ffd4f61220ec8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 11:52:06 -0400
Subject: [PATCH 054/309] bcachefs: kill __bch2_print_str()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 7 +------
 1 file changed, 1 insertion(+), 6 deletions(-)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index a3438b0dc0a9..c9013dd24ade 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -103,7 +103,7 @@ const char * const bch2_dev_write_refs[] = {
 };
 #undef x
 
-static void __bch2_print_str(struct bch_fs *c, const char *prefix,
+void bch2_print_str(struct bch_fs *c, const char *prefix,
 			     const char *str)
 {
 #ifdef __KERNEL__
@@ -117,11 +117,6 @@ static void __bch2_print_str(struct bch_fs *c, const char *prefix,
 	bch2_print_string_as_lines(KERN_ERR, str);
 }
 
-void bch2_print_str(struct bch_fs *c, const char *prefix, const char *str)
-{
-	__bch2_print_str(c, prefix, str);
-}
-
 __printf(2, 0)
 static void bch2_print_maybe_redirect(struct stdio_redirect *stdio, const char *fmt, va_list args)
 {
-- 
2.51.0


From 0e7bc6bf2f24b8af006a35373146c3b6fa7313d0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 11:53:41 -0400
Subject: [PATCH 055/309] bcachefs: bch_log()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h | 34 +++++++++++++---------------------
 1 file changed, 13 insertions(+), 21 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index fb3156ed7f0b..a6a7f995cdb1 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -329,19 +329,19 @@ do {									\
 		bch2_print_str(_c, __VA_ARGS__);			\
 } while (0)
 
-#define bch_info(c, fmt, ...) \
-	bch2_print(c, KERN_INFO bch2_fmt(c, fmt), ##__VA_ARGS__)
-#define bch_info_ratelimited(c, fmt, ...) \
-	bch2_print_ratelimited(c, KERN_INFO bch2_fmt(c, fmt), ##__VA_ARGS__)
-#define bch_notice(c, fmt, ...) \
-	bch2_print(c, KERN_NOTICE bch2_fmt(c, fmt), ##__VA_ARGS__)
-#define bch_warn(c, fmt, ...) \
-	bch2_print(c, KERN_WARNING bch2_fmt(c, fmt), ##__VA_ARGS__)
-#define bch_warn_ratelimited(c, fmt, ...) \
-	bch2_print_ratelimited(c, KERN_WARNING bch2_fmt(c, fmt), ##__VA_ARGS__)
-
-#define bch_err(c, fmt, ...) \
-	bch2_print(c, KERN_ERR bch2_fmt(c, fmt), ##__VA_ARGS__)
+#define bch_log(c, loglevel, fmt, ...) \
+	bch2_print(c, loglevel bch2_fmt(c, fmt), ##__VA_ARGS__)
+#define bch_log_ratelimited(c, loglevel, fmt, ...) \
+	bch2_print_ratelimited(c, loglevel bch2_fmt(c, fmt), ##__VA_ARGS__)
+
+#define bch_err(c, ...)			bch_log(c, KERN_ERR, __VA_ARGS__)
+#define bch_err_ratelimited(c, ...)	bch_log_ratelimited(c, KERN_ERR, __VA_ARGS__)
+#define bch_warn(c, ...)		bch_log(c, KERN_WARNING, __VA_ARGS__)
+#define bch_warn_ratelimited(c, ...)	bch_log_ratelimited(c, KERN_WARNING, __VA_ARGS__)
+#define bch_notice(c, ...)		bch_log(c, KERN_NOTICE, __VA_ARGS__)
+#define bch_info(c, ...)		bch_log(c, KERN_INFO, __VA_ARGS__)
+#define bch_info_ratelimited(c, ...)	bch_log_ratelimited(c, KERN_INFO, __VA_ARGS__)
+
 #define bch_err_dev(ca, fmt, ...) \
 	bch2_print(c, KERN_ERR bch2_fmt_dev(ca, fmt), ##__VA_ARGS__)
 #define bch_err_dev_offset(ca, _offset, fmt, ...) \
@@ -351,8 +351,6 @@ do {									\
 #define bch_err_inum_offset(c, _inum, _offset, fmt, ...) \
 	bch2_print(c, KERN_ERR bch2_fmt_inum_offset(c, _inum, _offset, fmt), ##__VA_ARGS__)
 
-#define bch_err_ratelimited(c, fmt, ...) \
-	bch2_print_ratelimited(c, KERN_ERR bch2_fmt(c, fmt), ##__VA_ARGS__)
 #define bch_err_dev_ratelimited(ca, fmt, ...) \
 	bch2_print_ratelimited(ca, KERN_ERR bch2_fmt_dev(ca, fmt), ##__VA_ARGS__)
 #define bch_err_dev_offset_ratelimited(ca, _offset, fmt, ...) \
@@ -398,12 +396,6 @@ do {									\
 		bch_info_ratelimited(c, fmt, ##__VA_ARGS__);		\
 } while (0)
 
-#define pr_verbose_init(opts, fmt, ...)					\
-do {									\
-	if (opt_get(opts, verbose))					\
-		pr_info(fmt, ##__VA_ARGS__);				\
-} while (0)
-
 static inline int __bch2_err_trace(struct bch_fs *c, int err)
 {
 	trace_error_throw(c, err, _THIS_IP_);
-- 
2.51.0


From 6cdf70dc209edf758aecd76980b212721eb95578 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 11:12:38 -0400
Subject: [PATCH 056/309] bcachefs: c->loglevel

'opts.verbose' controlls whether verbose logging is enabled; we need to
make it more fine grained for userspace tooling usage.

- move "should this print" logic into __bch2_print

- __bch2_print() now checks c->loglevel, if set it takes precedent over
  opts.verbose. This will let us do 'quiet' logging, where only errors
  are emitted.

For now this isn't exposed as an option, c->loglevel has to be set (e.g.
prior to calling bch2_fs_start). To expose it as an option we'd want to
make some improvements to the option parsing code to change how the
verbose option is handled.

Verbose logging is also now emitted at KERN_DEBUG.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h | 16 ++++------------
 fs/bcachefs/super.c    | 37 ++++++++++++++++++++++++++++++++++---
 2 files changed, 38 insertions(+), 15 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index a6a7f995cdb1..4f1ac7aa3532 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -341,6 +341,8 @@ do {									\
 #define bch_notice(c, ...)		bch_log(c, KERN_NOTICE, __VA_ARGS__)
 #define bch_info(c, ...)		bch_log(c, KERN_INFO, __VA_ARGS__)
 #define bch_info_ratelimited(c, ...)	bch_log_ratelimited(c, KERN_INFO, __VA_ARGS__)
+#define bch_verbose(c, ...)		bch_log(c, KERN_DEBUG, __VA_ARGS__)
+#define bch_verbose_ratelimited(c, ...)	bch_log_ratelimited(c, KERN_DEBUG, __VA_ARGS__)
 
 #define bch_err_dev(ca, fmt, ...) \
 	bch2_print(c, KERN_ERR bch2_fmt_dev(ca, fmt), ##__VA_ARGS__)
@@ -384,18 +386,6 @@ do {									\
 			##__VA_ARGS__, bch2_err_str(_ret));		\
 } while (0)
 
-#define bch_verbose(c, fmt, ...)					\
-do {									\
-	if ((c)->opts.verbose)						\
-		bch_info(c, fmt, ##__VA_ARGS__);			\
-} while (0)
-
-#define bch_verbose_ratelimited(c, fmt, ...)				\
-do {									\
-	if ((c)->opts.verbose)						\
-		bch_info_ratelimited(c, fmt, ##__VA_ARGS__);		\
-} while (0)
-
 static inline int __bch2_err_trace(struct bch_fs *c, int err)
 {
 	trace_error_throw(c, err, _THIS_IP_);
@@ -825,6 +815,8 @@ struct bch_fs {
 	struct bch_disk_groups_cpu __rcu *disk_groups;
 
 	struct bch_opts		opts;
+	unsigned		loglevel;
+	unsigned		prev_loglevel;
 
 	/* Updated by bch2_sb_update():*/
 	struct {
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index c9013dd24ade..317987bd116f 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -103,9 +103,32 @@ const char * const bch2_dev_write_refs[] = {
 };
 #undef x
 
-void bch2_print_str(struct bch_fs *c, const char *prefix,
-			     const char *str)
+static bool should_print_loglevel(struct bch_fs *c, const char *fmt)
 {
+	unsigned loglevel_opt = c->loglevel ?: c->opts.verbose ? 7: 6;
+
+	bool have_soh = fmt[0] == KERN_SOH[0];
+	bool have_loglevel = have_soh && fmt[1] >= '0' && fmt[1] <= '9';
+
+	unsigned loglevel = have_loglevel
+		? fmt[1] - '0'
+		: c->prev_loglevel;
+
+	if (have_loglevel)
+		c->prev_loglevel = loglevel;
+
+	return loglevel <= loglevel_opt;
+}
+
+void bch2_print_str(struct bch_fs *c, const char *prefix, const char *str)
+{
+	if (!should_print_loglevel(c, prefix))
+		return;
+
+#ifndef __KERNEL__
+	prefix = "";
+#endif
+
 #ifdef __KERNEL__
 	struct stdio_redirect *stdio = bch2_fs_stdio_redirect(c);
 
@@ -114,7 +137,7 @@ void bch2_print_str(struct bch_fs *c, const char *prefix,
 		return;
 	}
 #endif
-	bch2_print_string_as_lines(KERN_ERR, str);
+	bch2_print_string_as_lines(prefix, str);
 }
 
 __printf(2, 0)
@@ -144,6 +167,14 @@ void bch2_print_opts(struct bch_opts *opts, const char *fmt, ...)
 
 void __bch2_print(struct bch_fs *c, const char *fmt, ...)
 {
+	if (!should_print_loglevel(c, fmt))
+		return;
+
+#ifndef __KERNEL__
+	if (fmt[0] == KERN_SOH[0])
+		fmt += 2;
+#endif
+
 	struct stdio_redirect *stdio = bch2_fs_stdio_redirect(c);
 
 	va_list args;
-- 
2.51.0


From 2aa7dae954fb7457a6c807df145f7a9a2851851a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 12:14:26 -0400
Subject: [PATCH 057/309] bcachefs: Zero list_idx when deleting from async obj
 lists

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/async_objs.h | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/async_objs.h b/fs/bcachefs/async_objs.h
index cd6489b8cf76..451db4c51fb2 100644
--- a/fs/bcachefs/async_objs.h
+++ b/fs/bcachefs/async_objs.h
@@ -3,9 +3,10 @@
 #define _BCACHEFS_ASYNC_OBJS_H
 
 #ifdef CONFIG_BCACHEFS_ASYNC_OBJECT_LISTS
-static inline void __async_object_list_del(struct fast_list *head, unsigned idx)
+static inline void __async_object_list_del(struct fast_list *head, unsigned *idx)
 {
-	fast_list_remove(head, idx);
+	fast_list_remove(head, *idx);
+	*idx = 0;
 }
 
 static inline int __async_object_list_add(struct fast_list *head, void *obj, unsigned *idx)
@@ -16,7 +17,7 @@ static inline int __async_object_list_add(struct fast_list *head, void *obj, uns
 }
 
 #define async_object_list_del(_c, _list, idx)		\
-	__async_object_list_del(&(_c)->async_objs[BCH_ASYNC_OBJ_LIST_##_list].list, idx)
+	__async_object_list_del(&(_c)->async_objs[BCH_ASYNC_OBJ_LIST_##_list].list, &idx)
 
 #define async_object_list_add(_c, _list, obj, idx)		\
 	__async_object_list_add(&(_c)->async_objs[BCH_ASYNC_OBJ_LIST_##_list].list, obj, idx)
-- 
2.51.0


From 545076a9d8909b13607a9ad800f211008aba18cf Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 12:44:15 -0400
Subject: [PATCH 058/309] bcachefs: fix device add before fs started

Device freespace accounting must be initialized.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c  |  2 ++
 fs/bcachefs/super.c | 11 ++++++-----
 2 files changed, 8 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 48e756cf48f2..b8c86e09b038 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -3210,6 +3210,8 @@ static int bch2_fsck_offline_thread_fn(struct thread_with_stdio *stdio)
 	if (ret)
 		return ret;
 
+	thr->c->recovery_task = current;
+
 	ret = bch2_fs_start(thr->c);
 	if (ret)
 		goto err;
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 317987bd116f..0107a031d275 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1092,6 +1092,8 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 
 	if (ret)
 		goto err;
+
+	c->recovery_task = current;
 out:
 	return c;
 err:
@@ -1234,7 +1236,6 @@ int bch2_fs_start(struct bch_fs *c)
 	bch2_recalc_capacity(c);
 	up_write(&c->state_lock);
 
-	c->recovery_task = current;
 	ret = BCH_SB_INITIALIZED(c->disk_sb.sb)
 		? bch2_fs_recovery(c)
 		: bch2_fs_initialize(c);
@@ -2014,11 +2015,11 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 	bch2_write_super(c);
 	mutex_unlock(&c->sb_lock);
 
-	if (test_bit(BCH_FS_started, &c->flags)) {
-		ret = bch2_dev_usage_init(ca, false);
-		if (ret)
-			goto err_late;
+	ret = bch2_dev_usage_init(ca, false);
+	if (ret)
+		goto err_late;
 
+	if (test_bit(BCH_FS_started, &c->flags)) {
 		ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
 		bch_err_msg(ca, ret, "marking new superblock");
 		if (ret)
-- 
2.51.0


From 42579d1781b75b883e4e8fce41dc65251c0b4fe2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 10 Jul 2025 17:17:16 -0400
Subject: [PATCH 059/309] bcachefs: fast_list: warn if non-empty on exit

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fast_list.c | 17 +++++++++++++++--
 1 file changed, 15 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/fast_list.c b/fs/bcachefs/fast_list.c
index b52f264318d8..6be2a45be1dd 100644
--- a/fs/bcachefs/fast_list.c
+++ b/fs/bcachefs/fast_list.c
@@ -138,8 +138,21 @@ void fast_list_remove(struct fast_list *l, unsigned idx)
 
 void fast_list_exit(struct fast_list *l)
 {
-	/* XXX: warn if list isn't empty */
-	free_percpu(l->buffer);
+	if (l->buffer) {
+		int cpu;
+		for_each_possible_cpu(cpu) {
+			struct fast_list_pcpu *lp = per_cpu_ptr(l->buffer, cpu);
+
+			while (lp->nr)
+				ida_free(&l->slots_allocated, lp->entries[--lp->nr]);
+		}
+
+		free_percpu(l->buffer);
+	}
+
+	WARN(ida_find_first(&l->slots_allocated) >= 0,
+	     "fast_list still has objects on exit\n");
+
 	ida_destroy(&l->slots_allocated);
 	genradix_free(&l->items);
 }
-- 
2.51.0


From 6a55c1294d5ac2a89cb77215f2c75aa37cdd3327 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 13:38:22 -0400
Subject: [PATCH 060/309] bcachefs: bch2_journal_key_insert_take() accumulates
 accounting updates

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_journal_iter.c | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index ea839560a136..39ecd95ce2ff 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -5,6 +5,7 @@
 #include "bset.h"
 #include "btree_cache.h"
 #include "btree_journal_iter.h"
+#include "disk_accounting.h"
 #include "journal_io.h"
 
 #include <linux/sort.h>
@@ -278,12 +279,23 @@ int bch2_journal_key_insert_take(struct bch_fs *c, enum btree_id id,
 
 	if (idx < keys->size &&
 	    journal_key_cmp(&n, &keys->data[idx]) == 0) {
+		struct bkey_i *o = keys->data[idx].k;
+
+		if (k->k.type == KEY_TYPE_accounting &&
+		    o->k.type == KEY_TYPE_accounting) {
+			if (!keys->data[idx].allocated)
+				goto insert;
+
+			bch2_accounting_accumulate(bkey_i_to_accounting(k),
+						   bkey_i_to_s_c_accounting(o));
+		}
+
 		if (keys->data[idx].allocated)
 			kfree(keys->data[idx].k);
 		keys->data[idx] = n;
 		return 0;
 	}
-
+insert:
 	if (idx > keys->gap)
 		idx -= keys->size - keys->nr;
 
-- 
2.51.0


From 579e9a4b3d7c3c0cc0178841cb2a18f6f6df519b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 14:26:20 -0400
Subject: [PATCH 061/309] bcachefs: bch2_fs_initialize() now runs journal
 replay

Before going rw, we do updates by adding them to the list of updates for
journal replay to do; this helps simplify and regularize bootstrap.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 0def4ecb7f88..008a22d7a8fa 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -1217,8 +1217,9 @@ int bch2_fs_initialize(struct bch_fs *c)
 	if (ret)
 		goto err;
 
-	set_bit(BCH_FS_accounting_replay_done, &c->flags);
-	bch2_journal_set_replay_done(&c->journal);
+	ret = bch2_journal_replay(c);
+	if (ret)
+		goto err;
 
 	for_each_member_device(c, ca) {
 		ret = bch2_dev_usage_init(ca, false);
-- 
2.51.0


From d962e44787051291ef8affc7e836e6d7a2fbddb8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 9 Jul 2025 08:55:46 -0400
Subject: [PATCH 062/309] bcachefs: do_bch2_trans_commit_to_journal_replay
 handles accounting

Accounting updates must be mirrored to the in-memory counters.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_trans_commit.c | 55 ++++++++++++++++++++++++++------
 fs/bcachefs/disk_accounting.c    |  3 +-
 2 files changed, 47 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index a7e9d8916848..0f2812bb7963 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -591,7 +591,8 @@ static noinline int bch2_trans_commit_run_gc_triggers(struct btree_trans *trans)
 }
 
 static inline int
-bch2_trans_commit_write_locked(struct btree_trans *trans, unsigned flags,
+bch2_trans_commit_write_locked(struct btree_trans *trans,
+			       enum bch_trans_commit_flags flags,
 			       struct btree_insert_entry **stopped_at,
 			       unsigned long trace_ip)
 {
@@ -826,7 +827,8 @@ static int bch2_trans_commit_journal_pin_flush(struct journal *j,
 /*
  * Get journal reservation, take write locks, and attempt to do btree update(s):
  */
-static inline int do_bch2_trans_commit(struct btree_trans *trans, unsigned flags,
+static inline int do_bch2_trans_commit(struct btree_trans *trans,
+				       enum bch_trans_commit_flags flags,
 				       struct btree_insert_entry **stopped_at,
 				       unsigned long trace_ip)
 {
@@ -962,16 +964,33 @@ int bch2_trans_commit_error(struct btree_trans *trans, unsigned flags,
  * do.
  */
 static noinline int
-do_bch2_trans_commit_to_journal_replay(struct btree_trans *trans)
+do_bch2_trans_commit_to_journal_replay(struct btree_trans *trans,
+				       enum bch_trans_commit_flags flags)
 {
 	struct bch_fs *c = trans->c;
+	int ret = 0;
 
 	BUG_ON(current != c->recovery_task);
 
+	struct bkey_i *accounting;
+retry:
+	percpu_down_read(&c->mark_lock);
+	for (accounting = btree_trans_subbuf_base(trans, &trans->accounting);
+	     accounting != btree_trans_subbuf_top(trans, &trans->accounting);
+	     accounting = bkey_next(accounting)) {
+		ret = likely(!(flags & BCH_TRANS_COMMIT_skip_accounting_apply))
+			? bch2_accounting_mem_mod_locked(trans, bkey_i_to_s_c_accounting(accounting),
+							 BCH_ACCOUNTING_normal, false)
+			: 0;
+		if (ret)
+			goto revert_fs_usage;
+	}
+	percpu_up_read(&c->mark_lock);
+
 	trans_for_each_update(trans, i) {
-		int ret = bch2_journal_key_insert(c, i->btree_id, i->level, i->k);
+		ret = bch2_journal_key_insert(c, i->btree_id, i->level, i->k);
 		if (ret)
-			return ret;
+			goto fatal_err;
 	}
 
 	for (struct jset_entry *i = btree_trans_journal_entries_start(trans);
@@ -980,9 +999,9 @@ do_bch2_trans_commit_to_journal_replay(struct btree_trans *trans)
 		if (i->type == BCH_JSET_ENTRY_btree_keys ||
 		    i->type == BCH_JSET_ENTRY_write_buffer_keys) {
 			jset_entry_for_each_key(i, k) {
-				int ret = bch2_journal_key_insert(c, i->btree_id, i->level, k);
+				ret = bch2_journal_key_insert(c, i->btree_id, i->level, k);
 				if (ret)
-					return ret;
+					goto fatal_err;
 			}
 		}
 
@@ -1000,12 +1019,28 @@ do_bch2_trans_commit_to_journal_replay(struct btree_trans *trans)
 	for (struct bkey_i *i = btree_trans_subbuf_base(trans, &trans->accounting);
 	     i != btree_trans_subbuf_top(trans, &trans->accounting);
 	     i = bkey_next(i)) {
-		int ret = bch2_journal_key_insert(c, BTREE_ID_accounting, 0, i);
+		ret = bch2_journal_key_insert(c, BTREE_ID_accounting, 0, i);
 		if (ret)
-			return ret;
+			goto fatal_err;
 	}
 
 	return 0;
+fatal_err:
+	bch2_fs_fatal_error(c, "fatal error in transaction commit: %s", bch2_err_str(ret));
+	percpu_down_read(&c->mark_lock);
+revert_fs_usage:
+	for (struct bkey_i *i = btree_trans_subbuf_base(trans, &trans->accounting);
+	     i != accounting;
+	     i = bkey_next(i))
+		bch2_accounting_trans_commit_revert(trans, bkey_i_to_accounting(i), flags);
+	percpu_up_read(&c->mark_lock);
+
+	if (bch2_err_matches(ret, BCH_ERR_btree_insert_need_mark_replicas)) {
+		ret = drop_locks_do(trans, bch2_accounting_update_sb(trans));
+		if (!ret)
+			goto retry;
+	}
+	return ret;
 }
 
 int __bch2_trans_commit(struct btree_trans *trans, enum bch_trans_commit_flags flags)
@@ -1031,7 +1066,7 @@ int __bch2_trans_commit(struct btree_trans *trans, enum bch_trans_commit_flags f
 	if (!(flags & BCH_TRANS_COMMIT_no_check_rw) &&
 	    unlikely(!enumerated_ref_tryget(&c->writes, BCH_WRITE_REF_trans))) {
 		if (unlikely(!test_bit(BCH_FS_may_go_rw, &c->flags)))
-			ret = do_bch2_trans_commit_to_journal_replay(trans);
+			ret = do_bch2_trans_commit_to_journal_replay(trans, flags);
 		else
 			ret = bch_err_throw(c, erofs_trans_commit);
 		goto out_reset;
diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index f7528cd69c73..2591b4f470fc 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -622,7 +622,8 @@ int bch2_gc_accounting_done(struct bch_fs *c)
 
 			if (fsck_err(c, accounting_mismatch, "%s", buf.buf)) {
 				percpu_up_write(&c->mark_lock);
-				ret = commit_do(trans, NULL, NULL, 0,
+				ret = commit_do(trans, NULL, NULL,
+						BCH_TRANS_COMMIT_skip_accounting_apply,
 						bch2_disk_accounting_mod(trans, &acc_k, src_v, nr, false));
 				percpu_down_write(&c->mark_lock);
 				if (ret)
-- 
2.51.0


From aa7378acdabdac201a7dbd3bf587b95a2f96995d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 8 Jul 2025 23:04:10 -0400
Subject: [PATCH 063/309] bcachefs: bch2_set_nr_journal_buckets_iter() always
 marks

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c  | 20 +++++++++-----------
 fs/bcachefs/recovery.c |  2 +-
 2 files changed, 10 insertions(+), 12 deletions(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index ddbffd455c65..de66ec7231ca 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -1151,16 +1151,14 @@ static int bch2_set_nr_journal_buckets_iter(struct bch_dev *ca, unsigned nr,
 		if (ret)
 			break;
 
-		if (!new_fs) {
-			ret = bch2_trans_run(c,
-				bch2_trans_mark_metadata_bucket(trans, ca,
-						ob[nr_got]->bucket, BCH_DATA_journal,
-						ca->mi.bucket_size, BTREE_TRIGGER_transactional));
-			if (ret) {
-				bch2_open_bucket_put(c, ob[nr_got]);
-				bch_err_msg(c, ret, "marking new journal buckets");
-				break;
-			}
+		ret = bch2_trans_run(c,
+			bch2_trans_mark_metadata_bucket(trans, ca,
+					ob[nr_got]->bucket, BCH_DATA_journal,
+					ca->mi.bucket_size, BTREE_TRIGGER_transactional));
+		if (ret) {
+			bch2_open_bucket_put(c, ob[nr_got]);
+			bch_err_msg(c, ret, "marking new journal buckets");
+			break;
 		}
 
 		bu[nr_got] = ob[nr_got]->bucket;
@@ -1230,7 +1228,7 @@ static int bch2_set_nr_journal_buckets_iter(struct bch_dev *ca, unsigned nr,
 		mutex_unlock(&c->sb_lock);
 	}
 
-	if (ret && !new_fs)
+	if (ret)
 		for (i = 0; i < nr_got; i++)
 			bch2_trans_run(c,
 				bch2_trans_mark_metadata_bucket(trans, ca,
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 008a22d7a8fa..9cecc4e89b48 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -1196,7 +1196,6 @@ int bch2_fs_initialize(struct bch_fs *c)
 	mutex_unlock(&c->sb_lock);
 
 	set_bit(BCH_FS_btree_running, &c->flags);
-	set_bit(BCH_FS_may_go_rw, &c->flags);
 
 	for (unsigned i = 0; i < BTREE_ID_NR; i++)
 		bch2_btree_root_alloc_fake(c, i, 0);
@@ -1213,6 +1212,7 @@ int bch2_fs_initialize(struct bch_fs *c)
 	if (ret)
 		goto err;
 
+	set_bit(BCH_FS_may_go_rw, &c->flags);
 	ret = bch2_fs_read_write_early(c);
 	if (ret)
 		goto err;
-- 
2.51.0


From 900fe24a520e051db9c5222f1e777e2b765cd25a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 14:26:20 -0400
Subject: [PATCH 064/309] bcachefs: bch2_fs_initialize() initializes before
 going RW

Make sure superblocks and journal are marked before going RW, like in
normal recovery.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c | 36 ++++++++++++++++++------------------
 1 file changed, 18 insertions(+), 18 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 9cecc4e89b48..f82e9fb8f7bd 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -1200,6 +1200,24 @@ int bch2_fs_initialize(struct bch_fs *c)
 	for (unsigned i = 0; i < BTREE_ID_NR; i++)
 		bch2_btree_root_alloc_fake(c, i, 0);
 
+	for_each_member_device(c, ca) {
+		ret = bch2_dev_usage_init(ca, false);
+		if (ret) {
+			bch2_dev_put(ca);
+			goto err;
+		}
+	}
+
+	/*
+	 * Write out the superblock and journal buckets, now that we can do
+	 * btree updates
+	 */
+	bch_verbose(c, "marking superblocks");
+	ret = bch2_trans_mark_dev_sbs(c);
+	bch_err_msg(c, ret, "marking superblocks");
+	if (ret)
+		goto err;
+
 	ret = bch2_fs_journal_alloc(c);
 	if (ret)
 		goto err;
@@ -1221,24 +1239,6 @@ int bch2_fs_initialize(struct bch_fs *c)
 	if (ret)
 		goto err;
 
-	for_each_member_device(c, ca) {
-		ret = bch2_dev_usage_init(ca, false);
-		if (ret) {
-			bch2_dev_put(ca);
-			goto err;
-		}
-	}
-
-	/*
-	 * Write out the superblock and journal buckets, now that we can do
-	 * btree updates
-	 */
-	bch_verbose(c, "marking superblocks");
-	ret = bch2_trans_mark_dev_sbs(c);
-	bch_err_msg(c, ret, "marking superblocks");
-	if (ret)
-		goto err;
-
 	ret = bch2_fs_freespace_init(c);
 	if (ret)
 		goto err;
-- 
2.51.0


From 7f6ffae94282af1c775c1a7189a30bb928bd802d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 10 Jul 2025 15:12:54 -0400
Subject: [PATCH 065/309] bcachefs: Improve bch2_read_bio_to_text()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/async_objs.c       | 26 ++++++++++++++++++--------
 fs/bcachefs/async_objs_types.h |  2 +-
 fs/bcachefs/data_update.c      |  2 +-
 fs/bcachefs/io_read.c          | 29 ++++++++++++++++++++++-------
 fs/bcachefs/io_read.h          |  4 ++--
 5 files changed, 44 insertions(+), 19 deletions(-)

diff --git a/fs/bcachefs/async_objs.c b/fs/bcachefs/async_objs.c
index e368c765eb46..ad04e5f0f056 100644
--- a/fs/bcachefs/async_objs.c
+++ b/fs/bcachefs/async_objs.c
@@ -13,28 +13,38 @@
 
 #include <linux/debugfs.h>
 
-static void promote_obj_to_text(struct printbuf *out, void *obj)
+static void promote_obj_to_text(struct printbuf *out,
+				struct bch_fs *c,
+				void *obj)
 {
-	bch2_promote_op_to_text(out, obj);
+	bch2_promote_op_to_text(out, c, obj);
 }
 
-static void rbio_obj_to_text(struct printbuf *out, void *obj)
+static void rbio_obj_to_text(struct printbuf *out,
+			     struct bch_fs *c,
+			     void *obj)
 {
-	bch2_read_bio_to_text(out, obj);
+	bch2_read_bio_to_text(out, c, obj);
 }
 
-static void write_op_obj_to_text(struct printbuf *out, void *obj)
+static void write_op_obj_to_text(struct printbuf *out,
+				 struct bch_fs *c,
+				 void *obj)
 {
 	bch2_write_op_to_text(out, obj);
 }
 
-static void btree_read_bio_obj_to_text(struct printbuf *out, void *obj)
+static void btree_read_bio_obj_to_text(struct printbuf *out,
+				       struct bch_fs *c,
+				       void *obj)
 {
 	struct btree_read_bio *rbio = obj;
 	bch2_btree_read_bio_to_text(out, rbio);
 }
 
-static void btree_write_bio_obj_to_text(struct printbuf *out, void *obj)
+static void btree_write_bio_obj_to_text(struct printbuf *out,
+					struct bch_fs *c,
+					void *obj)
 {
 	struct btree_write_bio *wbio = obj;
 	bch2_bio_to_text(out, &wbio->wbio.bio);
@@ -79,7 +89,7 @@ static ssize_t bch2_async_obj_list_read(struct file *file, char __user *buf,
 		if (!i->size)
 			break;
 
-		list->obj_to_text(&i->buf, obj);
+		list->obj_to_text(&i->buf, i->c, obj);
 		i->iter = iter.pos;
 	}
 
diff --git a/fs/bcachefs/async_objs_types.h b/fs/bcachefs/async_objs_types.h
index 8d713c0f5841..ed262c874ad0 100644
--- a/fs/bcachefs/async_objs_types.h
+++ b/fs/bcachefs/async_objs_types.h
@@ -18,7 +18,7 @@ enum bch_async_obj_lists {
 
 struct async_obj_list {
 	struct fast_list	list;
-	void			(*obj_to_text)(struct printbuf *, void *);
+	void			(*obj_to_text)(struct printbuf *, struct bch_fs *, void *);
 	unsigned		idx;
 };
 
diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index 3968f3be7f3b..954d53239867 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -675,7 +675,7 @@ void bch2_data_update_inflight_to_text(struct printbuf *out, struct data_update
 	if (!m->read_done) {
 		prt_printf(out, "read:\n");
 		printbuf_indent_add(out, 2);
-		bch2_read_bio_to_text(out, &m->rbio);
+		bch2_read_bio_to_text(out, m->op.c, &m->rbio);
 	} else {
 		prt_printf(out, "write:\n");
 		printbuf_indent_add(out, 2);
diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index af5b91d85999..2f458fc88f03 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -363,12 +363,14 @@ static struct bch_read_bio *promote_alloc(struct btree_trans *trans,
 	return NULL;
 }
 
-void bch2_promote_op_to_text(struct printbuf *out, struct promote_op *op)
+void bch2_promote_op_to_text(struct printbuf *out,
+			     struct bch_fs *c,
+			     struct promote_op *op)
 {
 	if (!op->write.read_done) {
 		prt_printf(out, "parent read: %px\n", op->write.rbio.parent);
 		printbuf_indent_add(out, 2);
-		bch2_read_bio_to_text(out, op->write.rbio.parent);
+		bch2_read_bio_to_text(out, c, op->write.rbio.parent);
 		printbuf_indent_sub(out, 2);
 	}
 
@@ -1486,22 +1488,34 @@ static const char * const bch2_read_bio_flags[] = {
 	NULL
 };
 
-void bch2_read_bio_to_text(struct printbuf *out, struct bch_read_bio *rbio)
+void bch2_read_bio_to_text(struct printbuf *out,
+			   struct bch_fs *c,
+			   struct bch_read_bio *rbio)
 {
 	if (!out->nr_tabstops)
 		printbuf_tabstop_push(out, 20);
 
+	bch2_read_err_msg(c, out, rbio, rbio->read_pos);
+	prt_newline(out);
+
+	/* Are we in a retry? */
+
+	printbuf_indent_add(out, 2);
+
 	u64 now = local_clock();
-	prt_printf(out, "start_time:\t%llu\n", (rbio->start_time ? now - rbio->start_time : 0) / NSEC_PER_MSEC);
-	prt_printf(out, "submit_time:\t%llu ms ago\n", (rbio->submit_time ? now - rbio->submit_time : 0) / NSEC_PER_MSEC);
+	prt_printf(out, "start_time:\t");
+	bch2_pr_time_units(out, max_t(s64, 0, now - rbio->start_time));
+	prt_newline(out);
+
+	prt_printf(out, "submit_time:\t");
+	bch2_pr_time_units(out, max_t(s64, 0, now - rbio->submit_time));
+	prt_newline(out);
 
 	if (!rbio->split)
 		prt_printf(out, "end_io:\t%ps\n", rbio->end_io);
 	else
 		prt_printf(out, "parent:\t%px\n", rbio->parent);
 
-	prt_printf(out, "bi_end_io:\t%ps\n", rbio->bio.bi_end_io);
-
 	prt_printf(out, "promote:\t%u\n",	rbio->promote);
 	prt_printf(out, "bounce:\t%u\n",	rbio->bounce);
 	prt_printf(out, "split:\t%u\n",		rbio->split);
@@ -1520,6 +1534,7 @@ void bch2_read_bio_to_text(struct printbuf *out, struct bch_read_bio *rbio)
 	prt_newline(out);
 
 	bch2_bio_to_text(out, &rbio->bio);
+	printbuf_indent_sub(out, 2);
 }
 
 void bch2_fs_io_read_exit(struct bch_fs *c)
diff --git a/fs/bcachefs/io_read.h b/fs/bcachefs/io_read.h
index cfc8ef35b14d..1afd19402682 100644
--- a/fs/bcachefs/io_read.h
+++ b/fs/bcachefs/io_read.h
@@ -207,8 +207,8 @@ static inline struct bch_read_bio *rbio_init(struct bio *bio,
 }
 
 struct promote_op;
-void bch2_promote_op_to_text(struct printbuf *, struct promote_op *);
-void bch2_read_bio_to_text(struct printbuf *, struct bch_read_bio *);
+void bch2_promote_op_to_text(struct printbuf *, struct bch_fs *, struct promote_op *);
+void bch2_read_bio_to_text(struct printbuf *, struct bch_fs *, struct bch_read_bio *);
 
 void bch2_fs_io_read_exit(struct bch_fs *);
 int bch2_fs_io_read_init(struct bch_fs *);
-- 
2.51.0


From 236094e272521e5566f8f0d29ff8de7df7904d4b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 12 Jul 2025 19:45:02 -0400
Subject: [PATCH 066/309] bcachefs: Fix replicas max options

BCH_REPLICAS_MAX is the maximum allowed value for replicas settings.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/opts.h | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/opts.h b/fs/bcachefs/opts.h
index 63f8e254495c..84ce69a7f131 100644
--- a/fs/bcachefs/opts.h
+++ b/fs/bcachefs/opts.h
@@ -150,12 +150,12 @@ enum fsck_err_opts {
 	  NULL,		"Number of consecutive write errors allowed before kicking out a device")\
 	x(metadata_replicas,		u8,				\
 	  OPT_FS|OPT_FORMAT|OPT_MOUNT|OPT_RUNTIME,			\
-	  OPT_UINT(1, BCH_REPLICAS_MAX),				\
+	  OPT_UINT(1, BCH_REPLICAS_MAX + 1),				\
 	  BCH_SB_META_REPLICAS_WANT,	1,				\
 	  "#",		"Number of metadata replicas")			\
 	x(data_replicas,		u8,				\
 	  OPT_FS|OPT_INODE|OPT_FORMAT|OPT_MOUNT|OPT_RUNTIME,		\
-	  OPT_UINT(1, BCH_REPLICAS_MAX),				\
+	  OPT_UINT(1, BCH_REPLICAS_MAX + 1),				\
 	  BCH_SB_DATA_REPLICAS_WANT,	1,				\
 	  "#",		"Number of data replicas")			\
 	x(metadata_replicas_required, u8,				\
@@ -165,7 +165,7 @@ enum fsck_err_opts {
 	  "#",		NULL)						\
 	x(data_replicas_required,	u8,				\
 	  OPT_FS|OPT_FORMAT|OPT_MOUNT,					\
-	  OPT_UINT(1, BCH_REPLICAS_MAX),				\
+	  OPT_UINT(1, BCH_REPLICAS_MAX + 1),				\
 	  BCH_SB_DATA_REPLICAS_REQ,	1,				\
 	  "#",		NULL)						\
 	x(encoded_extent_max,		u32,				\
@@ -529,7 +529,7 @@ enum fsck_err_opts {
 	  "size",	"Specifies the bucket size; must be greater than the btree node size")\
 	x(durability,			u8,				\
 	  OPT_DEVICE|OPT_RUNTIME|OPT_SB_FIELD_ONE_BIAS,			\
-	  OPT_UINT(0, BCH_REPLICAS_MAX),				\
+	  OPT_UINT(0, BCH_REPLICAS_MAX + 1),				\
 	  BCH_MEMBER_DURABILITY,	1,				\
 	  "n",		"Data written to this device will be considered\n"\
 			"to have already been replicated n times")	\
-- 
2.51.0


From 68befdb1b3781af4e552daaa1f48563bd796ed4a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 13 Jul 2025 09:47:38 -0400
Subject: [PATCH 067/309] bcachefs: Better congestion visibilty in sysfs

/sys/fs/bcachefs/<uuid>/dev-n/congested now prints more info on how we
calculate device congestion.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.c | 61 ++++++++++++++++++++++++++++++++++---------
 fs/bcachefs/io_read.h |  4 +++
 fs/bcachefs/sysfs.c   | 11 +++++---
 3 files changed, 60 insertions(+), 16 deletions(-)

diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index 2f458fc88f03..f24c1c3e8f19 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -45,38 +45,73 @@ MODULE_PARM_DESC(poison_extents_on_checksum_error,
 
 #ifndef CONFIG_BCACHEFS_NO_LATENCY_ACCT
 
+static inline u32 bch2_dev_congested_read(struct bch_dev *ca, u64 now)
+{
+	s64 congested = atomic_read(&ca->congested);
+	u64 last = READ_ONCE(ca->congested_last);
+	if (time_after64(now, last))
+		congested -= (now - last) >> 12;
+
+	return clamp(congested, 0LL, CONGESTED_MAX);
+}
+
 static bool bch2_target_congested(struct bch_fs *c, u16 target)
 {
 	const struct bch_devs_mask *devs;
 	unsigned d, nr = 0, total = 0;
-	u64 now = local_clock(), last;
-	s64 congested;
-	struct bch_dev *ca;
-
-	if (!target)
-		return false;
+	u64 now = local_clock();
 
 	guard(rcu)();
 	devs = bch2_target_to_mask(c, target) ?:
 		&c->rw_devs[BCH_DATA_user];
 
 	for_each_set_bit(d, devs->d, BCH_SB_MEMBERS_MAX) {
-		ca = rcu_dereference(c->devs[d]);
+		struct bch_dev *ca = rcu_dereference(c->devs[d]);
 		if (!ca)
 			continue;
 
-		congested = atomic_read(&ca->congested);
-		last = READ_ONCE(ca->congested_last);
-		if (time_after64(now, last))
-			congested -= (now - last) >> 12;
-
-		total += max(congested, 0LL);
+		total += bch2_dev_congested_read(ca, now);
 		nr++;
 	}
 
 	return get_random_u32_below(nr * CONGESTED_MAX) < total;
 }
 
+void bch2_dev_congested_to_text(struct printbuf *out, struct bch_dev *ca)
+{
+	printbuf_tabstop_push(out, 32);
+
+	prt_printf(out, "current:\t%u%%\n",
+		   bch2_dev_congested_read(ca, local_clock()) *
+		   100 / CONGESTED_MAX);
+
+	prt_printf(out, "raw:\t%i/%u\n", atomic_read(&ca->congested), CONGESTED_MAX);
+
+	prt_printf(out, "last io over threshold:\t");
+	bch2_pr_time_units(out, local_clock() - ca->congested_last);
+	prt_newline(out);
+
+	prt_printf(out, "read latency threshold:\t");
+	bch2_pr_time_units(out,
+			   ca->io_latency[READ].quantiles.entries[QUANTILE_IDX(1)].m << 2);
+	prt_newline(out);
+
+	prt_printf(out, "median read latency:\t");
+	bch2_pr_time_units(out,
+			   ca->io_latency[READ].quantiles.entries[QUANTILE_IDX(7)].m);
+	prt_newline(out);
+
+	prt_printf(out, "write latency threshold:\t");
+	bch2_pr_time_units(out,
+			   ca->io_latency[WRITE].quantiles.entries[QUANTILE_IDX(1)].m << 3);
+	prt_newline(out);
+
+	prt_printf(out, "median write latency:\t");
+	bch2_pr_time_units(out,
+			   ca->io_latency[WRITE].quantiles.entries[QUANTILE_IDX(7)].m);
+	prt_newline(out);
+}
+
 #else
 
 static bool bch2_target_congested(struct bch_fs *c, u16 target)
diff --git a/fs/bcachefs/io_read.h b/fs/bcachefs/io_read.h
index 1afd19402682..8fef4e47f16d 100644
--- a/fs/bcachefs/io_read.h
+++ b/fs/bcachefs/io_read.h
@@ -7,6 +7,10 @@
 #include "extents_types.h"
 #include "reflink.h"
 
+#ifndef CONFIG_BCACHEFS_NO_LATENCY_ACCT
+void bch2_dev_congested_to_text(struct printbuf *, struct bch_dev *);
+#endif
+
 struct bch_read_bio {
 	struct bch_fs		*c;
 	u64			start_time;
diff --git a/fs/bcachefs/sysfs.c b/fs/bcachefs/sysfs.c
index 05848375cea2..ac8d03d3c835 100644
--- a/fs/bcachefs/sysfs.c
+++ b/fs/bcachefs/sysfs.c
@@ -170,7 +170,9 @@ read_attribute(io_latency_read);
 read_attribute(io_latency_write);
 read_attribute(io_latency_stats_read);
 read_attribute(io_latency_stats_write);
+#ifndef CONFIG_BCACHEFS_NO_LATENCY_ACCT
 read_attribute(congested);
+#endif
 
 read_attribute(btree_write_stats);
 
@@ -830,9 +832,10 @@ SHOW(bch2_dev)
 	if (attr == &sysfs_io_latency_stats_write)
 		bch2_time_stats_to_text(out, &ca->io_latency[WRITE].stats);
 
-	sysfs_printf(congested,			"%u%%",
-		     clamp(atomic_read(&ca->congested), 0, CONGESTED_MAX)
-		     * 100 / CONGESTED_MAX);
+#ifndef CONFIG_BCACHEFS_NO_LATENCY_ACCT
+	if (attr == &sysfs_congested)
+		bch2_dev_congested_to_text(out, ca);
+#endif
 
 	if (attr == &sysfs_alloc_debug)
 		bch2_dev_alloc_debug_to_text(out, ca);
@@ -900,7 +903,9 @@ struct attribute *bch2_dev_files[] = {
 	&sysfs_io_latency_write,
 	&sysfs_io_latency_stats_read,
 	&sysfs_io_latency_stats_write,
+#ifndef CONFIG_BCACHEFS_NO_LATENCY_ACCT
 	&sysfs_congested,
+#endif
 
 	/* debug: */
 	&sysfs_alloc_debug,
-- 
2.51.0


From 44f6da5d11b24a21e06b77b4e60ac27fd37cc645 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 13 Jul 2025 10:29:37 -0400
Subject: [PATCH 068/309] bcachefs: nopromote sub counters

Users have been complaining about promotes not happening, so break up
the nopromote counters into subcounters - these will show up in
'bcachefs fs top'.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.c            | 20 +++++++++++++++-----
 fs/bcachefs/sb-counters_format.h |  5 +++++
 2 files changed, 20 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index f24c1c3e8f19..929ca968308b 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -171,22 +171,32 @@ static inline int should_promote(struct bch_fs *c, struct bkey_s_c k,
 	if (!have_io_error(failed)) {
 		BUG_ON(!opts.promote_target);
 
-		if (!(flags & BCH_READ_may_promote))
+		if (!(flags & BCH_READ_may_promote)) {
+			count_event(c, io_read_nopromote_may_not);
 			return bch_err_throw(c, nopromote_may_not);
+		}
 
-		if (bch2_bkey_has_target(c, k, opts.promote_target))
+		if (bch2_bkey_has_target(c, k, opts.promote_target)) {
+			count_event(c, io_read_nopromote_already_promoted);
 			return bch_err_throw(c, nopromote_already_promoted);
+		}
 
-		if (bkey_extent_is_unwritten(k))
+		if (bkey_extent_is_unwritten(k)) {
+			count_event(c, io_read_nopromote_unwritten);
 			return bch_err_throw(c, nopromote_unwritten);
+		}
 
-		if (bch2_target_congested(c, opts.promote_target))
+		if (bch2_target_congested(c, opts.promote_target)) {
+			count_event(c, io_read_nopromote_congested);
 			return bch_err_throw(c, nopromote_congested);
+		}
 	}
 
 	if (rhashtable_lookup_fast(&c->promote_table, &pos,
-				   bch_promote_params))
+				   bch_promote_params)) {
+		count_event(c, io_read_nopromote_in_flight);
 		return bch_err_throw(c, nopromote_in_flight);
+	}
 
 	return 0;
 }
diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index a59b2a10659e..2e3a56bfd085 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -13,6 +13,11 @@ enum counters_flags {
 	x(io_read_hole,					81,	TYPE_SECTORS)	\
 	x(io_read_promote,				30,	TYPE_COUNTER)	\
 	x(io_read_nopromote,				85,	TYPE_COUNTER)	\
+	x(io_read_nopromote_may_not,			86,	TYPE_COUNTER)	\
+	x(io_read_nopromote_already_promoted,		87,	TYPE_COUNTER)	\
+	x(io_read_nopromote_unwritten,			88,	TYPE_COUNTER)	\
+	x(io_read_nopromote_congested,			89,	TYPE_COUNTER)	\
+	x(io_read_nopromote_in_flight,			90,	TYPE_COUNTER)	\
 	x(io_read_bounce,				31,	TYPE_COUNTER)	\
 	x(io_read_split,				33,	TYPE_COUNTER)	\
 	x(io_read_reuse_race,				34,	TYPE_COUNTER)	\
-- 
2.51.0


From 0c09b60f922f76a680ab71c6dda38523a514de30 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 13 Jul 2025 11:07:52 -0400
Subject: [PATCH 069/309] bcachefs: make congestion tracking less aggressive

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_write.c | 9 ++-------
 1 file changed, 2 insertions(+), 7 deletions(-)

diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index fa077341d2ef..aedbea633481 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -55,14 +55,9 @@ static inline void bch2_congested_acct(struct bch_dev *ca, u64 io_latency,
 	s64 latency_over = io_latency - latency_threshold;
 
 	if (latency_threshold && latency_over > 0) {
-		/*
-		 * bump up congested by approximately latency_over * 4 /
-		 * latency_threshold - we don't need much accuracy here so don't
-		 * bother with the divide:
-		 */
 		if (atomic_read(&ca->congested) < CONGESTED_MAX)
-			atomic_add(latency_over >>
-				   max_t(int, ilog2(latency_threshold) - 2, 0),
+			atomic_add((u32) min(U32_MAX, io_latency * 2) /
+				   (u32) min(U32_MAX, latency_threshold),
 				   &ca->congested);
 
 		ca->congested_last = now;
-- 
2.51.0


From f76497a6caf56af7528f3121591ecd7d12d05235 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 13 Jul 2025 17:21:48 -0400
Subject: [PATCH 070/309] bcachefs: __bset_aux_tree_verify_ro()

Fill out some missing asserts in the aux search tree code.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bset.c | 66 +++++++++++++++++++++++++++++++---------------
 1 file changed, 45 insertions(+), 21 deletions(-)

diff --git a/fs/bcachefs/bset.c b/fs/bcachefs/bset.c
index 32841f762eb2..90fd15748bb9 100644
--- a/fs/bcachefs/bset.c
+++ b/fs/bcachefs/bset.c
@@ -362,27 +362,6 @@ static struct bkey_float *bkey_float(const struct btree *b,
 	return ro_aux_tree_base(b, t)->f + idx;
 }
 
-static void __bset_aux_tree_verify(struct btree *b)
-{
-	for_each_bset(b, t) {
-		if (t->aux_data_offset == U16_MAX)
-			continue;
-
-		BUG_ON(t != b->set &&
-		       t[-1].aux_data_offset == U16_MAX);
-
-		BUG_ON(t->aux_data_offset < bset_aux_tree_buf_start(b, t));
-		BUG_ON(t->aux_data_offset > btree_aux_data_u64s(b));
-		BUG_ON(bset_aux_tree_buf_end(t) > btree_aux_data_u64s(b));
-	}
-}
-
-static inline void bset_aux_tree_verify(struct btree *b)
-{
-	if (static_branch_unlikely(&bch2_debug_check_bset_lookups))
-		__bset_aux_tree_verify(b);
-}
-
 void bch2_btree_keys_init(struct btree *b)
 {
 	unsigned i;
@@ -538,6 +517,51 @@ static inline void bch2_bset_verify_rw_aux_tree(struct btree *b,
 		__bch2_bset_verify_rw_aux_tree(b, t);
 }
 
+static void __bset_aux_tree_verify_ro(struct btree *b, struct bset_tree *t)
+{
+	struct bkey_packed *k = btree_bkey_first(b, t);
+
+	eytzinger1_for_each(j, t->size - 1) {
+		while (tree_to_bkey(b, t, j) > k &&
+		       k != btree_bkey_last(b, t))
+			k = bkey_p_next(k);
+
+		BUG_ON(tree_to_bkey(b, t, j) != k);
+	}
+}
+
+static void __bset_aux_tree_verify(struct btree *b)
+{
+	for_each_bset(b, t) {
+		if (t->aux_data_offset == U16_MAX)
+			continue;
+
+		BUG_ON(t != b->set &&
+		       t[-1].aux_data_offset == U16_MAX);
+
+		BUG_ON(t->aux_data_offset < bset_aux_tree_buf_start(b, t));
+		BUG_ON(t->aux_data_offset > btree_aux_data_u64s(b));
+		BUG_ON(bset_aux_tree_buf_end(t) > btree_aux_data_u64s(b));
+
+		switch (bset_aux_tree_type(t)) {
+		case BSET_RO_AUX_TREE:
+			__bset_aux_tree_verify_ro(b, t);
+			break;
+		case BSET_RW_AUX_TREE:
+			__bch2_bset_verify_rw_aux_tree(b, t);
+			break;
+		default:
+			break;
+		}
+	}
+}
+
+static inline void bset_aux_tree_verify(struct btree *b)
+{
+	if (static_branch_unlikely(&bch2_debug_check_bset_lookups))
+		__bset_aux_tree_verify(b);
+}
+
 /* returns idx of first entry >= offset: */
 static unsigned rw_aux_tree_bsearch(struct btree *b,
 				    struct bset_tree *t,
-- 
2.51.0


From a0b1ae260dd9403da36093406c1e5a0b323f88d0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 09:23:29 -0400
Subject: [PATCH 071/309] bcachefs: Add missing bch2_bkey_set_needs_rebalance
 to nocow write path

This fixes nocow writes not being rebalanced (to background target).

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_write.c | 9 +++++++--
 1 file changed, 7 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index aedbea633481..53ff9a014185 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -1218,6 +1218,7 @@ static bool bch2_extent_is_writeable(struct bch_write_op *op,
 
 static int bch2_nocow_write_convert_one_unwritten(struct btree_trans *trans,
 						  struct btree_iter *iter,
+						  struct bch_write_op *op,
 						  struct bkey_i *orig,
 						  struct bkey_s_c k,
 						  u64 new_i_size)
@@ -1227,11 +1228,13 @@ static int bch2_nocow_write_convert_one_unwritten(struct btree_trans *trans,
 		return 0;
 	}
 
-	struct bkey_i *new = bch2_bkey_make_mut_noupdate(trans, k);
+	struct bkey_i *new = bch2_trans_kmalloc_nomemzero(trans,
+				bkey_bytes(k.k) + sizeof(struct bch_extent_rebalance));
 	int ret = PTR_ERR_OR_ZERO(new);
 	if (ret)
 		return ret;
 
+	bkey_reassemble(new, k);
 	bch2_cut_front(bkey_start_pos(&orig->k), new);
 	bch2_cut_back(orig->k.p, new);
 
@@ -1239,6 +1242,8 @@ static int bch2_nocow_write_convert_one_unwritten(struct btree_trans *trans,
 	bkey_for_each_ptr(ptrs, ptr)
 		ptr->unwritten = 0;
 
+	bch2_bkey_set_needs_rebalance(op->c, &op->opts, new);
+
 	/*
 	 * Note that we're not calling bch2_subvol_get_snapshot() in this path -
 	 * that was done when we kicked off the write, and here it's important
@@ -1263,7 +1268,7 @@ static void bch2_nocow_write_convert_unwritten(struct bch_write_op *op)
 				     bkey_start_pos(&orig->k), orig->k.p,
 				     BTREE_ITER_intent, k,
 				     NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
-			bch2_nocow_write_convert_one_unwritten(trans, &iter, orig, k, op->new_i_size);
+			bch2_nocow_write_convert_one_unwritten(trans, &iter, op, orig, k, op->new_i_size);
 		}));
 		if (ret)
 			break;
-- 
2.51.0


From 76395d4dc09701c562b5d736c01c48a272a326a6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 13 Jul 2025 18:40:15 -0400
Subject: [PATCH 072/309] bcachefs: delete useless null ptr check

kthread_create() never returns NULL, and that error path doesn't handle
kthread_create() errors anyways.

Reported-by: Alexander Viro <viro@zeniv.linux.org.uk>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/thread_with_file.c | 3 +--
 1 file changed, 1 insertion(+), 2 deletions(-)

diff --git a/fs/bcachefs/thread_with_file.c b/fs/bcachefs/thread_with_file.c
index 314a24d15d4e..8d5fb16fe160 100644
--- a/fs/bcachefs/thread_with_file.c
+++ b/fs/bcachefs/thread_with_file.c
@@ -60,8 +60,7 @@ int bch2_run_thread_with_file(struct thread_with_file *thr,
 err:
 	if (fd >= 0)
 		put_unused_fd(fd);
-	if (thr->task)
-		kthread_stop(thr->task);
+	kthread_stop(thr->task);
 	return ret;
 }
 
-- 
2.51.0


From c9e7a2cbd45a986779b9e4abdcaf262d3cf98518 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 20:28:28 -0400
Subject: [PATCH 073/309] bcachefs: Also create snapshots with CAP_FOWNER

Like btrfs, allow CAP_FOWNER for creating snapshots, so that programs
that take backups can run as non-root.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/namei.c | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index 3e2b41babc26..9334c3e86190 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -99,7 +99,9 @@ int bch2_create_trans(struct btree_trans *trans,
 		 * If we're not root, we have to own the subvolume being
 		 * snapshotted:
 		 */
-		if (uid && new_inode->bi_uid != uid) {
+		if (uid &&
+		    !capable(CAP_FOWNER) &&
+		    new_inode->bi_uid != uid) {
 			ret = -EPERM;
 			goto err;
 		}
-- 
2.51.0


From d86b99c3f773c4e7fd4725f679a4de5f3d9aae08 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 11:44:29 -0400
Subject: [PATCH 074/309] bcachefs: Fix missing compat code in check_subvol()

Some key types have had new fields added since they were introduced; we
can't access the new ones directly without either checking the value
size or using bkey_val_copy().

Reported-by: syzbot+377f67f96ce8b673a57b@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/subvolume.c | 44 ++++++++++++++++++++---------------------
 1 file changed, 22 insertions(+), 22 deletions(-)

diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index 353df662a9b5..ccd2ba1f7930 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -47,8 +47,8 @@ static int check_subvol(struct btree_trans *trans,
 			struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct bkey_s_c_subvolume subvol;
 	struct btree_iter subvol_children_iter = {};
+	struct bch_subvolume subvol;
 	struct bch_snapshot snapshot;
 	struct printbuf buf = PRINTBUF;
 	unsigned snapid;
@@ -57,8 +57,8 @@ static int check_subvol(struct btree_trans *trans,
 	if (k.k->type != KEY_TYPE_subvolume)
 		return 0;
 
-	subvol = bkey_s_c_to_subvolume(k);
-	snapid = le32_to_cpu(subvol.v->snapshot);
+	bkey_val_copy(&subvol, bkey_s_c_to_subvolume(k));
+	snapid = le32_to_cpu(subvol.snapshot);
 	ret = bch2_snapshot_lookup(trans, snapid, &snapshot);
 
 	if (bch2_err_matches(ret, ENOENT))
@@ -67,19 +67,19 @@ static int check_subvol(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	if (BCH_SUBVOLUME_UNLINKED(subvol.v)) {
+	if (BCH_SUBVOLUME_UNLINKED(&subvol)) {
 		ret = bch2_subvolume_delete(trans, iter->pos.offset);
 		bch_err_msg(c, ret, "deleting subvolume %llu", iter->pos.offset);
 		return ret ?: bch_err_throw(c, transaction_restart_nested);
 	}
 
-	if (fsck_err_on(subvol.k->p.offset == BCACHEFS_ROOT_SUBVOL &&
-			subvol.v->fs_path_parent,
+	if (fsck_err_on(k.k->p.offset == BCACHEFS_ROOT_SUBVOL &&
+			subvol.fs_path_parent,
 			trans, subvol_root_fs_path_parent_nonzero,
 			"root subvolume has nonzero fs_path_parent\n%s",
 			(bch2_bkey_val_to_text(&buf, c, k), buf.buf))) {
 		struct bkey_i_subvolume *n =
-			bch2_bkey_make_mut_typed(trans, iter, &subvol.s_c, 0, subvolume);
+			bch2_bkey_make_mut_typed(trans, iter, &k, 0, subvolume);
 		ret = PTR_ERR_OR_ZERO(n);
 		if (ret)
 			goto err;
@@ -87,7 +87,7 @@ static int check_subvol(struct btree_trans *trans,
 		n->v.fs_path_parent = 0;
 	}
 
-	if (subvol.v->fs_path_parent) {
+	if (subvol.fs_path_parent) {
 		struct bpos pos = subvolume_children_pos(k);
 
 		struct bkey_s_c subvol_children_k =
@@ -111,16 +111,16 @@ static int check_subvol(struct btree_trans *trans,
 
 	struct bch_inode_unpacked inode;
 	ret = bch2_inode_find_by_inum_nowarn_trans(trans,
-				    (subvol_inum) { k.k->p.offset, le64_to_cpu(subvol.v->inode) },
+				    (subvol_inum) { k.k->p.offset, le64_to_cpu(subvol.inode) },
 				    &inode);
 	if (!ret) {
-		if (fsck_err_on(inode.bi_subvol != subvol.k->p.offset,
+		if (fsck_err_on(inode.bi_subvol != k.k->p.offset,
 				trans, subvol_root_wrong_bi_subvol,
 				"subvol root %llu:%u has wrong bi_subvol field: got %u, should be %llu",
 				inode.bi_inum, inode.bi_snapshot,
-				inode.bi_subvol, subvol.k->p.offset)) {
-			inode.bi_subvol = subvol.k->p.offset;
-			inode.bi_snapshot = le32_to_cpu(subvol.v->snapshot);
+				inode.bi_subvol, k.k->p.offset)) {
+			inode.bi_subvol = k.k->p.offset;
+			inode.bi_snapshot = le32_to_cpu(subvol.snapshot);
 			ret = __bch2_fsck_write_inode(trans, &inode);
 			if (ret)
 				goto err;
@@ -128,8 +128,8 @@ static int check_subvol(struct btree_trans *trans,
 	} else if (bch2_err_matches(ret, ENOENT)) {
 		if (fsck_err(trans, subvol_to_missing_root,
 			     "subvolume %llu points to missing subvolume root %llu:%u",
-			     k.k->p.offset, le64_to_cpu(subvol.v->inode),
-			     le32_to_cpu(subvol.v->snapshot))) {
+			     k.k->p.offset, le64_to_cpu(subvol.inode),
+			     le32_to_cpu(subvol.snapshot))) {
 			/*
 			 * Recreate - any contents that are still disconnected
 			 * will then get reattached under lost+found
@@ -137,10 +137,10 @@ static int check_subvol(struct btree_trans *trans,
 			bch2_inode_init_early(c, &inode);
 			bch2_inode_init_late(c, &inode, bch2_current_time(c),
 					     0, 0, S_IFDIR|0700, 0, NULL);
-			inode.bi_inum			= le64_to_cpu(subvol.v->inode);
-			inode.bi_snapshot		= le32_to_cpu(subvol.v->snapshot);
+			inode.bi_inum			= le64_to_cpu(subvol.inode);
+			inode.bi_snapshot		= le32_to_cpu(subvol.snapshot);
 			inode.bi_subvol			= k.k->p.offset;
-			inode.bi_parent_subvol		= le32_to_cpu(subvol.v->fs_path_parent);
+			inode.bi_parent_subvol		= le32_to_cpu(subvol.fs_path_parent);
 			ret = __bch2_fsck_write_inode(trans, &inode);
 			if (ret)
 				goto err;
@@ -149,8 +149,8 @@ static int check_subvol(struct btree_trans *trans,
 		goto err;
 	}
 
-	if (!BCH_SUBVOLUME_SNAP(subvol.v)) {
-		u32 snapshot_root = bch2_snapshot_root(c, le32_to_cpu(subvol.v->snapshot));
+	if (!BCH_SUBVOLUME_SNAP(&subvol)) {
+		u32 snapshot_root = bch2_snapshot_root(c, le32_to_cpu(subvol.snapshot));
 		u32 snapshot_tree = bch2_snapshot_tree(c, snapshot_root);
 
 		struct bch_snapshot_tree st;
@@ -162,12 +162,12 @@ static int check_subvol(struct btree_trans *trans,
 		if (ret)
 			goto err;
 
-		if (fsck_err_on(le32_to_cpu(st.master_subvol) != subvol.k->p.offset,
+		if (fsck_err_on(le32_to_cpu(st.master_subvol) != k.k->p.offset,
 				trans, subvol_not_master_and_not_snapshot,
 				"subvolume %llu is not set as snapshot but is not master subvolume",
 				k.k->p.offset)) {
 			struct bkey_i_subvolume *s =
-				bch2_bkey_make_mut_typed(trans, iter, &subvol.s_c, 0, subvolume);
+				bch2_bkey_make_mut_typed(trans, iter, &k, 0, subvolume);
 			ret = PTR_ERR_OR_ZERO(s);
 			if (ret)
 				goto err;
-- 
2.51.0


From 1514c3604de20f0647857b7324862ab322b9a283 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 11:49:09 -0400
Subject: [PATCH 075/309] bcachefs: Fix UAF in check_dirent()

Subtle one: transaction commit invalidates pointers to key values, and
we prefer to do a commit as the last step in a transaction - but here'
we're updating state outside the transaction, and that has to be done
after we can't take any more transaction restarts.

Reported-by: syzbot+fea0322882c0cba65f11@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index b8c86e09b038..487a1e5b9074 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -2440,12 +2440,18 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 			}
 	}
 
+	/*
+	 * Cannot access key values after doing a transaction commit without
+	 * revalidating:
+	 */
+	bool have_dir = d.v->d_type == DT_DIR;
+
 	ret = bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc);
 	if (ret)
 		goto err;
 
 	for_each_visible_inode(c, s, dir, d.k->p.snapshot, i) {
-		if (d.v->d_type == DT_DIR)
+		if (have_dir)
 			i->count++;
 		i->i_size += bkey_bytes(d.k);
 	}
-- 
2.51.0


From 634eac1d607b18b75b0ee361448da122ac803e04 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 11:53:00 -0400
Subject: [PATCH 076/309] bcachefs: Fix journal assertion

Can't access c->disk_sb.sb without c->sb_lock.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index de66ec7231ca..3dfdccfafbf4 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -397,7 +397,7 @@ static int journal_entry_open(struct journal *j)
 
 	lockdep_assert_held(&j->lock);
 	BUG_ON(journal_entry_is_open(j));
-	BUG_ON(BCH_SB_CLEAN(c->disk_sb.sb));
+	BUG_ON(c->sb.clean);
 
 	if (j->blocked)
 		return bch_err_throw(c, journal_blocked);
-- 
2.51.0


From f634dd264df5b1d6763c8d4a825289cbff440443 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 11:57:49 -0400
Subject: [PATCH 077/309] bcachefs: Fix __bch2_fs_read_write() error path

Don't go read-only unless we succesfully marked the filesystem dirty.

This fixes an assertion pop in the journal, which checks that the
journal is only used when the filesystem is dirty.

Reported-by: syzbot+b58cefdc75f590b71819@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 15 ++++++++++-----
 1 file changed, 10 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 0107a031d275..7e4bbf8236cd 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -513,11 +513,15 @@ static int __bch2_fs_read_write(struct bch_fs *c, bool early)
 
 	ret = bch2_fs_init_rw(c);
 	if (ret)
-		goto err;
+		return ret;
 
 	ret = bch2_sb_members_v2_init(c);
 	if (ret)
-		goto err;
+		return ret;
+
+	ret = bch2_fs_mark_dirty(c);
+	if (ret)
+		return ret;
 
 	clear_bit(BCH_FS_clean_shutdown, &c->flags);
 
@@ -542,9 +546,10 @@ static int __bch2_fs_read_write(struct bch_fs *c, bool early)
 	bch2_journal_space_available(&c->journal);
 	spin_unlock(&c->journal.lock);
 
-	ret = bch2_fs_mark_dirty(c);
-	if (ret)
-		goto err;
+	/*
+	 * Don't jump to our error path, and call bch2_fs_read_only(), unless we
+	 * successfully marked the filesystem dirty
+	 */
 
 	ret = bch2_journal_reclaim_start(&c->journal);
 	if (ret)
-- 
2.51.0


From 082ea585741666dfc0fe541e19395c382488c7a1 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 16 Jul 2025 11:50:01 -0400
Subject: [PATCH 078/309] bcachefs: Give debugfs cached btree nodes better
 indentation

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/debug.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/debug.c b/fs/bcachefs/debug.c
index 07c2a0f73cc2..8b228212f72f 100644
--- a/fs/bcachefs/debug.c
+++ b/fs/bcachefs/debug.c
@@ -465,7 +465,7 @@ static void bch2_cached_btree_node_to_text(struct printbuf *out, struct bch_fs *
 					   struct btree *b)
 {
 	if (!out->nr_tabstops)
-		printbuf_tabstop_push(out, 32);
+		printbuf_tabstop_push(out, 36);
 
 	prt_printf(out, "%px ", b);
 	bch2_btree_id_level_to_text(out, b->c.btree_id, b->c.level);
-- 
2.51.0


From b0c245800ec6954c9c68901655a70e785d7b73bb Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 15:38:13 -0400
Subject: [PATCH 079/309] bcachefs: Silence clang warning about enum types

bch2_dev_get_ioref() takes either a read ref idx or a write idx ref,
depending on the rw parameter - ugly from a type safety point of view.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/ec.c       | 8 ++++----
 fs/bcachefs/io_write.c | 4 ++--
 2 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index 687c3ba98095..6150232b2c61 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -703,8 +703,8 @@ static void ec_block_endio(struct bio *bio)
 	struct closure *cl = bio->bi_private;
 	int rw = ec_bio->rw;
 	unsigned ref = rw == READ
-		? BCH_DEV_READ_REF_ec_block
-		: BCH_DEV_WRITE_REF_ec_block;
+		? (unsigned) BCH_DEV_READ_REF_ec_block
+		: (unsigned) BCH_DEV_WRITE_REF_ec_block;
 
 	bch2_account_io_completion(ca, bio_data_dir(bio),
 				   ec_bio->submit_time, !bio->bi_status);
@@ -741,8 +741,8 @@ static void ec_block_io(struct bch_fs *c, struct ec_stripe_buf *buf,
 		: BCH_DATA_parity;
 	int rw = op_is_write(opf);
 	unsigned ref = rw == READ
-		? BCH_DEV_READ_REF_ec_block
-		: BCH_DEV_WRITE_REF_ec_block;
+		? (unsigned) BCH_DEV_READ_REF_ec_block
+		: (unsigned) BCH_DEV_WRITE_REF_ec_block;
 
 	struct bch_dev *ca = bch2_dev_get_ioref(c, ptr->dev, rw, ref);
 	if (!ca) {
diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index 53ff9a014185..eefedebf65fa 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -465,8 +465,8 @@ void bch2_submit_wbio_replicas(struct bch_write_bio *wbio, struct bch_fs *c,
 	struct bch_write_bio *n;
 	unsigned ref_rw  = type == BCH_DATA_btree ? READ : WRITE;
 	unsigned ref_idx = type == BCH_DATA_btree
-		? BCH_DEV_READ_REF_btree_node_write
-		: BCH_DEV_WRITE_REF_io_write;
+		? (unsigned) BCH_DEV_READ_REF_btree_node_write
+		: (unsigned) BCH_DEV_WRITE_REF_io_write;
 
 	BUG_ON(c->opts.nochanges);
 
-- 
2.51.0


From 09566d67b1841e58ba35003fa2e9556676792263 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 15:38:58 -0400
Subject: [PATCH 080/309] bcachefs: kill bkey_journal_seq()

dead code

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_node_scan.c | 10 ----------
 1 file changed, 10 deletions(-)

diff --git a/fs/bcachefs/btree_node_scan.c b/fs/bcachefs/btree_node_scan.c
index a3fb07c60e25..598605448a26 100644
--- a/fs/bcachefs/btree_node_scan.c
+++ b/fs/bcachefs/btree_node_scan.c
@@ -65,16 +65,6 @@ static void found_btree_node_to_key(struct bkey_i *k, const struct found_btree_n
 	memcpy(bp->v.start, f->ptrs, sizeof(struct bch_extent_ptr) * f->nr_ptrs);
 }
 
-static inline u64 bkey_journal_seq(struct bkey_s_c k)
-{
-	switch (k.k->type) {
-	case KEY_TYPE_inode_v3:
-		return le64_to_cpu(bkey_s_c_to_inode_v3(k).v->bi_journal_seq);
-	default:
-		return 0;
-	}
-}
-
 static int found_btree_node_cmp_cookie(const void *_l, const void *_r)
 {
 	const struct found_btree_node *l = _l;
-- 
2.51.0


From 9847e3893f5166120d5e270407b5eddb4dbecb83 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 15:42:49 -0400
Subject: [PATCH 081/309] bcachefs: don't pass bch_ioctl_data by value

Small stack usage reduction.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/chardev.c |  2 +-
 fs/bcachefs/move.c    | 26 +++++++++++++-------------
 fs/bcachefs/move.h    |  2 +-
 3 files changed, 15 insertions(+), 15 deletions(-)

diff --git a/fs/bcachefs/chardev.c b/fs/bcachefs/chardev.c
index 5ea89aa2b0c4..2d1ac4969863 100644
--- a/fs/bcachefs/chardev.c
+++ b/fs/bcachefs/chardev.c
@@ -312,7 +312,7 @@ static int bch2_data_thread(void *arg)
 {
 	struct bch_data_ctx *ctx = container_of(arg, struct bch_data_ctx, thr);
 
-	ctx->thr.ret = bch2_data_job(ctx->c, &ctx->stats, ctx->arg);
+	ctx->thr.ret = bch2_data_job(ctx->c, &ctx->stats, &ctx->arg);
 	if (ctx->thr.ret == -BCH_ERR_device_offline)
 		ctx->stats.ret = BCH_IOCTL_DATA_EVENT_RET_device_offline;
 	else {
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 0739287a61fe..b2ea4595e8cb 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -1342,18 +1342,18 @@ static bool scrub_pred(struct bch_fs *c, void *_arg,
 
 int bch2_data_job(struct bch_fs *c,
 		  struct bch_move_stats *stats,
-		  struct bch_ioctl_data op)
+		  struct bch_ioctl_data *op)
 {
-	struct bbpos start	= BBPOS(op.start_btree, op.start_pos);
-	struct bbpos end	= BBPOS(op.end_btree, op.end_pos);
+	struct bbpos start	= BBPOS(op->start_btree, op->start_pos);
+	struct bbpos end	= BBPOS(op->end_btree, op->end_pos);
 	int ret = 0;
 
-	if (op.op >= BCH_DATA_OP_NR)
+	if (op->op >= BCH_DATA_OP_NR)
 		return -EINVAL;
 
-	bch2_move_stats_init(stats, bch2_data_ops_strs[op.op]);
+	bch2_move_stats_init(stats, bch2_data_ops_strs[op->op]);
 
-	switch (op.op) {
+	switch (op->op) {
 	case BCH_DATA_OP_scrub:
 		/*
 		 * prevent tests from spuriously failing, make sure we see all
@@ -1361,13 +1361,13 @@ int bch2_data_job(struct bch_fs *c,
 		 */
 		bch2_btree_interior_updates_flush(c);
 
-		ret = bch2_move_data_phys(c, op.scrub.dev, 0, U64_MAX,
-					  op.scrub.data_types,
+		ret = bch2_move_data_phys(c, op->scrub.dev, 0, U64_MAX,
+					  op->scrub.data_types,
 					  NULL,
 					  stats,
 					  writepoint_hashed((unsigned long) current),
 					  false,
-					  scrub_pred, &op) ?: ret;
+					  scrub_pred, op) ?: ret;
 		break;
 
 	case BCH_DATA_OP_rereplicate:
@@ -1384,18 +1384,18 @@ int bch2_data_job(struct bch_fs *c,
 		ret = bch2_replicas_gc2(c) ?: ret;
 		break;
 	case BCH_DATA_OP_migrate:
-		if (op.migrate.dev >= c->sb.nr_devices)
+		if (op->migrate.dev >= c->sb.nr_devices)
 			return -EINVAL;
 
 		stats->data_type = BCH_DATA_journal;
-		ret = bch2_journal_flush_device_pins(&c->journal, op.migrate.dev);
-		ret = bch2_move_data_phys(c, op.migrate.dev, 0, U64_MAX,
+		ret = bch2_journal_flush_device_pins(&c->journal, op->migrate.dev);
+		ret = bch2_move_data_phys(c, op->migrate.dev, 0, U64_MAX,
 					  ~0,
 					  NULL,
 					  stats,
 					  writepoint_hashed((unsigned long) current),
 					  true,
-					  migrate_pred, &op) ?: ret;
+					  migrate_pred, op) ?: ret;
 		bch2_btree_interior_updates_flush(c);
 		ret = bch2_replicas_gc2(c) ?: ret;
 		break;
diff --git a/fs/bcachefs/move.h b/fs/bcachefs/move.h
index 86b80499ac55..fe92ca6d418d 100644
--- a/fs/bcachefs/move.h
+++ b/fs/bcachefs/move.h
@@ -152,7 +152,7 @@ int bch2_evacuate_bucket(struct moving_context *,
 			   struct data_update_opts);
 int bch2_data_job(struct bch_fs *,
 		  struct bch_move_stats *,
-		  struct bch_ioctl_data);
+		  struct bch_ioctl_data *);
 
 void bch2_move_stats_to_text(struct printbuf *, struct bch_move_stats *);
 void bch2_move_stats_exit(struct bch_move_stats *, struct bch_fs *);
-- 
2.51.0


From 6c630756a109aedd1ddf53e2cb273e24ecdb8e24 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 16:35:49 -0400
Subject: [PATCH 082/309] bcachefs: better device too small error message

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 7e4bbf8236cd..590224450220 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1611,7 +1611,10 @@ static int __bch2_dev_attach_bdev(struct bch_dev *ca, struct bch_sb_handle *sb)
 
 	if (get_capacity(sb->bdev->bd_disk) <
 	    ca->mi.bucket_size * ca->mi.nbuckets) {
-		bch_err(ca, "cannot online: device too small");
+		bch_err(ca, "cannot online: device too small (capacity %llu filesystem size %llu nbuckets %llu)",
+			get_capacity(sb->bdev->bd_disk),
+			ca->mi.bucket_size * ca->mi.nbuckets,
+			ca->mi.nbuckets);
 		return bch_err_throw(ca->fs, device_size_too_small);
 	}
 
-- 
2.51.0


From 9167b433bf791bf012aad0dad6edbcabd4bec522 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 16:21:55 -0400
Subject: [PATCH 083/309] bcachefs: check_i_sectors now prints paths

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 15 ++++++++++-----
 1 file changed, 10 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 487a1e5b9074..b6d3ed448d51 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1627,23 +1627,28 @@ static int check_i_sectors_notnested(struct btree_trans *trans, struct inode_wal
 		if (i->inode.bi_sectors == i->count)
 			continue;
 
+		CLASS(printbuf, buf)();
+		lockrestart_do(trans,
+			bch2_inum_snapshot_to_path(trans,
+						   i->inode.bi_inum,
+						   i->inode.bi_snapshot, NULL, &buf));
+
 		count2 = bch2_count_inode_sectors(trans, w->last_pos.inode, i->inode.bi_snapshot);
 
 		if (w->recalculate_sums)
 			i->count = count2;
 
 		if (i->count != count2) {
-			bch_err_ratelimited(c, "fsck counted i_sectors wrong for inode %llu:%u: got %llu should be %llu",
-					    w->last_pos.inode, i->inode.bi_snapshot, i->count, count2);
+			bch_err_ratelimited(c, "fsck counted i_sectors wrong: got %llu should be %llu\n%s",
+					    i->count, count2, buf.buf);
 			i->count = count2;
 		}
 
 		if (fsck_err_on(!(i->inode.bi_flags & BCH_INODE_i_sectors_dirty) &&
 				i->inode.bi_sectors != i->count,
 				trans, inode_i_sectors_wrong,
-				"inode %llu:%u has incorrect i_sectors: got %llu, should be %llu",
-				w->last_pos.inode, i->inode.bi_snapshot,
-				i->inode.bi_sectors, i->count)) {
+				"incorrect i_sectors: got %llu, should be %llu\n%s",
+				i->inode.bi_sectors, i->count, buf.buf)) {
 			i->inode.bi_sectors = i->count;
 			ret = bch2_fsck_write_inode(trans, &i->inode);
 			if (ret)
-- 
2.51.0


From 1719eb608ae84250b944d936e0deedf6350dd8f1 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:03:37 -0400
Subject: [PATCH 084/309] bcachefs: simplify bch2_trans_do()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.h | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index cc2c6bb6b6a8..53074ed62e09 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -1007,13 +1007,19 @@ static inline void class_btree_trans_destructor(struct btree_trans **p)
 
 #define class_btree_trans_constructor(_c)	bch2_trans_get(_c)
 
+/* deprecated, prefer CLASS(btree_trans) */
 #define bch2_trans_run(_c, _do)						\
 ({									\
 	CLASS(btree_trans, trans)(_c);					\
 	(_do);								\
 })
 
-#define bch2_trans_do(_c, _do)	bch2_trans_run(_c, lockrestart_do(trans, _do))
+/* deprecated, prefer CLASS(btree_trans) */
+#define bch2_trans_do(_c, _do)						\
+({									\
+	CLASS(btree_trans, trans)(_c);					\
+	lockrestart_do(trans, _do);					\
+})
 
 void bch2_btree_trans_to_text(struct printbuf *, struct btree_trans *);
 
-- 
2.51.0


From 80cb4ce9a17c5784d9d332bbf47ad20263f0b875 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:59:31 -0400
Subject: [PATCH 085/309] bcachefs: DEFINE_GUARD(printbuf_atomic)

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/printbuf.h | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/fs/bcachefs/printbuf.h b/fs/bcachefs/printbuf.h
index 8f4e28d440ac..907e5c97550b 100644
--- a/fs/bcachefs/printbuf.h
+++ b/fs/bcachefs/printbuf.h
@@ -295,4 +295,8 @@ static inline void printbuf_atomic_dec(struct printbuf *buf)
 	buf->atomic--;
 }
 
+DEFINE_GUARD(printbuf_atomic, struct printbuf *,
+	     printbuf_atomic_inc(_T),
+	     printbuf_atomic_dec(_T));
+
 #endif /* _BCACHEFS_PRINTBUF_H */
-- 
2.51.0


From d99b090923bc30314d54510c3dbd5dcb77ff410a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:29:34 -0400
Subject: [PATCH 086/309] bcachefs: convert super-io.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super-io.c | 69 +++++++++++++++---------------------------
 1 file changed, 25 insertions(+), 44 deletions(-)

diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index 85e460d10e9d..820cb0f4fe57 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -68,23 +68,21 @@ enum bcachefs_metadata_version bch2_latest_compatible_version(enum bcachefs_meta
 
 int bch2_set_version_incompat(struct bch_fs *c, enum bcachefs_metadata_version version)
 {
-	int ret = ((c->sb.features & BIT_ULL(BCH_FEATURE_incompat_version_field)) &&
-		   version <= c->sb.version_incompat_allowed)
-		? 0
-		: -BCH_ERR_may_not_use_incompat_feature;
+	guard(mutex)(&c->sb_lock);
 
-	mutex_lock(&c->sb_lock);
-	if (!ret) {
+	if (((c->sb.features & BIT_ULL(BCH_FEATURE_incompat_version_field)) &&
+	     version <= c->sb.version_incompat_allowed)) {
 		SET_BCH_SB_VERSION_INCOMPAT(c->disk_sb.sb,
 			max(BCH_SB_VERSION_INCOMPAT(c->disk_sb.sb), version));
 		bch2_write_super(c);
+		return 0;
 	} else {
 		darray_for_each(c->incompat_versions_requested, i)
 			if (version == *i)
-				goto out;
+				return -BCH_ERR_may_not_use_incompat_feature;
 
 		darray_push(&c->incompat_versions_requested, version);
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		prt_str(&buf, "requested incompat feature ");
 		bch2_version_to_text(&buf, version);
 		prt_str(&buf, " currently not enabled, allowed up to ");
@@ -92,13 +90,8 @@ int bch2_set_version_incompat(struct bch_fs *c, enum bcachefs_metadata_version v
 		prt_printf(&buf, "\n  set version_upgrade=incompat to enable");
 
 		bch_notice(c, "%s", buf.buf);
-		printbuf_exit(&buf);
+		return -BCH_ERR_may_not_use_incompat_feature;
 	}
-
-out:
-	mutex_unlock(&c->sb_lock);
-
-	return ret;
 }
 
 const char * const bch2_sb_fields[] = {
@@ -203,12 +196,11 @@ int bch2_sb_realloc(struct bch_sb_handle *sb, unsigned u64s)
 		u64 max_bytes = 512 << sb->sb->layout.sb_max_size_bits;
 
 		if (new_bytes > max_bytes) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 
 			prt_bdevname(&buf, sb->bdev);
 			prt_printf(&buf, ": superblock too big: want %zu but have %llu", new_bytes, max_bytes);
 			pr_err("%s", buf.buf);
-			printbuf_exit(&buf);
 			return -BCH_ERR_ENOSPC_sb;
 		}
 	}
@@ -783,8 +775,8 @@ static int __bch2_read_super(const char *path, struct bch_opts *opts,
 {
 	u64 offset = opt_get(*opts, sb);
 	struct bch_sb_layout layout;
-	struct printbuf err = PRINTBUF;
-	struct printbuf err2 = PRINTBUF;
+	CLASS(printbuf, err)();
+	CLASS(printbuf, err2)();
 	__le64 *i;
 	int ret;
 #ifndef __KERNEL__
@@ -859,7 +851,6 @@ static int __bch2_read_super(const char *path, struct bch_opts *opts,
 	else
 		bch2_print_opts(opts, KERN_ERR "%s", err2.buf);
 
-	printbuf_exit(&err2);
 	printbuf_reset(&err);
 
 	/*
@@ -925,15 +916,14 @@ static int __bch2_read_super(const char *path, struct bch_opts *opts,
 				path, err.buf);
 		goto err_no_print;
 	}
-out:
-	printbuf_exit(&err);
-	return ret;
+
+	return 0;
 err:
 	bch2_print_opts(opts, KERN_ERR "bcachefs (%s): error reading superblock: %s\n",
 			path, err.buf);
 err_no_print:
 	bch2_free_super(sb);
-	goto out;
+	return ret;
 }
 
 int bch2_read_super(const char *path, struct bch_opts *opts,
@@ -1019,7 +1009,7 @@ static void write_one_super(struct bch_fs *c, struct bch_dev *ca, unsigned idx)
 int bch2_write_super(struct bch_fs *c)
 {
 	struct closure *cl = &c->sb_write;
-	struct printbuf err = PRINTBUF;
+	CLASS(printbuf, err)();
 	unsigned sb = 0, nr_wrote;
 	struct bch_devs_mask sb_written;
 	bool wrote, can_mount_without_written, can_mount_with_written;
@@ -1101,14 +1091,13 @@ int bch2_write_super(struct bch_fs *c)
 		goto out;
 
 	if (le16_to_cpu(c->disk_sb.sb->version) > bcachefs_metadata_version_current) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		prt_printf(&buf, "attempting to write superblock that wasn't version downgraded (");
 		bch2_version_to_text(&buf, le16_to_cpu(c->disk_sb.sb->version));
 		prt_str(&buf, " > ");
 		bch2_version_to_text(&buf, bcachefs_metadata_version_current);
 		prt_str(&buf, ")");
 		bch2_fs_fatal_error(c, ": %s", buf.buf);
-		printbuf_exit(&buf);
 		ret = bch_err_throw(c, sb_not_downgraded);
 		goto out;
 	}
@@ -1129,7 +1118,7 @@ int bch2_write_super(struct bch_fs *c)
 			continue;
 
 		if (le64_to_cpu(ca->sb_read_scratch->seq) < ca->disk_sb.seq) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			prt_char(&buf, ' ');
 			prt_bdevname(&buf, ca->disk_sb.bdev);
 			prt_printf(&buf,
@@ -1144,12 +1133,10 @@ int bch2_write_super(struct bch_fs *c)
 			} else {
 				bch_err(c, "%s", buf.buf);
 			}
-
-			printbuf_exit(&buf);
 		}
 
 		if (le64_to_cpu(ca->sb_read_scratch->seq) > ca->disk_sb.seq) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			prt_char(&buf, ' ');
 			prt_bdevname(&buf, ca->disk_sb.bdev);
 			prt_printf(&buf,
@@ -1157,7 +1144,6 @@ int bch2_write_super(struct bch_fs *c)
 				le64_to_cpu(ca->sb_read_scratch->seq),
 				ca->disk_sb.seq);
 			bch2_fs_fatal_error(c, "%s", buf.buf);
-			printbuf_exit(&buf);
 			ret = bch_err_throw(c, erofs_sb_err);
 		}
 	}
@@ -1219,19 +1205,17 @@ int bch2_write_super(struct bch_fs *c)
 	darray_for_each(online_devices, ca)
 		enumerated_ref_put(&(*ca)->io_ref[READ], BCH_DEV_READ_REF_write_super);
 	darray_exit(&online_devices);
-	printbuf_exit(&err);
 	return ret;
 }
 
 void __bch2_check_set_feature(struct bch_fs *c, unsigned feat)
 {
-	mutex_lock(&c->sb_lock);
-	if (!(c->sb.features & (1ULL << feat))) {
-		c->disk_sb.sb->features[0] |= cpu_to_le64(1ULL << feat);
+	guard(mutex)(&c->sb_lock);
+	if (!(c->sb.features & BIT_ULL(feat))) {
+		c->disk_sb.sb->features[0] |= cpu_to_le64(BIT_ULL(feat));
 
 		bch2_write_super(c);
 	}
-	mutex_unlock(&c->sb_lock);
 }
 
 /* Downgrade if superblock is at a higher version than currently supported: */
@@ -1279,11 +1263,12 @@ void bch2_sb_upgrade(struct bch_fs *c, unsigned new_version, bool incompat)
 
 void bch2_sb_upgrade_incompat(struct bch_fs *c)
 {
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
+
 	if (c->sb.version == c->sb.version_incompat_allowed)
-		goto unlock;
+		return;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_str(&buf, "Now allowing incompatible features up to ");
 	bch2_version_to_text(&buf, c->sb.version);
@@ -1292,14 +1277,11 @@ void bch2_sb_upgrade_incompat(struct bch_fs *c)
 	prt_newline(&buf);
 
 	bch_notice(c, "%s", buf.buf);
-	printbuf_exit(&buf);
 
 	c->disk_sb.sb->features[0] |= cpu_to_le64(BCH_SB_FEATURES_ALL);
 	SET_BCH_SB_VERSION_INCOMPAT_ALLOWED(c->disk_sb.sb,
 			max(BCH_SB_VERSION_INCOMPAT_ALLOWED(c->disk_sb.sb), c->sb.version));
 	bch2_write_super(c);
-unlock:
-	mutex_unlock(&c->sb_lock);
 }
 
 static int bch2_sb_ext_validate(struct bch_sb *sb, struct bch_sb_field *f,
@@ -1365,7 +1347,7 @@ static int bch2_sb_field_validate(struct bch_sb *sb, struct bch_sb_field *f,
 				  enum bch_validate_flags flags, struct printbuf *err)
 {
 	unsigned type = le32_to_cpu(f->type);
-	struct printbuf field_err = PRINTBUF;
+	CLASS(printbuf, field_err)();
 	const struct bch_sb_field_ops *ops = bch2_sb_field_type_ops(type);
 	int ret;
 
@@ -1377,7 +1359,6 @@ static int bch2_sb_field_validate(struct bch_sb *sb, struct bch_sb_field *f,
 		bch2_sb_field_to_text(err, sb, f);
 	}
 
-	printbuf_exit(&field_err);
 	return ret;
 }
 
-- 
2.51.0


From b031d27f7ec259b4b15d0b390041de638d5b3dd3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:35:16 -0400
Subject: [PATCH 087/309] bcachefs: convert super.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h |   2 +-
 fs/bcachefs/super.c    | 499 +++++++++++++++++------------------------
 2 files changed, 210 insertions(+), 291 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index 4f1ac7aa3532..8a6f886b5bf2 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -1165,7 +1165,7 @@ static inline bool bch2_ro_ref_tryget(struct bch_fs *c)
 
 static inline void bch2_ro_ref_put(struct bch_fs *c)
 {
-	if (refcount_dec_and_test(&c->ro_ref))
+	if (c && refcount_dec_and_test(&c->ro_ref))
 		wake_up(&c->ro_ref_wait);
 }
 
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 590224450220..0fc0b2221036 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -267,14 +267,11 @@ static struct bch_fs *__bch2_uuid_to_fs(__uuid_t uuid)
 
 struct bch_fs *bch2_uuid_to_fs(__uuid_t uuid)
 {
-	struct bch_fs *c;
+	guard(mutex)(&bch_fs_list_lock);
 
-	mutex_lock(&bch_fs_list_lock);
-	c = __bch2_uuid_to_fs(uuid);
+	struct bch_fs *c = __bch2_uuid_to_fs(uuid);
 	if (c)
 		closure_get(&c->cl);
-	mutex_unlock(&bch_fs_list_lock);
-
 	return c;
 }
 
@@ -418,9 +415,8 @@ void bch2_fs_read_only(struct bch_fs *c)
 		bch2_fs_mark_clean(c);
 	} else {
 		/* Make sure error counts/counters are persisted */
-		mutex_lock(&c->sb_lock);
+		guard(mutex)(&c->sb_lock);
 		bch2_write_super(c);
-		mutex_unlock(&c->sb_lock);
 
 		bch_verbose(c, "done going read-only, filesystem not clean");
 	}
@@ -431,9 +427,8 @@ static void bch2_fs_read_only_work(struct work_struct *work)
 	struct bch_fs *c =
 		container_of(work, struct bch_fs, read_only_work);
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 	bch2_fs_read_only(c);
-	up_write(&c->state_lock);
 }
 
 static void bch2_fs_read_only_async(struct bch_fs *c)
@@ -540,11 +535,11 @@ static int __bch2_fs_read_write(struct bch_fs *c, bool early)
 	 * overwriting whatever was there previously, and there must always be
 	 * at least one non-flush write in the journal or recovery will fail:
 	 */
-	spin_lock(&c->journal.lock);
-	set_bit(JOURNAL_need_flush_write, &c->journal.flags);
-	set_bit(JOURNAL_running, &c->journal.flags);
-	bch2_journal_space_available(&c->journal);
-	spin_unlock(&c->journal.lock);
+	scoped_guard(spinlock, &c->journal.lock) {
+		set_bit(JOURNAL_need_flush_write, &c->journal.flags);
+		set_bit(JOURNAL_running, &c->journal.flags);
+		bch2_journal_space_available(&c->journal);
+	}
 
 	/*
 	 * Don't jump to our error path, and call bch2_fs_read_only(), unless we
@@ -602,11 +597,8 @@ int bch2_fs_read_write(struct bch_fs *c)
 
 int bch2_fs_read_write_early(struct bch_fs *c)
 {
-	down_write(&c->state_lock);
-	int ret = __bch2_fs_read_write(c, true);
-	up_write(&c->state_lock);
-
-	return ret;
+	guard(rwsem_write)(&c->state_lock);
+	return __bch2_fs_read_write(c, true);
 }
 
 /* Filesystem startup/shutdown: */
@@ -704,9 +696,8 @@ void __bch2_fs_stop(struct bch_fs *c)
 
 	set_bit(BCH_FS_stopping, &c->flags);
 
-	down_write(&c->state_lock);
-	bch2_fs_read_only(c);
-	up_write(&c->state_lock);
+	scoped_guard(rwsem_write, &c->state_lock)
+		bch2_fs_read_only(c);
 
 	for (unsigned i = 0; i < c->sb.nr_devices; i++) {
 		struct bch_dev *ca = rcu_dereference_protected(c->devs[i], true);
@@ -742,9 +733,8 @@ void __bch2_fs_stop(struct bch_fs *c)
 
 void bch2_fs_free(struct bch_fs *c)
 {
-	mutex_lock(&bch_fs_list_lock);
-	list_del(&c->list);
-	mutex_unlock(&bch_fs_list_lock);
+	scoped_guard(mutex, &bch_fs_list_lock)
+		list_del(&c->list);
 
 	closure_sync(&c->cl);
 	closure_debug_destroy(&c->cl);
@@ -806,21 +796,19 @@ static int bch2_fs_online(struct bch_fs *c)
 		return ret;
 	}
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 
 	for_each_member_device(c, ca) {
 		ret = bch2_dev_sysfs_online(c, ca);
 		if (ret) {
 			bch_err(c, "error creating sysfs objects");
 			bch2_dev_put(ca);
-			goto err;
+			return ret;
 		}
 	}
 
 	BUG_ON(!list_empty(&c->list));
 	list_add(&c->list, &bch_fs_list);
-err:
-	up_write(&c->state_lock);
 	return ret;
 }
 
@@ -857,8 +845,8 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 				    bch_sb_handles *sbs)
 {
 	struct bch_fs *c;
-	struct printbuf name = PRINTBUF;
 	unsigned i, iter_size;
+	CLASS(printbuf, name)();
 	int ret = 0;
 
 	c = kvmalloc(sizeof(struct bch_fs), GFP_KERNEL|__GFP_ZERO);
@@ -945,9 +933,8 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 	if (ret)
 		goto err;
 
-	mutex_lock(&c->sb_lock);
-	ret = bch2_sb_to_fs(c, sb);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock)
+		ret = bch2_sb_to_fs(c, sb);
 
 	if (ret)
 		goto err;
@@ -999,7 +986,6 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 		goto err;
 
 	strscpy(c->name, name.buf, sizeof(c->name));
-	printbuf_exit(&name);
 
 	iter_size = sizeof(struct sort_iter) +
 		(btree_blocks(c) + 1) * 2 *
@@ -1091,9 +1077,8 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 			&c->clock_journal_res,
 			(sizeof(struct jset_entry_clock) / sizeof(u64)) * 2);
 
-	mutex_lock(&bch_fs_list_lock);
-	ret = bch2_fs_online(c);
-	mutex_unlock(&bch_fs_list_lock);
+	scoped_guard(mutex, &bch_fs_list_lock)
+		ret = bch2_fs_online(c);
 
 	if (ret)
 		goto err;
@@ -1166,8 +1151,8 @@ static bool bch2_fs_may_start(struct bch_fs *c)
 	case BCH_DEGRADED_yes:
 		flags |= BCH_FORCE_IF_DEGRADED;
 		break;
-	default:
-		mutex_lock(&c->sb_lock);
+	default: {
+		guard(mutex)(&c->sb_lock);
 		for (unsigned i = 0; i < c->disk_sb.sb->nr_devices; i++) {
 			if (!bch2_member_exists(c->disk_sb.sb, i))
 				continue;
@@ -1176,13 +1161,11 @@ static bool bch2_fs_may_start(struct bch_fs *c)
 
 			if (!bch2_dev_is_online(ca) &&
 			    (ca->mi.state == BCH_MEMBER_STATE_rw ||
-			     ca->mi.state == BCH_MEMBER_STATE_ro)) {
-				mutex_unlock(&c->sb_lock);
+			     ca->mi.state == BCH_MEMBER_STATE_ro))
 				return false;
-			}
 		}
-		mutex_unlock(&c->sb_lock);
 		break;
+	 }
 	}
 
 	return bch2_have_enough_devs(c, c->online_devs, flags, true);
@@ -1193,6 +1176,8 @@ int bch2_fs_start(struct bch_fs *c)
 	time64_t now = ktime_get_real_seconds();
 	int ret = 0;
 
+	BUG_ON(test_bit(BCH_FS_started, &c->flags));
+
 	print_mount_opts(c);
 
 	if (c->cf_encoding)
@@ -1204,43 +1189,29 @@ int bch2_fs_start(struct bch_fs *c)
 	if (!bch2_fs_may_start(c))
 		return bch_err_throw(c, insufficient_devices_to_start);
 
-	down_write(&c->state_lock);
-	mutex_lock(&c->sb_lock);
+	scoped_guard(rwsem_write, &c->state_lock) {
+		guard(mutex)(&c->sb_lock);
+		if (!bch2_sb_field_get_minsize(&c->disk_sb, ext,
+				sizeof(struct bch_sb_field_ext) / sizeof(u64))) {
+			ret = bch_err_throw(c, ENOSPC_sb);
+			goto err;
+		}
 
-	BUG_ON(test_bit(BCH_FS_started, &c->flags));
+		ret = bch2_sb_members_v2_init(c);
+		if (ret)
+			goto err;
 
-	if (!bch2_sb_field_get_minsize(&c->disk_sb, ext,
-			sizeof(struct bch_sb_field_ext) / sizeof(u64))) {
-		mutex_unlock(&c->sb_lock);
-		up_write(&c->state_lock);
-		ret = bch_err_throw(c, ENOSPC_sb);
-		goto err;
-	}
+		scoped_guard(rcu)
+			for_each_online_member_rcu(c, ca) {
+				bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx)->last_mount =
+					cpu_to_le64(now);
+				if (ca->mi.state == BCH_MEMBER_STATE_rw)
+					bch2_dev_allocator_add(c, ca);
+			}
 
-	ret = bch2_sb_members_v2_init(c);
-	if (ret) {
-		mutex_unlock(&c->sb_lock);
-		up_write(&c->state_lock);
-		goto err;
+		bch2_recalc_capacity(c);
 	}
 
-	scoped_guard(rcu)
-		for_each_online_member_rcu(c, ca)
-			bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx)->last_mount =
-			cpu_to_le64(now);
-
-	/*
-	 * Dno't write superblock yet: recovery might have to downgrade
-	 */
-	mutex_unlock(&c->sb_lock);
-
-	scoped_guard(rcu)
-		for_each_online_member_rcu(c, ca)
-			if (ca->mi.state == BCH_MEMBER_STATE_rw)
-				bch2_dev_allocator_add(c, ca);
-	bch2_recalc_capacity(c);
-	up_write(&c->state_lock);
-
 	ret = BCH_SB_INITIALIZED(c->disk_sb.sb)
 		? bch2_fs_recovery(c)
 		: bch2_fs_initialize(c);
@@ -1261,13 +1232,12 @@ int bch2_fs_start(struct bch_fs *c)
 	set_bit(BCH_FS_started, &c->flags);
 	wake_up(&c->ro_ref_wait);
 
-	down_write(&c->state_lock);
-	if (c->opts.read_only)
-		bch2_fs_read_only(c);
-	else if (!test_bit(BCH_FS_rw, &c->flags))
-		ret = bch2_fs_read_write(c);
-	up_write(&c->state_lock);
-
+	scoped_guard(rwsem_write, &c->state_lock) {
+		if (c->opts.read_only)
+			bch2_fs_read_only(c);
+		else if (!test_bit(BCH_FS_rw, &c->flags))
+			ret = bch2_fs_read_write(c);
+	}
 err:
 	if (ret)
 		bch_err_msg(c, ret, "starting filesystem");
@@ -1312,7 +1282,7 @@ static int bch2_dev_in_fs(struct bch_sb_handle *fs,
 
 	if (fs->sb->seq == sb->sb->seq &&
 	    fs->sb->write_time != sb->sb->write_time) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_str(&buf, "Split brain detected between ");
 		prt_bdevname(&buf, sb->bdev);
@@ -1337,7 +1307,6 @@ static int bch2_dev_in_fs(struct bch_sb_handle *fs,
 			prt_printf(&buf, "Not using older sb");
 
 		pr_err("%s", buf.buf);
-		printbuf_exit(&buf);
 
 		if (!opts->no_splitbrain_check)
 			return -BCH_ERR_device_splitbrain;
@@ -1348,7 +1317,7 @@ static int bch2_dev_in_fs(struct bch_sb_handle *fs,
 	u64 seq_from_member	= le64_to_cpu(sb->sb->seq);
 
 	if (seq_from_fs && seq_from_fs < seq_from_member) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_str(&buf, "Split brain detected between ");
 		prt_bdevname(&buf, sb->bdev);
@@ -1370,7 +1339,6 @@ static int bch2_dev_in_fs(struct bch_sb_handle *fs,
 		}
 
 		pr_err("%s", buf.buf);
-		printbuf_exit(&buf);
 
 		if (!opts->no_splitbrain_check)
 			return -BCH_ERR_device_splitbrain;
@@ -1585,18 +1553,16 @@ static int bch2_dev_alloc(struct bch_fs *c, unsigned dev_idx)
 	struct bch_dev *ca = NULL;
 
 	if (bch2_fs_init_fault("dev_alloc"))
-		goto err;
+		return bch_err_throw(c, ENOMEM_dev_alloc);
 
 	ca = __bch2_dev_alloc(c, &member);
 	if (!ca)
-		goto err;
+		return bch_err_throw(c, ENOMEM_dev_alloc);
 
 	ca->fs = c;
 
 	bch2_dev_attach(c, ca, dev_idx);
 	return 0;
-err:
-	return bch_err_throw(c, ENOMEM_dev_alloc);
 }
 
 static int __bch2_dev_attach_bdev(struct bch_dev *ca, struct bch_sb_handle *sb)
@@ -1625,10 +1591,9 @@ static int __bch2_dev_attach_bdev(struct bch_dev *ca, struct bch_sb_handle *sb)
 	if (ret)
 		return ret;
 
-	struct printbuf name = PRINTBUF;
+	CLASS(printbuf, name)();
 	prt_bdevname(&name, sb->bdev);
 	strscpy(ca->name, name.buf, sizeof(ca->name));
-	printbuf_exit(&name);
 
 	/* Commit: */
 	ca->disk_sb = *sb;
@@ -1760,7 +1725,6 @@ static void __bch2_dev_read_write(struct bch_fs *c, struct bch_dev *ca)
 int __bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
 			 enum bch_member_state new_state, int flags)
 {
-	struct bch_member *m;
 	int ret = 0;
 
 	if (ca->mi.state == new_state)
@@ -1774,11 +1738,11 @@ int __bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
 
 	bch_notice(ca, "%s", bch2_member_states[new_state]);
 
-	mutex_lock(&c->sb_lock);
-	m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
-	SET_BCH_MEMBER_STATE(m, new_state);
-	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock) {
+		struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
+		SET_BCH_MEMBER_STATE(m, new_state);
+		bch2_write_super(c);
+	}
 
 	if (new_state == BCH_MEMBER_STATE_rw)
 		__bch2_dev_read_write(c, ca);
@@ -1791,26 +1755,20 @@ int __bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
 int bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
 		       enum bch_member_state new_state, int flags)
 {
-	int ret;
-
-	down_write(&c->state_lock);
-	ret = __bch2_dev_set_state(c, ca, new_state, flags);
-	up_write(&c->state_lock);
-
-	return ret;
+	guard(rwsem_write)(&c->state_lock);
+	return __bch2_dev_set_state(c, ca, new_state, flags);
 }
 
 /* Device add/removal: */
 
 int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 {
-	struct bch_member *m;
 	unsigned dev_idx = ca->dev_idx, data;
 	bool fast_device_removal = !bch2_request_incompat_feature(c,
 					bcachefs_metadata_version_fast_device_removal);
 	int ret;
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 
 	/*
 	 * We consume a reference to ca->ref, regardless of whether we succeed
@@ -1877,20 +1835,17 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 
 	data = bch2_dev_has_data(c, ca);
 	if (data) {
-		struct printbuf data_has = PRINTBUF;
-
+		CLASS(printbuf, data_has)();
 		prt_bitflags(&data_has, __bch2_data_types, data);
 		bch_err(ca, "Remove failed, still has data (%s)", data_has.buf);
-		printbuf_exit(&data_has);
 		ret = -EBUSY;
 		goto err;
 	}
 
 	__bch2_dev_offline(c, ca);
 
-	mutex_lock(&c->sb_lock);
-	rcu_assign_pointer(c->devs[ca->dev_idx], NULL);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock)
+		rcu_assign_pointer(c->devs[ca->dev_idx], NULL);
 
 #ifndef CONFIG_BCACHEFS_DEBUG
 	percpu_ref_kill(&ca->ref);
@@ -1906,25 +1861,23 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 	 * Free this device's slot in the bch_member array - all pointers to
 	 * this device must be gone:
 	 */
-	mutex_lock(&c->sb_lock);
-	m = bch2_members_v2_get_mut(c->disk_sb.sb, dev_idx);
+	scoped_guard(mutex, &c->sb_lock) {
+		struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, dev_idx);
 
-	if (fast_device_removal)
-		m->uuid = BCH_SB_MEMBER_DELETED_UUID;
-	else
-		memset(&m->uuid, 0, sizeof(m->uuid));
+		if (fast_device_removal)
+			m->uuid = BCH_SB_MEMBER_DELETED_UUID;
+		else
+			memset(&m->uuid, 0, sizeof(m->uuid));
 
-	bch2_write_super(c);
+		bch2_write_super(c);
+	}
 
-	mutex_unlock(&c->sb_lock);
-	up_write(&c->state_lock);
 	return 0;
 err:
 	if (test_bit(BCH_FS_rw, &c->flags) &&
 	    ca->mi.state == BCH_MEMBER_STATE_rw &&
 	    !enumerated_ref_is_zero(&ca->io_ref[READ]))
 		__bch2_dev_read_write(c, ca);
-	up_write(&c->state_lock);
 	return ret;
 }
 
@@ -1934,8 +1887,7 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 	struct bch_opts opts = bch2_opts_empty();
 	struct bch_sb_handle sb = {};
 	struct bch_dev *ca = NULL;
-	struct printbuf errbuf = PRINTBUF;
-	struct printbuf label = PRINTBUF;
+	CLASS(printbuf, label)();
 	int ret = 0;
 
 	ret = bch2_read_super(path, &opts, &sb);
@@ -1954,12 +1906,12 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 	}
 
 	if (list_empty(&c->list)) {
-		mutex_lock(&bch_fs_list_lock);
-		if (__bch2_uuid_to_fs(c->sb.uuid))
-			ret = bch_err_throw(c, filesystem_uuid_already_open);
-		else
-			list_add(&c->list, &bch_fs_list);
-		mutex_unlock(&bch_fs_list_lock);
+		scoped_guard(mutex, &bch_fs_list_lock) {
+			if (__bch2_uuid_to_fs(c->sb.uuid))
+				ret = bch_err_throw(c, filesystem_uuid_already_open);
+			else
+				list_add(&c->list, &bch_fs_list);
+		}
 
 		if (ret) {
 			bch_err(c, "filesystem UUID already open");
@@ -1981,105 +1933,95 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 	if (ret)
 		goto err;
 
-	down_write(&c->state_lock);
-	mutex_lock(&c->sb_lock);
-	SET_BCH_SB_MULTI_DEVICE(c->disk_sb.sb, true);
-
-	ret = bch2_sb_from_fs(c, ca);
-	bch_err_msg(c, ret, "setting up new superblock");
-	if (ret)
-		goto err_unlock;
+	scoped_guard(rwsem_write, &c->state_lock) {
+		scoped_guard(mutex, &c->sb_lock) {
+			SET_BCH_SB_MULTI_DEVICE(c->disk_sb.sb, true);
 
-	if (dynamic_fault("bcachefs:add:no_slot"))
-		goto err_unlock;
+			ret = bch2_sb_from_fs(c, ca);
+			bch_err_msg(c, ret, "setting up new superblock");
+			if (ret)
+				goto err;
 
-	ret = bch2_sb_member_alloc(c);
-	if (ret < 0) {
-		bch_err_msg(c, ret, "setting up new superblock");
-		goto err_unlock;
-	}
-	unsigned dev_idx = ret;
-	ret = 0;
+			if (dynamic_fault("bcachefs:add:no_slot"))
+				goto err;
 
-	/* success: */
+			ret = bch2_sb_member_alloc(c);
+			if (ret < 0) {
+				bch_err_msg(c, ret, "setting up new superblock");
+				goto err;
+			}
+			unsigned dev_idx = ret;
+			ret = 0;
 
-	dev_mi.last_mount = cpu_to_le64(ktime_get_real_seconds());
-	*bch2_members_v2_get_mut(c->disk_sb.sb, dev_idx) = dev_mi;
+			/* success: */
 
-	ca->disk_sb.sb->dev_idx	= dev_idx;
-	bch2_dev_attach(c, ca, dev_idx);
+			dev_mi.last_mount = cpu_to_le64(ktime_get_real_seconds());
+			*bch2_members_v2_get_mut(c->disk_sb.sb, dev_idx) = dev_mi;
 
-	set_bit(ca->dev_idx, c->online_devs.d);
+			ca->disk_sb.sb->dev_idx	= dev_idx;
+			bch2_dev_attach(c, ca, dev_idx);
 
-	if (BCH_MEMBER_GROUP(&dev_mi)) {
-		ret = __bch2_dev_group_set(c, ca, label.buf);
-		bch_err_msg(c, ret, "creating new label");
-		if (ret) {
-			mutex_unlock(&c->sb_lock);
-			goto err_late;
-		}
-	}
+			set_bit(ca->dev_idx, c->online_devs.d);
 
-	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+			if (BCH_MEMBER_GROUP(&dev_mi)) {
+				ret = __bch2_dev_group_set(c, ca, label.buf);
+				bch_err_msg(c, ret, "creating new label");
+				if (ret)
+					goto err_late;
+			}
 
-	ret = bch2_dev_usage_init(ca, false);
-	if (ret)
-		goto err_late;
+			bch2_write_super(c);
+		}
 
-	if (test_bit(BCH_FS_started, &c->flags)) {
-		ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
-		bch_err_msg(ca, ret, "marking new superblock");
+		ret = bch2_dev_usage_init(ca, false);
 		if (ret)
 			goto err_late;
 
-		ret = bch2_fs_freespace_init(c);
-		bch_err_msg(ca, ret, "initializing free space");
-		if (ret)
-			goto err_late;
+		if (test_bit(BCH_FS_started, &c->flags)) {
+			ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
+			bch_err_msg(ca, ret, "marking new superblock");
+			if (ret)
+				goto err_late;
 
-		if (ca->mi.state == BCH_MEMBER_STATE_rw)
-			__bch2_dev_read_write(c, ca);
+			ret = bch2_fs_freespace_init(c);
+			bch_err_msg(ca, ret, "initializing free space");
+			if (ret)
+				goto err_late;
 
-		ret = bch2_dev_journal_alloc(ca, false);
-		bch_err_msg(c, ret, "allocating journal");
-		if (ret)
-			goto err_late;
-	}
+			if (ca->mi.state == BCH_MEMBER_STATE_rw)
+				__bch2_dev_read_write(c, ca);
 
-	/*
-	 * We just changed the superblock UUID, invalidate cache and send a
-	 * uevent to update /dev/disk/by-uuid
-	 */
-	invalidate_bdev(ca->disk_sb.bdev);
+			ret = bch2_dev_journal_alloc(ca, false);
+			bch_err_msg(c, ret, "allocating journal");
+			if (ret)
+				goto err_late;
+		}
 
-	char uuid_str[37];
-	snprintf(uuid_str, sizeof(uuid_str), "UUID=%pUb", &c->sb.uuid);
+		/*
+		 * We just changed the superblock UUID, invalidate cache and send a
+		 * uevent to update /dev/disk/by-uuid
+		 */
+		invalidate_bdev(ca->disk_sb.bdev);
 
-	char *envp[] = {
-		"CHANGE=uuid",
-		uuid_str,
-		NULL,
-	};
-	kobject_uevent_env(&ca->disk_sb.bdev->bd_device.kobj, KOBJ_CHANGE, envp);
+		char uuid_str[37];
+		snprintf(uuid_str, sizeof(uuid_str), "UUID=%pUb", &c->sb.uuid);
 
-	up_write(&c->state_lock);
+		char *envp[] = {
+			"CHANGE=uuid",
+			uuid_str,
+			NULL,
+		};
+		kobject_uevent_env(&ca->disk_sb.bdev->bd_device.kobj, KOBJ_CHANGE, envp);
+	}
 out:
-	printbuf_exit(&label);
-	printbuf_exit(&errbuf);
 	bch_err_fn(c, ret);
 	return ret;
-
-err_unlock:
-	mutex_unlock(&c->sb_lock);
-	up_write(&c->state_lock);
 err:
 	if (ca)
 		bch2_dev_free(ca);
 	bch2_free_super(&sb);
 	goto out;
 err_late:
-	up_write(&c->state_lock);
 	ca = NULL;
 	goto err;
 }
@@ -2093,13 +2035,11 @@ int bch2_dev_online(struct bch_fs *c, const char *path)
 	unsigned dev_idx;
 	int ret;
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 
 	ret = bch2_read_super(path, &opts, &sb);
-	if (ret) {
-		up_write(&c->state_lock);
+	if (ret)
 		return ret;
-	}
 
 	dev_idx = sb.sb->dev_idx;
 
@@ -2136,39 +2076,33 @@ int bch2_dev_online(struct bch_fs *c, const char *path)
 			goto err;
 	}
 
-	mutex_lock(&c->sb_lock);
-	bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx)->last_mount =
-		cpu_to_le64(ktime_get_real_seconds());
-	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock) {
+		bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx)->last_mount =
+			cpu_to_le64(ktime_get_real_seconds());
+		bch2_write_super(c);
+	}
 
-	up_write(&c->state_lock);
 	return 0;
 err:
-	up_write(&c->state_lock);
 	bch2_free_super(&sb);
 	return ret;
 }
 
 int bch2_dev_offline(struct bch_fs *c, struct bch_dev *ca, int flags)
 {
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 
 	if (!bch2_dev_is_online(ca)) {
 		bch_err(ca, "Already offline");
-		up_write(&c->state_lock);
 		return 0;
 	}
 
 	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags)) {
 		bch_err(ca, "Cannot offline required disk");
-		up_write(&c->state_lock);
 		return bch_err_throw(c, device_state_not_allowed);
 	}
 
 	__bch2_dev_offline(c, ca);
-
-	up_write(&c->state_lock);
 	return 0;
 }
 
@@ -2186,60 +2120,54 @@ static int __bch2_dev_resize_alloc(struct bch_dev *ca, u64 old_nbuckets, u64 new
 
 int bch2_dev_resize(struct bch_fs *c, struct bch_dev *ca, u64 nbuckets)
 {
-	struct bch_member *m;
 	u64 old_nbuckets;
 	int ret = 0;
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 	old_nbuckets = ca->mi.nbuckets;
 
 	if (nbuckets < ca->mi.nbuckets) {
 		bch_err(ca, "Cannot shrink yet");
-		ret = -EINVAL;
-		goto err;
+		return -EINVAL;
 	}
 
 	if (nbuckets > BCH_MEMBER_NBUCKETS_MAX) {
 		bch_err(ca, "New device size too big (%llu greater than max %u)",
 			nbuckets, BCH_MEMBER_NBUCKETS_MAX);
-		ret = bch_err_throw(c, device_size_too_big);
-		goto err;
+		return bch_err_throw(c, device_size_too_big);
 	}
 
 	if (bch2_dev_is_online(ca) &&
 	    get_capacity(ca->disk_sb.bdev->bd_disk) <
 	    ca->mi.bucket_size * nbuckets) {
 		bch_err(ca, "New size larger than device");
-		ret = bch_err_throw(c, device_size_too_small);
-		goto err;
+		return bch_err_throw(c, device_size_too_small);
 	}
 
 	ret = bch2_dev_buckets_resize(c, ca, nbuckets);
 	bch_err_msg(ca, ret, "resizing buckets");
 	if (ret)
-		goto err;
+		return ret;
 
 	ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
 	if (ret)
-		goto err;
+		return ret;
 
-	mutex_lock(&c->sb_lock);
-	m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
-	m->nbuckets = cpu_to_le64(nbuckets);
+	scoped_guard(mutex, &c->sb_lock) {
+		struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
+		m->nbuckets = cpu_to_le64(nbuckets);
 
-	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+		bch2_write_super(c);
+	}
 
 	if (ca->mi.freespace_initialized) {
 		ret = __bch2_dev_resize_alloc(ca, old_nbuckets, nbuckets);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	bch2_recalc_capacity(c);
-err:
-	up_write(&c->state_lock);
-	return ret;
+	return 0;
 }
 
 int bch2_fs_resize_on_mount(struct bch_fs *c)
@@ -2257,26 +2185,24 @@ int bch2_fs_resize_on_mount(struct bch_fs *c)
 			if (ret) {
 				enumerated_ref_put(&ca->io_ref[READ],
 						   BCH_DEV_READ_REF_fs_resize_on_mount);
-				up_write(&c->state_lock);
 				return ret;
 			}
 
-			mutex_lock(&c->sb_lock);
-			struct bch_member *m =
-				bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
-			m->nbuckets = cpu_to_le64(new_nbuckets);
-			SET_BCH_MEMBER_RESIZE_ON_MOUNT(m, false);
+			scoped_guard(mutex, &c->sb_lock) {
+				struct bch_member *m =
+					bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
+				m->nbuckets = cpu_to_le64(new_nbuckets);
+				SET_BCH_MEMBER_RESIZE_ON_MOUNT(m, false);
 
-			c->disk_sb.sb->features[0] &= ~cpu_to_le64(BIT_ULL(BCH_FEATURE_small_image));
-			bch2_write_super(c);
-			mutex_unlock(&c->sb_lock);
+				c->disk_sb.sb->features[0] &= ~cpu_to_le64(BIT_ULL(BCH_FEATURE_small_image));
+				bch2_write_super(c);
+			}
 
 			if (ca->mi.freespace_initialized) {
 				ret = __bch2_dev_resize_alloc(ca, old_nbuckets, new_nbuckets);
 				if (ret) {
 					enumerated_ref_put(&ca->io_ref[READ],
 							BCH_DEV_READ_REF_fs_resize_on_mount);
-					up_write(&c->state_lock);
 					return ret;
 				}
 			}
@@ -2315,6 +2241,10 @@ static struct bch_fs *bdev_get_fs(struct block_device *bdev)
 	return c;
 }
 
+DEFINE_CLASS(bdev_get_fs, struct bch_fs *,
+	     bch2_ro_ref_put(_T), bdev_get_fs(bdev),
+	     struct block_device *bdev);
+
 /* returns with ref on ca->ref */
 static struct bch_dev *bdev_to_bch_dev(struct bch_fs *c, struct block_device *bdev)
 {
@@ -2326,7 +2256,7 @@ static struct bch_dev *bdev_to_bch_dev(struct bch_fs *c, struct block_device *bd
 
 static void bch2_fs_bdev_mark_dead(struct block_device *bdev, bool surprise)
 {
-	struct bch_fs *c = bdev_get_fs(bdev);
+	CLASS(bdev_get_fs, c)(bdev);
 	if (!c)
 		return;
 
@@ -2340,48 +2270,45 @@ static void bch2_fs_bdev_mark_dead(struct block_device *bdev, bool surprise)
 		down_read(&sb->s_umount);
 	}
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
+
 	struct bch_dev *ca = bdev_to_bch_dev(c, bdev);
-	if (!ca)
-		goto unlock;
+	if (ca) {
+		bool dev = bch2_dev_state_allowed(c, ca,
+						  BCH_MEMBER_STATE_failed,
+						  BCH_FORCE_IF_DEGRADED);
+
+		if (!dev && sb) {
+			if (!surprise)
+				sync_filesystem(sb);
+			shrink_dcache_sb(sb);
+			evict_inodes(sb);
+		}
 
-	bool dev = bch2_dev_state_allowed(c, ca,
-					  BCH_MEMBER_STATE_failed,
-					  BCH_FORCE_IF_DEGRADED);
+		CLASS(printbuf, buf)();
+		__bch2_log_msg_start(ca->name, &buf);
 
-	if (!dev && sb) {
-		if (!surprise)
-			sync_filesystem(sb);
-		shrink_dcache_sb(sb);
-		evict_inodes(sb);
-	}
+		prt_printf(&buf, "offline from block layer");
 
-	struct printbuf buf = PRINTBUF;
-	__bch2_log_msg_start(ca->name, &buf);
+		if (dev) {
+			__bch2_dev_offline(c, ca);
+		} else {
+			bch2_journal_flush(&c->journal);
+			bch2_fs_emergency_read_only2(c, &buf);
+		}
 
-	prt_printf(&buf, "offline from block layer");
+		bch2_print_str(c, KERN_ERR, buf.buf);
 
-	if (dev) {
-		__bch2_dev_offline(c, ca);
-	} else {
-		bch2_journal_flush(&c->journal);
-		bch2_fs_emergency_read_only2(c, &buf);
+		bch2_dev_put(ca);
 	}
 
-	bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
-
-	bch2_dev_put(ca);
-unlock:
 	if (sb)
 		up_read(&sb->s_umount);
-	up_write(&c->state_lock);
-	bch2_ro_ref_put(c);
 }
 
 static void bch2_fs_bdev_sync(struct block_device *bdev)
 {
-	struct bch_fs *c = bdev_get_fs(bdev);
+	CLASS(bdev_get_fs, c)(bdev);
 	if (!c)
 		return;
 
@@ -2392,12 +2319,9 @@ static void bch2_fs_bdev_sync(struct block_device *bdev)
 		 * unmounted - we only take this to avoid a warning in
 		 * sync_filesystem:
 		 */
-		down_read(&sb->s_umount);
+		guard(rwsem_read)(&sb->s_umount);
 		sync_filesystem(sb);
-		up_read(&sb->s_umount);
 	}
-
-	bch2_ro_ref_put(c);
 }
 
 const struct blk_holder_ops bch2_sb_handle_bdev_ops = {
@@ -2419,7 +2343,6 @@ struct bch_fs *bch2_fs_open(darray_const_str *devices,
 	bch_sb_handles sbs = {};
 	struct bch_fs *c = NULL;
 	struct bch_sb_handle *best = NULL;
-	struct printbuf errbuf = PRINTBUF;
 	int ret = 0;
 
 	if (!try_module_get(THIS_MODULE))
@@ -2474,15 +2397,12 @@ struct bch_fs *bch2_fs_open(darray_const_str *devices,
 	if (ret)
 		goto err;
 
-	down_write(&c->state_lock);
-	darray_for_each(sbs, sb) {
-		ret = bch2_dev_attach_bdev(c, sb);
-		if (ret) {
-			up_write(&c->state_lock);
-			goto err;
+	scoped_guard(rwsem_write, &c->state_lock)
+		darray_for_each(sbs, sb) {
+			ret = bch2_dev_attach_bdev(c, sb);
+			if (ret)
+				goto err;
 		}
-	}
-	up_write(&c->state_lock);
 
 	if (!c->opts.nostart) {
 		ret = bch2_fs_start(c);
@@ -2493,7 +2413,6 @@ struct bch_fs *bch2_fs_open(darray_const_str *devices,
 	darray_for_each(sbs, sb)
 		bch2_free_super(sb);
 	darray_exit(&sbs);
-	printbuf_exit(&errbuf);
 	module_put(THIS_MODULE);
 	return c;
 err_print:
-- 
2.51.0


From 388af9bc2be6c02290d22ed5489dcde60a47520d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:45:45 -0400
Subject: [PATCH 088/309] bcachefs: convert acl.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/acl.c | 15 +++++----------
 1 file changed, 5 insertions(+), 10 deletions(-)

diff --git a/fs/bcachefs/acl.c b/fs/bcachefs/acl.c
index d03adc36100e..307824d6eccb 100644
--- a/fs/bcachefs/acl.c
+++ b/fs/bcachefs/acl.c
@@ -279,7 +279,7 @@ struct posix_acl *bch2_get_acl(struct inode *vinode, int type, bool rcu)
 	if (rcu)
 		return ERR_PTR(-ECHILD);
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 retry:
 	bch2_trans_begin(trans);
 
@@ -304,7 +304,6 @@ struct posix_acl *bch2_get_acl(struct inode *vinode, int type, bool rcu)
 		set_cached_acl(&inode->v, type, acl);
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return acl;
 }
 
@@ -350,8 +349,8 @@ int bch2_set_acl(struct mnt_idmap *idmap,
 	umode_t mode;
 	int ret;
 
-	mutex_lock(&inode->ei_update_lock);
-	struct btree_trans *trans = bch2_trans_get(c);
+	guard(mutex)(&inode->ei_update_lock);
+	CLASS(btree_trans, trans)(c);
 retry:
 	bch2_trans_begin(trans);
 	acl = _acl;
@@ -385,17 +384,13 @@ int bch2_set_acl(struct mnt_idmap *idmap,
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 	if (unlikely(ret))
-		goto err;
+		return ret;
 
 	bch2_inode_update_after_write(trans, inode, &inode_u,
 				      ATTR_CTIME|ATTR_MODE);
 
 	set_cached_acl(&inode->v, type, acl);
-err:
-	bch2_trans_put(trans);
-	mutex_unlock(&inode->ei_update_lock);
-
-	return ret;
+	return 0;
 }
 
 int bch2_acl_chmod(struct btree_trans *trans, subvol_inum inum,
-- 
2.51.0


From 569ce3092ef05a1eb088f8465619d380b1de7663 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:45:59 -0400
Subject: [PATCH 089/309] bcachefs: convert xattr.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/xattr.c | 52 ++++++++++++++++++++++-----------------------
 1 file changed, 25 insertions(+), 27 deletions(-)

diff --git a/fs/bcachefs/xattr.c b/fs/bcachefs/xattr.c
index 627f153798c6..903e20cd34fa 100644
--- a/fs/bcachefs/xattr.c
+++ b/fs/bcachefs/xattr.c
@@ -313,8 +313,8 @@ ssize_t bch2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 	struct xattr_buf buf = { .buf = buffer, .len = buffer_size };
 	u64 offset = 0, inum = inode->ei_inode.bi_inum;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_xattrs,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_xattrs,
 				   POS(inum, offset),
 				   POS(inum, U64_MAX),
 				   inode->ei_inum.subvol, 0, k, ({
@@ -322,7 +322,7 @@ ssize_t bch2_xattr_list(struct dentry *dentry, char *buffer, size_t buffer_size)
 				continue;
 
 			bch2_xattr_emit(dentry, bkey_s_c_to_xattr(k).v, &buf);
-		}))) ?:
+		})) ?:
 		bch2_xattr_list_bcachefs(c, &inode->ei_inode, &buf, false) ?:
 		bch2_xattr_list_bcachefs(c, &inode->ei_inode, &buf, true);
 
@@ -335,9 +335,10 @@ static int bch2_xattr_get_handler(const struct xattr_handler *handler,
 {
 	struct bch_inode_info *inode = to_bch_ei(vinode);
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	int ret = bch2_trans_do(c,
-		bch2_xattr_get_trans(trans, inode, name, buffer, size, handler->flags));
+	CLASS(btree_trans, trans)(c);
 
+	int ret = lockrestart_do(trans,
+		bch2_xattr_get_trans(trans, inode, name, buffer, size, handler->flags));
 	if (ret < 0 && bch2_err_matches(ret, ENOENT))
 		ret = -ENODATA;
 
@@ -356,12 +357,12 @@ static int bch2_xattr_set_handler(const struct xattr_handler *handler,
 	struct bch_inode_unpacked inode_u;
 	int ret;
 
-	ret = bch2_trans_run(c,
-		commit_do(trans, NULL, NULL, 0,
+	CLASS(btree_trans, trans)(c);
+	ret = commit_do(trans, NULL, NULL, 0,
 			bch2_xattr_set(trans, inode_inum(inode), &inode_u,
 				       &hash, name, value, size,
 				       handler->flags, flags)) ?:
-		(bch2_inode_update_after_write(trans, inode, &inode_u, ATTR_CTIME), 0));
+		(bch2_inode_update_after_write(trans, inode, &inode_u, ATTR_CTIME), 0);
 
 	return bch2_err_class(ret);
 }
@@ -418,7 +419,6 @@ static int __bch2_xattr_bcachefs_get(const struct xattr_handler *handler,
 		bch2_inode_opts_to_opts(&inode->ei_inode);
 	const struct bch_option *opt;
 	int id, inode_opt_id;
-	struct printbuf out = PRINTBUF;
 	int ret;
 	u64 v;
 
@@ -439,6 +439,7 @@ static int __bch2_xattr_bcachefs_get(const struct xattr_handler *handler,
 	    !(inode->ei_inode.bi_fields_set & (1 << inode_opt_id)))
 		return -ENODATA;
 
+	CLASS(printbuf, out)();
 	v = bch2_opt_get_by_id(&opts, id);
 	bch2_opt_to_text(&out, c, c->disk_sb.sb, opt, v, 0);
 
@@ -453,7 +454,6 @@ static int __bch2_xattr_bcachefs_get(const struct xattr_handler *handler,
 			memcpy(buffer, out.buf, out.pos);
 	}
 
-	printbuf_exit(&out);
 	return ret;
 }
 
@@ -532,11 +532,11 @@ static int bch2_xattr_bcachefs_set(const struct xattr_handler *handler,
 		kfree(buf);
 
 		if (ret < 0)
-			goto err_class_exit;
+			goto err;
 
 		ret = bch2_opt_hook_pre_set(c, NULL, opt_id, v);
 		if (ret < 0)
-			goto err_class_exit;
+			goto err;
 
 		s.v = v + 1;
 		s.defined = true;
@@ -548,7 +548,7 @@ static int bch2_xattr_bcachefs_set(const struct xattr_handler *handler,
 		 * rename() also has to deal with keeping inherited options up
 		 * to date - see bch2_reinherit_attrs()
 		 */
-		spin_lock(&dentry->d_lock);
+		guard(spinlock)(&dentry->d_lock);
 		if (!IS_ROOT(dentry)) {
 			struct bch_inode_info *dir =
 				to_bch_ei(d_inode(dentry->d_parent));
@@ -557,26 +557,24 @@ static int bch2_xattr_bcachefs_set(const struct xattr_handler *handler,
 		} else {
 			s.v = 0;
 		}
-		spin_unlock(&dentry->d_lock);
 
 		s.defined = false;
 	}
 
-	mutex_lock(&inode->ei_update_lock);
-	if (inode_opt_id == Inode_opt_project) {
-		/*
-		 * inode fields accessible via the xattr interface are stored
-		 * with a +1 bias, so that 0 means unset:
-		 */
-		ret = bch2_set_projid(c, inode, s.v ? s.v - 1 : 0);
-		if (ret)
-			goto err;
-	}
+	scoped_guard(mutex, &inode->ei_update_lock) {
+		if (inode_opt_id == Inode_opt_project) {
+			/*
+			 * inode fields accessible via the xattr interface are stored
+			 * with a +1 bias, so that 0 means unset:
+			 */
+			ret = bch2_set_projid(c, inode, s.v ? s.v - 1 : 0);
+			if (ret)
+				goto err;
+		}
 
-	ret = bch2_write_inode(c, inode, inode_opt_set_fn, &s, 0);
+		ret = bch2_write_inode(c, inode, inode_opt_set_fn, &s, 0);
+	}
 err:
-	mutex_unlock(&inode->ei_update_lock);
-err_class_exit:
 	return bch2_err_class(ret);
 }
 
-- 
2.51.0


From 39919768719ae8309314e407d52dba599885f583 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:48:54 -0400
Subject: [PATCH 090/309] bcachefs: convert thread_with_file.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/thread_with_file.c | 49 +++++++++++++++++-----------------
 1 file changed, 25 insertions(+), 24 deletions(-)

diff --git a/fs/bcachefs/thread_with_file.c b/fs/bcachefs/thread_with_file.c
index 8d5fb16fe160..c2eae0ab7765 100644
--- a/fs/bcachefs/thread_with_file.c
+++ b/fs/bcachefs/thread_with_file.c
@@ -184,23 +184,23 @@ static ssize_t thread_with_stdio_write(struct file *file, const char __user *ubu
 			break;
 		}
 
-		spin_lock(&buf->lock);
-		size_t makeroom = b;
-		if (!buf->waiting_for_line || memchr(buf->buf.data, '\n', buf->buf.nr))
-			makeroom = min_t(ssize_t, makeroom,
-				   max_t(ssize_t, STDIO_REDIRECT_BUFSIZE - buf->buf.nr,
-						  0));
-		darray_make_room_gfp(&buf->buf, makeroom, GFP_NOWAIT);
-
-		b = min(len, darray_room(buf->buf));
-
-		if (b && !copy_from_user_nofault(&darray_top(buf->buf), ubuf, b)) {
-			buf->buf.nr += b;
-			ubuf	+= b;
-			len	-= b;
-			copied	+= b;
+		scoped_guard(spinlock, &buf->lock) {
+			size_t makeroom = b;
+			if (!buf->waiting_for_line || memchr(buf->buf.data, '\n', buf->buf.nr))
+				makeroom = min_t(ssize_t, makeroom,
+					   max_t(ssize_t, STDIO_REDIRECT_BUFSIZE - buf->buf.nr,
+							  0));
+			darray_make_room_gfp(&buf->buf, makeroom, GFP_NOWAIT);
+
+			b = min(len, darray_room(buf->buf));
+
+			if (b && !copy_from_user_nofault(&darray_top(buf->buf), ubuf, b)) {
+				buf->buf.nr += b;
+				ubuf	+= b;
+				len	-= b;
+				copied	+= b;
+			}
 		}
-		spin_unlock(&buf->lock);
 
 		if (b) {
 			wake_up(&buf->wait);
@@ -348,14 +348,15 @@ int bch2_stdio_redirect_read(struct stdio_redirect *stdio, char *ubuf, size_t le
 	if (stdio->done)
 		return -1;
 
-	spin_lock(&buf->lock);
-	int ret = min(len, buf->buf.nr);
-	buf->buf.nr -= ret;
-	memcpy(ubuf, buf->buf.data, ret);
-	memmove(buf->buf.data,
-		buf->buf.data + ret,
-		buf->buf.nr);
-	spin_unlock(&buf->lock);
+	int ret;
+	scoped_guard(spinlock, &buf->lock) {
+		ret = min(len, buf->buf.nr);
+		buf->buf.nr -= ret;
+		memcpy(ubuf, buf->buf.data, ret);
+		memmove(buf->buf.data,
+			buf->buf.data + ret,
+			buf->buf.nr);
+	}
 
 	wake_up(&buf->wait);
 	return ret;
-- 
2.51.0


From b496b798a7f502aaccaa6884f9721594454a2d17 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:51:15 -0400
Subject: [PATCH 091/309] bcachefs: convert unit tests to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/tests.c | 198 +++++++++++++++++++-------------------------
 1 file changed, 87 insertions(+), 111 deletions(-)

diff --git a/fs/bcachefs/tests.c b/fs/bcachefs/tests.c
index 782a05fe7656..ea27df30cfcb 100644
--- a/fs/bcachefs/tests.c
+++ b/fs/bcachefs/tests.c
@@ -31,7 +31,7 @@ static void delete_test_keys(struct bch_fs *c)
 
 static int test_delete(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_i_cookie k;
 	int ret;
@@ -66,13 +66,12 @@ static int test_delete(struct bch_fs *c, u64 nr)
 		goto err;
 err:
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
 static int test_delete_written(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_i_cookie k;
 	int ret;
@@ -101,7 +100,6 @@ static int test_delete_written(struct bch_fs *c, u64 nr)
 		goto err;
 err:
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
@@ -130,13 +128,14 @@ static int test_iterate(struct bch_fs *c, u64 nr)
 	pr_info("iterating forwards");
 	i = 0;
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
-					SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
-					0, k, ({
+	CLASS(btree_trans, trans)(c);
+
+	ret = for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
+				     SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
+				     0, k, ({
 			BUG_ON(k.k->p.offset != i++);
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating forwards");
 	if (ret)
 		return ret;
@@ -145,12 +144,11 @@ static int test_iterate(struct bch_fs *c, u64 nr)
 
 	pr_info("iterating backwards");
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_reverse(trans, iter, BTREE_ID_xattrs,
+	ret = for_each_btree_key_reverse(trans, iter, BTREE_ID_xattrs,
 				SPOS(0, U64_MAX, U32_MAX), 0, k, ({
 			BUG_ON(k.k->p.offset != --i);
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating backwards");
 	if (ret)
 		return ret;
@@ -185,14 +183,15 @@ static int test_iterate_extents(struct bch_fs *c, u64 nr)
 	pr_info("iterating forwards");
 	i = 0;
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_extents,
-					SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
-					0, k, ({
+	CLASS(btree_trans, trans)(c);
+
+	ret = for_each_btree_key_max(trans, iter, BTREE_ID_extents,
+				     SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
+				     0, k, ({
 			BUG_ON(bkey_start_offset(k.k) != i);
 			i = k.k->p.offset;
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating forwards");
 	if (ret)
 		return ret;
@@ -201,13 +200,12 @@ static int test_iterate_extents(struct bch_fs *c, u64 nr)
 
 	pr_info("iterating backwards");
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_reverse(trans, iter, BTREE_ID_extents,
+	ret = for_each_btree_key_reverse(trans, iter, BTREE_ID_extents,
 				SPOS(0, U64_MAX, U32_MAX), 0, k, ({
 			BUG_ON(k.k->p.offset != i);
 			i = bkey_start_offset(k.k);
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating backwards");
 	if (ret)
 		return ret;
@@ -241,14 +239,15 @@ static int test_iterate_slots(struct bch_fs *c, u64 nr)
 	pr_info("iterating forwards");
 	i = 0;
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
-					  SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
-					  0, k, ({
+	CLASS(btree_trans, trans)(c);
+
+	ret = for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
+				     SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
+				     0, k, ({
 			BUG_ON(k.k->p.offset != i);
 			i += 2;
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating forwards");
 	if (ret)
 		return ret;
@@ -258,10 +257,9 @@ static int test_iterate_slots(struct bch_fs *c, u64 nr)
 	pr_info("iterating forwards by slots");
 	i = 0;
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
-					SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
-					BTREE_ITER_slots, k, ({
+	ret = for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
+				     SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
+				     BTREE_ITER_slots, k, ({
 			if (i >= nr * 2)
 				break;
 
@@ -270,7 +268,7 @@ static int test_iterate_slots(struct bch_fs *c, u64 nr)
 
 			i++;
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating forwards by slots");
 	return ret;
 }
@@ -301,15 +299,16 @@ static int test_iterate_slots_extents(struct bch_fs *c, u64 nr)
 	pr_info("iterating forwards");
 	i = 0;
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_extents,
-					SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
-					0, k, ({
+	CLASS(btree_trans, trans)(c);
+
+	ret = for_each_btree_key_max(trans, iter, BTREE_ID_extents,
+				     SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
+				     0, k, ({
 			BUG_ON(bkey_start_offset(k.k) != i + 8);
 			BUG_ON(k.k->size != 8);
 			i += 16;
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating forwards");
 	if (ret)
 		return ret;
@@ -319,10 +318,9 @@ static int test_iterate_slots_extents(struct bch_fs *c, u64 nr)
 	pr_info("iterating forwards by slots");
 	i = 0;
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_extents,
-					SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
-					BTREE_ITER_slots, k, ({
+	ret = for_each_btree_key_max(trans, iter, BTREE_ID_extents,
+				     SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
+				     BTREE_ITER_slots, k, ({
 			if (i == nr)
 				break;
 			BUG_ON(bkey_deleted(k.k) != !(i % 16));
@@ -331,7 +329,7 @@ static int test_iterate_slots_extents(struct bch_fs *c, u64 nr)
 			BUG_ON(k.k->size != 8);
 			i = k.k->p.offset;
 			0;
-		})));
+		}));
 	bch_err_msg(c, ret, "error iterating forwards by slots");
 	return ret;
 }
@@ -344,7 +342,7 @@ static int test_peek_end(struct bch_fs *c, u64 nr)
 {
 	delete_test_keys(c);
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_s_c k;
 
@@ -358,7 +356,6 @@ static int test_peek_end(struct bch_fs *c, u64 nr)
 	BUG_ON(k.k);
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return 0;
 }
 
@@ -366,7 +363,7 @@ static int test_peek_end_extents(struct bch_fs *c, u64 nr)
 {
 	delete_test_keys(c);
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_s_c k;
 
@@ -380,7 +377,6 @@ static int test_peek_end_extents(struct bch_fs *c, u64 nr)
 	BUG_ON(k.k);
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return 0;
 }
 
@@ -392,15 +388,13 @@ static int insert_test_extent(struct bch_fs *c,
 			      u64 start, u64 end)
 {
 	struct bkey_i_cookie k;
-	int ret;
-
 	bkey_cookie_init(&k.k_i);
 	k.k_i.k.p.offset = end;
 	k.k_i.k.p.snapshot = U32_MAX;
 	k.k_i.k.size = end - start;
 	k.k_i.k.bversion.lo = test_version++;
 
-	ret = bch2_btree_insert(c, BTREE_ID_extents, &k.k_i, NULL, 0, 0);
+	int ret = bch2_btree_insert(c, BTREE_ID_extents, &k.k_i, NULL, 0, 0);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -446,15 +440,14 @@ static int test_extent_overwrite_all(struct bch_fs *c, u64 nr)
 static int insert_test_overlapping_extent(struct bch_fs *c, u64 inum, u64 start, u32 len, u32 snapid)
 {
 	struct bkey_i_cookie k;
-	int ret;
-
 	bkey_cookie_init(&k.k_i);
 	k.k_i.k.p.inode	= inum;
 	k.k_i.k.p.offset = start + len;
 	k.k_i.k.p.snapshot = snapid;
 	k.k_i.k.size = len;
 
-	ret = bch2_trans_commit_do(c, NULL, NULL, 0,
+	CLASS(btree_trans, trans)(c);
+	int ret = commit_do(trans, NULL, NULL, 0,
 		bch2_btree_insert_nonextent(trans, BTREE_ID_extents, &k.k_i,
 					    BTREE_UPDATE_internal_snapshot_node));
 	bch_err_fn(c, ret);
@@ -477,7 +470,6 @@ static int test_extent_create_overlapping(struct bch_fs *c, u64 inum)
 /* Test skipping over keys in unrelated snapshots: */
 static int test_snapshot_filter(struct bch_fs *c, u32 snapid_lo, u32 snapid_hi)
 {
-	struct btree_trans *trans;
 	struct btree_iter iter;
 	struct bkey_s_c k;
 	struct bkey_i_cookie cookie;
@@ -489,7 +481,7 @@ static int test_snapshot_filter(struct bch_fs *c, u32 snapid_lo, u32 snapid_hi)
 	if (ret)
 		return ret;
 
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
 			     SPOS(0, 0, snapid_lo), 0);
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX))));
@@ -497,28 +489,28 @@ static int test_snapshot_filter(struct bch_fs *c, u32 snapid_lo, u32 snapid_hi)
 	BUG_ON(k.k->p.snapshot != U32_MAX);
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
 static int test_snapshots(struct bch_fs *c, u64 nr)
 {
 	struct bkey_i_cookie cookie;
-	u32 snapids[2];
-	u32 snapid_subvols[2] = { 1, 1 };
-	int ret;
-
 	bkey_cookie_init(&cookie.k_i);
 	cookie.k.p.snapshot = U32_MAX;
-	ret = bch2_btree_insert(c, BTREE_ID_xattrs, &cookie.k_i, NULL, 0, 0);
+
+	int ret = bch2_btree_insert(c, BTREE_ID_xattrs, &cookie.k_i, NULL, 0, 0);
 	if (ret)
 		return ret;
 
-	ret = bch2_trans_commit_do(c, NULL, NULL, 0,
-		      bch2_snapshot_node_create(trans, U32_MAX,
-						snapids,
-						snapid_subvols,
-						2));
+	u32 snapids[2];
+	u32 snapid_subvols[2] = { 1, 1 };
+
+	CLASS(btree_trans, trans)(c);
+	ret = commit_do(trans, NULL, NULL, 0,
+			bch2_snapshot_node_create(trans, U32_MAX,
+						  snapids,
+						  snapid_subvols,
+						  2));
 	if (ret)
 		return ret;
 
@@ -542,42 +534,37 @@ static u64 test_rand(void)
 
 static int rand_insert(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct bkey_i_cookie k;
-	int ret = 0;
-	u64 i;
+	CLASS(btree_trans, trans)(c);
 
-	for (i = 0; i < nr; i++) {
+	for (u64 i = 0; i < nr; i++) {
+		struct bkey_i_cookie k;
 		bkey_cookie_init(&k.k_i);
 		k.k.p.offset = test_rand();
 		k.k.p.snapshot = U32_MAX;
 
-		ret = commit_do(trans, NULL, NULL, 0,
+		int ret = commit_do(trans, NULL, NULL, 0,
 			bch2_btree_insert_trans(trans, BTREE_ID_xattrs, &k.k_i, 0));
 		if (ret)
-			break;
+			return ret;
 	}
 
-	bch2_trans_put(trans);
-	return ret;
+	return 0;
 }
 
 static int rand_insert_multi(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct bkey_i_cookie k[8];
-	int ret = 0;
 	unsigned j;
-	u64 i;
 
-	for (i = 0; i < nr; i += ARRAY_SIZE(k)) {
+	for (u64 i = 0; i < nr; i += ARRAY_SIZE(k)) {
 		for (j = 0; j < ARRAY_SIZE(k); j++) {
 			bkey_cookie_init(&k[j].k_i);
 			k[j].k.p.offset = test_rand();
 			k[j].k.p.snapshot = U32_MAX;
 		}
 
-		ret = commit_do(trans, NULL, NULL, 0,
+		int ret = commit_do(trans, NULL, NULL, 0,
 			bch2_btree_insert_trans(trans, BTREE_ID_xattrs, &k[0].k_i, 0) ?:
 			bch2_btree_insert_trans(trans, BTREE_ID_xattrs, &k[1].k_i, 0) ?:
 			bch2_btree_insert_trans(trans, BTREE_ID_xattrs, &k[2].k_i, 0) ?:
@@ -587,25 +574,23 @@ static int rand_insert_multi(struct bch_fs *c, u64 nr)
 			bch2_btree_insert_trans(trans, BTREE_ID_xattrs, &k[6].k_i, 0) ?:
 			bch2_btree_insert_trans(trans, BTREE_ID_xattrs, &k[7].k_i, 0));
 		if (ret)
-			break;
+			return ret;
 	}
 
-	bch2_trans_put(trans);
-	return ret;
+	return 0;
 }
 
 static int rand_lookup(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
-	u64 i;
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
 			     SPOS(0, 0, U32_MAX), 0);
 
-	for (i = 0; i < nr; i++) {
+	for (u64 i = 0; i < nr; i++) {
 		bch2_btree_iter_set_pos(trans, &iter, SPOS(0, test_rand(), U32_MAX));
 
 		lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek(trans, &iter)));
@@ -615,7 +600,6 @@ static int rand_lookup(struct bch_fs *c, u64 nr)
 	}
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
@@ -646,17 +630,16 @@ static int rand_mixed_trans(struct btree_trans *trans,
 
 static int rand_mixed(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_i_cookie cookie;
 	int ret = 0;
-	u64 i, rand;
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
 			     SPOS(0, 0, U32_MAX), 0);
 
-	for (i = 0; i < nr; i++) {
-		rand = test_rand();
+	for (u64 i = 0; i < nr; i++) {
+		u64 rand = test_rand();
 		ret = commit_do(trans, NULL, NULL, 0,
 			rand_mixed_trans(trans, &iter, &cookie, i, rand));
 		if (ret)
@@ -664,7 +647,6 @@ static int rand_mixed(struct bch_fs *c, u64 nr)
 	}
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
@@ -692,31 +674,27 @@ static int __do_delete(struct btree_trans *trans, struct bpos pos)
 
 static int rand_delete(struct bch_fs *c, u64 nr)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	int ret = 0;
-	u64 i;
+	CLASS(btree_trans, trans)(c);
 
-	for (i = 0; i < nr; i++) {
+	for (u64 i = 0; i < nr; i++) {
 		struct bpos pos = SPOS(0, test_rand(), U32_MAX);
 
-		ret = commit_do(trans, NULL, NULL, 0,
+		int ret = commit_do(trans, NULL, NULL, 0,
 			__do_delete(trans, pos));
 		if (ret)
-			break;
+			return ret;
 	}
 
-	bch2_trans_put(trans);
-	return ret;
+	return 0;
 }
 
 static int seq_insert(struct bch_fs *c, u64 nr)
 {
 	struct bkey_i_cookie insert;
-
 	bkey_cookie_init(&insert.k_i);
 
-	return bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
+	CLASS(btree_trans, trans)(c);
+	return for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
 					SPOS(0, 0, U32_MAX),
 					BTREE_ITER_slots|BTREE_ITER_intent, k,
 					NULL, NULL, 0, ({
@@ -724,22 +702,22 @@ static int seq_insert(struct bch_fs *c, u64 nr)
 				break;
 			insert.k.p = iter.pos;
 			bch2_trans_update(trans, &iter, &insert.k_i, 0);
-		})));
+		}));
 }
 
 static int seq_lookup(struct bch_fs *c, u64 nr)
 {
-	return bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
+	CLASS(btree_trans, trans)(c);
+	return for_each_btree_key_max(trans, iter, BTREE_ID_xattrs,
 				  SPOS(0, 0, U32_MAX), POS(0, U64_MAX),
 				  0, k,
-		0));
+		0);
 }
 
 static int seq_overwrite(struct bch_fs *c, u64 nr)
 {
-	return bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
+	CLASS(btree_trans, trans)(c);
+	return for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
 					SPOS(0, 0, U32_MAX),
 					BTREE_ITER_intent, k,
 					NULL, NULL, 0, ({
@@ -747,7 +725,7 @@ static int seq_overwrite(struct bch_fs *c, u64 nr)
 
 			bkey_reassemble(&u.k_i, k);
 			bch2_trans_update(trans, &iter, &u.k_i, 0);
-		})));
+		}));
 }
 
 static int seq_delete(struct bch_fs *c, u64 nr)
@@ -808,8 +786,8 @@ int bch2_btree_perf_test(struct bch_fs *c, const char *testname,
 {
 	struct test_job j = { .c = c, .nr = nr, .nr_threads = nr_threads };
 	char name_buf[20];
-	struct printbuf nr_buf = PRINTBUF;
-	struct printbuf per_sec_buf = PRINTBUF;
+	CLASS(printbuf, nr_buf)();
+	CLASS(printbuf, per_sec_buf)();
 	unsigned i;
 	u64 time;
 
@@ -883,8 +861,6 @@ int bch2_btree_perf_test(struct bch_fs *c, const char *testname,
 		div_u64(time, NSEC_PER_SEC),
 		div_u64(time * nr_threads, nr),
 		per_sec_buf.buf);
-	printbuf_exit(&per_sec_buf);
-	printbuf_exit(&nr_buf);
 	return j.ret;
 }
 
-- 
2.51.0


From 97ce55dc74485c341e3c1b83b7d1982bdfb58d99 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:51:57 -0400
Subject: [PATCH 092/309] bcachefs: convert util.[ch] to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/time_stats.c | 7 ++-----
 fs/bcachefs/util.c       | 8 +++-----
 fs/bcachefs/util.h       | 3 ++-
 3 files changed, 7 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/time_stats.c b/fs/bcachefs/time_stats.c
index 2c34fe4be912..7b5fa44807d7 100644
--- a/fs/bcachefs/time_stats.c
+++ b/fs/bcachefs/time_stats.c
@@ -138,10 +138,8 @@ void __bch2_time_stats_update(struct bch2_time_stats *stats, u64 start, u64 end)
 						 GFP_ATOMIC);
 		spin_unlock_irqrestore(&stats->lock, flags);
 	} else {
-		struct time_stat_buffer *b;
-
-		preempt_disable();
-		b = this_cpu_ptr(stats->buffer);
+		guard(preempt)();
+		struct time_stat_buffer *b = this_cpu_ptr(stats->buffer);
 
 		BUG_ON(b->nr >= ARRAY_SIZE(b->entries));
 		b->entries[b->nr++] = (struct time_stat_buffer_entry) {
@@ -151,7 +149,6 @@ void __bch2_time_stats_update(struct bch2_time_stats *stats, u64 start, u64 end)
 
 		if (unlikely(b->nr == ARRAY_SIZE(b->entries)))
 			time_stats_clear_buffer(stats, b);
-		preempt_enable();
 	}
 }
 
diff --git a/fs/bcachefs/util.c b/fs/bcachefs/util.c
index 7a4436fd4441..2ded7f3c835f 100644
--- a/fs/bcachefs/util.c
+++ b/fs/bcachefs/util.c
@@ -321,11 +321,10 @@ void bch2_prt_backtrace(struct printbuf *out, bch_stacktrace *stack)
 
 int bch2_prt_task_backtrace(struct printbuf *out, struct task_struct *task, unsigned skipnr, gfp_t gfp)
 {
-	bch_stacktrace stack = { 0 };
+	CLASS(bch_stacktrace, stack)();
 	int ret = bch2_save_backtrace(&stack, task, skipnr + 1, gfp);
 
 	bch2_prt_backtrace(out, &stack);
-	darray_exit(&stack);
 	return ret;
 }
 
@@ -982,9 +981,8 @@ u64 *bch2_acc_percpu_u64s(u64 __percpu *p, unsigned nr)
 	int cpu;
 
 	/* access to pcpu vars has to be blocked by other locking */
-	preempt_disable();
-	ret = this_cpu_ptr(p);
-	preempt_enable();
+	scoped_guard(preempt)
+		ret = this_cpu_ptr(p);
 
 	for_each_possible_cpu(cpu) {
 		u64 *i = per_cpu_ptr(p, cpu);
diff --git a/fs/bcachefs/util.h b/fs/bcachefs/util.h
index 6488f098d140..768528c2bae7 100644
--- a/fs/bcachefs/util.h
+++ b/fs/bcachefs/util.h
@@ -216,7 +216,8 @@ void bch2_prt_u64_base2(struct printbuf *, u64);
 
 void bch2_print_string_as_lines(const char *, const char *);
 
-typedef DARRAY(unsigned long) bch_stacktrace;
+DEFINE_DARRAY_NAMED(bch_stacktrace, unsigned long);
+
 int bch2_save_backtrace(bch_stacktrace *stack, struct task_struct *, unsigned, gfp_t);
 void bch2_prt_backtrace(struct printbuf *, bch_stacktrace *);
 int bch2_prt_task_backtrace(struct printbuf *, struct task_struct *, unsigned, gfp_t);
-- 
2.51.0


From 284c30c9bf32255a85db56f3501aacab84fe848f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:53:06 -0400
Subject: [PATCH 093/309] bcachefs: convert six.c to guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/six.c | 21 +++++++++------------
 1 file changed, 9 insertions(+), 12 deletions(-)

diff --git a/fs/bcachefs/six.c b/fs/bcachefs/six.c
index 538c324f4765..08083d6ca8bc 100644
--- a/fs/bcachefs/six.c
+++ b/fs/bcachefs/six.c
@@ -152,16 +152,16 @@ static int __do_six_trylock(struct six_lock *lock, enum six_lock_type type,
 	 * here.
 	 */
 	if (type == SIX_LOCK_read && lock->readers) {
-		preempt_disable();
-		this_cpu_inc(*lock->readers); /* signal that we own lock */
+		scoped_guard(preempt) {
+			this_cpu_inc(*lock->readers); /* signal that we own lock */
 
-		smp_mb();
+			smp_mb();
 
-		old = atomic_read(&lock->state);
-		ret = !(old & l[type].lock_fail);
+			old = atomic_read(&lock->state);
+			ret = !(old & l[type].lock_fail);
 
-		this_cpu_sub(*lock->readers, !ret);
-		preempt_enable();
+			this_cpu_sub(*lock->readers, !ret);
+		}
 
 		if (!ret) {
 			smp_mb();
@@ -360,7 +360,7 @@ static inline bool six_optimistic_spin(struct six_lock *lock,
 	if (atomic_read(&lock->state) & SIX_LOCK_NOSPIN)
 		return false;
 
-	preempt_disable();
+	guard(preempt)();
 	end_time = sched_clock() + 10 * NSEC_PER_USEC;
 
 	while (!need_resched() && six_owner_running(lock)) {
@@ -369,10 +369,8 @@ static inline bool six_optimistic_spin(struct six_lock *lock,
 		 * wait->lock_acquired: pairs with the smp_store_release in
 		 * __six_lock_wakeup
 		 */
-		if (smp_load_acquire(&wait->lock_acquired)) {
-			preempt_enable();
+		if (smp_load_acquire(&wait->lock_acquired))
 			return true;
-		}
 
 		if (!(++loop & 0xf) && (time_after64(sched_clock(), end_time))) {
 			six_set_bitmask(lock, SIX_LOCK_NOSPIN);
@@ -388,7 +386,6 @@ static inline bool six_optimistic_spin(struct six_lock *lock,
 		cpu_relax();
 	}
 
-	preempt_enable();
 	return false;
 }
 
-- 
2.51.0


From 506143091363340fe22283f4db04d33f7fb96a09 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:53:33 -0400
Subject: [PATCH 094/309] bcachefs: convert progress.c to guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/progress.c | 3 +--
 1 file changed, 1 insertion(+), 2 deletions(-)

diff --git a/fs/bcachefs/progress.c b/fs/bcachefs/progress.c
index d09898566abe..42353067ba28 100644
--- a/fs/bcachefs/progress.c
+++ b/fs/bcachefs/progress.c
@@ -46,7 +46,7 @@ void bch2_progress_update_iter(struct btree_trans *trans,
 	s->last_node = b;
 
 	if (progress_update_p(s)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		unsigned percent = s->nodes_total
 			? div64_u64(s->nodes_seen * 100, s->nodes_total)
 			: 0;
@@ -56,6 +56,5 @@ void bch2_progress_update_iter(struct btree_trans *trans,
 		bch2_bbpos_to_text(&buf, BBPOS(iter->btree_id, iter->pos));
 
 		bch_info(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 }
-- 
2.51.0


From ffaf13ba76b8c2aed64ae743be84805239256c4f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:53:58 -0400
Subject: [PATCH 095/309] bcachefs: convert enumerated_ref.c to guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/enumerated_ref.c | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/fs/bcachefs/enumerated_ref.c b/fs/bcachefs/enumerated_ref.c
index 56ab430f209f..2ded74135977 100644
--- a/fs/bcachefs/enumerated_ref.c
+++ b/fs/bcachefs/enumerated_ref.c
@@ -75,13 +75,11 @@ void enumerated_ref_stop(struct enumerated_ref *ref,
 {
 	enumerated_ref_stop_async(ref);
 	while (!wait_for_completion_timeout(&ref->stop_complete, HZ * 10)) {
-		struct printbuf buf = PRINTBUF;
-
+		CLASS(printbuf, buf)();
 		prt_str(&buf, "Waited for 10 seconds to shutdown enumerated ref\n");
 		prt_str(&buf, "Outstanding refs:\n");
 		enumerated_ref_to_text(&buf, ref, names);
 		printk(KERN_ERR "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 }
 
-- 
2.51.0


From 78802d52e6f8ee55f8fa2c5f782dad38e5010651 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:57:20 -0400
Subject: [PATCH 096/309] bcachefs: convert opts.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/opts.c | 33 ++++++++++-----------------------
 1 file changed, 10 insertions(+), 23 deletions(-)

diff --git a/fs/bcachefs/opts.c b/fs/bcachefs/opts.c
index b1cf88905b81..921f9049912d 100644
--- a/fs/bcachefs/opts.c
+++ b/fs/bcachefs/opts.c
@@ -584,7 +584,7 @@ void bch2_opt_hook_post_set(struct bch_fs *c, struct bch_dev *ca, u64 inum,
 		break;
 	case Opt_discard:
 		if (!ca) {
-			mutex_lock(&c->sb_lock);
+			guard(mutex)(&c->sb_lock);
 			for_each_member_device(c, ca) {
 				struct bch_member *m =
 					bch2_members_v2_get_mut(ca->disk_sb.sb, ca->dev_idx);
@@ -592,7 +592,6 @@ void bch2_opt_hook_post_set(struct bch_fs *c, struct bch_dev *ca, u64 inum,
 			}
 
 			bch2_write_super(c);
-			mutex_unlock(&c->sb_lock);
 		}
 		break;
 	case Opt_version_upgrade:
@@ -613,7 +612,6 @@ int bch2_parse_one_mount_opt(struct bch_fs *c, struct bch_opts *opts,
 			     struct printbuf *parse_later,
 			     const char *name, const char *val)
 {
-	struct printbuf err = PRINTBUF;
 	u64 v;
 	int ret, id;
 
@@ -638,46 +636,36 @@ int bch2_parse_one_mount_opt(struct bch_fs *c, struct bch_opts *opts,
 	val = bch2_opt_val_synonym_lookup(name, val);
 
 	if (!(bch2_opt_table[id].flags & OPT_MOUNT))
-		goto bad_opt;
+		return -BCH_ERR_option_name;
 
 	if (id == Opt_acl &&
 	    !IS_ENABLED(CONFIG_BCACHEFS_POSIX_ACL))
-		goto bad_opt;
+		return -BCH_ERR_option_name;
 
 	if ((id == Opt_usrquota ||
 	     id == Opt_grpquota) &&
 	    !IS_ENABLED(CONFIG_BCACHEFS_QUOTA))
-		goto bad_opt;
+		return -BCH_ERR_option_name;
 
+	CLASS(printbuf, err)();
 	ret = bch2_opt_parse(c, &bch2_opt_table[id], val, &v, &err);
 	if (ret == -BCH_ERR_option_needs_open_fs) {
-		ret = 0;
-
 		if (parse_later) {
 			prt_printf(parse_later, "%s=%s,", name, val);
 			if (parse_later->allocation_failure)
-				ret = -ENOMEM;
+				return -ENOMEM;
 		}
 
-		goto out;
+		return 0;
 	}
 
 	if (ret < 0)
-		goto bad_val;
+		return -BCH_ERR_option_value;
 
 	if (opts)
 		bch2_opt_set_by_id(opts, id, v);
 
-	ret = 0;
-out:
-	printbuf_exit(&err);
-	return ret;
-bad_opt:
-	ret = -BCH_ERR_option_name;
-	goto out;
-bad_val:
-	ret = -BCH_ERR_option_value;
-	goto out;
+	return 0;
 }
 
 int bch2_parse_mount_opts(struct bch_fs *c, struct bch_opts *opts,
@@ -805,11 +793,10 @@ bool __bch2_opt_set_sb(struct bch_sb *sb, int dev_idx,
 bool bch2_opt_set_sb(struct bch_fs *c, struct bch_dev *ca,
 		     const struct bch_option *opt, u64 v)
 {
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	bool changed = __bch2_opt_set_sb(c->disk_sb.sb, ca ? ca->dev_idx : -1, opt, v);
 	if (changed)
 		bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
 	return changed;
 }
 
-- 
2.51.0


From 487fd91655d24b9add4f784bcf9b83eeaa8882b2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:00:12 -0400
Subject: [PATCH 097/309] bcachefs: convert sysfs.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sysfs.c | 9 +++------
 1 file changed, 3 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/sysfs.c b/fs/bcachefs/sysfs.c
index ac8d03d3c835..a3a9a29e1db5 100644
--- a/fs/bcachefs/sysfs.c
+++ b/fs/bcachefs/sysfs.c
@@ -61,7 +61,7 @@ static ssize_t fn ## _to_text(struct printbuf *,			\
 static ssize_t fn ## _show(struct kobject *kobj, struct attribute *attr,\
 			   char *buf)					\
 {									\
-	struct printbuf out = PRINTBUF;					\
+	CLASS(printbuf, out)();						\
 	ssize_t ret = fn ## _to_text(&out, kobj, attr);			\
 									\
 	if (out.pos && out.buf[out.pos - 1] != '\n')			\
@@ -74,7 +74,6 @@ static ssize_t fn ## _show(struct kobject *kobj, struct attribute *attr,\
 		ret = min_t(size_t, out.pos, PAGE_SIZE - 1);		\
 		memcpy(buf, out.buf, ret);				\
 	}								\
-	printbuf_exit(&out);						\
 	return bch2_err_class(ret);					\
 }									\
 									\
@@ -233,14 +232,13 @@ static size_t bch2_btree_cache_size(struct bch_fs *c)
 	size_t ret = 0;
 	struct btree *b;
 
-	mutex_lock(&bc->lock);
+	guard(mutex)(&bc->lock);
 	list_for_each_entry(b, &bc->live[0].list, list)
 		ret += btree_buf_bytes(b);
 	list_for_each_entry(b, &bc->live[1].list, list)
 		ret += btree_buf_bytes(b);
 	list_for_each_entry(b, &bc->freeable, list)
 		ret += btree_buf_bytes(b);
-	mutex_unlock(&bc->lock);
 	return ret;
 }
 
@@ -453,9 +451,8 @@ STORE(bch2_fs)
 		closure_wake_up(&c->freelist_wait);
 
 	if (attr == &sysfs_trigger_recalc_capacity) {
-		down_read(&c->state_lock);
+		guard(rwsem_read)(&c->state_lock);
 		bch2_recalc_capacity(c);
-		up_read(&c->state_lock);
 	}
 
 	if (attr == &sysfs_trigger_delete_dead_snapshots)
-- 
2.51.0


From 9c6fde5547ea3169a7e9d3f205b0364b4ec80013 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:02:19 -0400
Subject: [PATCH 098/309] bcachefs: convert buckets_waiting_for_journal.c to
 CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/buckets_waiting_for_journal.c | 30 ++++++++---------------
 1 file changed, 10 insertions(+), 20 deletions(-)

diff --git a/fs/bcachefs/buckets_waiting_for_journal.c b/fs/bcachefs/buckets_waiting_for_journal.c
index 832eff93acb6..ca341586920b 100644
--- a/fs/bcachefs/buckets_waiting_for_journal.c
+++ b/fs/bcachefs/buckets_waiting_for_journal.c
@@ -25,25 +25,20 @@ static void bucket_table_init(struct buckets_waiting_for_journal_table *t, size_
 u64 bch2_bucket_journal_seq_ready(struct buckets_waiting_for_journal *b,
 				  unsigned dev, u64 bucket)
 {
-	struct buckets_waiting_for_journal_table *t;
 	u64 dev_bucket = (u64) dev << 56 | bucket;
-	u64 ret = 0;
 
-	mutex_lock(&b->lock);
-	t = b->t;
+	guard(mutex)(&b->lock);
+
+	struct buckets_waiting_for_journal_table *t = b->t;
 
 	for (unsigned i = 0; i < ARRAY_SIZE(t->hash_seeds); i++) {
 		struct bucket_hashed *h = bucket_hash(t, i, dev_bucket);
 
-		if (h->dev_bucket == dev_bucket) {
-			ret = h->journal_seq;
-			break;
-		}
+		if (h->dev_bucket == dev_bucket)
+			return h->journal_seq;
 	}
 
-	mutex_unlock(&b->lock);
-
-	return ret;
+	return 0;
 }
 
 static bool bucket_table_insert(struct buckets_waiting_for_journal_table *t,
@@ -92,12 +87,11 @@ int bch2_set_bucket_needs_journal_commit(struct buckets_waiting_for_journal *b,
 		.journal_seq	= journal_seq,
 	};
 	size_t i, size, new_bits, nr_elements = 1, nr_rehashes = 0, nr_rehashes_this_size = 0;
-	int ret = 0;
 
-	mutex_lock(&b->lock);
+	guard(mutex)(&b->lock);
 
 	if (likely(bucket_table_insert(b->t, &new, flushed_seq)))
-		goto out;
+		return 0;
 
 	t = b->t;
 	size = 1UL << t->bits;
@@ -109,8 +103,7 @@ int bch2_set_bucket_needs_journal_commit(struct buckets_waiting_for_journal *b,
 	n = kvmalloc(sizeof(*n) + (sizeof(n->d[0]) << new_bits), GFP_KERNEL);
 	if (!n) {
 		struct bch_fs *c = container_of(b, struct bch_fs, buckets_waiting_for_journal);
-		ret = bch_err_throw(c, ENOMEM_buckets_waiting_for_journal_set);
-		goto out;
+		return bch_err_throw(c, ENOMEM_buckets_waiting_for_journal_set);
 	}
 
 retry_rehash:
@@ -143,10 +136,7 @@ int bch2_set_bucket_needs_journal_commit(struct buckets_waiting_for_journal *b,
 
 	pr_debug("took %zu rehashes, table at %zu/%lu elements",
 		 nr_rehashes, nr_elements, 1UL << b->t->bits);
-out:
-	mutex_unlock(&b->lock);
-
-	return ret;
+	return 0;
 }
 
 void bch2_fs_buckets_waiting_for_journal_exit(struct bch_fs *c)
-- 
2.51.0


From c6a444e481f62ebbf2d50f2557d5a636280bcbb0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:04:45 -0400
Subject: [PATCH 099/309] bcachefs: convert quota.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/quota.c | 96 +++++++++++++++++----------------------------
 1 file changed, 35 insertions(+), 61 deletions(-)

diff --git a/fs/bcachefs/quota.c b/fs/bcachefs/quota.c
index f241efb1fb50..5f1eff591b29 100644
--- a/fs/bcachefs/quota.c
+++ b/fs/bcachefs/quota.c
@@ -394,12 +394,10 @@ static int __bch2_quota_set(struct bch_fs *c, struct bkey_s_c k,
 		dq = bkey_s_c_to_quota(k);
 		q = &c->quotas[k.k->p.inode];
 
-		mutex_lock(&q->lock);
+		guard(mutex)(&q->lock);
 		mq = genradix_ptr_alloc(&q->table, k.k->p.offset, GFP_KERNEL);
-		if (!mq) {
-			mutex_unlock(&q->lock);
+		if (!mq)
 			return -ENOMEM;
-		}
 
 		for (i = 0; i < Q_COUNTERS; i++) {
 			mq->c[i].hardlimit = le64_to_cpu(dq.v->c[i].hardlimit);
@@ -414,8 +412,6 @@ static int __bch2_quota_set(struct bch_fs *c, struct bkey_s_c k,
 			mq->c[Q_INO].timer	= qdq->d_ino_timer;
 		if (qdq && qdq->d_fieldmask & QC_INO_WARNS)
 			mq->c[Q_INO].warns	= qdq->d_ino_warns;
-
-		mutex_unlock(&q->lock);
 	}
 
 	return 0;
@@ -522,24 +518,21 @@ static int bch2_fs_quota_read_inode(struct btree_trans *trans,
 
 int bch2_fs_quota_read(struct bch_fs *c)
 {
+	scoped_guard(mutex, &c->sb_lock) {
+		struct bch_sb_field_quota *sb_quota = bch2_sb_get_or_create_quota(&c->disk_sb);
+		if (!sb_quota)
+			return bch_err_throw(c, ENOSPC_sb_quota);
 
-	mutex_lock(&c->sb_lock);
-	struct bch_sb_field_quota *sb_quota = bch2_sb_get_or_create_quota(&c->disk_sb);
-	if (!sb_quota) {
-		mutex_unlock(&c->sb_lock);
-		return bch_err_throw(c, ENOSPC_sb_quota);
+		bch2_sb_quota_read(c);
 	}
 
-	bch2_sb_quota_read(c);
-	mutex_unlock(&c->sb_lock);
-
-	int ret = bch2_trans_run(c,
-		for_each_btree_key(trans, iter, BTREE_ID_quotas, POS_MIN,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key(trans, iter, BTREE_ID_quotas, POS_MIN,
 				   BTREE_ITER_prefetch, k,
 			__bch2_quota_set(c, k, NULL)) ?:
 		for_each_btree_key(trans, iter, BTREE_ID_inodes, POS_MIN,
 				   BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
-			bch2_fs_quota_read_inode(trans, &iter, k)));
+			bch2_fs_quota_read_inode(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -550,7 +543,6 @@ static int bch2_quota_enable(struct super_block	*sb, unsigned uflags)
 {
 	struct bch_fs *c = sb->s_fs_info;
 	struct bch_sb_field_quota *sb_quota;
-	int ret = 0;
 
 	if (sb->s_flags & SB_RDONLY)
 		return -EROFS;
@@ -569,11 +561,12 @@ static int bch2_quota_enable(struct super_block	*sb, unsigned uflags)
 	if (uflags & FS_QUOTA_PDQ_ENFD && !c->opts.prjquota)
 		return -EINVAL;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	sb_quota = bch2_sb_get_or_create_quota(&c->disk_sb);
 	if (!sb_quota) {
-		ret = bch_err_throw(c, ENOSPC_sb_quota);
-		goto unlock;
+		int ret = bch_err_throw(c, ENOSPC_sb_quota);
+		bch_err_fn(c, ret);
+		return ret;
 	}
 
 	if (uflags & FS_QUOTA_UDQ_ENFD)
@@ -586,10 +579,7 @@ static int bch2_quota_enable(struct super_block	*sb, unsigned uflags)
 		SET_BCH_SB_PRJQUOTA(c->disk_sb.sb, true);
 
 	bch2_write_super(c);
-unlock:
-	mutex_unlock(&c->sb_lock);
-
-	return bch2_err_class(ret);
+	return 0;
 }
 
 static int bch2_quota_disable(struct super_block *sb, unsigned uflags)
@@ -599,7 +589,7 @@ static int bch2_quota_disable(struct super_block *sb, unsigned uflags)
 	if (sb->s_flags & SB_RDONLY)
 		return -EROFS;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	if (uflags & FS_QUOTA_UDQ_ENFD)
 		SET_BCH_SB_USRQUOTA(c->disk_sb.sb, false);
 
@@ -610,8 +600,6 @@ static int bch2_quota_disable(struct super_block *sb, unsigned uflags)
 		SET_BCH_SB_PRJQUOTA(c->disk_sb.sb, false);
 
 	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
-
 	return 0;
 }
 
@@ -700,14 +688,12 @@ static int bch2_quota_set_info(struct super_block *sb, int type,
 {
 	struct bch_fs *c = sb->s_fs_info;
 	struct bch_sb_field_quota *sb_quota;
-	int ret = 0;
 
 	if (0) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		qc_info_to_text(&buf, info);
 		pr_info("setting:\n%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	if (sb->s_flags & SB_RDONLY)
@@ -723,11 +709,12 @@ static int bch2_quota_set_info(struct super_block *sb, int type,
 	    ~(QC_SPC_TIMER|QC_INO_TIMER|QC_SPC_WARNS|QC_INO_WARNS))
 		return -EINVAL;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	sb_quota = bch2_sb_get_or_create_quota(&c->disk_sb);
 	if (!sb_quota) {
-		ret = bch_err_throw(c, ENOSPC_sb_quota);
-		goto unlock;
+		int ret = bch_err_throw(c, ENOSPC_sb_quota);
+		bch_err_fn(c, ret);
+		return bch2_err_class(ret);
 	}
 
 	if (info->i_fieldmask & QC_SPC_TIMER)
@@ -749,10 +736,7 @@ static int bch2_quota_set_info(struct super_block *sb, int type,
 	bch2_sb_quota_read(c);
 
 	bch2_write_super(c);
-unlock:
-	mutex_unlock(&c->sb_lock);
-
-	return bch2_err_class(ret);
+	return 0;
 }
 
 /* Get/set individual quotas: */
@@ -778,15 +762,13 @@ static int bch2_get_quota(struct super_block *sb, struct kqid kqid,
 	struct bch_fs *c		= sb->s_fs_info;
 	struct bch_memquota_type *q	= &c->quotas[kqid.type];
 	qid_t qid			= from_kqid(&init_user_ns, kqid);
-	struct bch_memquota *mq;
 
 	memset(qdq, 0, sizeof(*qdq));
 
-	mutex_lock(&q->lock);
-	mq = genradix_ptr(&q->table, qid);
+	guard(mutex)(&q->lock);
+	struct bch_memquota *mq = genradix_ptr(&q->table, qid);
 	if (mq)
 		__bch2_quota_get(qdq, mq);
-	mutex_unlock(&q->lock);
 
 	return 0;
 }
@@ -799,21 +781,17 @@ static int bch2_get_next_quota(struct super_block *sb, struct kqid *kqid,
 	qid_t qid			= from_kqid(&init_user_ns, *kqid);
 	struct genradix_iter iter;
 	struct bch_memquota *mq;
-	int ret = 0;
 
-	mutex_lock(&q->lock);
+	guard(mutex)(&q->lock);
 
 	genradix_for_each_from(&q->table, iter, mq, qid)
 		if (memcmp(mq, page_address(ZERO_PAGE(0)), sizeof(*mq))) {
 			__bch2_quota_get(qdq, mq);
 			*kqid = make_kqid(current_user_ns(), kqid->type, iter.pos);
-			goto found;
+			return 0;
 		}
 
-	ret = -ENOENT;
-found:
-	mutex_unlock(&q->lock);
-	return bch2_err_class(ret);
+	return -ENOENT;
 }
 
 static int bch2_set_quota_trans(struct btree_trans *trans,
@@ -821,12 +799,10 @@ static int bch2_set_quota_trans(struct btree_trans *trans,
 				struct qc_dqblk *qdq)
 {
 	struct btree_iter iter;
-	struct bkey_s_c k;
-	int ret;
-
-	k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_quotas, new_quota->k.p,
-			       BTREE_ITER_slots|BTREE_ITER_intent);
-	ret = bkey_err(k);
+	struct bkey_s_c k =
+		bch2_bkey_get_iter(trans, &iter, BTREE_ID_quotas, new_quota->k.p,
+				   BTREE_ITER_slots|BTREE_ITER_intent);
+	int ret = bkey_err(k);
 	if (unlikely(ret))
 		return ret;
 
@@ -852,24 +828,22 @@ static int bch2_set_quota(struct super_block *sb, struct kqid qid,
 			  struct qc_dqblk *qdq)
 {
 	struct bch_fs *c = sb->s_fs_info;
-	struct bkey_i_quota new_quota;
-	int ret;
 
 	if (0) {
-		struct printbuf buf = PRINTBUF;
-
+		CLASS(printbuf, buf)();
 		qc_dqblk_to_text(&buf, qdq);
 		pr_info("setting:\n%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	if (sb->s_flags & SB_RDONLY)
 		return -EROFS;
 
+	struct bkey_i_quota new_quota;
 	bkey_quota_init(&new_quota.k_i);
 	new_quota.k.p = POS(qid.type, from_kqid(&init_user_ns, qid));
 
-	ret = bch2_trans_commit_do(c, NULL, NULL, 0,
+	CLASS(btree_trans, trans)(c);
+	int ret = commit_do(trans, NULL, NULL, 0,
 			    bch2_set_quota_trans(trans, &new_quota, qdq)) ?:
 		__bch2_quota_set(c, bkey_i_to_s_c(&new_quota.k_i), qdq);
 
-- 
2.51.0


From 729095e79b9abe8090124c277cf0f4491cbe51e0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:05:35 -0400
Subject: [PATCH 100/309] bcachefs: convert sb-clean.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-clean.c | 36 ++++++++++--------------------------
 1 file changed, 10 insertions(+), 26 deletions(-)

diff --git a/fs/bcachefs/sb-clean.c b/fs/bcachefs/sb-clean.c
index 59c8770e4a0e..a5916984565e 100644
--- a/fs/bcachefs/sb-clean.c
+++ b/fs/bcachefs/sb-clean.c
@@ -89,8 +89,8 @@ int bch2_verify_superblock_clean(struct bch_fs *c,
 {
 	unsigned i;
 	struct bch_sb_field_clean *clean = *cleanp;
-	struct printbuf buf1 = PRINTBUF;
-	struct printbuf buf2 = PRINTBUF;
+	CLASS(printbuf, buf1)();
+	CLASS(printbuf, buf2)();
 	int ret = 0;
 
 	if (mustfix_fsck_err_on(j->seq != clean->journal_seq, c,
@@ -140,8 +140,6 @@ int bch2_verify_superblock_clean(struct bch_fs *c,
 			l2, buf2.buf);
 	}
 fsck_err:
-	printbuf_exit(&buf2);
-	printbuf_exit(&buf1);
 	return ret;
 }
 
@@ -150,7 +148,7 @@ struct bch_sb_field_clean *bch2_read_superblock_clean(struct bch_fs *c)
 	struct bch_sb_field_clean *clean, *sb_clean;
 	int ret;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	sb_clean = bch2_sb_field_get(c->disk_sb.sb, clean);
 
 	if (fsck_err_on(!sb_clean, c,
@@ -158,29 +156,22 @@ struct bch_sb_field_clean *bch2_read_superblock_clean(struct bch_fs *c)
 			"superblock marked clean but clean section not present")) {
 		SET_BCH_SB_CLEAN(c->disk_sb.sb, false);
 		c->sb.clean = false;
-		mutex_unlock(&c->sb_lock);
 		return ERR_PTR(-BCH_ERR_invalid_sb_clean);
 	}
 
 	clean = kmemdup(sb_clean, vstruct_bytes(&sb_clean->field),
 			GFP_KERNEL);
-	if (!clean) {
-		mutex_unlock(&c->sb_lock);
+	if (!clean)
 		return ERR_PTR(-BCH_ERR_ENOMEM_read_superblock_clean);
-	}
 
 	ret = bch2_sb_clean_validate_late(c, clean, READ);
 	if (ret) {
 		kfree(clean);
-		mutex_unlock(&c->sb_lock);
 		return ERR_PTR(ret);
 	}
 
-	mutex_unlock(&c->sb_lock);
-
 	return clean;
 fsck_err:
-	mutex_unlock(&c->sb_lock);
 	return ERR_PTR(ret);
 }
 
@@ -265,21 +256,16 @@ const struct bch_sb_field_ops bch_sb_field_ops_clean = {
 
 int bch2_fs_mark_dirty(struct bch_fs *c)
 {
-	int ret;
-
 	/*
 	 * Unconditionally write superblock, to verify it hasn't changed before
 	 * we go rw:
 	 */
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	SET_BCH_SB_CLEAN(c->disk_sb.sb, false);
 	c->disk_sb.sb->features[0] |= cpu_to_le64(BCH_SB_FEATURES_ALWAYS);
 
-	ret = bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
-
-	return ret;
+	return bch2_write_super(c);
 }
 
 void bch2_fs_mark_clean(struct bch_fs *c)
@@ -289,9 +275,9 @@ void bch2_fs_mark_clean(struct bch_fs *c)
 	unsigned u64s;
 	int ret;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	if (BCH_SB_CLEAN(c->disk_sb.sb))
-		goto out;
+		return;
 
 	SET_BCH_SB_CLEAN(c->disk_sb.sb, true);
 
@@ -305,7 +291,7 @@ void bch2_fs_mark_clean(struct bch_fs *c)
 	sb_clean = bch2_sb_field_resize(&c->disk_sb, clean, u64s);
 	if (!sb_clean) {
 		bch_err(c, "error resizing superblock while setting filesystem clean");
-		goto out;
+		return;
 	}
 
 	sb_clean->flags		= 0;
@@ -329,12 +315,10 @@ void bch2_fs_mark_clean(struct bch_fs *c)
 	ret = bch2_sb_clean_validate_late(c, sb_clean, WRITE);
 	if (ret) {
 		bch_err(c, "error writing marking filesystem clean: validate error");
-		goto out;
+		return;
 	}
 
 	bch2_journal_pos_from_member_info_set(c);
 
 	bch2_write_super(c);
-out:
-	mutex_unlock(&c->sb_lock);
 }
-- 
2.51.0


From 9ef6d11511e48a5b20828573715780efcd025f8e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:05:52 -0400
Subject: [PATCH 101/309] bcachefs: convert sb-downgrade.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-downgrade.c | 19 +++++++------------
 1 file changed, 7 insertions(+), 12 deletions(-)

diff --git a/fs/bcachefs/sb-downgrade.c b/fs/bcachefs/sb-downgrade.c
index 1506d05e0665..de56a1ee79db 100644
--- a/fs/bcachefs/sb-downgrade.c
+++ b/fs/bcachefs/sb-downgrade.c
@@ -191,7 +191,7 @@ int bch2_sb_set_upgrade_extra(struct bch_fs *c)
 	bool write_sb = false;
 	int ret = 0;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
 
 	if (old_version <  bcachefs_metadata_version_bucket_stripe_sectors &&
@@ -205,7 +205,6 @@ int bch2_sb_set_upgrade_extra(struct bch_fs *c)
 
 	if (write_sb)
 		bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
 
 	return ret < 0 ? ret : 0;
 }
@@ -372,7 +371,7 @@ int bch2_sb_downgrade_update(struct bch_fs *c)
 	if (!test_bit(BCH_FS_btree_running, &c->flags))
 		return 0;
 
-	darray_char table = {};
+	CLASS(darray_char, table)();
 	int ret = 0;
 
 	for (const struct upgrade_downgrade_entry *src = downgrade_table;
@@ -389,7 +388,7 @@ int bch2_sb_downgrade_update(struct bch_fs *c)
 
 		ret = darray_make_room(&table, bytes);
 		if (ret)
-			goto out;
+			return ret;
 
 		dst = (void *) &darray_top(table);
 		dst->version = cpu_to_le16(src->version);
@@ -401,7 +400,7 @@ int bch2_sb_downgrade_update(struct bch_fs *c)
 
 		ret = downgrade_table_extra(c, &table);
 		if (ret)
-			goto out;
+			return ret;
 
 		if (!dst->recovery_passes[0] &&
 		    !dst->recovery_passes[1] &&
@@ -416,18 +415,14 @@ int bch2_sb_downgrade_update(struct bch_fs *c)
 	unsigned sb_u64s = DIV_ROUND_UP(sizeof(*d) + table.nr, sizeof(u64));
 
 	if (d && le32_to_cpu(d->field.u64s) > sb_u64s)
-		goto out;
+		return 0;
 
 	d = bch2_sb_field_resize(&c->disk_sb, downgrade, sb_u64s);
-	if (!d) {
-		ret = bch_err_throw(c, ENOSPC_sb_downgrade);
-		goto out;
-	}
+	if (!d)
+		return bch_err_throw(c, ENOSPC_sb_downgrade);
 
 	memcpy(d->entries, table.data, table.nr);
 	memset_u64s_tail(d->entries, 0, table.nr);
-out:
-	darray_exit(&table);
 	return ret;
 }
 
-- 
2.51.0


From 771b84e19c9231db09101e51dd91353c1e8a7e12 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:06:07 -0400
Subject: [PATCH 102/309] bcachefs: convert sb-errors.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-errors.c | 45 +++++++++++++++++------------------------
 1 file changed, 18 insertions(+), 27 deletions(-)

diff --git a/fs/bcachefs/sb-errors.c b/fs/bcachefs/sb-errors.c
index 48853efdc105..41a259eab4fb 100644
--- a/fs/bcachefs/sb-errors.c
+++ b/fs/bcachefs/sb-errors.c
@@ -110,75 +110,66 @@ void bch2_sb_error_count(struct bch_fs *c, enum bch_sb_error_id err)
 	};
 	unsigned i;
 
-	mutex_lock(&c->fsck_error_counts_lock);
+	guard(mutex)(&c->fsck_error_counts_lock);
+
 	for (i = 0; i < e->nr; i++) {
 		if (err == e->data[i].id) {
 			e->data[i].nr++;
 			e->data[i].last_error_time = n.last_error_time;
-			goto out;
+			return;
 		}
 		if (err < e->data[i].id)
 			break;
 	}
 
 	if (darray_make_room(e, 1))
-		goto out;
+		return;
 
 	darray_insert_item(e, i, n);
-out:
-	mutex_unlock(&c->fsck_error_counts_lock);
 }
 
 void bch2_sb_errors_from_cpu(struct bch_fs *c)
 {
-	bch_sb_errors_cpu *src = &c->fsck_error_counts;
-	struct bch_sb_field_errors *dst;
-	unsigned i;
-
-	mutex_lock(&c->fsck_error_counts_lock);
-
-	dst = bch2_sb_field_resize(&c->disk_sb, errors,
-				   bch2_sb_field_errors_u64s(src->nr));
+	guard(mutex)(&c->fsck_error_counts_lock);
 
+	bch_sb_errors_cpu *src = &c->fsck_error_counts;
+	struct bch_sb_field_errors *dst =
+		bch2_sb_field_resize(&c->disk_sb, errors,
+				     bch2_sb_field_errors_u64s(src->nr));
 	if (!dst)
-		goto err;
+		return;
 
-	for (i = 0; i < src->nr; i++) {
+	for (unsigned i = 0; i < src->nr; i++) {
 		SET_BCH_SB_ERROR_ENTRY_ID(&dst->entries[i], src->data[i].id);
 		SET_BCH_SB_ERROR_ENTRY_NR(&dst->entries[i], src->data[i].nr);
 		dst->entries[i].last_error_time = cpu_to_le64(src->data[i].last_error_time);
 	}
-
-err:
-	mutex_unlock(&c->fsck_error_counts_lock);
 }
 
 static int bch2_sb_errors_to_cpu(struct bch_fs *c)
 {
+	guard(mutex)(&c->fsck_error_counts_lock);
+
 	struct bch_sb_field_errors *src = bch2_sb_field_get(c->disk_sb.sb, errors);
 	bch_sb_errors_cpu *dst = &c->fsck_error_counts;
-	unsigned i, nr = bch2_sb_field_errors_nr_entries(src);
-	int ret;
+	unsigned nr = bch2_sb_field_errors_nr_entries(src);
 
 	if (!nr)
 		return 0;
 
-	mutex_lock(&c->fsck_error_counts_lock);
-	ret = darray_make_room(dst, nr);
+	int ret = darray_make_room(dst, nr);
 	if (ret)
-		goto err;
+		return ret;
 
 	dst->nr = nr;
 
-	for (i = 0; i < nr; i++) {
+	for (unsigned i = 0; i < nr; i++) {
 		dst->data[i].id = BCH_SB_ERROR_ENTRY_ID(&src->entries[i]);
 		dst->data[i].nr = BCH_SB_ERROR_ENTRY_NR(&src->entries[i]);
 		dst->data[i].last_error_time = le64_to_cpu(src->entries[i].last_error_time);
 	}
-err:
-	mutex_unlock(&c->fsck_error_counts_lock);
 
-	return ret;
+	return 0;
 }
 
 void bch2_fs_sb_errors_exit(struct bch_fs *c)
-- 
2.51.0


From 1c0a3d8c80426ec48b5bf5858325a9031b384102 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:10:57 -0400
Subject: [PATCH 103/309] bcachefs: convert sb-members.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-members.c | 18 +++++++-----------
 1 file changed, 7 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/sb-members.c b/fs/bcachefs/sb-members.c
index 340d4fb7f9b6..0573c7b00151 100644
--- a/fs/bcachefs/sb-members.c
+++ b/fs/bcachefs/sb-members.c
@@ -12,7 +12,7 @@
 
 int bch2_dev_missing_bkey(struct bch_fs *c, struct bkey_s_c k, unsigned dev)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	bool removed = test_bit(dev, c->devs_removed.d);
@@ -31,7 +31,6 @@ int bch2_dev_missing_bkey(struct bch_fs *c, struct bkey_s_c k, unsigned dev)
 
 	if (print)
 		bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -442,9 +441,8 @@ void bch2_dev_io_errors_to_text(struct printbuf *out, struct bch_dev *ca)
 	struct bch_fs *c = ca->fs;
 	struct bch_member m;
 
-	mutex_lock(&ca->fs->sb_lock);
-	m = bch2_sb_member_get(c->disk_sb.sb, ca->dev_idx);
-	mutex_unlock(&ca->fs->sb_lock);
+	scoped_guard(mutex, &ca->fs->sb_lock)
+		m = bch2_sb_member_get(c->disk_sb.sb, ca->dev_idx);
 
 	printbuf_tabstop_push(out, 12);
 
@@ -471,16 +469,15 @@ void bch2_dev_io_errors_to_text(struct printbuf *out, struct bch_dev *ca)
 void bch2_dev_errors_reset(struct bch_dev *ca)
 {
 	struct bch_fs *c = ca->fs;
-	struct bch_member *m;
 
-	mutex_lock(&c->sb_lock);
-	m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
+	guard(mutex)(&c->sb_lock);
+
+	struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
 	for (unsigned i = 0; i < ARRAY_SIZE(m->errors_at_reset); i++)
 		m->errors_at_reset[i] = cpu_to_le64(atomic64_read(&ca->errors[i]));
 	m->errors_reset_time = cpu_to_le64(ktime_get_real_seconds());
 
 	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
 }
 
 /*
@@ -612,7 +609,7 @@ int bch2_sb_member_alloc(struct bch_fs *c)
 
 void bch2_sb_members_clean_deleted(struct bch_fs *c)
 {
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	bool write_sb = false;
 
 	for (unsigned i = 0; i < c->sb.nr_devices; i++) {
@@ -626,5 +623,4 @@ void bch2_sb_members_clean_deleted(struct bch_fs *c)
 
 	if (write_sb)
 		bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
 }
-- 
2.51.0


From 4572d0c41f61d25d9010cb6f1b08a93f42552fc6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:11:35 -0400
Subject: [PATCH 104/309] bcachefs: convert clock.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/clock.c | 17 +++++++----------
 1 file changed, 7 insertions(+), 10 deletions(-)

diff --git a/fs/bcachefs/clock.c b/fs/bcachefs/clock.c
index 8e9264b5a84e..1c6d0cdca3c5 100644
--- a/fs/bcachefs/clock.c
+++ b/fs/bcachefs/clock.c
@@ -40,15 +40,13 @@ void bch2_io_timer_add(struct io_clock *clock, struct io_timer *timer)
 
 void bch2_io_timer_del(struct io_clock *clock, struct io_timer *timer)
 {
-	spin_lock(&clock->timer_lock);
+	guard(spinlock)(&clock->timer_lock);
 
 	for (size_t i = 0; i < clock->timers.nr; i++)
 		if (clock->timers.data[i] == timer) {
 			min_heap_del(&clock->timers, i, &callbacks, NULL);
-			break;
+			return;
 		}
-
-	spin_unlock(&clock->timer_lock);
 }
 
 struct io_clock_wait {
@@ -133,28 +131,27 @@ void __bch2_increment_clock(struct io_clock *clock, u64 sectors)
 	struct io_timer *timer;
 	u64 now = atomic64_add_return(sectors, &clock->now);
 
-	spin_lock(&clock->timer_lock);
+	guard(spinlock)(&clock->timer_lock);
+
 	while ((timer = get_expired_timer(clock, now)))
 		timer->fn(timer);
-	spin_unlock(&clock->timer_lock);
 }
 
 void bch2_io_timers_to_text(struct printbuf *out, struct io_clock *clock)
 {
-	out->atomic++;
-	spin_lock(&clock->timer_lock);
 	u64 now = atomic64_read(&clock->now);
 
 	printbuf_tabstop_push(out, 40);
 	prt_printf(out, "current time:\t%llu\n", now);
 
+	guard(printbuf_atomic)(out);
+	guard(spinlock)(&clock->timer_lock);
+
 	for (unsigned i = 0; i < clock->timers.nr; i++)
 		prt_printf(out, "%ps %ps:\t%llu\n",
 		       clock->timers.data[i]->fn,
 		       clock->timers.data[i]->fn2,
 		       clock->timers.data[i]->expire);
-	spin_unlock(&clock->timer_lock);
-	--out->atomic;
 }
 
 void bch2_io_clock_exit(struct io_clock *clock)
-- 
2.51.0


From 82942afe445a69872f6252b6c3b05c920a330de0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:12:42 -0400
Subject: [PATCH 105/309] bcachefs: convert debug.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/debug.c | 90 +++++++++++++++++++++------------------------
 1 file changed, 42 insertions(+), 48 deletions(-)

diff --git a/fs/bcachefs/debug.c b/fs/bcachefs/debug.c
index 8b228212f72f..33cb94f70b19 100644
--- a/fs/bcachefs/debug.c
+++ b/fs/bcachefs/debug.c
@@ -141,7 +141,7 @@ void __bch2_btree_verify(struct bch_fs *c, struct btree *b)
 		return;
 
 	bch2_btree_node_io_lock(b);
-	mutex_lock(&c->verify_lock);
+	guard(mutex)(&c->verify_lock);
 
 	if (!c->verify_ondisk) {
 		c->verify_ondisk = kvmalloc(btree_buf_bytes(b), GFP_KERNEL);
@@ -172,14 +172,11 @@ void __bch2_btree_verify(struct bch_fs *c, struct btree *b)
 		failed |= bch2_btree_verify_replica(c, b, p);
 
 	if (failed) {
-		struct printbuf buf = PRINTBUF;
-
+		CLASS(printbuf, buf)();
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&b->key));
 		bch2_fs_fatal_error(c, ": btree node verify failed for: %s\n", buf.buf);
-		printbuf_exit(&buf);
 	}
 out:
-	mutex_unlock(&c->verify_lock);
 	bch2_btree_node_io_unlock(b);
 }
 
@@ -367,17 +364,17 @@ static ssize_t bch2_read_btree(struct file *file, char __user *buf,
 	i->size	= size;
 	i->ret	= 0;
 
+	CLASS(btree_trans, trans)(i->c);
 	return bch2_debugfs_flush_buf(i) ?:
-		bch2_trans_run(i->c,
-			for_each_btree_key(trans, iter, i->id, i->from,
-					   BTREE_ITER_prefetch|
-					   BTREE_ITER_all_snapshots, k, ({
-				bch2_bkey_val_to_text(&i->buf, i->c, k);
-				prt_newline(&i->buf);
-				bch2_trans_unlock(trans);
-				i->from = bpos_successor(iter.pos);
-				bch2_debugfs_flush_buf(i);
-			}))) ?:
+		for_each_btree_key(trans, iter, i->id, i->from,
+				   BTREE_ITER_prefetch|
+				   BTREE_ITER_all_snapshots, k, ({
+			bch2_bkey_val_to_text(&i->buf, i->c, k);
+			prt_newline(&i->buf);
+			bch2_trans_unlock(trans);
+			i->from = bpos_successor(iter.pos);
+			bch2_debugfs_flush_buf(i);
+		})) ?:
 		i->ret;
 }
 
@@ -404,15 +401,15 @@ static ssize_t bch2_read_btree_formats(struct file *file, char __user *buf,
 	if (bpos_eq(SPOS_MAX, i->from))
 		return i->ret;
 
-	return bch2_trans_run(i->c,
-		for_each_btree_node(trans, iter, i->id, i->from, 0, b, ({
-			bch2_btree_node_to_text(&i->buf, i->c, b);
-			i->from = !bpos_eq(SPOS_MAX, b->key.k.p)
-				? bpos_successor(b->key.k.p)
-				: b->key.k.p;
+	CLASS(btree_trans, trans)(i->c);
+	return for_each_btree_node(trans, iter, i->id, i->from, 0, b, ({
+		bch2_btree_node_to_text(&i->buf, i->c, b);
+		i->from = !bpos_eq(SPOS_MAX, b->key.k.p)
+			? bpos_successor(b->key.k.p)
+			: b->key.k.p;
 
-			drop_locks_do(trans, bch2_debugfs_flush_buf(i));
-		}))) ?: i->ret;
+		drop_locks_do(trans, bch2_debugfs_flush_buf(i));
+	})) ?: i->ret;
 }
 
 static const struct file_operations btree_format_debug_ops = {
@@ -431,27 +428,27 @@ static ssize_t bch2_read_bfloat_failed(struct file *file, char __user *buf,
 	i->size	= size;
 	i->ret	= 0;
 
+	CLASS(btree_trans, trans)(i->c);
 	return bch2_debugfs_flush_buf(i) ?:
-		bch2_trans_run(i->c,
-			for_each_btree_key(trans, iter, i->id, i->from,
-					   BTREE_ITER_prefetch|
-					   BTREE_ITER_all_snapshots, k, ({
-				struct btree_path_level *l =
-					&btree_iter_path(trans, &iter)->l[0];
-				struct bkey_packed *_k =
-					bch2_btree_node_iter_peek(&l->iter, l->b);
-
-				if (bpos_gt(l->b->key.k.p, i->prev_node)) {
-					bch2_btree_node_to_text(&i->buf, i->c, l->b);
-					i->prev_node = l->b->key.k.p;
-				}
-
-				bch2_bfloat_to_text(&i->buf, l->b, _k);
-				bch2_trans_unlock(trans);
-				i->from = bpos_successor(iter.pos);
-				bch2_debugfs_flush_buf(i);
-			}))) ?:
-		i->ret;
+		for_each_btree_key(trans, iter, i->id, i->from,
+				   BTREE_ITER_prefetch|
+				   BTREE_ITER_all_snapshots, k, ({
+			struct btree_path_level *l =
+				&btree_iter_path(trans, &iter)->l[0];
+			struct bkey_packed *_k =
+				bch2_btree_node_iter_peek(&l->iter, l->b);
+
+			if (bpos_gt(l->b->key.k.p, i->prev_node)) {
+				bch2_btree_node_to_text(&i->buf, i->c, l->b);
+				i->prev_node = l->b->key.k.p;
+			}
+
+			bch2_bfloat_to_text(&i->buf, l->b, _k);
+			bch2_trans_unlock(trans);
+			i->from = bpos_successor(iter.pos);
+			bch2_debugfs_flush_buf(i);
+		})) ?:
+	i->ret;
 }
 
 static const struct file_operations bfloat_failed_debug_ops = {
@@ -512,8 +509,8 @@ static ssize_t bch2_cached_btree_nodes_read(struct file *file, char __user *buf,
 		if (ret)
 			return ret;
 
-		i->buf.atomic++;
 		scoped_guard(rcu) {
+			guard(printbuf_atomic)(&i->buf);
 			struct bucket_table *tbl =
 				rht_dereference_rcu(c->btree_cache.table.tbl,
 						    &c->btree_cache.table);
@@ -528,7 +525,6 @@ static ssize_t bch2_cached_btree_nodes_read(struct file *file, char __user *buf,
 				done = true;
 			}
 		}
-		--i->buf.atomic;
 	} while (!done);
 
 	if (i->buf.allocation_failure)
@@ -771,7 +767,7 @@ static ssize_t btree_transaction_stats_read(struct file *file, char __user *buf,
 		prt_printf(&i->buf, "%s:\n", bch2_btree_transaction_fns[i->iter]);
 		printbuf_indent_add(&i->buf, 2);
 
-		mutex_lock(&s->lock);
+		guard(mutex)(&s->lock);
 
 		prt_printf(&i->buf, "Max mem used: %u\n", s->max_mem);
 #ifdef CONFIG_BCACHEFS_TRANS_KMALLOC_TRACE
@@ -802,8 +798,6 @@ static ssize_t btree_transaction_stats_read(struct file *file, char __user *buf,
 			printbuf_indent_sub(&i->buf, 2);
 		}
 
-		mutex_unlock(&s->lock);
-
 		printbuf_indent_sub(&i->buf, 2);
 		prt_newline(&i->buf);
 		i->iter++;
-- 
2.51.0


From 3bd63a312f5bad411fd641e9ffff0d0742e44218 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:13:31 -0400
Subject: [PATCH 106/309] bcachefs: convert nocow_locking.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/nocow_locking.c | 10 ++++------
 1 file changed, 4 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/nocow_locking.c b/fs/bcachefs/nocow_locking.c
index 962218fa68ec..58cfd540c6d6 100644
--- a/fs/bcachefs/nocow_locking.c
+++ b/fs/bcachefs/nocow_locking.c
@@ -47,7 +47,7 @@ bool __bch2_bucket_nocow_trylock(struct nocow_lock_bucket *l,
 	int v, lock_val = flags ? 1 : -1;
 	unsigned i;
 
-	spin_lock(&l->lock);
+	guard(spinlock)(&l->lock);
 
 	for (i = 0; i < ARRAY_SIZE(l->b); i++)
 		if (l->b[i] == dev_bucket)
@@ -58,21 +58,19 @@ bool __bch2_bucket_nocow_trylock(struct nocow_lock_bucket *l,
 			l->b[i] = dev_bucket;
 			goto take_lock;
 		}
-fail:
-	spin_unlock(&l->lock);
+
 	return false;
 got_entry:
 	v = atomic_read(&l->l[i]);
 	if (lock_val > 0 ? v < 0 : v > 0)
-		goto fail;
+		return false;
 take_lock:
 	v = atomic_read(&l->l[i]);
 	/* Overflow? */
 	if (v && sign(v + lock_val) != sign(v))
-		goto fail;
+		return false;
 
 	atomic_add(lock_val, &l->l[i]);
-	spin_unlock(&l->lock);
 	return true;
 }
 
-- 
2.51.0


From 5af8041ed33ad471de8a03c851b0c7d151ba3216 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:14:19 -0400
Subject: [PATCH 107/309] bcachefs: convert replicas.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/replicas.c | 147 +++++++++++++++++------------------------
 1 file changed, 59 insertions(+), 88 deletions(-)

diff --git a/fs/bcachefs/replicas.c b/fs/bcachefs/replicas.c
index 8383bd7fdb3f..0784283ce78c 100644
--- a/fs/bcachefs/replicas.c
+++ b/fs/bcachefs/replicas.c
@@ -286,11 +286,8 @@ bool bch2_replicas_marked_locked(struct bch_fs *c,
 bool bch2_replicas_marked(struct bch_fs *c,
 			  struct bch_replicas_entry_v1 *search)
 {
-	percpu_down_read(&c->mark_lock);
-	bool ret = bch2_replicas_marked_locked(c, search);
-	percpu_up_read(&c->mark_lock);
-
-	return ret;
+	guard(percpu_read)(&c->mark_lock);
+	return bch2_replicas_marked_locked(c, search);
 }
 
 noinline
@@ -305,14 +302,14 @@ static int bch2_mark_replicas_slowpath(struct bch_fs *c,
 	memset(&new_r, 0, sizeof(new_r));
 	memset(&new_gc, 0, sizeof(new_gc));
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 
 	if (c->replicas_gc.entries &&
 	    !__replicas_has_entry(&c->replicas_gc, new_entry)) {
 		new_gc = cpu_replicas_add_entry(c, &c->replicas_gc, new_entry);
 		if (!new_gc.entries) {
 			ret = bch_err_throw(c, ENOMEM_cpu_replicas);
-			goto err;
+			goto out;
 		}
 	}
 
@@ -320,12 +317,12 @@ static int bch2_mark_replicas_slowpath(struct bch_fs *c,
 		new_r = cpu_replicas_add_entry(c, &c->replicas, new_entry);
 		if (!new_r.entries) {
 			ret = bch_err_throw(c, ENOMEM_cpu_replicas);
-			goto err;
+			goto out;
 		}
 
 		ret = bch2_cpu_replicas_to_sb_replicas(c, &new_r);
 		if (ret)
-			goto err;
+			goto out;
 	}
 
 	if (!new_r.entries &&
@@ -338,22 +335,18 @@ static int bch2_mark_replicas_slowpath(struct bch_fs *c,
 		bch2_write_super(c);
 
 	/* don't update in memory replicas until changes are persistent */
-	percpu_down_write(&c->mark_lock);
-	if (new_r.entries)
-		swap(c->replicas, new_r);
-	if (new_gc.entries)
-		swap(new_gc, c->replicas_gc);
-	percpu_up_write(&c->mark_lock);
+	scoped_guard(percpu_write, &c->mark_lock) {
+		if (new_r.entries)
+			swap(c->replicas, new_r);
+		if (new_gc.entries)
+			swap(new_gc, c->replicas_gc);
+	}
 out:
-	mutex_unlock(&c->sb_lock);
-
 	kfree(new_r.entries);
 	kfree(new_gc.entries);
 
-	return ret;
-err:
 	bch_err_msg(c, ret, "adding replicas entry");
-	goto out;
+	return ret;
 }
 
 int bch2_mark_replicas(struct bch_fs *c, struct bch_replicas_entry_v1 *r)
@@ -371,24 +364,20 @@ int bch2_replicas_gc_end(struct bch_fs *c, int ret)
 {
 	lockdep_assert_held(&c->replicas_gc_lock);
 
-	mutex_lock(&c->sb_lock);
-	percpu_down_write(&c->mark_lock);
-
-	ret =   ret ?:
-		bch2_cpu_replicas_to_sb_replicas(c, &c->replicas_gc);
-	if (!ret)
-		swap(c->replicas, c->replicas_gc);
-
-	kfree(c->replicas_gc.entries);
-	c->replicas_gc.entries = NULL;
+	guard(mutex)(&c->sb_lock);
+	scoped_guard(percpu_write, &c->mark_lock) {
+		ret =   ret ?:
+			bch2_cpu_replicas_to_sb_replicas(c, &c->replicas_gc);
+		if (!ret)
+			swap(c->replicas, c->replicas_gc);
 
-	percpu_up_write(&c->mark_lock);
+		kfree(c->replicas_gc.entries);
+		c->replicas_gc.entries = NULL;
+	}
 
 	if (!ret)
 		bch2_write_super(c);
 
-	mutex_unlock(&c->sb_lock);
-
 	return ret;
 }
 
@@ -399,7 +388,7 @@ int bch2_replicas_gc_start(struct bch_fs *c, unsigned typemask)
 
 	lockdep_assert_held(&c->replicas_gc_lock);
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	BUG_ON(c->replicas_gc.entries);
 
 	c->replicas_gc.nr		= 0;
@@ -420,7 +409,6 @@ int bch2_replicas_gc_start(struct bch_fs *c, unsigned typemask)
 					 c->replicas_gc.entry_size,
 					 GFP_KERNEL);
 	if (!c->replicas_gc.entries) {
-		mutex_unlock(&c->sb_lock);
 		bch_err(c, "error allocating c->replicas_gc");
 		return bch_err_throw(c, ENOMEM_replicas_gc);
 	}
@@ -432,8 +420,6 @@ int bch2_replicas_gc_start(struct bch_fs *c, unsigned typemask)
 			       e, c->replicas_gc.entry_size);
 
 	bch2_cpu_replicas_sort(&c->replicas_gc);
-	mutex_unlock(&c->sb_lock);
-
 	return 0;
 }
 
@@ -461,55 +447,48 @@ int bch2_replicas_gc2(struct bch_fs *c)
 		return bch_err_throw(c, ENOMEM_replicas_gc);
 	}
 
-	mutex_lock(&c->sb_lock);
-	percpu_down_write(&c->mark_lock);
-
-	if (nr			!= c->replicas.nr ||
-	    new.entry_size	!= c->replicas.entry_size) {
-		percpu_up_write(&c->mark_lock);
-		mutex_unlock(&c->sb_lock);
-		kfree(new.entries);
-		goto retry;
-	}
-
-	for (unsigned i = 0; i < c->replicas.nr; i++) {
-		struct bch_replicas_entry_v1 *e =
-			cpu_replicas_entry(&c->replicas, i);
+	guard(mutex)(&c->sb_lock);
+	scoped_guard(percpu_write, &c->mark_lock) {
+		if (nr			!= c->replicas.nr ||
+		    new.entry_size	!= c->replicas.entry_size) {
+			kfree(new.entries);
+			goto retry;
+		}
 
-		struct disk_accounting_pos k = {
-			.type = BCH_DISK_ACCOUNTING_replicas,
-		};
+		for (unsigned i = 0; i < c->replicas.nr; i++) {
+			struct bch_replicas_entry_v1 *e =
+				cpu_replicas_entry(&c->replicas, i);
 
-		unsafe_memcpy(&k.replicas, e, replicas_entry_bytes(e),
-			      "embedded variable length struct");
+			struct disk_accounting_pos k = {
+				.type = BCH_DISK_ACCOUNTING_replicas,
+			};
 
-		struct bpos p = disk_accounting_pos_to_bpos(&k);
+			unsafe_memcpy(&k.replicas, e, replicas_entry_bytes(e),
+				      "embedded variable length struct");
 
-		struct bch_accounting_mem *acc = &c->accounting;
-		bool kill = eytzinger0_find(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
-					    accounting_pos_cmp, &p) >= acc->k.nr;
+			struct bpos p = disk_accounting_pos_to_bpos(&k);
 
-		if (e->data_type == BCH_DATA_journal || !kill)
-			memcpy(cpu_replicas_entry(&new, new.nr++),
-			       e, new.entry_size);
-	}
+			struct bch_accounting_mem *acc = &c->accounting;
+			bool kill = eytzinger0_find(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
+						    accounting_pos_cmp, &p) >= acc->k.nr;
 
-	bch2_cpu_replicas_sort(&new);
+			if (e->data_type == BCH_DATA_journal || !kill)
+				memcpy(cpu_replicas_entry(&new, new.nr++),
+				       e, new.entry_size);
+		}
 
-	ret = bch2_cpu_replicas_to_sb_replicas(c, &new);
+		bch2_cpu_replicas_sort(&new);
 
-	if (!ret)
-		swap(c->replicas, new);
+		ret = bch2_cpu_replicas_to_sb_replicas(c, &new);
 
-	kfree(new.entries);
+		if (!ret)
+			swap(c->replicas, new);
 
-	percpu_up_write(&c->mark_lock);
+		kfree(new.entries);
+	}
 
 	if (!ret)
 		bch2_write_super(c);
-
-	mutex_unlock(&c->sb_lock);
-
 	return ret;
 }
 
@@ -597,9 +576,8 @@ int bch2_sb_replicas_to_cpu_replicas(struct bch_fs *c)
 
 	bch2_cpu_replicas_sort(&new_r);
 
-	percpu_down_write(&c->mark_lock);
+	guard(percpu_write)(&c->mark_lock);
 	swap(c->replicas, new_r);
-	percpu_up_write(&c->mark_lock);
 
 	kfree(new_r.entries);
 
@@ -809,9 +787,8 @@ bool bch2_have_enough_devs(struct bch_fs *c, struct bch_devs_mask devs,
 			   unsigned flags, bool print)
 {
 	struct bch_replicas_entry_v1 *e;
-	bool ret = true;
 
-	percpu_down_read(&c->mark_lock);
+	guard(percpu_read)(&c->mark_lock);
 	for_each_cpu_replicas_entry(&c->replicas, e) {
 		unsigned nr_online = 0, nr_failed = 0, dflags = 0;
 		bool metadata = e->data_type < BCH_DATA_user;
@@ -847,21 +824,18 @@ bool bch2_have_enough_devs(struct bch_fs *c, struct bch_devs_mask devs,
 
 		if (dflags & ~flags) {
 			if (print) {
-				struct printbuf buf = PRINTBUF;
+				CLASS(printbuf, buf)();
 
 				bch2_replicas_entry_to_text(&buf, e);
 				bch_err(c, "insufficient devices online (%u) for replicas entry %s",
 					nr_online, buf.buf);
-				printbuf_exit(&buf);
 			}
-			ret = false;
-			break;
+			return false;
 		}
 
 	}
-	percpu_up_read(&c->mark_lock);
 
-	return ret;
+	return true;
 }
 
 unsigned bch2_sb_dev_has_data(struct bch_sb *sb, unsigned dev)
@@ -904,11 +878,8 @@ unsigned bch2_sb_dev_has_data(struct bch_sb *sb, unsigned dev)
 
 unsigned bch2_dev_has_data(struct bch_fs *c, struct bch_dev *ca)
 {
-	mutex_lock(&c->sb_lock);
-	unsigned ret = bch2_sb_dev_has_data(c->disk_sb.sb, ca->dev_idx);
-	mutex_unlock(&c->sb_lock);
-
-	return ret;
+	guard(mutex)(&c->sb_lock);
+	return bch2_sb_dev_has_data(c->disk_sb.sb, ca->dev_idx);
 }
 
 void bch2_fs_replicas_exit(struct bch_fs *c)
-- 
2.51.0


From 2bc3b94417abb754c160ae73ca1c8cad64750a82 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:16:55 -0400
Subject: [PATCH 108/309] bcachefs: convert bset.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bset.c | 8 ++------
 1 file changed, 2 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/bset.c b/fs/bcachefs/bset.c
index 90fd15748bb9..72698c0d9f0e 100644
--- a/fs/bcachefs/bset.c
+++ b/fs/bcachefs/bset.c
@@ -58,7 +58,7 @@ void bch2_dump_bset(struct bch_fs *c, struct btree *b,
 	struct bkey_packed *_k, *_n;
 	struct bkey uk, n;
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	if (!i->u64s)
 		return;
@@ -97,8 +97,6 @@ void bch2_dump_bset(struct bch_fs *c, struct btree *b,
 		if (!bkey_deleted(k.k) && bpos_eq(n.p, k.k->p))
 			printk(KERN_ERR "Duplicate keys\n");
 	}
-
-	printbuf_exit(&buf);
 }
 
 void bch2_dump_btree_node(struct bch_fs *c, struct btree *b)
@@ -113,7 +111,7 @@ void bch2_dump_btree_node_iter(struct btree *b,
 			      struct btree_node_iter *iter)
 {
 	struct btree_node_iter_set *set;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	printk(KERN_ERR "btree node iter with %u/%u sets:\n",
 	       __btree_node_iter_used(iter), b->nsets);
@@ -128,8 +126,6 @@ void bch2_dump_btree_node_iter(struct btree *b,
 		printk(KERN_ERR "set %zu key %u: %s\n",
 		       t - b->set, set->k, buf.buf);
 	}
-
-	printbuf_exit(&buf);
 }
 
 struct btree_nr_keys bch2_btree_node_count_keys(struct btree *b)
-- 
2.51.0


From 1b3a78f5f4719bc926c8c6d698d51f2c20fc41e2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:17:03 -0400
Subject: [PATCH 109/309] bcachefs: convert bkey.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bkey.c | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/fs/bcachefs/bkey.c b/fs/bcachefs/bkey.c
index ee823c640642..67e39f835b96 100644
--- a/fs/bcachefs/bkey.c
+++ b/fs/bcachefs/bkey.c
@@ -624,10 +624,8 @@ struct bkey_format bch2_bkey_format_done(struct bkey_format_state *s)
 	}
 
 	if (static_branch_unlikely(&bch2_debug_check_bkey_unpack)) {
-		struct printbuf buf = PRINTBUF;
-
+		CLASS(printbuf, buf)();
 		BUG_ON(bch2_bkey_format_invalid(NULL, &ret, 0, &buf));
-		printbuf_exit(&buf);
 	}
 
 	return ret;
-- 
2.51.0


From cfcb67ab61fba319c6eaa813e5b9bd94ca4d341f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:17:44 -0400
Subject: [PATCH 110/309] bcachefs: convert chardev.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/chardev.c    | 118 +++++++++++++--------------------------
 fs/bcachefs/sb-members.h |   2 +-
 2 files changed, 39 insertions(+), 81 deletions(-)

diff --git a/fs/bcachefs/chardev.c b/fs/bcachefs/chardev.c
index 2d1ac4969863..467fc45e84fe 100644
--- a/fs/bcachefs/chardev.c
+++ b/fs/bcachefs/chardev.c
@@ -52,6 +52,11 @@ static struct bch_dev *bch2_device_lookup(struct bch_fs *c, u64 dev,
 	return ca;
 }
 
+DEFINE_CLASS(bch2_device_lookup, struct bch_dev *,
+      bch2_dev_put(_T),
+      bch2_device_lookup(c, dev, flags),
+      struct bch_fs *c, u64 dev, unsigned flags);
+
 #if 0
 static long bch2_ioctl_assemble(struct bch_ioctl_assemble __user *user_arg)
 {
@@ -207,8 +212,6 @@ static long bch2_ioctl_disk_add(struct bch_fs *c, struct bch_ioctl_disk arg)
 
 static long bch2_ioctl_disk_remove(struct bch_fs *c, struct bch_ioctl_disk arg)
 {
-	struct bch_dev *ca;
-
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -219,7 +222,7 @@ static long bch2_ioctl_disk_remove(struct bch_fs *c, struct bch_ioctl_disk arg)
 	    arg.pad)
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	struct bch_dev *ca = bch2_device_lookup(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
@@ -249,9 +252,6 @@ static long bch2_ioctl_disk_online(struct bch_fs *c, struct bch_ioctl_disk arg)
 
 static long bch2_ioctl_disk_offline(struct bch_fs *c, struct bch_ioctl_disk arg)
 {
-	struct bch_dev *ca;
-	int ret;
-
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -262,21 +262,16 @@ static long bch2_ioctl_disk_offline(struct bch_fs *c, struct bch_ioctl_disk arg)
 	    arg.pad)
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	ret = bch2_dev_offline(c, ca, arg.flags);
-	bch2_dev_put(ca);
-	return ret;
+	return bch2_dev_offline(c, ca, arg.flags);
 }
 
 static long bch2_ioctl_disk_set_state(struct bch_fs *c,
 			struct bch_ioctl_disk_set_state arg)
 {
-	struct bch_dev *ca;
-	int ret;
-
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -288,15 +283,12 @@ static long bch2_ioctl_disk_set_state(struct bch_fs *c,
 	    arg.new_state >= BCH_MEMBER_STATE_NR)
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	ret = bch2_dev_set_state(c, ca, arg.new_state, arg.flags);
-	if (ret)
-		bch_err(c, "Error setting device state: %s", bch2_err_str(ret));
-
-	bch2_dev_put(ca);
+	int ret = bch2_dev_set_state(c, ca, arg.new_state, arg.flags);
+	bch_err_msg(ca, ret, "setting device state");
 	return ret;
 }
 
@@ -349,14 +341,13 @@ static ssize_t bch2_data_job_read(struct file *file, char __user *buf,
 	};
 
 	if (ctx->arg.op == BCH_DATA_OP_scrub) {
-		struct bch_dev *ca = bch2_dev_tryget(c, ctx->arg.scrub.dev);
+		CLASS(bch2_dev_tryget_noerror, ca)(c, ctx->arg.scrub.dev);
 		if (ca) {
 			struct bch_dev_usage_full u;
 			bch2_dev_usage_full_read_fast(ca, &u);
 			for (unsigned i = BCH_DATA_btree; i < ARRAY_SIZE(u.d); i++)
 				if (ctx->arg.scrub.data_types & BIT(i))
 					e.p.sectors_total += u.d[i].sectors;
-			bch2_dev_put(ca);
 		}
 	} else {
 		e.p.sectors_total	= bch2_fs_usage_read_short(c).used;
@@ -418,9 +409,8 @@ static noinline_for_stack long bch2_ioctl_fs_usage(struct bch_fs *c,
 				struct bch_ioctl_fs_usage __user *user_arg)
 {
 	struct bch_ioctl_fs_usage arg = {};
-	darray_char replicas = {};
+	CLASS(darray_char, replicas)();
 	u32 replica_entries_bytes;
-	int ret = 0;
 
 	if (!test_bit(BCH_FS_started, &c->flags))
 		return -EINVAL;
@@ -428,11 +418,11 @@ static noinline_for_stack long bch2_ioctl_fs_usage(struct bch_fs *c,
 	if (get_user(replica_entries_bytes, &user_arg->replica_entries_bytes))
 		return -EFAULT;
 
-	ret   = bch2_fs_replicas_usage_read(c, &replicas) ?:
+	int ret = bch2_fs_replicas_usage_read(c, &replicas) ?:
 		(replica_entries_bytes < replicas.nr ? -ERANGE : 0) ?:
 		copy_to_user_errcode(&user_arg->replicas, replicas.data, replicas.nr);
 	if (ret)
-		goto err;
+		return ret;
 
 	struct bch_fs_usage_short u = bch2_fs_usage_read_short(c);
 	arg.capacity		= c->capacity;
@@ -449,52 +439,41 @@ static noinline_for_stack long bch2_ioctl_fs_usage(struct bch_fs *c,
 					 &arg.persistent_reserved[i], 1);
 	}
 
-	ret = copy_to_user_errcode(user_arg, &arg, sizeof(arg));
-err:
-	darray_exit(&replicas);
-	return ret;
+	return copy_to_user_errcode(user_arg, &arg, sizeof(arg));
 }
 
 static long bch2_ioctl_query_accounting(struct bch_fs *c,
 			struct bch_ioctl_query_accounting __user *user_arg)
 {
 	struct bch_ioctl_query_accounting arg;
-	darray_char accounting = {};
-	int ret = 0;
+	CLASS(darray_char, accounting)();
 
 	if (!test_bit(BCH_FS_started, &c->flags))
 		return -EINVAL;
 
-	ret   = copy_from_user_errcode(&arg, user_arg, sizeof(arg)) ?:
+	int ret = copy_from_user_errcode(&arg, user_arg, sizeof(arg)) ?:
 		bch2_fs_accounting_read(c, &accounting, arg.accounting_types_mask) ?:
 		(arg.accounting_u64s * sizeof(u64) < accounting.nr ? -ERANGE : 0) ?:
 		copy_to_user_errcode(&user_arg->accounting, accounting.data, accounting.nr);
 	if (ret)
-		goto err;
+		return ret;
 
 	arg.capacity		= c->capacity;
 	arg.used		= bch2_fs_usage_read_short(c).used;
 	arg.online_reserved	= percpu_u64_get(c->online_reserved);
 	arg.accounting_u64s	= accounting.nr / sizeof(u64);
 
-	ret = copy_to_user_errcode(user_arg, &arg, sizeof(arg));
-err:
-	darray_exit(&accounting);
-	return ret;
+	return copy_to_user_errcode(user_arg, &arg, sizeof(arg));
 }
 
 /* obsolete, didn't allow for new data types: */
 static noinline_for_stack long bch2_ioctl_dev_usage(struct bch_fs *c,
 				 struct bch_ioctl_dev_usage __user *user_arg)
 {
-	struct bch_ioctl_dev_usage arg;
-	struct bch_dev_usage_full src;
-	struct bch_dev *ca;
-	unsigned i;
-
 	if (!test_bit(BCH_FS_started, &c->flags))
 		return -EINVAL;
 
+	struct bch_ioctl_dev_usage arg;
 	if (copy_from_user(&arg, user_arg, sizeof(arg)))
 		return -EFAULT;
 
@@ -504,38 +483,32 @@ static noinline_for_stack long bch2_ioctl_dev_usage(struct bch_fs *c,
 	    arg.pad[2])
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	src = bch2_dev_usage_full_read(ca);
+	struct bch_dev_usage_full src = bch2_dev_usage_full_read(ca);
 
 	arg.state		= ca->mi.state;
 	arg.bucket_size		= ca->mi.bucket_size;
 	arg.nr_buckets		= ca->mi.nbuckets - ca->mi.first_bucket;
 
-	for (i = 0; i < ARRAY_SIZE(arg.d); i++) {
+	for (unsigned i = 0; i < ARRAY_SIZE(arg.d); i++) {
 		arg.d[i].buckets	= src.d[i].buckets;
 		arg.d[i].sectors	= src.d[i].sectors;
 		arg.d[i].fragmented	= src.d[i].fragmented;
 	}
 
-	bch2_dev_put(ca);
-
 	return copy_to_user_errcode(user_arg, &arg, sizeof(arg));
 }
 
 static long bch2_ioctl_dev_usage_v2(struct bch_fs *c,
 				 struct bch_ioctl_dev_usage_v2 __user *user_arg)
 {
-	struct bch_ioctl_dev_usage_v2 arg;
-	struct bch_dev_usage_full src;
-	struct bch_dev *ca;
-	int ret = 0;
-
 	if (!test_bit(BCH_FS_started, &c->flags))
 		return -EINVAL;
 
+	struct bch_ioctl_dev_usage_v2 arg;
 	if (copy_from_user(&arg, user_arg, sizeof(arg)))
 		return -EFAULT;
 
@@ -545,20 +518,20 @@ static long bch2_ioctl_dev_usage_v2(struct bch_fs *c,
 	    arg.pad[2])
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	src = bch2_dev_usage_full_read(ca);
+	struct bch_dev_usage_full src = bch2_dev_usage_full_read(ca);
 
 	arg.state		= ca->mi.state;
 	arg.bucket_size		= ca->mi.bucket_size;
 	arg.nr_data_types	= min(arg.nr_data_types, BCH_DATA_NR);
 	arg.nr_buckets		= ca->mi.nbuckets - ca->mi.first_bucket;
 
-	ret = copy_to_user_errcode(user_arg, &arg, sizeof(arg));
+	int ret = copy_to_user_errcode(user_arg, &arg, sizeof(arg));
 	if (ret)
-		goto err;
+		return ret;
 
 	for (unsigned i = 0; i < arg.nr_data_types; i++) {
 		struct bch_ioctl_dev_usage_type t = {
@@ -569,11 +542,10 @@ static long bch2_ioctl_dev_usage_v2(struct bch_fs *c,
 
 		ret = copy_to_user_errcode(&user_arg->d[i], &t, sizeof(t));
 		if (ret)
-			goto err;
+			return ret;
 	}
-err:
-	bch2_dev_put(ca);
-	return ret;
+
+	return 0;
 }
 
 static long bch2_ioctl_read_super(struct bch_fs *c,
@@ -590,13 +562,13 @@ static long bch2_ioctl_read_super(struct bch_fs *c,
 	    arg.pad)
 		return -EINVAL;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 
 	if (arg.flags & BCH_READ_DEV) {
 		ca = bch2_device_lookup(c, arg.dev, arg.flags);
 		ret = PTR_ERR_OR_ZERO(ca);
 		if (ret)
-			goto err_unlock;
+			return ret;
 
 		sb = ca->disk_sb.sb;
 	} else {
@@ -612,8 +584,6 @@ static long bch2_ioctl_read_super(struct bch_fs *c,
 				   vstruct_bytes(sb));
 err:
 	bch2_dev_put(ca);
-err_unlock:
-	mutex_unlock(&c->sb_lock);
 	return ret;
 }
 
@@ -639,9 +609,6 @@ static long bch2_ioctl_disk_get_idx(struct bch_fs *c,
 static long bch2_ioctl_disk_resize(struct bch_fs *c,
 				   struct bch_ioctl_disk_resize arg)
 {
-	struct bch_dev *ca;
-	int ret;
-
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -649,22 +616,16 @@ static long bch2_ioctl_disk_resize(struct bch_fs *c,
 	    arg.pad)
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	ret = bch2_dev_resize(c, ca, arg.nbuckets);
-
-	bch2_dev_put(ca);
-	return ret;
+	return bch2_dev_resize(c, ca, arg.nbuckets);
 }
 
 static long bch2_ioctl_disk_resize_journal(struct bch_fs *c,
 				   struct bch_ioctl_disk_resize_journal arg)
 {
-	struct bch_dev *ca;
-	int ret;
-
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -675,14 +636,11 @@ static long bch2_ioctl_disk_resize_journal(struct bch_fs *c,
 	if (arg.nbuckets > U32_MAX)
 		return -EINVAL;
 
-	ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	ret = bch2_set_nr_journal_buckets(c, ca, arg.nbuckets);
-
-	bch2_dev_put(ca);
-	return ret;
+	return bch2_set_nr_journal_buckets(c, ca, arg.nbuckets);
 }
 
 #define BCH_IOCTL(_name, _argtype)					\
diff --git a/fs/bcachefs/sb-members.h b/fs/bcachefs/sb-members.h
index 0d363a1cdd47..35d4ab9b6197 100644
--- a/fs/bcachefs/sb-members.h
+++ b/fs/bcachefs/sb-members.h
@@ -133,7 +133,7 @@ static inline void __bch2_dev_put(struct bch_dev *ca)
 
 static inline void bch2_dev_put(struct bch_dev *ca)
 {
-	if (ca)
+	if (!IS_ERR_OR_NULL(ca))
 		__bch2_dev_put(ca);
 }
 
-- 
2.51.0


From 341dc3f353719222c6e368740e8db053a0d02955 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:36:43 -0400
Subject: [PATCH 111/309] bcachefs: convert fs-ioctl.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-ioctl.c | 33 +++++++++++++--------------------
 1 file changed, 13 insertions(+), 20 deletions(-)

diff --git a/fs/bcachefs/fs-ioctl.c b/fs/bcachefs/fs-ioctl.c
index 4e72e654da96..8b9d3c7d1f57 100644
--- a/fs/bcachefs/fs-ioctl.c
+++ b/fs/bcachefs/fs-ioctl.c
@@ -111,9 +111,8 @@ static int bch2_ioc_getlabel(struct bch_fs *c, char __user *user_label)
 
 	BUILD_BUG_ON(BCH_SB_LABEL_SIZE >= FSLABEL_MAX);
 
-	mutex_lock(&c->sb_lock);
-	memcpy(label, c->disk_sb.sb->label, BCH_SB_LABEL_SIZE);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock)
+		memcpy(label, c->disk_sb.sb->label, BCH_SB_LABEL_SIZE);
 
 	len = strnlen(label, BCH_SB_LABEL_SIZE);
 	if (len == BCH_SB_LABEL_SIZE) {
@@ -152,10 +151,10 @@ static int bch2_ioc_setlabel(struct bch_fs *c,
 	if (ret)
 		return ret;
 
-	mutex_lock(&c->sb_lock);
-	strscpy(c->disk_sb.sb->label, label, BCH_SB_LABEL_SIZE);
-	ret = bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock) {
+		strscpy(c->disk_sb.sb->label, label, BCH_SB_LABEL_SIZE);
+		ret = bch2_write_super(c);
+	}
 
 	mnt_drop_write_file(file);
 	return ret;
@@ -172,7 +171,7 @@ static int bch2_ioc_goingdown(struct bch_fs *c, u32 __user *arg)
 	if (get_user(flags, arg))
 		return -EFAULT;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	prt_printf(&buf, "shutdown by ioctl type %u", flags);
@@ -193,13 +192,10 @@ static int bch2_ioc_goingdown(struct bch_fs *c, u32 __user *arg)
 		bch2_fs_emergency_read_only2(c, &buf);
 		break;
 	default:
-		ret = -EINVAL;
-		goto noprint;
+		return -EINVAL;
 	}
 
 	bch2_print_str(c, KERN_ERR, buf.buf);
-noprint:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -234,9 +230,8 @@ static long bch2_ioctl_subvolume_create(struct bch_fs *c, struct file *filp,
 
 	if (arg.flags & BCH_SUBVOL_SNAPSHOT_CREATE) {
 		/* sync_inodes_sb enforce s_umount is locked */
-		down_read(&c->vfs_sb->s_umount);
+		guard(rwsem_read)(&c->vfs_sb->s_umount);
 		sync_inodes_sb(c->vfs_sb);
-		up_read(&c->vfs_sb->s_umount);
 	}
 
 	if (arg.src_ptr) {
@@ -301,12 +296,10 @@ static long bch2_ioctl_subvolume_create(struct bch_fs *c, struct file *filp,
 	    !arg.src_ptr)
 		snapshot_src.subvol = inode_inum(to_bch_ei(dir)).subvol;
 
-	down_write(&c->snapshot_create_lock);
-	inode = __bch2_create(file_mnt_idmap(filp), to_bch_ei(dir),
-			      dst_dentry, arg.mode|S_IFDIR,
-			      0, snapshot_src, create_flags);
-	up_write(&c->snapshot_create_lock);
-
+	scoped_guard(rwsem_write, &c->snapshot_create_lock)
+		inode = __bch2_create(file_mnt_idmap(filp), to_bch_ei(dir),
+				      dst_dentry, arg.mode|S_IFDIR,
+				      0, snapshot_src, create_flags);
 	error = PTR_ERR_OR_ZERO(inode);
 	if (error)
 		goto err3;
-- 
2.51.0


From dcf152fc3c695367be303111e18ebfbd8f3c1095 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:30:45 -0400
Subject: [PATCH 112/309] bcachefs: convert disk_groups.c to guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/disk_groups.c | 27 ++++++++-------------------
 1 file changed, 8 insertions(+), 19 deletions(-)

diff --git a/fs/bcachefs/disk_groups.c b/fs/bcachefs/disk_groups.c
index cde842ac1886..293e47268508 100644
--- a/fs/bcachefs/disk_groups.c
+++ b/fs/bcachefs/disk_groups.c
@@ -375,7 +375,7 @@ void bch2_disk_groups_to_text(struct printbuf *out, struct bch_fs *c)
 {
 	bch2_printbuf_make_room(out, 4096);
 
-	out->atomic++;
+	guard(printbuf_atomic)(out);
 	guard(rcu)();
 	struct bch_disk_groups_cpu *g = rcu_dereference(c->disk_groups);
 
@@ -396,16 +396,13 @@ void bch2_disk_groups_to_text(struct printbuf *out, struct bch_fs *c)
 next:
 		prt_newline(out);
 	}
-
-	out->atomic--;
 }
 
 void bch2_disk_path_to_text(struct printbuf *out, struct bch_fs *c, unsigned v)
 {
-	out->atomic++;
+	guard(printbuf_atomic)(out);
 	guard(rcu)();
-	__bch2_disk_path_to_text(out, rcu_dereference(c->disk_groups), v),
-	--out->atomic;
+	__bch2_disk_path_to_text(out, rcu_dereference(c->disk_groups), v);
 }
 
 void bch2_disk_path_to_text_sb(struct printbuf *out, struct bch_sb *sb, unsigned v)
@@ -471,14 +468,9 @@ int __bch2_dev_group_set(struct bch_fs *c, struct bch_dev *ca, const char *name)
 
 int bch2_dev_group_set(struct bch_fs *c, struct bch_dev *ca, const char *name)
 {
-	int ret;
-
-	mutex_lock(&c->sb_lock);
-	ret = __bch2_dev_group_set(c, ca, name) ?:
+	guard(mutex)(&c->sb_lock);
+	return __bch2_dev_group_set(c, ca, name) ?:
 		bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
-
-	return ret;
 }
 
 int bch2_opt_target_parse(struct bch_fs *c, const char *val, u64 *res,
@@ -506,9 +498,8 @@ int bch2_opt_target_parse(struct bch_fs *c, const char *val, u64 *res,
 		return 0;
 	}
 
-	mutex_lock(&c->sb_lock);
-	g = bch2_disk_path_find(&c->disk_sb, val);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock)
+		g = bch2_disk_path_find(&c->disk_sb, val);
 
 	if (g >= 0) {
 		*res = group_to_target(g);
@@ -527,7 +518,7 @@ void bch2_target_to_text(struct printbuf *out, struct bch_fs *c, unsigned v)
 		prt_printf(out, "none");
 		return;
 	case TARGET_DEV: {
-		out->atomic++;
+		guard(printbuf_atomic)(out);
 		guard(rcu)();
 		struct bch_dev *ca = t.dev < c->sb.nr_devices
 			? rcu_dereference(c->devs[t.dev])
@@ -539,8 +530,6 @@ void bch2_target_to_text(struct printbuf *out, struct bch_fs *c, unsigned v)
 			prt_printf(out, "offline device %u", t.dev);
 		else
 			prt_printf(out, "invalid device %u", t.dev);
-
-		out->atomic--;
 		return;
 	}
 	case TARGET_GROUP:
-- 
2.51.0


From 625b42ed556b201f452c930b36e28f223f968373 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:31:36 -0400
Subject: [PATCH 113/309] bcachefs: convert checksum.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/checksum.c | 54 ++++++++++++++++--------------------------
 1 file changed, 21 insertions(+), 33 deletions(-)

diff --git a/fs/bcachefs/checksum.c b/fs/bcachefs/checksum.c
index a6795e73f0b9..b1ec38992852 100644
--- a/fs/bcachefs/checksum.c
+++ b/fs/bcachefs/checksum.c
@@ -361,7 +361,7 @@ int bch2_rechecksum_bio(struct bch_fs *c, struct bio *bio,
 				extent_nonce(version, crc_old), bio);
 
 	if (bch2_crc_cmp(merged, crc_old.csum) && !c->opts.no_data_io) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		prt_printf(&buf, "checksum error in %s() (memory corruption or bug?)\n"
 			   "  expected %0llx:%0llx got %0llx:%0llx (old type ",
 			   __func__,
@@ -374,7 +374,6 @@ int bch2_rechecksum_bio(struct bch_fs *c, struct bio *bio,
 		bch2_prt_csum_type(&buf, new_csum_type);
 		prt_str(&buf, ")");
 		WARN_RATELIMIT(1, "%s", buf.buf);
-		printbuf_exit(&buf);
 		return bch_err_throw(c, recompute_checksum);
 	}
 
@@ -438,23 +437,21 @@ const struct bch_sb_field_ops bch_sb_field_ops_crypt = {
 #ifdef __KERNEL__
 static int __bch2_request_key(char *key_description, struct bch_key *key)
 {
-	struct key *keyring_key;
-	const struct user_key_payload *ukp;
 	int ret;
 
-	keyring_key = request_key(&key_type_user, key_description, NULL);
+	struct key *keyring_key = request_key(&key_type_user, key_description, NULL);
 	if (IS_ERR(keyring_key))
 		return PTR_ERR(keyring_key);
 
-	down_read(&keyring_key->sem);
-	ukp = dereference_key_locked(keyring_key);
-	if (ukp->datalen == sizeof(*key)) {
-		memcpy(key, ukp->data, ukp->datalen);
-		ret = 0;
-	} else {
-		ret = -EINVAL;
+	scoped_guard(rwsem_read, &keyring_key->sem) {
+		const struct user_key_payload *ukp = dereference_key_locked(keyring_key);
+		if (ukp->datalen == sizeof(*key)) {
+			memcpy(key, ukp->data, ukp->datalen);
+			ret = 0;
+		} else {
+			ret = -EINVAL;
+		}
 	}
-	up_read(&keyring_key->sem);
 	key_put(keyring_key);
 
 	return ret;
@@ -495,14 +492,13 @@ static int __bch2_request_key(char *key_description, struct bch_key *key)
 
 int bch2_request_key(struct bch_sb *sb, struct bch_key *key)
 {
-	struct printbuf key_description = PRINTBUF;
+	CLASS(printbuf, key_description)();
 	int ret;
 
 	prt_printf(&key_description, "bcachefs:");
 	pr_uuid(&key_description, sb->user_uuid.b);
 
 	ret = __bch2_request_key(key_description.buf, key);
-	printbuf_exit(&key_description);
 
 #ifndef __KERNEL__
 	if (ret) {
@@ -524,13 +520,12 @@ int bch2_request_key(struct bch_sb *sb, struct bch_key *key)
 int bch2_revoke_key(struct bch_sb *sb)
 {
 	key_serial_t key_id;
-	struct printbuf key_description = PRINTBUF;
+	CLASS(printbuf, key_description)();
 
 	prt_printf(&key_description, "bcachefs:");
 	pr_uuid(&key_description, sb->user_uuid.b);
 
 	key_id = request_key("user", key_description.buf, NULL, KEY_SPEC_USER_KEYRING);
-	printbuf_exit(&key_description);
 	if (key_id < 0)
 		return errno;
 
@@ -584,34 +579,28 @@ int bch2_decrypt_sb_key(struct bch_fs *c,
  */
 int bch2_disable_encryption(struct bch_fs *c)
 {
-	struct bch_sb_field_crypt *crypt;
-	struct bch_key key;
-	int ret = -EINVAL;
-
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 
-	crypt = bch2_sb_field_get(c->disk_sb.sb, crypt);
+	struct bch_sb_field_crypt *crypt = bch2_sb_field_get(c->disk_sb.sb, crypt);
 	if (!crypt)
-		goto out;
+		return -EINVAL;
 
 	/* is key encrypted? */
 	ret = 0;
 	if (bch2_key_is_encrypted(&crypt->key))
-		goto out;
+		return 0;
 
-	ret = bch2_decrypt_sb_key(c, crypt, &key);
+	struct bch_key key;
+	int ret = bch2_decrypt_sb_key(c, crypt, &key);
 	if (ret)
-		goto out;
+		return ret;
 
 	crypt->key.magic	= cpu_to_le64(BCH_KEY_MAGIC);
 	crypt->key.key		= key;
 
 	SET_BCH_SB_ENCRYPTION_TYPE(c->disk_sb.sb, 0);
 	bch2_write_super(c);
-out:
-	mutex_unlock(&c->sb_lock);
-
-	return ret;
+	return 0;
 }
 
 /*
@@ -625,7 +614,7 @@ int bch2_enable_encryption(struct bch_fs *c, bool keyed)
 	struct bch_sb_field_crypt *crypt;
 	int ret = -EINVAL;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 
 	/* Do we already have an encryption key? */
 	if (bch2_sb_field_get(c->disk_sb.sb, crypt))
@@ -669,7 +658,6 @@ int bch2_enable_encryption(struct bch_fs *c, bool keyed)
 	SET_BCH_SB_ENCRYPTION_TYPE(c->disk_sb.sb, 1);
 	bch2_write_super(c);
 err:
-	mutex_unlock(&c->sb_lock);
 	memzero_explicit(&user_key, sizeof(user_key));
 	memzero_explicit(&key, sizeof(key));
 	return ret;
-- 
2.51.0


From e0c2e8b0aab6c591abcc76e1f4a58a970de7e1a5 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:33:05 -0400
Subject: [PATCH 114/309] bcachefs: convert compress.c to guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/compress.c | 12 +++---------
 1 file changed, 3 insertions(+), 9 deletions(-)

diff --git a/fs/bcachefs/compress.c b/fs/bcachefs/compress.c
index 5f74de920c92..aeb9b9bd7d33 100644
--- a/fs/bcachefs/compress.c
+++ b/fs/bcachefs/compress.c
@@ -579,23 +579,17 @@ static int __bch2_check_set_has_compressed_data(struct bch_fs *c, u64 f)
 	if ((c->sb.features & f) == f)
 		return 0;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 
-	if ((c->sb.features & f) == f) {
-		mutex_unlock(&c->sb_lock);
+	if ((c->sb.features & f) == f)
 		return 0;
-	}
 
 	ret = __bch2_fs_compress_init(c, c->sb.features|f);
-	if (ret) {
-		mutex_unlock(&c->sb_lock);
+	if (ret)
 		return ret;
-	}
 
 	c->disk_sb.sb->features[0] |= cpu_to_le64(f);
 	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
-
 	return 0;
 }
 
-- 
2.51.0


From fb021e8ae7db85fa4520c11e02f20a495850bacb Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:38:30 -0400
Subject: [PATCH 115/309] bcachefs: convert rebalance.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/rebalance.c | 49 ++++++++++++++---------------------------
 1 file changed, 17 insertions(+), 32 deletions(-)

diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index 73b463c94966..32fa7cf90b63 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -235,24 +235,19 @@ static const char * const bch2_rebalance_state_strs[] = {
 int bch2_set_rebalance_needs_scan_trans(struct btree_trans *trans, u64 inum)
 {
 	struct btree_iter iter;
-	struct bkey_s_c k;
-	struct bkey_i_cookie *cookie;
-	u64 v;
-	int ret;
-
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_rebalance_work,
 			     SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
 			     BTREE_ITER_intent);
-	k = bch2_btree_iter_peek_slot(trans, &iter);
-	ret = bkey_err(k);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, &iter);
+	int ret = bkey_err(k);
 	if (ret)
 		goto err;
 
-	v = k.k->type == KEY_TYPE_cookie
+	u64 v = k.k->type == KEY_TYPE_cookie
 		? le64_to_cpu(bkey_s_c_to_cookie(k).v->cookie)
 		: 0;
 
-	cookie = bch2_trans_kmalloc(trans, sizeof(*cookie));
+	struct bkey_i_cookie *cookie = bch2_trans_kmalloc(trans, sizeof(*cookie));
 	ret = PTR_ERR_OR_ZERO(cookie);
 	if (ret)
 		goto err;
@@ -269,8 +264,8 @@ int bch2_set_rebalance_needs_scan_trans(struct btree_trans *trans, u64 inum)
 
 int bch2_set_rebalance_needs_scan(struct bch_fs *c, u64 inum)
 {
-	int ret = bch2_trans_commit_do(c, NULL, NULL,
-				       BCH_TRANS_COMMIT_no_enospc,
+	CLASS(btree_trans, trans)(c);
+	int ret = commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			    bch2_set_rebalance_needs_scan_trans(trans, inum));
 	bch2_rebalance_wakeup(c);
 	return ret;
@@ -284,19 +279,15 @@ int bch2_set_fs_needs_rebalance(struct bch_fs *c)
 static int bch2_clear_rebalance_needs_scan(struct btree_trans *trans, u64 inum, u64 cookie)
 {
 	struct btree_iter iter;
-	struct bkey_s_c k;
-	u64 v;
-	int ret;
-
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_rebalance_work,
 			     SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
 			     BTREE_ITER_intent);
-	k = bch2_btree_iter_peek_slot(trans, &iter);
-	ret = bkey_err(k);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, &iter);
+	int ret = bkey_err(k);
 	if (ret)
 		goto err;
 
-	v = k.k->type == KEY_TYPE_cookie
+	u64 v = k.k->type == KEY_TYPE_cookie
 		? le64_to_cpu(bkey_s_c_to_cookie(k).v->cookie)
 		: 0;
 
@@ -373,7 +364,7 @@ static struct bkey_s_c next_rebalance_extent(struct btree_trans *trans,
 	}
 
 	if (trace_rebalance_extent_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_bkey_val_to_text(&buf, c, k);
 		prt_newline(&buf);
@@ -399,7 +390,6 @@ static struct bkey_s_c next_rebalance_extent(struct btree_trans *trans,
 		}
 
 		trace_rebalance_extent(c, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	return k;
@@ -713,17 +703,15 @@ void bch2_rebalance_stop(struct bch_fs *c)
 
 int bch2_rebalance_start(struct bch_fs *c)
 {
-	struct task_struct *p;
-	int ret;
-
 	if (c->rebalance.thread)
 		return 0;
 
 	if (c->opts.nochanges)
 		return 0;
 
-	p = kthread_create(bch2_rebalance_thread, c, "bch-rebalance/%s", c->name);
-	ret = PTR_ERR_OR_ZERO(p);
+	struct task_struct *p =
+		kthread_create(bch2_rebalance_thread, c, "bch-rebalance/%s", c->name);
+	int ret = PTR_ERR_OR_ZERO(p);
 	bch_err_msg(c, ret, "creating rebalance thread");
 	if (ret)
 		return ret;
@@ -779,7 +767,7 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct bkey_s_c extent_k, rebalance_k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	int ret = bkey_err(extent_k	= bch2_btree_iter_peek(trans, extent_iter)) ?:
 		  bkey_err(rebalance_k	= bch2_btree_iter_peek(trans, rebalance_iter));
@@ -833,7 +821,7 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 		ret = bch2_btree_bit_mod_buffered(trans, BTREE_ID_rebalance_work,
 						  extent_k.k->p, false);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (fsck_err_on(should_have_rebalance && !have_rebalance,
@@ -842,22 +830,20 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 		ret = bch2_btree_bit_mod_buffered(trans, BTREE_ID_rebalance_work,
 						  extent_k.k->p, true);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (cmp <= 0)
 		bch2_btree_iter_advance(trans, extent_iter);
 	if (cmp >= 0)
 		bch2_btree_iter_advance(trans, rebalance_iter);
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
 int bch2_check_rebalance_work(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter rebalance_iter, extent_iter;
 	int ret = 0;
 
@@ -884,6 +870,5 @@ int bch2_check_rebalance_work(struct bch_fs *c)
 	bch2_bkey_buf_exit(&last_flushed, c);
 	bch2_trans_iter_exit(trans, &extent_iter);
 	bch2_trans_iter_exit(trans, &rebalance_iter);
-	bch2_trans_put(trans);
 	return ret < 0 ? ret : 0;
 }
-- 
2.51.0


From 6c39d26e264ea2d5bb7c07724e5650e88b1e3e44 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:39:01 -0400
Subject: [PATCH 116/309] bcachefs: convert migrate.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/migrate.c | 21 +++++++--------------
 1 file changed, 7 insertions(+), 14 deletions(-)

diff --git a/fs/bcachefs/migrate.c b/fs/bcachefs/migrate.c
index f296cce95338..bd1e54e0efd5 100644
--- a/fs/bcachefs/migrate.c
+++ b/fs/bcachefs/migrate.c
@@ -119,34 +119,29 @@ static int bch2_dev_usrdata_drop(struct bch_fs *c,
 				 struct progress_indicator_state *progress,
 				 unsigned dev_idx, unsigned flags)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	enum btree_id id;
-	int ret = 0;
+	CLASS(btree_trans, trans)(c);
 
-	for (id = 0; id < BTREE_ID_NR; id++) {
+	for (unsigned id = 0; id < BTREE_ID_NR; id++) {
 		if (!btree_type_has_ptrs(id))
 			continue;
 
-		ret = for_each_btree_key_commit(trans, iter, id, POS_MIN,
+		int ret = for_each_btree_key_commit(trans, iter, id, POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
 			bch2_progress_update_iter(trans, progress, &iter, "dropping user data");
 			bch2_dev_usrdata_drop_key(trans, &iter, k, dev_idx, flags);
 		}));
 		if (ret)
-			break;
+			return ret;
 	}
 
-	bch2_trans_put(trans);
-
-	return ret;
+	return 0;
 }
 
 static int bch2_dev_metadata_drop(struct bch_fs *c,
 				  struct progress_indicator_state *progress,
 				  unsigned dev_idx, unsigned flags)
 {
-	struct btree_trans *trans;
 	struct btree_iter iter;
 	struct closure cl;
 	struct btree *b;
@@ -158,7 +153,7 @@ static int bch2_dev_metadata_drop(struct bch_fs *c,
 	if (flags & BCH_FORCE_IF_METADATA_LOST)
 		return bch_err_throw(c, remove_with_metadata_missing_unimplemented);
 
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	bch2_bkey_buf_init(&k);
 	closure_init_stack(&cl);
 
@@ -199,7 +194,6 @@ static int bch2_dev_metadata_drop(struct bch_fs *c,
 	ret = 0;
 err:
 	bch2_bkey_buf_exit(&k, c);
-	bch2_trans_put(trans);
 
 	BUG_ON(bch2_err_matches(ret, BCH_ERR_transaction_restart));
 
@@ -240,7 +234,7 @@ static int data_drop_bp(struct btree_trans *trans, unsigned dev_idx,
 
 int bch2_dev_data_drop_by_backpointers(struct bch_fs *c, unsigned dev_idx, unsigned flags)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	struct bkey_buf last_flushed;
 	bch2_bkey_buf_init(&last_flushed);
@@ -260,7 +254,6 @@ int bch2_dev_data_drop_by_backpointers(struct bch_fs *c, unsigned dev_idx, unsig
 	}));
 
 	bch2_bkey_buf_exit(&last_flushed, trans->c);
-	bch2_trans_put(trans);
 	bch_err_fn(c, ret);
 	return ret;
 }
-- 
2.51.0


From 10f2c984365eeae0f89f6e0bf51e2628d5759f08 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:44:26 -0400
Subject: [PATCH 117/309] bcachefs: convert move.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/move.c | 75 +++++++++++++++++++---------------------------
 1 file changed, 30 insertions(+), 45 deletions(-)

diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index b2ea4595e8cb..3f44bb54f91a 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -54,22 +54,20 @@ trace_io_move2(struct bch_fs *c, struct bkey_s_c k,
 	       struct bch_io_opts *io_opts,
 	       struct data_update_opts *data_opts)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_bkey_val_to_text(&buf, c, k);
 	prt_newline(&buf);
 	bch2_data_update_opts_to_text(&buf, c, io_opts, data_opts);
 	trace_io_move(c, buf.buf);
-	printbuf_exit(&buf);
 }
 
 static noinline void trace_io_move_read2(struct bch_fs *c, struct bkey_s_c k)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_bkey_val_to_text(&buf, c, k);
 	trace_io_move_read(c, buf.buf);
-	printbuf_exit(&buf);
 }
 
 static noinline void
@@ -78,7 +76,7 @@ trace_io_move_pred2(struct bch_fs *c, struct bkey_s_c k,
 		    struct data_update_opts *data_opts,
 		    move_pred_fn pred, void *_arg, bool p)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_printf(&buf, "%ps: %u", pred, p);
 
@@ -92,7 +90,6 @@ trace_io_move_pred2(struct bch_fs *c, struct bkey_s_c k,
 	prt_newline(&buf);
 	bch2_data_update_opts_to_text(&buf, c, io_opts, data_opts);
 	trace_io_move_pred(c, buf.buf);
-	printbuf_exit(&buf);
 }
 
 static noinline void
@@ -128,10 +125,9 @@ static void move_free(struct moving_io *io)
 	if (io->b)
 		atomic_dec(&io->b->count);
 
-	mutex_lock(&ctxt->lock);
-	list_del(&io->io_list);
+	scoped_guard(mutex, &ctxt->lock)
+		list_del(&io->io_list);
 	wake_up(&ctxt->wait);
-	mutex_unlock(&ctxt->lock);
 
 	if (!io->write.data_opts.scrub) {
 		bch2_data_update_exit(&io->write);
@@ -150,11 +146,9 @@ static void move_write_done(struct bch_write_op *op)
 
 	if (op->error) {
 		if (trace_io_move_write_fail_enabled()) {
-			struct printbuf buf = PRINTBUF;
-
+			CLASS(printbuf, buf)();
 			bch2_write_op_to_text(&buf, op);
 			trace_io_move_write_fail(c, buf.buf);
-			printbuf_exit(&buf);
 		}
 		this_cpu_inc(c->counters[BCH_COUNTER_io_move_write_fail]);
 
@@ -203,11 +197,9 @@ static void move_write(struct moving_io *io)
 	}
 
 	if (trace_io_move_write_enabled()) {
-		struct printbuf buf = PRINTBUF;
-
+		CLASS(printbuf, buf)();
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(io->write.k.k));
 		trace_io_move_write(c, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	closure_get(&io->write.ctxt->cl);
@@ -276,9 +268,8 @@ void bch2_moving_ctxt_exit(struct moving_context *ctxt)
 	EBUG_ON(atomic_read(&ctxt->read_sectors));
 	EBUG_ON(atomic_read(&ctxt->read_ios));
 
-	mutex_lock(&c->moving_context_lock);
-	list_del(&ctxt->list);
-	mutex_unlock(&c->moving_context_lock);
+	scoped_guard(mutex, &c->moving_context_lock)
+		list_del(&ctxt->list);
 
 	/*
 	 * Generally, releasing a transaction within a transaction restart means
@@ -314,9 +305,8 @@ void bch2_moving_ctxt_init(struct moving_context *ctxt,
 	INIT_LIST_HEAD(&ctxt->ios);
 	init_waitqueue_head(&ctxt->wait);
 
-	mutex_lock(&c->moving_context_lock);
-	list_add(&ctxt->list, &c->moving_context_list);
-	mutex_unlock(&c->moving_context_lock);
+	scoped_guard(mutex, &c->moving_context_lock)
+		list_add(&ctxt->list, &c->moving_context_list);
 }
 
 void bch2_move_stats_exit(struct bch_move_stats *stats, struct bch_fs *c)
@@ -412,13 +402,13 @@ int bch2_move_extent(struct moving_context *ctxt,
 	if (trace_io_move_read_enabled())
 		trace_io_move_read2(c, k);
 
-	mutex_lock(&ctxt->lock);
-	atomic_add(io->read_sectors, &ctxt->read_sectors);
-	atomic_inc(&ctxt->read_ios);
+	scoped_guard(mutex, &ctxt->lock) {
+		atomic_add(io->read_sectors, &ctxt->read_sectors);
+		atomic_inc(&ctxt->read_ios);
 
-	list_add_tail(&io->read_list, &ctxt->reads);
-	list_add_tail(&io->io_list, &ctxt->ios);
-	mutex_unlock(&ctxt->lock);
+		list_add_tail(&io->read_list, &ctxt->reads);
+		list_add_tail(&io->io_list, &ctxt->ios);
+	}
 
 	/*
 	 * dropped by move_read_endio() - guards against use after free of
@@ -443,13 +433,11 @@ int bch2_move_extent(struct moving_context *ctxt,
 	count_event(c, io_move_start_fail);
 
 	if (trace_io_move_start_fail_enabled()) {
-		struct printbuf buf = PRINTBUF;
-
+		CLASS(printbuf, buf)();
 		bch2_bkey_val_to_text(&buf, c, k);
 		prt_str(&buf, ": ");
 		prt_str(&buf, bch2_err_str(ret));
 		trace_io_move_start_fail(c, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	if (bch2_err_matches(ret, BCH_ERR_data_update_done))
@@ -874,7 +862,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 	u64 check_mismatch_done = bucket_start;
 	int ret = 0;
 
-	struct bch_dev *ca = bch2_dev_tryget(c, dev);
+	CLASS(bch2_dev_tryget, ca)(c, dev);
 	if (!ca)
 		return 0;
 
@@ -1013,7 +1001,6 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 	bch2_trans_iter_exit(trans, &bp_iter);
 	bch2_bkey_buf_exit(&sk, c);
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch2_dev_put(ca);
 	return ret;
 }
 
@@ -1030,9 +1017,9 @@ int bch2_move_data_phys(struct bch_fs *c,
 {
 	struct moving_context ctxt;
 
-	bch2_trans_run(c, bch2_btree_write_buffer_flush_sync(trans));
-
 	bch2_moving_ctxt_init(&ctxt, c, rate, stats, wp, wait_on_copygc);
+	bch2_btree_write_buffer_flush_sync(ctxt.trans);
+
 	if (ctxt.stats) {
 		ctxt.stats->phys = true;
 		ctxt.stats->data_type = (int) DATA_PROGRESS_DATA_TYPE_phys;
@@ -1267,12 +1254,11 @@ int bch2_scan_old_btree_nodes(struct bch_fs *c, struct bch_move_stats *stats)
 			      BBPOS_MAX,
 			      rewrite_old_nodes_pred, c, stats);
 	if (!ret) {
-		mutex_lock(&c->sb_lock);
+		guard(mutex)(&c->sb_lock);
 		c->disk_sb.sb->compat[0] |= cpu_to_le64(1ULL << BCH_COMPAT_extents_above_btree_updates_done);
 		c->disk_sb.sb->compat[0] |= cpu_to_le64(1ULL << BCH_COMPAT_bformat_overflow_done);
 		c->disk_sb.sb->version_min = c->disk_sb.sb->version;
 		bch2_write_super(c);
-		mutex_unlock(&c->sb_lock);
 	}
 
 	bch_err_fn(c, ret);
@@ -1467,11 +1453,11 @@ static void bch2_moving_ctxt_to_text(struct printbuf *out, struct bch_fs *c, str
 
 	printbuf_indent_add(out, 2);
 
-	mutex_lock(&ctxt->lock);
-	struct moving_io *io;
-	list_for_each_entry(io, &ctxt->ios, io_list)
-		bch2_data_update_inflight_to_text(out, &io->write);
-	mutex_unlock(&ctxt->lock);
+	scoped_guard(mutex, &ctxt->lock) {
+		struct moving_io *io;
+		list_for_each_entry(io, &ctxt->ios, io_list)
+			bch2_data_update_inflight_to_text(out, &io->write);
+	}
 
 	printbuf_indent_sub(out, 4);
 }
@@ -1480,10 +1466,9 @@ void bch2_fs_moving_ctxts_to_text(struct printbuf *out, struct bch_fs *c)
 {
 	struct moving_context *ctxt;
 
-	mutex_lock(&c->moving_context_lock);
-	list_for_each_entry(ctxt, &c->moving_context_list, list)
-		bch2_moving_ctxt_to_text(out, c, ctxt);
-	mutex_unlock(&c->moving_context_lock);
+	scoped_guard(mutex, &c->moving_context_lock)
+		list_for_each_entry(ctxt, &c->moving_context_list, list)
+			bch2_moving_ctxt_to_text(out, c, ctxt);
 }
 
 void bch2_fs_move_init(struct bch_fs *c)
-- 
2.51.0


From 4afb2f11ea419b60412426682f7d0269209980f3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:46:30 -0400
Subject: [PATCH 118/309] bcachefs: convert movinggc.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/movinggc.c | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/movinggc.c b/fs/bcachefs/movinggc.c
index 5e6de91a8763..9192b1fc3594 100644
--- a/fs/bcachefs/movinggc.c
+++ b/fs/bcachefs/movinggc.c
@@ -71,7 +71,7 @@ static int bch2_bucket_is_movable(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	struct bch_dev *ca = bch2_dev_bucket_tryget(c, k.k->p);
+	CLASS(bch2_dev_bucket_tryget, ca)(c, k.k->p);
 	if (!ca)
 		goto out;
 
@@ -90,7 +90,6 @@ static int bch2_bucket_is_movable(struct btree_trans *trans,
 
 	ret = lru_idx && lru_idx <= time;
 out:
-	bch2_dev_put(ca);
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
 }
@@ -320,8 +319,8 @@ void bch2_copygc_wait_to_text(struct printbuf *out, struct bch_fs *c)
 	bch2_printbuf_make_room(out, 4096);
 
 	struct task_struct *t;
-	out->atomic++;
 	scoped_guard(rcu) {
+		guard(printbuf_atomic)(out);
 		prt_printf(out, "Currently calculated wait:\n");
 		for_each_rw_member_rcu(c, ca) {
 			prt_printf(out, "  %s:\t", ca->name);
@@ -333,7 +332,6 @@ void bch2_copygc_wait_to_text(struct printbuf *out, struct bch_fs *c)
 		if (t)
 			get_task_struct(t);
 	}
-	--out->atomic;
 
 	if (t) {
 		bch2_prt_task_backtrace(out, t, 0, GFP_KERNEL);
-- 
2.51.0


From b4bfd5ce83531b3e0079817fee1d5b49fe5dc906 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:20:12 -0400
Subject: [PATCH 119/309] bcachefs: convert data_update.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/data_update.c | 20 ++++++++------------
 1 file changed, 8 insertions(+), 12 deletions(-)

diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index 954d53239867..ccedc93fe0ef 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -115,7 +115,7 @@ static void trace_io_move_finish2(struct data_update *u,
 				  struct bkey_i *insert)
 {
 	struct bch_fs *c = u->op.c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_newline(&buf);
 
@@ -131,7 +131,6 @@ static void trace_io_move_finish2(struct data_update *u,
 	prt_newline(&buf);
 
 	trace_io_move_finish(c, buf.buf);
-	printbuf_exit(&buf);
 }
 
 noinline_for_stack
@@ -143,7 +142,7 @@ static void trace_io_move_fail2(struct data_update *m,
 {
 	struct bch_fs *c = m->op.c;
 	struct bkey_s_c old = bkey_i_to_s_c(m->k.k);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	unsigned rewrites_found = 0;
 
 	if (!trace_io_move_fail_enabled())
@@ -187,7 +186,6 @@ static void trace_io_move_fail2(struct data_update *m,
 	}
 
 	trace_io_move_fail(c, buf.buf);
-	printbuf_exit(&buf);
 }
 
 noinline_for_stack
@@ -196,7 +194,7 @@ static void trace_data_update2(struct data_update *m,
 			       struct bkey_i *insert)
 {
 	struct bch_fs *c = m->op.c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_str(&buf, "\nold: ");
 	bch2_bkey_val_to_text(&buf, c, old);
@@ -206,7 +204,6 @@ static void trace_data_update2(struct data_update *m,
 	bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(insert));
 
 	trace_data_update(c, buf.buf);
-	printbuf_exit(&buf);
 }
 
 noinline_for_stack
@@ -215,7 +212,7 @@ static void trace_io_move_created_rebalance2(struct data_update *m,
 					     struct bkey_i *insert)
 {
 	struct bch_fs *c = m->op.c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_data_update_opts_to_text(&buf, c, &m->op.opts, &m->data_opts);
 
@@ -227,7 +224,6 @@ static void trace_io_move_created_rebalance2(struct data_update *m,
 	bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(insert));
 
 	trace_io_move_created_rebalance(c, buf.buf);
-	printbuf_exit(&buf);
 
 	this_cpu_inc(c->counters[BCH_COUNTER_io_move_created_rebalance]);
 }
@@ -238,7 +234,7 @@ static int data_update_invalid_bkey(struct data_update *m,
 				    struct bkey_i *insert)
 {
 	struct bch_fs *c = m->op.c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	prt_str(&buf, "about to insert invalid key in data update path");
@@ -254,7 +250,6 @@ static int data_update_invalid_bkey(struct data_update *m,
 	bch2_fs_emergency_read_only2(c, &buf);
 
 	bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 
 	return bch_err_throw(c, invalid_bkey);
 }
@@ -499,7 +494,8 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 
 int bch2_data_update_index_update(struct bch_write_op *op)
 {
-	return bch2_trans_run(op->c, __bch2_data_update_index_update(trans, op));
+	CLASS(btree_trans, trans)(op->c);
+	return __bch2_data_update_index_update(trans, op);
 }
 
 void bch2_data_update_read_done(struct data_update *m)
@@ -784,8 +780,8 @@ static int can_write_extent(struct bch_fs *c, struct data_update *m)
 		__clear_bit(*i, devs.d);
 
 	CLASS(printbuf, buf)();
-	buf.atomic++;
 
+	guard(printbuf_atomic)(&buf);
 	guard(rcu)();
 
 	unsigned nr_replicas = 0, i;
-- 
2.51.0


From 62ae1f589c5e42a74f19308500af07fa5fc485f3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:49:19 -0400
Subject: [PATCH 120/309] bcachefs: convert reflink.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/reflink.c | 59 +++++++++++++++++--------------------------
 1 file changed, 23 insertions(+), 36 deletions(-)

diff --git a/fs/bcachefs/reflink.c b/fs/bcachefs/reflink.c
index 8d8e045b6bd5..60abd89d7c9f 100644
--- a/fs/bcachefs/reflink.c
+++ b/fs/bcachefs/reflink.c
@@ -183,7 +183,7 @@ static int bch2_indirect_extent_missing_error(struct btree_trans *trans,
 	u64 live_end	= REFLINK_P_IDX(p.v) + p.k->size;
 	u64 refd_start	= live_start	- le32_to_cpu(p.v->front_pad);
 	u64 refd_end	= live_end	+ le32_to_cpu(p.v->back_pad);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	BUG_ON(missing_start	< refd_start);
@@ -195,7 +195,7 @@ static int bch2_indirect_extent_missing_error(struct btree_trans *trans,
 	prt_printf(&buf, "pointer to missing indirect extent in ");
 	ret = bch2_inum_snap_offset_err_msg_trans(trans, &buf, missing_pos);
 	if (ret)
-		goto err;
+		return ret;
 
 	prt_printf(&buf, "-%llu\n", (missing_pos.offset + (missing_end - missing_start)) << 9);
 	bch2_bkey_val_to_text(&buf, c, p.s_c);
@@ -207,7 +207,7 @@ static int bch2_indirect_extent_missing_error(struct btree_trans *trans,
 		struct bkey_i_reflink_p *new = bch2_bkey_make_mut_noupdate_typed(trans, p.s_c, reflink_p);
 		ret = PTR_ERR_OR_ZERO(new);
 		if (ret)
-			goto err;
+			return ret;
 
 		/*
 		 * Is the missing range not actually needed?
@@ -238,15 +238,13 @@ static int bch2_indirect_extent_missing_error(struct btree_trans *trans,
 
 		ret = bch2_btree_insert_trans(trans, BTREE_ID_extents, &new->k_i, BTREE_TRIGGER_norun);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (should_commit)
 			ret =   bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
 				bch_err_throw(c, transaction_restart_nested);
 	}
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -301,7 +299,7 @@ static int trans_trigger_reflink_p_segment(struct btree_trans *trans,
 			enum btree_iter_update_trigger_flags flags)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	s64 offset_into_extent = *idx - REFLINK_P_IDX(p.v);
 	struct btree_iter iter;
@@ -360,7 +358,6 @@ static int trans_trigger_reflink_p_segment(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -374,7 +371,7 @@ static s64 gc_trigger_reflink_p_segment(struct btree_trans *trans,
 	int add = !(flags & BTREE_TRIGGER_overwrite) ? 1 : -1;
 	u64 next_idx = REFLINK_P_IDX(p.v) + p.k->size + le32_to_cpu(p.v->back_pad);
 	s64 ret = 0;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	if (r_idx >= c->reflink_gc_nr)
 		goto not_found;
@@ -394,12 +391,10 @@ static s64 gc_trigger_reflink_p_segment(struct btree_trans *trans,
 	if (flags & BTREE_TRIGGER_check_repair) {
 		ret = bch2_indirect_extent_missing_error(trans, p, *idx, next_idx, false);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	*idx = next_idx;
-err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -498,20 +493,15 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 				     bool reflink_p_may_update_opts_field)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter reflink_iter = {};
-	struct bkey_s_c k;
-	struct bkey_i *r_v;
-	struct bkey_i_reflink_p *r_p;
-	__le64 *refcount;
-	int ret;
 
 	if (orig->k.type == KEY_TYPE_inline_data)
 		bch2_check_set_feature(c, BCH_FEATURE_reflink_inline_data);
 
+	struct btree_iter reflink_iter;
 	bch2_trans_iter_init(trans, &reflink_iter, BTREE_ID_reflink, POS_MAX,
 			     BTREE_ITER_intent);
-	k = bch2_btree_iter_peek_prev(trans, &reflink_iter);
-	ret = bkey_err(k);
+	struct bkey_s_c k = bch2_btree_iter_peek_prev(trans, &reflink_iter);
+	int ret = bkey_err(k);
 	if (ret)
 		goto err;
 
@@ -523,7 +513,7 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	if (bkey_ge(reflink_iter.pos, POS(0, REFLINK_P_IDX_MAX - orig->k.size)))
 		return -ENOSPC;
 
-	r_v = bch2_trans_kmalloc(trans, sizeof(__le64) + bkey_bytes(&orig->k));
+	struct bkey_i *r_v = bch2_trans_kmalloc(trans, sizeof(__le64) + bkey_bytes(&orig->k));
 	ret = PTR_ERR_OR_ZERO(r_v);
 	if (ret)
 		goto err;
@@ -536,7 +526,7 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 
 	set_bkey_val_bytes(&r_v->k, sizeof(__le64) + bkey_val_bytes(&orig->k));
 
-	refcount	= bkey_refcount(bkey_i_to_s(r_v));
+	__le64 *refcount = bkey_refcount(bkey_i_to_s(r_v));
 	*refcount	= 0;
 	memcpy(refcount + 1, &orig->v, bkey_val_bytes(&orig->k));
 
@@ -549,7 +539,8 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	 * so we know it will be big enough:
 	 */
 	orig->k.type = KEY_TYPE_reflink_p;
-	r_p = bkey_i_to_reflink_p(orig);
+
+	struct bkey_i_reflink_p *r_p = bkey_i_to_reflink_p(orig);
 	set_bkey_val_bytes(&r_p->k, sizeof(r_p->v));
 
 	/* FORTIFY_SOURCE is broken here, and doesn't provide unsafe_memset() */
@@ -598,7 +589,6 @@ s64 bch2_remap_range(struct bch_fs *c,
 		     u64 new_i_size, s64 *i_sectors_delta,
 		     bool may_change_src_io_path_opts)
 {
-	struct btree_trans *trans;
 	struct btree_iter dst_iter, src_iter;
 	struct bkey_s_c src_k;
 	struct bkey_buf new_dst, new_src;
@@ -623,7 +613,7 @@ s64 bch2_remap_range(struct bch_fs *c,
 
 	bch2_bkey_buf_init(&new_dst);
 	bch2_bkey_buf_init(&new_src);
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	ret = bch2_inum_opts_get(trans, src_inum, &opts);
 	if (ret)
@@ -761,7 +751,6 @@ s64 bch2_remap_range(struct bch_fs *c,
 		bch2_trans_iter_exit(trans, &inode_iter);
 	} while (bch2_err_matches(ret2, BCH_ERR_transaction_restart));
 err:
-	bch2_trans_put(trans);
 	bch2_bkey_buf_exit(&new_src, c);
 	bch2_bkey_buf_exit(&new_dst, c);
 
@@ -779,7 +768,7 @@ static int bch2_gc_write_reflink_key(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	const __le64 *refcount = bkey_refcount_c(k);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct reflink_gc *r;
 	int ret = 0;
 
@@ -807,7 +796,7 @@ static int bch2_gc_write_reflink_key(struct btree_trans *trans,
 		struct bkey_i *new = bch2_bkey_make_mut_noupdate(trans, k);
 		ret = PTR_ERR_OR_ZERO(new);
 		if (ret)
-			goto out;
+			return ret;
 
 		if (!r->refcount)
 			new->k.type = KEY_TYPE_deleted;
@@ -815,32 +804,30 @@ static int bch2_gc_write_reflink_key(struct btree_trans *trans,
 			*bkey_refcount(bkey_i_to_s(new)) = cpu_to_le64(r->refcount);
 		ret = bch2_trans_update(trans, iter, new, 0);
 	}
-out:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
 int bch2_gc_reflink_done(struct bch_fs *c)
 {
+	CLASS(btree_trans, trans)(c);
 	size_t idx = 0;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_reflink, POS_MIN,
 				BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_gc_write_reflink_key(trans, &iter, k, &idx)));
+			bch2_gc_write_reflink_key(trans, &iter, k, &idx));
 	c->reflink_gc_nr = 0;
 	return ret;
 }
 
 int bch2_gc_reflink_start(struct bch_fs *c)
 {
+	CLASS(btree_trans, trans)(c);
 	c->reflink_gc_nr = 0;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key(trans, iter, BTREE_ID_reflink, POS_MIN,
+	int ret = for_each_btree_key(trans, iter, BTREE_ID_reflink, POS_MIN,
 				   BTREE_ITER_prefetch, k, ({
 			const __le64 *refcount = bkey_refcount_c(k);
 
@@ -858,7 +845,7 @@ int bch2_gc_reflink_start(struct bch_fs *c)
 			r->size		= k.k->size;
 			r->refcount	= 0;
 			0;
-		})));
+		}));
 
 	bch_err_fn(c, ret);
 	return ret;
-- 
2.51.0


From 521afa1d74876cdbc500d92aa01e4823121d1149 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:50:35 -0400
Subject: [PATCH 121/309] bcachefs: convert snapshot.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/snapshot.c       | 91 ++++++++++++++++--------------------
 fs/bcachefs/snapshot_types.h |  2 +-
 2 files changed, 40 insertions(+), 53 deletions(-)

diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 4c43d2a2c1f5..398a1a8bceab 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -284,12 +284,10 @@ int bch2_snapshot_validate(struct bch_fs *c, struct bkey_s_c k,
 
 static int bch2_snapshot_table_make_room(struct bch_fs *c, u32 id)
 {
-	mutex_lock(&c->snapshot_table_lock);
-	int ret = snapshot_t_mut(c, id)
+	guard(mutex)(&c->snapshot_table_lock);
+	return snapshot_t_mut(c, id)
 		? 0
 		: bch_err_throw(c, ENOMEM_mark_snapshot);
-	mutex_unlock(&c->snapshot_table_lock);
-	return ret;
 }
 
 static int __bch2_mark_snapshot(struct btree_trans *trans,
@@ -300,15 +298,12 @@ static int __bch2_mark_snapshot(struct btree_trans *trans,
 	struct bch_fs *c = trans->c;
 	struct snapshot_t *t;
 	u32 id = new.k->p.offset;
-	int ret = 0;
 
-	mutex_lock(&c->snapshot_table_lock);
+	guard(mutex)(&c->snapshot_table_lock);
 
 	t = snapshot_t_mut(c, id);
-	if (!t) {
-		ret = bch_err_throw(c, ENOMEM_mark_snapshot);
-		goto err;
-	}
+	if (!t)
+		return bch_err_throw(c, ENOMEM_mark_snapshot);
 
 	if (new.k->type == KEY_TYPE_snapshot) {
 		struct bkey_s_c_snapshot s = bkey_s_c_to_snapshot(new);
@@ -348,9 +343,8 @@ static int __bch2_mark_snapshot(struct btree_trans *trans,
 	} else {
 		memset(t, 0, sizeof(*t));
 	}
-err:
-	mutex_unlock(&c->snapshot_table_lock);
-	return ret;
+
+	return 0;
 }
 
 int bch2_mark_snapshot(struct btree_trans *trans,
@@ -481,7 +475,7 @@ static int check_snapshot_tree(struct btree_trans *trans,
 	struct bkey_s_c_snapshot_tree st;
 	struct bch_snapshot s;
 	struct bch_subvolume subvol;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct btree_iter snapshot_iter = {};
 	u32 root_id;
 	int ret;
@@ -567,7 +561,6 @@ static int check_snapshot_tree(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &snapshot_iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -580,12 +573,12 @@ static int check_snapshot_tree(struct btree_trans *trans,
  */
 int bch2_check_snapshot_trees(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 			BTREE_ID_snapshot_trees, POS_MIN,
 			BTREE_ITER_prefetch, k,
 			NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-		check_snapshot_tree(trans, &iter, k)));
+		check_snapshot_tree(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -706,7 +699,7 @@ static int check_snapshot(struct btree_trans *trans,
 	struct bkey_i_snapshot *u;
 	u32 parent_id = bch2_snapshot_parent_early(c, k.k->p.offset);
 	u32 real_depth;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	u32 i, id;
 	int ret = 0;
 
@@ -839,7 +832,6 @@ static int check_snapshot(struct btree_trans *trans,
 	ret = 0;
 err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -849,12 +841,12 @@ int bch2_check_snapshots(struct bch_fs *c)
 	 * We iterate backwards as checking/fixing the depth field requires that
 	 * the parent's depth already be correct:
 	 */
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_reverse_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_reverse_commit(trans, iter,
 				BTREE_ID_snapshots, POS_MAX,
 				BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_snapshot(trans, &iter, k)));
+			check_snapshot(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -980,8 +972,8 @@ static int get_snapshot_trees(struct bch_fs *c, struct snapshot_tree_reconstruct
 
 int bch2_reconstruct_snapshots(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct printbuf buf = PRINTBUF;
+	CLASS(btree_trans, trans)(c);
+	CLASS(printbuf, buf)();
 	struct snapshot_tree_reconstruct r = {};
 	int ret = 0;
 
@@ -1023,9 +1015,7 @@ int bch2_reconstruct_snapshots(struct bch_fs *c)
 	}
 fsck_err:
 err:
-	bch2_trans_put(trans);
 	snapshot_tree_reconstruct_exit(&r);
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1035,7 +1025,7 @@ int __bch2_check_key_has_snapshot(struct btree_trans *trans,
 				  struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 	enum snapshot_id_state state = bch2_snapshot_id_state(c, k.k->p.snapshot);
 
@@ -1083,7 +1073,6 @@ int __bch2_check_key_has_snapshot(struct btree_trans *trans,
 		}
 	}
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1693,7 +1682,7 @@ static int check_should_delete_snapshot(struct btree_trans *trans, struct bkey_s
 	if (BCH_SNAPSHOT_DELETED(s.v))
 		return 0;
 
-	mutex_lock(&d->progress_lock);
+	guard(mutex)(&d->progress_lock);
 	for (unsigned i = 0; i < 2; i++) {
 		u32 child = le32_to_cpu(s.v->children[i]);
 
@@ -1720,7 +1709,6 @@ static int check_should_delete_snapshot(struct btree_trans *trans, struct bkey_s
 				darray_push(&d->delete_interior, n);
 		}
 	}
-	mutex_unlock(&d->progress_lock);
 
 	return ret;
 }
@@ -1825,10 +1813,12 @@ int __bch2_delete_dead_snapshots(struct bch_fs *c)
 	if (!mutex_trylock(&d->lock))
 		return 0;
 
-	if (!test_and_clear_bit(BCH_FS_need_delete_dead_snapshots, &c->flags))
-		goto out_unlock;
+	if (!test_and_clear_bit(BCH_FS_need_delete_dead_snapshots, &c->flags)) {
+		mutex_unlock(&d->lock);
+		return 0;
+	}
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	/*
 	 * For every snapshot node: If we have no live children and it's not
@@ -1848,11 +1838,10 @@ int __bch2_delete_dead_snapshots(struct bch_fs *c)
 		goto err;
 
 	{
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_snapshot_delete_nodes_to_text(&buf, d);
 
 		ret = commit_do(trans, NULL, NULL, 0, bch2_trans_log_msg(trans, &buf));
-		printbuf_exit(&buf);
 		if (ret)
 			goto err;
 	}
@@ -1895,16 +1884,15 @@ int __bch2_delete_dead_snapshots(struct bch_fs *c)
 			goto err;
 	}
 err:
-	mutex_lock(&d->progress_lock);
-	darray_exit(&d->deleting_from_trees);
-	darray_exit(&d->delete_interior);
-	darray_exit(&d->delete_leaves);
-	d->running = false;
-	mutex_unlock(&d->progress_lock);
-	bch2_trans_put(trans);
+	scoped_guard(mutex, &d->progress_lock) {
+		darray_exit(&d->deleting_from_trees);
+		darray_exit(&d->delete_interior);
+		darray_exit(&d->delete_leaves);
+		d->running = false;
+	}
 
 	bch2_recovery_pass_set_no_ratelimit(c, BCH_RECOVERY_PASS_check_snapshots);
-out_unlock:
+
 	mutex_unlock(&d->lock);
 	if (!bch2_err_matches(ret, EROFS))
 		bch_err_fn(c, ret);
@@ -1952,11 +1940,10 @@ void bch2_snapshot_delete_status_to_text(struct printbuf *out, struct bch_fs *c)
 		return;
 	}
 
-	mutex_lock(&d->progress_lock);
-	bch2_snapshot_delete_nodes_to_text(out, d);
-
-	bch2_bbpos_to_text(out, d->pos);
-	mutex_unlock(&d->progress_lock);
+	scoped_guard(mutex, &d->progress_lock) {
+		bch2_snapshot_delete_nodes_to_text(out, d);
+		bch2_bbpos_to_text(out, d->pos);
+	}
 }
 
 int __bch2_key_has_snapshot_overwrites(struct btree_trans *trans,
@@ -2010,11 +1997,11 @@ int bch2_snapshots_read(struct bch_fs *c)
 	 * Initializing the is_ancestor bitmaps requires ancestors to already be
 	 * initialized - so mark in reverse:
 	 */
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_reverse(trans, iter, BTREE_ID_snapshots,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_reverse(trans, iter, BTREE_ID_snapshots,
 				   POS_MAX, 0, k,
 			__bch2_mark_snapshot(trans, BTREE_ID_snapshots, 0, bkey_s_c_null, k, 0) ?:
-			bch2_check_snapshot_needs_deletion(trans, k)));
+			bch2_check_snapshot_needs_deletion(trans, k));
 	bch_err_fn(c, ret);
 
 	/*
diff --git a/fs/bcachefs/snapshot_types.h b/fs/bcachefs/snapshot_types.h
index 0ab698f13e5c..a826c9c83c11 100644
--- a/fs/bcachefs/snapshot_types.h
+++ b/fs/bcachefs/snapshot_types.h
@@ -6,7 +6,7 @@
 #include "darray.h"
 #include "subvolume_types.h"
 
-typedef DARRAY(u32) snapshot_id_list;
+DEFINE_DARRAY_NAMED(snapshot_id_list, u32);
 
 #define IS_ANCESTOR_BITMAP	128
 
-- 
2.51.0


From d714e058e51bd3f8d947e6fe8e3ed183cbdc3bb7 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:54:54 -0400
Subject: [PATCH 122/309] bcachefs: convert subvolume.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/subvolume.c | 47 ++++++++++++++++++++++-------------------
 1 file changed, 25 insertions(+), 22 deletions(-)

diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index ccd2ba1f7930..dbd6bbfd972f 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -17,7 +17,7 @@ static int bch2_subvolume_delete(struct btree_trans *, u32);
 
 static int bch2_subvolume_missing(struct bch_fs *c, u32 subvolid)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	prt_printf(&buf, "missing subvolume %u", subvolid);
@@ -27,7 +27,6 @@ static int bch2_subvolume_missing(struct bch_fs *c, u32 subvolid)
 					BCH_RECOVERY_PASS_check_inodes, 0);
 	if (print)
 		bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -50,7 +49,7 @@ static int check_subvol(struct btree_trans *trans,
 	struct btree_iter subvol_children_iter = {};
 	struct bch_subvolume subvol;
 	struct bch_snapshot snapshot;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	unsigned snapid;
 	int ret = 0;
 
@@ -178,17 +177,16 @@ static int check_subvol(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &subvol_children_iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
 int bch2_check_subvols(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolumes, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_subvol(trans, &iter, k)));
+			check_subvol(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -219,11 +217,11 @@ static int check_subvol_child(struct btree_trans *trans,
 
 int bch2_check_subvol_children(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolume_children, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_subvol_child(trans, &iter, k)));
+			check_subvol_child(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return 0;
 }
@@ -348,7 +346,8 @@ int bch2_subvol_is_ro_trans(struct btree_trans *trans, u32 subvol)
 
 int bch2_subvol_is_ro(struct bch_fs *c, u32 subvol)
 {
-	return bch2_trans_do(c, bch2_subvol_is_ro_trans(trans, subvol));
+	CLASS(btree_trans, trans)(c);
+	return lockrestart_do(trans, bch2_subvol_is_ro_trans(trans, subvol));
 }
 
 int bch2_snapshot_get_subvol(struct btree_trans *trans, u32 snapshot,
@@ -514,18 +513,22 @@ static void bch2_subvolume_wait_for_pagecache_and_delete(struct work_struct *wor
 	int ret = 0;
 
 	while (!ret) {
-		mutex_lock(&c->snapshots_unlinked_lock);
-		snapshot_id_list s = c->snapshots_unlinked;
-		darray_init(&c->snapshots_unlinked);
-		mutex_unlock(&c->snapshots_unlinked_lock);
+		snapshot_id_list s;
+
+		scoped_guard(mutex, &c->snapshots_unlinked_lock) {
+			s = c->snapshots_unlinked;
+			darray_init(&c->snapshots_unlinked);
+		}
 
 		if (!s.nr)
 			break;
 
 		bch2_evict_subvolume_inodes(c, &s);
 
+		CLASS(btree_trans, trans)(c);
+
 		darray_for_each(s, id) {
-			ret = bch2_trans_run(c, bch2_subvolume_delete(trans, *id));
+			ret = bch2_subvolume_delete(trans, *id);
 			bch_err_msg(c, ret, "deleting subvolume %u", *id);
 			if (ret)
 				break;
@@ -549,10 +552,9 @@ static int bch2_subvolume_wait_for_pagecache_and_delete_hook(struct btree_trans
 	struct bch_fs *c = trans->c;
 	int ret = 0;
 
-	mutex_lock(&c->snapshots_unlinked_lock);
-	if (!snapshot_list_has_id(&c->snapshots_unlinked, h->subvol))
-		ret = snapshot_list_add(c, &c->snapshots_unlinked, h->subvol);
-	mutex_unlock(&c->snapshots_unlinked_lock);
+	scoped_guard(mutex, &c->snapshots_unlinked_lock)
+		if (!snapshot_list_has_id(&c->snapshots_unlinked, h->subvol))
+			ret = snapshot_list_add(c, &c->snapshots_unlinked, h->subvol);
 
 	if (ret)
 		return ret;
@@ -739,8 +741,9 @@ static int __bch2_fs_upgrade_for_subvolumes(struct btree_trans *trans)
 /* set bi_subvol on root inode */
 int bch2_fs_upgrade_for_subvolumes(struct bch_fs *c)
 {
-	int ret = bch2_trans_commit_do(c, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-				       __bch2_fs_upgrade_for_subvolumes(trans));
+	CLASS(btree_trans, trans)(c);
+	int ret = commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
+			    __bch2_fs_upgrade_for_subvolumes(trans));
 	bch_err_fn(c, ret);
 	return ret;
 }
-- 
2.51.0


From a23365a89646389d3be62bd607167579a59632ca Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:55:28 -0400
Subject: [PATCH 123/309] bcachefs: convert str_hash.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/str_hash.c | 17 ++++++-----------
 1 file changed, 6 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/str_hash.c b/fs/bcachefs/str_hash.c
index d39fd4261e1b..3e08e55d2dc1 100644
--- a/fs/bcachefs/str_hash.c
+++ b/fs/bcachefs/str_hash.c
@@ -125,7 +125,7 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 	struct bch_fs *c = trans->c;
 	struct btree_iter iter;
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool need_commit = false;
 	int ret = 0;
 
@@ -183,7 +183,7 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 		goto err;
 
 	if (!need_commit) {
-		struct printbuf buf = PRINTBUF;
+		printbuf_reset(&buf);
 		bch2_log_msg_start(c, &buf);
 
 		prt_printf(&buf, "inode %llu hash info mismatch with root, but mismatch not found\n",
@@ -198,7 +198,6 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 		prt_printf(&buf, " %llx %llx", hash_info->siphash_key.k0, hash_info->siphash_key.k1);
 #endif
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 		ret = bch_err_throw(c, fsck_repair_unimplemented);
 		goto err;
 	}
@@ -207,7 +206,6 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 		bch_err_throw(c, transaction_restart_nested);
 err:
 fsck_err:
-	printbuf_exit(&buf);
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
 }
@@ -244,7 +242,7 @@ int bch2_str_hash_repair_key(struct btree_trans *trans,
 			     bool *updated_before_k_pos)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool free_snapshots_seen = false;
 	int ret = 0;
 
@@ -331,7 +329,6 @@ int bch2_str_hash_repair_key(struct btree_trans *trans,
 out:
 fsck_err:
 	bch2_trans_iter_exit(trans, dup_iter);
-	printbuf_exit(&buf);
 	if (free_snapshots_seen)
 		darray_exit(&s->ids);
 	return ret;
@@ -346,7 +343,7 @@ int __bch2_str_hash_check_key(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter iter = {};
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct bkey_s_c k;
 	int ret = 0;
 
@@ -375,9 +372,7 @@ int __bch2_str_hash_check_key(struct btree_trans *trans,
 			goto bad_hash;
 	}
 	bch2_trans_iter_exit(trans, &iter);
-out:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 bad_hash:
 	bch2_trans_iter_exit(trans, &iter);
@@ -386,7 +381,7 @@ int __bch2_str_hash_check_key(struct btree_trans *trans,
 	 */
 	ret = check_inode_hash_info_matches_root(trans, hash_k.k->p.inode, hash_info);
 	if (ret)
-		goto out;
+		return ret;
 
 	if (fsck_err(trans, hash_table_key_wrong_offset,
 		     "hash table key at wrong offset: should be at %llu\n%s",
@@ -396,5 +391,5 @@ int __bch2_str_hash_check_key(struct btree_trans *trans,
 					       k_iter, hash_k,
 					       &iter, bkey_s_c_null,
 					       updated_before_k_pos);
-	goto out;
+	return ret;
 }
-- 
2.51.0


From 09d09e4fefbe98f1e9a9263e568501df80c1ae46 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:02:08 -0400
Subject: [PATCH 124/309] bcachefs: convert recovery_passes.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery_passes.c | 24 +++++++++---------------
 1 file changed, 9 insertions(+), 15 deletions(-)

diff --git a/fs/bcachefs/recovery_passes.c b/fs/bcachefs/recovery_passes.c
index 6a039e011064..a89508a87def 100644
--- a/fs/bcachefs/recovery_passes.c
+++ b/fs/bcachefs/recovery_passes.c
@@ -237,8 +237,9 @@ static int bch2_lookup_root_inode(struct bch_fs *c)
 	subvol_inum inum = BCACHEFS_ROOT_SUBVOL_INUM;
 	struct bch_inode_unpacked inode_u;
 	struct bch_subvolume subvol;
+	CLASS(btree_trans, trans)(c);
 
-	return bch2_trans_do(c,
+	return lockrestart_do(trans,
 		bch2_subvolume_get(trans, inum.subvol, true, &subvol) ?:
 		bch2_inode_find_by_inum_trans(trans, inum, &inode_u));
 }
@@ -346,13 +347,11 @@ int __bch2_run_explicit_recovery_pass(struct bch_fs *c,
 	lockdep_assert_held(&c->sb_lock);
 
 	bch2_printbuf_make_room(out, 1024);
-	out->atomic++;
-
-	unsigned long lockflags;
-	spin_lock_irqsave(&r->lock, lockflags);
+	guard(printbuf_atomic)(out);
+	guard(spinlock_irq)(&r->lock);
 
 	if (!recovery_pass_needs_set(c, pass, &flags))
-		goto out;
+		return 0;
 
 	bool in_recovery = test_bit(BCH_FS_in_recovery, &c->flags);
 	bool rewind = in_recovery &&
@@ -369,8 +368,7 @@ int __bch2_run_explicit_recovery_pass(struct bch_fs *c,
 	    (!in_recovery || r->curr_pass >= BCH_RECOVERY_PASS_set_may_go_rw)) {
 		prt_printf(out, "need recovery pass %s (%u), but already rw\n",
 			   bch2_recovery_passes[pass], pass);
-		ret = bch_err_throw(c, cannot_rewind_recovery);
-		goto out;
+		return bch_err_throw(c, cannot_rewind_recovery);
 	}
 
 	if (ratelimit)
@@ -400,9 +398,7 @@ int __bch2_run_explicit_recovery_pass(struct bch_fs *c,
 		if (p->when & PASS_ONLINE)
 			bch2_run_async_recovery_passes(c);
 	}
-out:
-	spin_unlock_irqrestore(&r->lock, lockflags);
-	--out->atomic;
+
 	return ret;
 }
 
@@ -458,16 +454,14 @@ int bch2_run_print_explicit_recovery_pass(struct bch_fs *c, enum bch_recovery_pa
 	if (!recovery_pass_needs_set(c, pass, &flags))
 		return 0;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	int ret = __bch2_run_explicit_recovery_pass(c, &buf, pass,
 						RUN_RECOVERY_PASS_nopersistent);
-	mutex_unlock(&c->sb_lock);
 
 	bch2_print_str(c, KERN_NOTICE, buf.buf);
-	printbuf_exit(&buf);
 	return ret;
 }
 
-- 
2.51.0


From e9a50fb16e0457883d0c7159fefb5b3714348dee Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:29:40 -0400
Subject: [PATCH 125/309] bcachefs: convert recovery.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c | 113 ++++++++++++++++-------------------------
 1 file changed, 43 insertions(+), 70 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index f82e9fb8f7bd..a8eea4787a3e 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -40,7 +40,7 @@ int bch2_btree_lost_data(struct bch_fs *c,
 	u64 b = BIT_ULL(btree);
 	int ret = 0;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
 
 	if (!(c->sb.btrees_lost_data & b)) {
@@ -109,8 +109,6 @@ int bch2_btree_lost_data(struct bch_fs *c,
 	}
 out:
 	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
-
 	return ret;
 }
 
@@ -123,7 +121,7 @@ static void kill_btree(struct bch_fs *c, enum btree_id btree)
 /* for -o reconstruct_alloc: */
 void bch2_reconstruct_alloc(struct bch_fs *c)
 {
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
 
 	__set_bit_le64(BCH_RECOVERY_PASS_STABLE_check_allocations, ext->recovery_passes_required);
@@ -167,7 +165,6 @@ void bch2_reconstruct_alloc(struct bch_fs *c)
 	c->disk_sb.sb->features[0] &= ~cpu_to_le64(BIT_ULL(BCH_FEATURE_no_alloc_info));
 
 	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
 
 	for (unsigned i = 0; i < btree_id_nr_alive(c); i++)
 		if (btree_id_is_alloc(i))
@@ -339,14 +336,15 @@ static int journal_sort_seq_cmp(const void *_l, const void *_r)
 	return cmp_int(l->journal_seq - 1, r->journal_seq - 1);
 }
 
+DEFINE_DARRAY_NAMED(darray_journal_keys, struct journal_key *)
+
 int bch2_journal_replay(struct bch_fs *c)
 {
 	struct journal_keys *keys = &c->journal_keys;
-	DARRAY(struct journal_key *) keys_sorted = { 0 };
+	CLASS(darray_journal_keys, keys_sorted)();
 	struct journal *j = &c->journal;
 	u64 start_seq	= c->journal_replay_seq_start;
 	u64 end_seq	= c->journal_replay_seq_start;
-	struct btree_trans *trans = NULL;
 	bool immediate_flush = false;
 	int ret = 0;
 
@@ -354,13 +352,13 @@ int bch2_journal_replay(struct bch_fs *c)
 		ret = bch2_journal_log_msg(c, "Starting journal replay (%zu keys in entries %llu-%llu)",
 					   keys->nr, start_seq, end_seq);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	BUG_ON(!atomic_read(&keys->ref));
 
 	move_gap(keys, keys->nr);
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	/*
 	 * Replay accounting keys first: we can't allow the write buffer to
@@ -380,7 +378,7 @@ int bch2_journal_replay(struct bch_fs *c)
 				BCH_WATERMARK_reclaim,
 			     bch2_journal_replay_accounting_key(trans, k));
 		if (bch2_fs_fatal_err_on(ret, c, "error replaying accounting; %s", bch2_err_str(ret)))
-			goto err;
+			return ret;
 
 		k->overwritten = true;
 	}
@@ -414,7 +412,7 @@ int bch2_journal_replay(struct bch_fs *c)
 		if (ret) {
 			ret = darray_push(&keys_sorted, k);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	}
 
@@ -445,22 +443,16 @@ int bch2_journal_replay(struct bch_fs *c)
 				 : 0),
 			     bch2_journal_replay_key(trans, k));
 		if (ret) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			bch2_btree_id_level_to_text(&buf, k->btree_id, k->level);
 			bch_err_msg(c, ret, "while replaying key at %s:", buf.buf);
-			printbuf_exit(&buf);
-			goto err;
+			return ret;
 		}
 
 		BUG_ON(k->btree_id != BTREE_ID_accounting && !k->overwritten);
 	}
 
-	/*
-	 * We need to put our btree_trans before calling flush_all_pins(), since
-	 * that will use a btree_trans internally
-	 */
-	bch2_trans_put(trans);
-	trans = NULL;
+	bch2_trans_unlock_long(trans);
 
 	if (!c->opts.retain_recovery_info &&
 	    c->recovery.pass_done >= BCH_RECOVERY_PASS_journal_replay)
@@ -479,12 +471,7 @@ int bch2_journal_replay(struct bch_fs *c)
 
 	if (keys->nr)
 		bch2_journal_log_msg(c, "journal replay finished");
-err:
-	if (trans)
-		bch2_trans_put(trans);
-	darray_exit(&keys_sorted);
-	bch_err_fn(c, ret);
-	return ret;
+	return 0;
 }
 
 /* journal replay early: */
@@ -596,7 +583,7 @@ static int journal_replay_early(struct bch_fs *c,
 
 static int read_btree_roots(struct bch_fs *c)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	for (unsigned i = 0; i < btree_id_nr_alive(c); i++) {
@@ -632,7 +619,6 @@ static int read_btree_roots(struct bch_fs *c)
 		}
 	}
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -666,7 +652,7 @@ static bool check_version_upgrade(struct bch_fs *c)
 	}
 
 	if (new_version > old_version) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		if (old_version < bcachefs_metadata_required_upgrade_below)
 			prt_str(&buf, "Version upgrade required:\n");
@@ -699,14 +685,12 @@ static bool check_version_upgrade(struct bch_fs *c)
 		}
 
 		bch_notice(c, "%s", buf.buf);
-		printbuf_exit(&buf);
-
 		ret = true;
 	}
 
 	if (new_version > c->sb.version_incompat_allowed &&
 	    c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_str(&buf, "Now allowing incompatible features up to ");
 		bch2_version_to_text(&buf, new_version);
@@ -715,8 +699,6 @@ static bool check_version_upgrade(struct bch_fs *c)
 		prt_newline(&buf);
 
 		bch_notice(c, "%s", buf.buf);
-		printbuf_exit(&buf);
-
 		ret = true;
 	}
 
@@ -796,15 +778,14 @@ int bch2_fs_recovery(struct bch_fs *c)
 
 	u64 sb_passes = bch2_recovery_passes_from_stable(le64_to_cpu(ext->recovery_passes_required[0]));
 	if (sb_passes) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		prt_str(&buf, "superblock requires following recovery passes to be run:\n  ");
 		prt_bitflags(&buf, bch2_recovery_passes, sb_passes);
 		bch_info(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	if (bch2_check_version_downgrade(c)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_str(&buf, "Version downgrade required:");
 
@@ -820,7 +801,6 @@ int bch2_fs_recovery(struct bch_fs *c)
 		}
 
 		bch_info(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 		write_sb = true;
 	}
 
@@ -937,11 +917,10 @@ int bch2_fs_recovery(struct bch_fs *c)
 	if (ret)
 		goto err;
 
-	ret = bch2_fs_resize_on_mount(c);
-	if (ret) {
-		up_write(&c->state_lock);
+	scoped_guard(rwsem_write, &c->state_lock)
+		ret = bch2_fs_resize_on_mount(c);
+	if (ret)
 		goto err;
-	}
 
 	if (c->sb.features & BIT_ULL(BCH_FEATURE_small_image)) {
 		bch_info(c, "filesystem is an unresized image file, mounting ro");
@@ -1119,10 +1098,9 @@ int bch2_fs_recovery(struct bch_fs *c)
 
 		bch2_move_stats_init(&stats, "recovery");
 
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_version_to_text(&buf, c->sb.version_min);
 		bch_info(c, "scanning for old btree nodes: min_version %s", buf.buf);
-		printbuf_exit(&buf);
 
 		ret =   bch2_fs_read_write_early(c) ?:
 			bch2_scan_old_btree_nodes(c, &stats);
@@ -1150,14 +1128,13 @@ int bch2_fs_recovery(struct bch_fs *c)
 err:
 fsck_err:
 	{
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 
 		prt_printf(&buf, "error in recovery: %s\n", bch2_err_str(ret));
 		bch2_fs_emergency_read_only2(c, &buf);
 
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
 	goto final_out;
 }
@@ -1167,33 +1144,30 @@ int bch2_fs_initialize(struct bch_fs *c)
 	struct bch_inode_unpacked root_inode, lostfound_inode;
 	struct bkey_inode_buf packed_inode;
 	struct qstr lostfound = QSTR("lost+found");
-	struct bch_member *m;
 	int ret;
 
 	bch_notice(c, "initializing new filesystem");
 	set_bit(BCH_FS_new_fs, &c->flags);
 
-	mutex_lock(&c->sb_lock);
-	c->disk_sb.sb->compat[0] |= cpu_to_le64(1ULL << BCH_COMPAT_extents_above_btree_updates_done);
-	c->disk_sb.sb->compat[0] |= cpu_to_le64(1ULL << BCH_COMPAT_bformat_overflow_done);
-
-	bch2_check_version_downgrade(c);
+	scoped_guard(mutex, &c->sb_lock) {
+		c->disk_sb.sb->compat[0] |= cpu_to_le64(1ULL << BCH_COMPAT_extents_above_btree_updates_done);
+		c->disk_sb.sb->compat[0] |= cpu_to_le64(1ULL << BCH_COMPAT_bformat_overflow_done);
 
-	if (c->opts.version_upgrade != BCH_VERSION_UPGRADE_none) {
-		bch2_sb_upgrade(c, bcachefs_metadata_version_current, false);
-		SET_BCH_SB_VERSION_UPGRADE_COMPLETE(c->disk_sb.sb, bcachefs_metadata_version_current);
-		bch2_write_super(c);
-	}
+		bch2_check_version_downgrade(c);
 
-	for_each_member_device(c, ca) {
-		m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
-		SET_BCH_MEMBER_FREESPACE_INITIALIZED(m, false);
-	}
+		if (c->opts.version_upgrade != BCH_VERSION_UPGRADE_none) {
+			bch2_sb_upgrade(c, bcachefs_metadata_version_current, false);
+			SET_BCH_SB_VERSION_UPGRADE_COMPLETE(c->disk_sb.sb, bcachefs_metadata_version_current);
+			bch2_write_super(c);
+		}
 
-	bch2_sb_members_to_cpu(c);
+		for_each_member_device(c, ca) {
+			struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
+			SET_BCH_MEMBER_FREESPACE_INITIALIZED(m, false);
+		}
 
-	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+		bch2_write_super(c);
+	}
 
 	set_bit(BCH_FS_btree_running, &c->flags);
 
@@ -1293,12 +1267,11 @@ int bch2_fs_initialize(struct bch_fs *c)
 	if (ret)
 		goto err;
 
-	mutex_lock(&c->sb_lock);
-	SET_BCH_SB_INITIALIZED(c->disk_sb.sb, true);
-	SET_BCH_SB_CLEAN(c->disk_sb.sb, false);
-
-	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock) {
+		SET_BCH_SB_INITIALIZED(c->disk_sb.sb, true);
+		SET_BCH_SB_CLEAN(c->disk_sb.sb, false);
+		bch2_write_super(c);
+	}
 
 	c->recovery.curr_pass = BCH_RECOVERY_PASS_NR;
 	return 0;
-- 
2.51.0


From 1244d52f05ff9711b1e2dfc9e221bf990e598e39 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:20:49 -0400
Subject: [PATCH 126/309] bcachefs: convert lru.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/lru.c | 15 ++++++---------
 1 file changed, 6 insertions(+), 9 deletions(-)

diff --git a/fs/bcachefs/lru.c b/fs/bcachefs/lru.c
index 57b5b3263b08..c2c593356f41 100644
--- a/fs/bcachefs/lru.c
+++ b/fs/bcachefs/lru.c
@@ -86,7 +86,7 @@ int bch2_lru_check_set(struct btree_trans *trans,
 		       struct bkey_buf *last_flushed)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct btree_iter lru_iter;
 	struct bkey_s_c lru_k =
 		bch2_bkey_get_iter(trans, &lru_iter, BTREE_ID_lru,
@@ -112,7 +112,6 @@ int bch2_lru_check_set(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &lru_iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -166,8 +165,8 @@ static int bch2_check_lru_key(struct btree_trans *trans,
 			      struct bkey_buf *last_flushed)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf1 = PRINTBUF;
-	struct printbuf buf2 = PRINTBUF;
+	CLASS(printbuf, buf1)();
+	CLASS(printbuf, buf2)();
 
 	struct bbpos bp = lru_pos_to_bp(lru_k);
 
@@ -198,8 +197,6 @@ static int bch2_check_lru_key(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &iter);
-	printbuf_exit(&buf2);
-	printbuf_exit(&buf1);
 	return ret;
 }
 
@@ -210,11 +207,11 @@ int bch2_check_lrus(struct bch_fs *c)
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_lru, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_check_lru_key(trans, &iter, k, &last_flushed)));
+			bch2_check_lru_key(trans, &iter, k, &last_flushed));
 
 	bch2_bkey_buf_exit(&last_flushed, c);
 	bch_err_fn(c, ret);
-- 
2.51.0


From 5c89e4c5dd445ca144a4a338894c42ea80191960 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:22:10 -0400
Subject: [PATCH 127/309] bcachefs: convert extents.c to guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/extents.c | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/extents.c b/fs/bcachefs/extents.c
index a286bd994101..b36ecfc0ab9d 100644
--- a/fs/bcachefs/extents.c
+++ b/fs/bcachefs/extents.c
@@ -63,15 +63,14 @@ void bch2_io_failures_to_text(struct printbuf *out,
 			((!!f->failed_ec)		<< 3);
 
 		bch2_printbuf_make_room(out, 1024);
-		out->atomic++;
 		scoped_guard(rcu) {
+			guard(printbuf_atomic)(out);
 			struct bch_dev *ca = bch2_dev_rcu_noerror(c, f->dev);
 			if (ca)
 				prt_str(out, ca->name);
 			else
 				prt_printf(out, "(invalid device %u)", f->dev);
 		}
-		--out->atomic;
 
 		prt_char(out, ' ');
 
@@ -1237,7 +1236,7 @@ bool bch2_extent_normalize_by_opts(struct bch_fs *c,
 
 void bch2_extent_ptr_to_text(struct printbuf *out, struct bch_fs *c, const struct bch_extent_ptr *ptr)
 {
-	out->atomic++;
+	guard(printbuf_atomic)(out);
 	guard(rcu)();
 	struct bch_dev *ca = bch2_dev_rcu_noerror(c, ptr->dev);
 	if (!ca) {
@@ -1262,7 +1261,6 @@ void bch2_extent_ptr_to_text(struct printbuf *out, struct bch_fs *c, const struc
 		else if (stale)
 			prt_printf(out, " invalid");
 	}
-	--out->atomic;
 }
 
 void bch2_extent_crc_unpacked_to_text(struct printbuf *out, struct bch_extent_crc_unpacked *crc)
-- 
2.51.0


From 24211908df4c512fd55a83471e9d99580d322156 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:22:41 -0400
Subject: [PATCH 128/309] bcachefs: convert logged_ops.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/logged_ops.c | 12 +++++-------
 1 file changed, 5 insertions(+), 7 deletions(-)

diff --git a/fs/bcachefs/logged_ops.c b/fs/bcachefs/logged_ops.c
index 75f27ec26f85..3964f92a26b0 100644
--- a/fs/bcachefs/logged_ops.c
+++ b/fs/bcachefs/logged_ops.c
@@ -35,7 +35,7 @@ static int resume_logged_op(struct btree_trans *trans, struct btree_iter *iter,
 {
 	struct bch_fs *c = trans->c;
 	u32 restart_count = trans->restart_count;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	fsck_err_on(test_bit(BCH_FS_clean_recovery, &c->flags),
@@ -56,19 +56,18 @@ static int resume_logged_op(struct btree_trans *trans, struct btree_iter *iter,
 
 	bch2_bkey_buf_exit(&sk, c);
 fsck_err:
-	printbuf_exit(&buf);
 	return ret ?: trans_was_restarted(trans, restart_count);
 }
 
 int bch2_resume_logged_ops(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_max(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_max(trans, iter,
 				   BTREE_ID_logged_ops,
 				   POS(LOGGED_OPS_INUM_logged_ops, 0),
 				   POS(LOGGED_OPS_INUM_logged_ops, U64_MAX),
 				   BTREE_ITER_prefetch, k,
-			resume_logged_op(trans, &iter, k)));
+			resume_logged_op(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -107,12 +106,11 @@ int bch2_logged_op_finish(struct btree_trans *trans, struct bkey_i *k)
 	 */
 	if (ret) {
 		struct bch_fs *c = trans->c;
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(k));
 		bch2_fs_fatal_error(c, "deleting logged operation %s: %s",
 				    buf.buf, bch2_err_str(ret));
-		printbuf_exit(&buf);
 	}
 
 	return ret;
-- 
2.51.0


From 567ab92254d4aa43c66659e4c0968f9645673330 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:23:47 -0400
Subject: [PATCH 129/309] bcachefs: convert inode.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/inode.c | 22 +++++++++-------------
 1 file changed, 9 insertions(+), 13 deletions(-)

diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 307fb0c95656..fd4a20ce06ff 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -417,7 +417,8 @@ int bch2_inode_find_by_inum_trans(struct btree_trans *trans,
 int bch2_inode_find_by_inum(struct bch_fs *c, subvol_inum inum,
 			    struct bch_inode_unpacked *inode)
 {
-	return bch2_trans_do(c, bch2_inode_find_by_inum_trans(trans, inum, inode));
+	CLASS(btree_trans, trans)(c);
+	return lockrestart_do(trans, bch2_inode_find_by_inum_trans(trans, inum, inode));
 }
 
 int bch2_inode_find_snapshot_root(struct btree_trans *trans, u64 inum,
@@ -1132,7 +1133,7 @@ static int bch2_inode_delete_keys(struct btree_trans *trans,
 
 int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter = {};
 	struct bkey_s_c k;
 	struct bch_inode_unpacked inode;
@@ -1141,7 +1142,7 @@ int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 
 	ret = lockrestart_do(trans, may_delete_deleted_inum(trans, inum, &inode));
 	if (ret)
-		goto err2;
+		return ret;
 
 	/*
 	 * If this was a directory, there shouldn't be any real dirents left -
@@ -1156,7 +1157,7 @@ int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 		 : bch2_inode_delete_keys(trans, inum, BTREE_ID_dirents)) ?:
 		bch2_inode_delete_keys(trans, inum, BTREE_ID_xattrs);
 	if (ret)
-		goto err2;
+		return ret;
 retry:
 	bch2_trans_begin(trans);
 
@@ -1188,12 +1189,9 @@ int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 		goto retry;
 
 	if (ret)
-		goto err2;
+		return ret;
 
-	ret = delete_ancestor_snapshot_inodes(trans, SPOS(0, inum.inum, snapshot));
-err2:
-	bch2_trans_put(trans);
-	return ret;
+	return delete_ancestor_snapshot_inodes(trans, SPOS(0, inum.inum, snapshot));
 }
 
 int bch2_inode_nlink_inc(struct bch_inode_unpacked *bi)
@@ -1413,7 +1411,7 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 	struct bch_fs *c = trans->c;
 	struct btree_iter inode_iter;
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret;
 
 	k = bch2_bkey_get_iter(trans, &inode_iter, BTREE_ID_inodes, pos, BTREE_ITER_cached);
@@ -1506,7 +1504,6 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 out:
 fsck_err:
 	bch2_trans_iter_exit(trans, &inode_iter);
-	printbuf_exit(&buf);
 	return ret;
 delete:
 	ret = bch2_btree_bit_mod_buffered(trans, BTREE_ID_deleted_inodes, pos, false);
@@ -1524,7 +1521,7 @@ static int may_delete_deleted_inum(struct btree_trans *trans, subvol_inum inum,
 
 int bch2_delete_dead_inodes(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	int ret;
 
 	/*
@@ -1568,7 +1565,6 @@ int bch2_delete_dead_inodes(struct bch_fs *c)
 		ret;
 	}));
 err:
-	bch2_trans_put(trans);
 	bch_err_fn(c, ret);
 	return ret;
 }
-- 
2.51.0


From 1b97b3a55ed232ea3f2705c5b6c8f5a01b0b4757 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:24:35 -0400
Subject: [PATCH 130/309] bcachefs: convert dirent.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/dirent.c | 9 ++++-----
 1 file changed, 4 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index 216ab5f4f59e..e27cf62d3a5e 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -621,13 +621,12 @@ u64 bch2_dirent_lookup(struct bch_fs *c, subvol_inum dir,
 		       const struct bch_hash_info *hash_info,
 		       const struct qstr *name, subvol_inum *inum)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter = {};
 
 	int ret = lockrestart_do(trans,
 		bch2_dirent_lookup_trans(trans, &iter, dir, hash_info, name, inum, 0));
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
@@ -687,8 +686,8 @@ int bch2_readdir(struct bch_fs *c, subvol_inum inum,
 	struct bkey_buf sk;
 	bch2_bkey_buf_init(&sk);
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_dirents,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_dirents,
 				   POS(inum.inum, ctx->pos),
 				   POS(inum.inum, U64_MAX),
 				   inum.subvol, 0, k, ({
@@ -709,7 +708,7 @@ int bch2_readdir(struct bch_fs *c, subvol_inum inum,
 				continue;
 
 			ret2 ?: (bch2_trans_unlock(trans), bch2_dir_emit(ctx, dirent, target));
-		})));
+		}));
 
 	bch2_bkey_buf_exit(&sk, c);
 
-- 
2.51.0


From 600387c961b2ea69c29c25bab5ab2cf100f5cb45 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:24:57 -0400
Subject: [PATCH 131/309] bcachefs: convert namei.c to CLASS

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/namei.c | 20 ++++++++------------
 1 file changed, 8 insertions(+), 12 deletions(-)

diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index 9334c3e86190..8fa108880f58 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -729,7 +729,7 @@ static int bch2_check_dirent_inode_dirent(struct btree_trans *trans,
 					  bool in_fsck)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct btree_iter bp_iter = {};
 	int ret = 0;
 
@@ -837,7 +837,6 @@ static int bch2_check_dirent_inode_dirent(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &bp_iter);
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -849,7 +848,7 @@ int __bch2_check_dirent_target(struct btree_trans *trans,
 			       bool in_fsck)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	ret = bch2_check_dirent_inode_dirent(trans, d, target, in_fsck);
@@ -884,7 +883,6 @@ int __bch2_check_dirent_target(struct btree_trans *trans,
 	}
 err:
 fsck_err:
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -942,7 +940,7 @@ int bch2_check_inode_has_case_insensitive(struct btree_trans *trans,
 					  snapshot_id_list *snapshot_overwrites,
 					  bool *do_update)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool repairing_parents = false;
 	int ret = 0;
 
@@ -969,7 +967,7 @@ int bch2_check_inode_has_case_insensitive(struct btree_trans *trans,
 		ret = bch2_inum_snapshot_to_path(trans, inode->bi_inum, inode->bi_snapshot,
 						 snapshot_overwrites, &buf);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (fsck_err(trans, inode_has_case_insensitive_not_set, "%s", buf.buf)) {
 			inode->bi_flags |= BCH_INODE_has_case_insensitive;
@@ -988,14 +986,14 @@ int bch2_check_inode_has_case_insensitive(struct btree_trans *trans,
 		if (dir.bi_parent_subvol) {
 			ret = bch2_subvolume_get_snapshot(trans, dir.bi_parent_subvol, &snapshot);
 			if (ret)
-				goto err;
+				return ret;
 
 			snapshot_overwrites = NULL;
 		}
 
 		ret = bch2_inode_find_by_inum_snapshot(trans, dir.bi_dir, snapshot, &dir, 0);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (!(dir.bi_flags & BCH_INODE_has_case_insensitive)) {
 			prt_printf(&buf, "parent of casefolded dir with has_case_insensitive not set\n");
@@ -1003,13 +1001,13 @@ int bch2_check_inode_has_case_insensitive(struct btree_trans *trans,
 			ret = bch2_inum_snapshot_to_path(trans, dir.bi_inum, dir.bi_snapshot,
 							 snapshot_overwrites, &buf);
 			if (ret)
-				goto err;
+				return ret;
 
 			if (fsck_err(trans, inode_parent_has_case_insensitive_not_set, "%s", buf.buf)) {
 				dir.bi_flags |= BCH_INODE_has_case_insensitive;
 				ret = __bch2_fsck_write_inode(trans, &dir);
 				if (ret)
-					goto err;
+					return ret;
 			}
 		}
 
@@ -1021,9 +1019,7 @@ int bch2_check_inode_has_case_insensitive(struct btree_trans *trans,
 			break;
 	}
 out:
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	if (ret)
 		return ret;
 
-- 
2.51.0


From 6228d8d7ce24e4e2ed69b7c752f34d5f8cca521f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:31:36 -0400
Subject: [PATCH 132/309] bcachefs: convert io_read.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.c | 33 +++++++++++++--------------------
 fs/bcachefs/io_read.h | 10 +++++-----
 2 files changed, 18 insertions(+), 25 deletions(-)

diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index 929ca968308b..386b2480b026 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -443,7 +443,8 @@ static int bch2_read_err_msg_trans(struct btree_trans *trans, struct printbuf *o
 static void bch2_read_err_msg(struct bch_fs *c, struct printbuf *out,
 			      struct bch_read_bio *rbio, struct bpos read_pos)
 {
-	bch2_trans_run(c, bch2_read_err_msg_trans(trans, out, rbio, read_pos));
+	CLASS(btree_trans, trans)(c);
+	bch2_read_err_msg_trans(trans, out, rbio, read_pos);
 }
 
 enum rbio_context {
@@ -647,7 +648,7 @@ static void bch2_rbio_retry(struct work_struct *work)
 	};
 	struct bch_io_failures failed = { .nr = 0 };
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	struct bkey_buf sk;
 	bch2_bkey_buf_init(&sk);
@@ -689,7 +690,7 @@ static void bch2_rbio_retry(struct work_struct *work)
 	}
 
 	if (failed.nr || ret) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 
 		lockrestart_do(trans,
@@ -717,12 +718,10 @@ static void bch2_rbio_retry(struct work_struct *work)
 		bch2_io_failures_to_text(&buf, c, &failed);
 
 		bch2_print_str_ratelimited(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	bch2_rbio_done(rbio);
 	bch2_bkey_buf_exit(&sk, c);
-	bch2_trans_put(trans);
 }
 
 static void bch2_rbio_error(struct bch_read_bio *rbio,
@@ -810,8 +809,9 @@ static int __bch2_rbio_narrow_crcs(struct btree_trans *trans,
 
 static noinline void bch2_rbio_narrow_crcs(struct bch_read_bio *rbio)
 {
-	bch2_trans_commit_do(rbio->c, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			     __bch2_rbio_narrow_crcs(trans, rbio));
+	CLASS(btree_trans, trans)(rbio->c);
+	commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
+		  __bch2_rbio_narrow_crcs(trans, rbio));
 }
 
 static void bch2_read_decompress_err(struct work_struct *work)
@@ -819,7 +819,7 @@ static void bch2_read_decompress_err(struct work_struct *work)
 	struct bch_read_bio *rbio =
 		container_of(work, struct bch_read_bio, work);
 	struct bch_fs *c	= rbio->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_read_err_msg(c, &buf, rbio, rbio->read_pos);
 	prt_str(&buf, "decompression error");
@@ -831,7 +831,6 @@ static void bch2_read_decompress_err(struct work_struct *work)
 		bch_err_ratelimited(c, "%s", buf.buf);
 
 	bch2_rbio_error(rbio, -BCH_ERR_data_read_decompress_err, BLK_STS_IOERR);
-	printbuf_exit(&buf);
 }
 
 static void bch2_read_decrypt_err(struct work_struct *work)
@@ -839,7 +838,7 @@ static void bch2_read_decrypt_err(struct work_struct *work)
 	struct bch_read_bio *rbio =
 		container_of(work, struct bch_read_bio, work);
 	struct bch_fs *c	= rbio->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_read_err_msg(c, &buf, rbio, rbio->read_pos);
 	prt_str(&buf, "decrypt error");
@@ -851,7 +850,6 @@ static void bch2_read_decrypt_err(struct work_struct *work)
 		bch_err_ratelimited(c, "%s", buf.buf);
 
 	bch2_rbio_error(rbio, -BCH_ERR_data_read_decrypt_err, BLK_STS_IOERR);
-	printbuf_exit(&buf);
 }
 
 /* Inner part that may run in process context */
@@ -1033,7 +1031,7 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter iter;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret;
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_alloc,
@@ -1070,7 +1068,6 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 	bch2_fs_inconsistent(c, "%s", buf.buf);
 
 	bch2_trans_iter_exit(trans, &iter);
-	printbuf_exit(&buf);
 }
 
 int __bch2_read_extent(struct btree_trans *trans, struct bch_read_bio *orig,
@@ -1122,25 +1119,22 @@ int __bch2_read_extent(struct btree_trans *trans, struct bch_read_bio *orig,
 			trace_and_count(c, io_read_fail_and_poison, &orig->bio);
 		}
 
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_read_err_msg_trans(trans, &buf, orig, read_pos);
 		prt_printf(&buf, "%s\n  ", bch2_err_str(ret));
 		bch2_bkey_val_to_text(&buf, c, k);
-
 		bch_err_ratelimited(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 		goto err;
 	}
 
 	if (unlikely(bch2_csum_type_is_encryption(pick.crc.csum_type)) &&
 	    !c->chacha20_key_set) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_read_err_msg_trans(trans, &buf, orig, read_pos);
 		prt_printf(&buf, "attempting to read encrypted data without encryption key\n  ");
 		bch2_bkey_val_to_text(&buf, c, k);
 
 		bch_err_ratelimited(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 		ret = bch_err_throw(c, data_read_no_encryption_key);
 		goto err;
 	}
@@ -1505,13 +1499,12 @@ int __bch2_read(struct btree_trans *trans, struct bch_read_bio *rbio,
 
 	if (unlikely(ret)) {
 		if (ret != -BCH_ERR_extent_poisoned) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			lockrestart_do(trans,
 				       bch2_inum_offset_err_msg_trans(trans, &buf, inum,
 								      bvec_iter.bi_sector << 9));
 			prt_printf(&buf, "data read error: %s", bch2_err_str(ret));
 			bch_err_ratelimited(c, "%s", buf.buf);
-			printbuf_exit(&buf);
 		}
 
 		rbio->bio.bi_status	= BLK_STS_IOERR;
diff --git a/fs/bcachefs/io_read.h b/fs/bcachefs/io_read.h
index 8fef4e47f16d..9d63d5914b20 100644
--- a/fs/bcachefs/io_read.h
+++ b/fs/bcachefs/io_read.h
@@ -165,11 +165,11 @@ static inline void bch2_read(struct bch_fs *c, struct bch_read_bio *rbio,
 
 	rbio->subvol = inum.subvol;
 
-	bch2_trans_run(c,
-		__bch2_read(trans, rbio, rbio->bio.bi_iter, inum, NULL, NULL,
-			    BCH_READ_retry_if_stale|
-			    BCH_READ_may_promote|
-			    BCH_READ_user_mapped));
+	CLASS(btree_trans, trans)(c);
+	__bch2_read(trans, rbio, rbio->bio.bi_iter, inum, NULL, NULL,
+		    BCH_READ_retry_if_stale|
+		    BCH_READ_may_promote|
+		    BCH_READ_user_mapped);
 }
 
 static inline struct bch_read_bio *rbio_init_fragment(struct bio *bio,
-- 
2.51.0


From 3e45706bb210f65851513404d8cad47a318cad77 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:31:44 -0400
Subject: [PATCH 133/309] bcachefs: convert io_write.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_write.c | 16 ++++++----------
 1 file changed, 6 insertions(+), 10 deletions(-)

diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index eefedebf65fa..d7620138e038 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -256,7 +256,7 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 		s64 bi_sectors = le64_to_cpu(inode->v.bi_sectors);
 		if (unlikely(bi_sectors + i_sectors_delta < 0)) {
 			struct bch_fs *c = trans->c;
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			bch2_log_msg_start(c, &buf);
 			prt_printf(&buf, "inode %llu i_sectors underflow: %lli + %lli < 0",
 				   extent_iter->pos.inode, bi_sectors, i_sectors_delta);
@@ -264,7 +264,6 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 			bool print = bch2_count_fsck_err(c, inode_i_sectors_underflow, &buf);
 			if (print)
 				bch2_print_str(c, KERN_ERR, buf.buf);
-			printbuf_exit(&buf);
 
 			if (i_sectors_delta < 0)
 				i_sectors_delta = -bi_sectors;
@@ -370,7 +369,6 @@ static int bch2_write_index_default(struct bch_write_op *op)
 	struct bkey_buf sk;
 	struct keylist *keys = &op->insert_keys;
 	struct bkey_i *k = bch2_keylist_front(keys);
-	struct btree_trans *trans = bch2_trans_get(c);
 	struct btree_iter iter;
 	subvol_inum inum = {
 		.subvol = op->subvol,
@@ -380,6 +378,7 @@ static int bch2_write_index_default(struct bch_write_op *op)
 
 	BUG_ON(!inum.subvol);
 
+	CLASS(btree_trans, trans)(c);
 	bch2_bkey_buf_init(&sk);
 
 	do {
@@ -416,7 +415,6 @@ static int bch2_write_index_default(struct bch_write_op *op)
 			bch2_cut_front(iter.pos, k);
 	} while (!bch2_keylist_empty(keys));
 
-	bch2_trans_put(trans);
 	bch2_bkey_buf_exit(&sk, c);
 
 	return ret;
@@ -426,7 +424,7 @@ static int bch2_write_index_default(struct bch_write_op *op)
 
 void bch2_write_op_error(struct bch_write_op *op, u64 offset, const char *fmt, ...)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	if (op->subvol) {
 		bch2_inum_offset_err_msg(op->c, &buf,
@@ -453,7 +451,6 @@ void bch2_write_op_error(struct bch_write_op *op, u64 offset, const char *fmt, .
 	}
 
 	bch_err_ratelimited(op->c, "%s", buf.buf);
-	printbuf_exit(&buf);
 }
 
 void bch2_submit_wbio_replicas(struct bch_write_bio *wbio, struct bch_fs *c,
@@ -1477,7 +1474,7 @@ static void bch2_nocow_write(struct bch_write_op *op)
 			break;
 	}
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	if (bch2_fs_inconsistent_on(stale < 0, c,
 				    "pointer to invalid bucket in nocow path on device %llu\n  %s",
 				    stale_at->b.inode,
@@ -1487,7 +1484,6 @@ static void bch2_nocow_write(struct bch_write_op *op)
 		/* We can retry this: */
 		ret = bch_err_throw(c, transaction_restart);
 	}
-	printbuf_exit(&buf);
 
 	goto err_get_ioref;
 }
@@ -1531,7 +1527,7 @@ static void __bch2_write(struct bch_write_op *op)
 		 * freeing up space on specific disks, which means that
 		 * allocations for specific disks may hang arbitrarily long:
 		 */
-		ret = bch2_trans_run(c, lockrestart_do(trans,
+		ret = bch2_trans_do(c,
 			bch2_alloc_sectors_start_trans(trans,
 				op->target,
 				op->opts.erasure_code && !(op->flags & BCH_WRITE_cached),
@@ -1541,7 +1537,7 @@ static void __bch2_write(struct bch_write_op *op)
 				op->nr_replicas_required,
 				op->watermark,
 				op->flags,
-				&op->cl, &wp)));
+				&op->cl, &wp));
 		if (unlikely(ret)) {
 			if (bch2_err_matches(ret, BCH_ERR_operation_blocked))
 				break;
-- 
2.51.0


From 45228f675e7ac373054b153c37c9fa6cda88c593 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:31:51 -0400
Subject: [PATCH 134/309] bcachefs: convert io_misc.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_misc.c | 36 +++++++++++-------------------------
 1 file changed, 11 insertions(+), 25 deletions(-)

diff --git a/fs/bcachefs/io_misc.c b/fs/bcachefs/io_misc.c
index 07023667a475..5d6681c070ba 100644
--- a/fs/bcachefs/io_misc.c
+++ b/fs/bcachefs/io_misc.c
@@ -114,12 +114,11 @@ int bch2_extent_fallocate(struct btree_trans *trans,
 	if (!ret && sectors_allocated)
 		bch2_increment_clock(c, sectors_allocated, WRITE);
 	if (should_print_err(ret)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		lockrestart_do(trans,
 			bch2_inum_offset_err_msg_trans(trans, &buf, inum, iter->pos.offset << 9));
 		prt_printf(&buf, "fallocate error: %s", bch2_err_str(ret));
 		bch_err_ratelimited(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 err_noprint:
 	bch2_open_buckets_put(c, &open_buckets);
@@ -222,23 +221,18 @@ int bch2_fpunch_at(struct btree_trans *trans, struct btree_iter *iter,
 int bch2_fpunch(struct bch_fs *c, subvol_inum inum, u64 start, u64 end,
 		s64 *i_sectors_delta)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct btree_iter iter;
-	int ret;
+	CLASS(btree_trans, trans)(c);
 
+	struct btree_iter iter;
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
 			     POS(inum.inum, start),
 			     BTREE_ITER_intent);
 
-	ret = bch2_fpunch_at(trans, &iter, inum, end, i_sectors_delta);
+	int ret = bch2_fpunch_at(trans, &iter, inum, end, i_sectors_delta);
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
-
-	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
-		ret = 0;
 
-	return ret;
+	return bch2_err_matches(ret, BCH_ERR_transaction_restart) ? 0 : ret;
 }
 
 /* truncate: */
@@ -319,17 +313,13 @@ int bch2_truncate(struct bch_fs *c, subvol_inum inum, u64 new_i_size, u64 *i_sec
 	 * snapshot while they're in progress, then crashing, will result in the
 	 * resume only proceeding in one of the snapshots
 	 */
-	down_read(&c->snapshot_create_lock);
-	struct btree_trans *trans = bch2_trans_get(c);
+	guard(rwsem_read)(&c->snapshot_create_lock);
+	CLASS(btree_trans, trans)(c);
 	int ret = bch2_logged_op_start(trans, &op.k_i);
 	if (ret)
-		goto out;
+		return ret;
 	ret = __bch2_resume_logged_op_truncate(trans, &op.k_i, i_sectors_delta);
 	ret = bch2_logged_op_finish(trans, &op.k_i) ?: ret;
-out:
-	bch2_trans_put(trans);
-	up_read(&c->snapshot_create_lock);
-
 	return ret;
 }
 
@@ -555,16 +545,12 @@ int bch2_fcollapse_finsert(struct bch_fs *c, subvol_inum inum,
 	 * snapshot while they're in progress, then crashing, will result in the
 	 * resume only proceeding in one of the snapshots
 	 */
-	down_read(&c->snapshot_create_lock);
-	struct btree_trans *trans = bch2_trans_get(c);
+	guard(rwsem_read)(&c->snapshot_create_lock);
+	CLASS(btree_trans, trans)(c);
 	int ret = bch2_logged_op_start(trans, &op.k_i);
 	if (ret)
-		goto out;
+		return ret;
 	ret = __bch2_resume_logged_op_finsert(trans, &op.k_i, i_sectors_delta);
 	ret = bch2_logged_op_finish(trans, &op.k_i) ?: ret;
-out:
-	bch2_trans_put(trans);
-	up_read(&c->snapshot_create_lock);
-
 	return ret;
 }
-- 
2.51.0


From 037733c903c76d86f55c15e45d5a806e75898d47 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:30:11 -0400
Subject: [PATCH 135/309] bcachefs: convert fsck.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 262 +++++++++++++++++++--------------------------
 1 file changed, 113 insertions(+), 149 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index b6d3ed448d51..2526a7121dee 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -53,10 +53,9 @@ static int dirent_points_to_inode(struct bch_fs *c,
 {
 	int ret = dirent_points_to_inode_nowarn(c, dirent, inode);
 	if (ret) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		dirent_inode_mismatch_msg(&buf, c, dirent, inode);
 		bch_warn(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 	return ret;
 }
@@ -253,14 +252,13 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 	 * XXX: we could have a nicer log message here  if we had a nice way to
 	 * walk backpointers to print a path
 	 */
-	struct printbuf path = PRINTBUF;
+	CLASS(printbuf, path)();
 	ret = bch2_inum_to_path(trans, root_inum, &path);
 	if (ret)
 		goto err;
 
 	bch_notice(c, "creating %s/lost+found in subvol %llu snapshot %u",
 		   path.buf, root_inum.subvol, snapshot);
-	printbuf_exit(&path);
 
 	u64 now = bch2_current_time(c);
 	u64 cpu = raw_smp_processor_id();
@@ -455,7 +453,7 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 	 * whiteouts for the dirent we just created.
 	 */
 	if (!inode->bi_subvol && bch2_snapshot_is_leaf(c, inode->bi_snapshot) <= 0) {
-		snapshot_id_list whiteouts_done;
+		CLASS(snapshot_id_list, whiteouts_done)();
 		struct btree_iter iter;
 		struct bkey_s_c k;
 
@@ -499,7 +497,6 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 					break;
 			}
 		}
-		darray_exit(&whiteouts_done);
 		bch2_trans_iter_exit(trans, &iter);
 	}
 
@@ -683,11 +680,15 @@ static inline void snapshots_seen_exit(struct snapshots_seen *s)
 	darray_exit(&s->ids);
 }
 
-static inline void snapshots_seen_init(struct snapshots_seen *s)
+static inline struct snapshots_seen snapshots_seen_init(void)
 {
-	memset(s, 0, sizeof(*s));
+	return (struct snapshots_seen) {};
 }
 
+DEFINE_CLASS(snapshots_seen, struct snapshots_seen,
+	     snapshots_seen_exit(&_T),
+	     snapshots_seen_init(), void)
+
 static int snapshots_seen_add_inorder(struct bch_fs *c, struct snapshots_seen *s, u32 id)
 {
 	u32 *i;
@@ -815,9 +816,13 @@ static void inode_walker_exit(struct inode_walker *w)
 
 static struct inode_walker inode_walker_init(void)
 {
-	return (struct inode_walker) { 0, };
+	return (struct inode_walker) {};
 }
 
+DEFINE_CLASS(inode_walker, struct inode_walker,
+	     inode_walker_exit(&_T),
+	     inode_walker_init(), void)
+
 static int add_inode(struct bch_fs *c, struct inode_walker *w,
 		     struct bkey_s_c inode)
 {
@@ -917,7 +922,7 @@ lookup_inode_for_snapshot(struct btree_trans *trans, struct inode_walker *w, str
 	if (!i)
 		return NULL;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	if (fsck_err_on(k.k->p.snapshot != i->inode.bi_snapshot,
@@ -967,10 +972,8 @@ lookup_inode_for_snapshot(struct btree_trans *trans, struct inode_walker *w, str
 		goto fsck_err;
 	}
 
-	printbuf_exit(&buf);
 	return i;
 fsck_err:
-	printbuf_exit(&buf);
 	return ERR_PTR(ret);
 }
 
@@ -1004,27 +1007,25 @@ int bch2_fsck_update_backpointers(struct btree_trans *trans,
 		return 0;
 
 	struct bkey_i_dirent *d = bkey_i_to_dirent(new);
-	struct inode_walker target = inode_walker_init();
-	int ret = 0;
+	CLASS(inode_walker, target)();
 
 	if (d->v.d_type == DT_SUBVOL) {
 		bch_err(trans->c, "%s does not support DT_SUBVOL", __func__);
-		ret = -BCH_ERR_fsck_repair_unimplemented;
+		return bch_err_throw(trans->c, fsck_repair_unimplemented);
 	} else {
-		ret = get_visible_inodes(trans, &target, s, le64_to_cpu(d->v.d_inum));
+		int ret = get_visible_inodes(trans, &target, s, le64_to_cpu(d->v.d_inum));
 		if (ret)
-			goto err;
+			return ret;
 
 		darray_for_each(target.inodes, i) {
 			i->inode.bi_dir_offset = d->k.p.offset;
 			ret = __bch2_fsck_write_inode(trans, &i->inode);
 			if (ret)
-				goto err;
+				return ret;
 		}
+
+		return 0;
 	}
-err:
-	inode_walker_exit(&target);
-	return ret;
 }
 
 static struct bkey_s_c_dirent inode_get_dirent(struct btree_trans *trans,
@@ -1056,7 +1057,7 @@ static int check_inode_dirent_inode(struct btree_trans *trans,
 				    bool *write_inode)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	u32 inode_snapshot = inode->bi_snapshot;
 	struct btree_iter dirent_iter = {};
@@ -1106,7 +1107,6 @@ static int check_inode_dirent_inode(struct btree_trans *trans,
 	ret = 0;
 fsck_err:
 	bch2_trans_iter_exit(trans, &dirent_iter);
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1118,7 +1118,7 @@ static int check_inode(struct btree_trans *trans,
 		       struct snapshots_seen *s)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct bch_inode_unpacked u;
 	bool do_update = false;
 	int ret;
@@ -1234,7 +1234,7 @@ static int check_inode(struct btree_trans *trans,
 			 */
 			ret = check_inode_deleted_list(trans, k.k->p);
 			if (ret < 0)
-				goto err_noprint;
+				return ret;
 
 			fsck_err_on(!ret,
 				    trans, unlinked_inode_not_on_deleted_list,
@@ -1255,7 +1255,7 @@ static int check_inode(struct btree_trans *trans,
 				      u.bi_inum, u.bi_snapshot)) {
 				ret = bch2_inode_rm_snapshot(trans, u.bi_inum, iter->pos.snapshot);
 				bch_err_msg(c, ret, "in fsck deleting inode");
-				goto err_noprint;
+				return ret;
 			}
 			ret = 0;
 		}
@@ -1316,31 +1316,27 @@ static int check_inode(struct btree_trans *trans,
 		ret = __bch2_fsck_write_inode(trans, &u);
 		bch_err_msg(c, ret, "in fsck updating inode");
 		if (ret)
-			goto err_noprint;
+			return ret;
 	}
 err:
 fsck_err:
 	bch_err_fn(c, ret);
-err_noprint:
-	printbuf_exit(&buf);
 	return ret;
 }
 
 int bch2_check_inodes(struct bch_fs *c)
 {
 	struct bch_inode_unpacked snapshot_root = {};
-	struct snapshots_seen s;
 
-	snapshots_seen_init(&s);
+	CLASS(btree_trans, trans)(c);
+	CLASS(snapshots_seen, s)();
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_inode(trans, &iter, k, &snapshot_root, &s)));
+			check_inode(trans, &iter, k, &snapshot_root, &s));
 
-	snapshots_seen_exit(&s);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1390,7 +1386,7 @@ static int check_unreachable_inode(struct btree_trans *trans,
 				   struct btree_iter *iter,
 				   struct bkey_s_c k)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	if (!bkey_is_inode(k.k))
@@ -1414,7 +1410,6 @@ static int check_unreachable_inode(struct btree_trans *trans,
 		      buf.buf)))
 		ret = reattach_inode(trans, &inode);
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1430,12 +1425,12 @@ static int check_unreachable_inode(struct btree_trans *trans,
  */
 int bch2_check_unreachable_inodes(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_unreachable_inode(trans, &iter, k)));
+			check_unreachable_inode(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1461,7 +1456,7 @@ static int check_key_has_inode(struct btree_trans *trans,
 			       struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct btree_iter iter2 = {};
 	int ret = PTR_ERR_OR_ZERO(i);
 	if (ret)
@@ -1557,7 +1552,6 @@ static int check_key_has_inode(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &iter2);
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 delete:
@@ -1691,11 +1685,15 @@ static void extent_ends_exit(struct extent_ends *extent_ends)
 	darray_exit(&extent_ends->e);
 }
 
-static void extent_ends_init(struct extent_ends *extent_ends)
+static struct extent_ends extent_ends_init(void)
 {
-	memset(extent_ends, 0, sizeof(*extent_ends));
+	return (struct extent_ends) {};
 }
 
+DEFINE_CLASS(extent_ends, struct extent_ends,
+	     extent_ends_exit(&_T),
+	     extent_ends_init(), void)
+
 static int extent_ends_at(struct bch_fs *c,
 			  struct extent_ends *extent_ends,
 			  struct snapshots_seen *seen,
@@ -1735,7 +1733,7 @@ static int overlapping_extents_found(struct btree_trans *trans,
 				     struct extent_end *extent_end)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct btree_iter iter1, iter2 = {};
 	struct bkey_s_c k1, k2;
 	int ret;
@@ -1841,7 +1839,6 @@ static int overlapping_extents_found(struct btree_trans *trans,
 err:
 	bch2_trans_iter_exit(trans, &iter2);
 	bch2_trans_iter_exit(trans, &iter1);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1898,11 +1895,10 @@ static int check_extent_overbig(struct btree_trans *trans, struct btree_iter *it
 	bkey_for_each_crc(k.k, ptrs, crc, i)
 		if (crc_is_encoded(crc) &&
 		    crc.uncompressed_size > encoded_extent_max_sectors) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 
 			bch2_bkey_val_to_text(&buf, c, k);
 			bch_err(c, "overbig encoded extent, please report this:\n  %s", buf.buf);
-			printbuf_exit(&buf);
 		}
 
 	return 0;
@@ -1916,7 +1912,7 @@ static int check_extent(struct btree_trans *trans, struct btree_iter *iter,
 			struct disk_reservation *res)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	ret = bch2_check_key_has_snapshot(trans, iter, k);
@@ -2010,7 +2006,6 @@ static int check_extent(struct btree_trans *trans, struct btree_iter *iter,
 out:
 err:
 fsck_err:
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2021,28 +2016,23 @@ static int check_extent(struct btree_trans *trans, struct btree_iter *iter,
  */
 int bch2_check_extents(struct bch_fs *c)
 {
-	struct inode_walker w = inode_walker_init();
-	struct snapshots_seen s;
-	struct extent_ends extent_ends;
 	struct disk_reservation res = { 0 };
 
-	snapshots_seen_init(&s);
-	extent_ends_init(&extent_ends);
+	CLASS(btree_trans, trans)(c);
+	CLASS(snapshots_seen, s)();
+	CLASS(inode_walker, w)();
+	CLASS(extent_ends, extent_ends)();
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key(trans, iter, BTREE_ID_extents,
+	int ret = for_each_btree_key(trans, iter, BTREE_ID_extents,
 				POS(BCACHEFS_ROOT_INO, 0),
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k, ({
 			bch2_disk_reservation_put(c, &res);
 			check_extent(trans, &iter, k, &w, &s, &extent_ends, &res) ?:
 			check_extent_overbig(trans, &iter, k);
 		})) ?:
-		check_i_sectors_notnested(trans, &w));
+		check_i_sectors_notnested(trans, &w);
 
 	bch2_disk_reservation_put(c, &res);
-	extent_ends_exit(&extent_ends);
-	inode_walker_exit(&w);
-	snapshots_seen_exit(&s);
 
 	bch_err_fn(c, ret);
 	return ret;
@@ -2050,17 +2040,17 @@ int bch2_check_extents(struct bch_fs *c)
 
 int bch2_check_indirect_extents(struct bch_fs *c)
 {
+	CLASS(btree_trans, trans)(c);
 	struct disk_reservation res = { 0 };
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_reflink,
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_reflink,
 				POS_MIN,
 				BTREE_ITER_prefetch, k,
 				&res, NULL,
 				BCH_TRANS_COMMIT_no_enospc, ({
 			bch2_disk_reservation_put(c, &res);
 			check_extent_overbig(trans, &iter, k);
-		})));
+		}));
 
 	bch2_disk_reservation_put(c, &res);
 	bch_err_fn(c, ret);
@@ -2156,7 +2146,7 @@ static int check_dirent_to_subvol(struct btree_trans *trans, struct btree_iter *
 	u32 parent_snapshot;
 	u32 new_parent_subvol = 0;
 	u64 parent_inum;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	ret = subvol_lookup(trans, parent_subvol, &parent_snapshot, &parent_inum);
@@ -2280,7 +2270,6 @@ static int check_dirent_to_subvol(struct btree_trans *trans, struct btree_iter *
 err:
 fsck_err:
 	bch2_trans_iter_exit(trans, &subvol_iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -2294,39 +2283,37 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 {
 	struct bch_fs *c = trans->c;
 	struct inode_walker_entry *i;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	ret = bch2_check_key_has_snapshot(trans, iter, k);
-	if (ret) {
-		ret = ret < 0 ? ret : 0;
-		goto out;
-	}
+	if (ret)
+		return ret < 0 ? ret : 0;
 
 	ret = snapshots_seen_update(c, s, iter->btree_id, k.k->p);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (k.k->type == KEY_TYPE_whiteout)
-		goto out;
+		return 0;
 
 	if (dir->last_pos.inode != k.k->p.inode && dir->have_inodes) {
 		ret = check_subdir_dirents_count(trans, dir);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	i = walk_inode(trans, dir, k);
 	ret = PTR_ERR_OR_ZERO(i);
-	if (ret < 0)
-		goto err;
+	if (ret)
+		return ret;
 
 	ret = check_key_has_inode(trans, iter, dir, i, k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (!i || i->whiteout)
-		goto out;
+		return 0;
 
 	if (dir->first_this_inode)
 		*hash_info = bch2_hash_info_init(c, &i->inode);
@@ -2337,15 +2324,11 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 	ret = bch2_str_hash_check_key(trans, s, &bch2_dirent_hash_desc, hash_info,
 				      iter, k, need_second_pass);
 	if (ret < 0)
-		goto err;
-	if (ret) {
-		/* dirent has been deleted */
-		ret = 0;
-		goto out;
-	}
-
+		return ret;
+	if (ret)
+		return 0; /* dirent has been deleted */
 	if (k.k->type != KEY_TYPE_dirent)
-		goto out;
+		return 0;
 
 	struct bkey_s_c_dirent d = bkey_s_c_to_dirent(k);
 
@@ -2370,13 +2353,13 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 					       d.v->d_type, &name, NULL, target);
 		ret = PTR_ERR_OR_ZERO(new_d);
 		if (ret)
-			goto out;
+			return ret;
 
 		new_d->k.p.inode	= d.k->p.inode;
 		new_d->k.p.snapshot	= d.k->p.snapshot;
 
 		struct btree_iter dup_iter = {};
-		ret =	bch2_hash_delete_at(trans,
+		return  bch2_hash_delete_at(trans,
 					    bch2_dirent_hash_desc, hash_info, iter,
 					    BTREE_UPDATE_internal_snapshot_node) ?:
 			bch2_str_hash_repair_key(trans, s,
@@ -2384,17 +2367,16 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 						 iter, bkey_i_to_s_c(&new_d->k_i),
 						 &dup_iter, bkey_s_c_null,
 						 need_second_pass);
-		goto out;
 	}
 
 	if (d.v->d_type == DT_SUBVOL) {
 		ret = check_dirent_to_subvol(trans, iter, d);
 		if (ret)
-			goto err;
+			return ret;
 	} else {
 		ret = get_visible_inodes(trans, target, s, le64_to_cpu(d.v->d_inum));
 		if (ret)
-			goto err;
+			return ret;
 
 		if (!target->inodes.nr) {
 			ret = maybe_reconstruct_inum(trans, le64_to_cpu(d.v->d_inum),
@@ -2411,13 +2393,13 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 				 buf.buf))) {
 			ret = bch2_fsck_remove_dirent(trans, d.k->p);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		darray_for_each(target->inodes, i) {
 			ret = bch2_check_dirent_target(trans, iter, d, &i->inode, true);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		darray_for_each(target->deletes, i)
@@ -2440,7 +2422,7 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 							  BTREE_UPDATE_internal_snapshot_node);
 				bch2_trans_iter_exit(trans, &delete_iter);
 				if (ret)
-					goto err;
+					return ret;
 
 			}
 	}
@@ -2453,17 +2435,14 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 
 	ret = bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc);
 	if (ret)
-		goto err;
+		return ret;
 
 	for_each_visible_inode(c, s, dir, d.k->p.snapshot, i) {
 		if (have_dir)
 			i->count++;
 		i->i_size += bkey_bytes(d.k);
 	}
-out:
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -2473,23 +2452,21 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
  */
 int bch2_check_dirents(struct bch_fs *c)
 {
-	struct inode_walker dir = inode_walker_init();
-	struct inode_walker target = inode_walker_init();
-	struct snapshots_seen s;
 	struct bch_hash_info hash_info;
+	CLASS(btree_trans, trans)(c);
+	CLASS(snapshots_seen, s)();
+	CLASS(inode_walker, dir)();
+	CLASS(inode_walker, target)();
 	bool need_second_pass = false, did_second_pass = false;
 	int ret;
-
-	snapshots_seen_init(&s);
 again:
-	ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_dirents,
+	ret = for_each_btree_key_commit(trans, iter, BTREE_ID_dirents,
 				POS(BCACHEFS_ROOT_INO, 0),
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_dirent(trans, &iter, k, &hash_info, &dir, &target, &s,
 				     &need_second_pass)) ?:
-		check_subdir_count_notnested(trans, &dir));
+		check_subdir_count_notnested(trans, &dir);
 
 	if (!ret && need_second_pass && !did_second_pass) {
 		bch_info(c, "check_dirents requires second pass");
@@ -2502,9 +2479,6 @@ int bch2_check_dirents(struct bch_fs *c)
 		ret = -EINVAL;
 	}
 
-	snapshots_seen_exit(&s);
-	inode_walker_exit(&dir);
-	inode_walker_exit(&target);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2548,20 +2522,17 @@ static int check_xattr(struct btree_trans *trans, struct btree_iter *iter,
  */
 int bch2_check_xattrs(struct bch_fs *c)
 {
-	struct inode_walker inode = inode_walker_init();
 	struct bch_hash_info hash_info;
-	int ret = 0;
+	CLASS(btree_trans, trans)(c);
+	CLASS(inode_walker, inode)();
 
-	ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
 			POS(BCACHEFS_ROOT_INO, 0),
 			BTREE_ITER_prefetch|BTREE_ITER_all_snapshots,
 			k,
 			NULL, NULL,
 			BCH_TRANS_COMMIT_no_enospc,
-		check_xattr(trans, &iter, k, &hash_info, &inode)));
-
-	inode_walker_exit(&inode);
+		check_xattr(trans, &iter, k, &hash_info, &inode));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2627,8 +2598,9 @@ static int check_root_trans(struct btree_trans *trans)
 /* Get root directory, create if it doesn't exist: */
 int bch2_check_root(struct bch_fs *c)
 {
-	int ret = bch2_trans_commit_do(c, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-		check_root_trans(trans));
+	CLASS(btree_trans, trans)(c);
+	int ret = commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
+			    check_root_trans(trans));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2637,8 +2609,8 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter parent_iter = {};
-	darray_u32 subvol_path = {};
-	struct printbuf buf = PRINTBUF;
+	CLASS(darray_u32, subvol_path)();
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	if (k.k->type != KEY_TYPE_subvolume)
@@ -2698,19 +2670,17 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 	}
 fsck_err:
 err:
-	printbuf_exit(&buf);
-	darray_exit(&subvol_path);
 	bch2_trans_iter_exit(trans, &parent_iter);
 	return ret;
 }
 
 int bch2_check_subvolume_structure(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolumes, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_subvol_path(trans, &iter, k)));
+			check_subvol_path(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2763,8 +2733,8 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter inode_iter = {};
-	darray_u64 path = {};
-	struct printbuf buf = PRINTBUF;
+	CLASS(darray_u64, path)();
+	CLASS(printbuf, buf)();
 	u32 snapshot = inode_k.k->p.snapshot;
 	bool redo_bi_depth = false;
 	u32 min_bi_depth = U32_MAX;
@@ -2870,8 +2840,6 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 out:
 fsck_err:
 	bch2_trans_iter_exit(trans, &inode_iter);
-	darray_exit(&path);
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2882,8 +2850,8 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
  */
 int bch2_check_directory_structure(struct bch_fs *c)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_reverse_commit(trans, iter, BTREE_ID_inodes, POS_MIN,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_reverse_commit(trans, iter, BTREE_ID_inodes, POS_MIN,
 					  BTREE_ITER_intent|
 					  BTREE_ITER_prefetch|
 					  BTREE_ITER_all_snapshots, k,
@@ -2895,7 +2863,7 @@ int bch2_check_directory_structure(struct bch_fs *c)
 				continue;
 
 			check_path_loop(trans, k);
-		})));
+		}));
 
 	bch_err_fn(c, ret);
 	return ret;
@@ -2982,8 +2950,8 @@ static int check_nlinks_find_hardlinks(struct bch_fs *c,
 				       struct nlink_table *t,
 				       u64 start, u64 *end)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key(trans, iter, BTREE_ID_inodes,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key(trans, iter, BTREE_ID_inodes,
 				   POS(0, start),
 				   BTREE_ITER_intent|
 				   BTREE_ITER_prefetch|
@@ -3018,7 +2986,7 @@ static int check_nlinks_find_hardlinks(struct bch_fs *c,
 				break;
 			}
 			0;
-		})));
+		}));
 
 	bch_err_fn(c, ret);
 	return ret;
@@ -3028,12 +2996,10 @@ noinline_for_stack
 static int check_nlinks_walk_dirents(struct bch_fs *c, struct nlink_table *links,
 				     u64 range_start, u64 range_end)
 {
-	struct snapshots_seen s;
+	CLASS(btree_trans, trans)(c);
+	CLASS(snapshots_seen, s)();
 
-	snapshots_seen_init(&s);
-
-	int ret = bch2_trans_run(c,
-		for_each_btree_key(trans, iter, BTREE_ID_dirents, POS_MIN,
+	int ret = for_each_btree_key(trans, iter, BTREE_ID_dirents, POS_MIN,
 				   BTREE_ITER_intent|
 				   BTREE_ITER_prefetch|
 				   BTREE_ITER_all_snapshots, k, ({
@@ -3050,9 +3016,7 @@ static int check_nlinks_walk_dirents(struct bch_fs *c, struct nlink_table *links
 						 le64_to_cpu(d.v->d_inum), d.k->p.snapshot);
 			}
 			0;
-		})));
-
-	snapshots_seen_exit(&s);
+		}));
 
 	bch_err_fn(c, ret);
 	return ret;
@@ -3106,14 +3070,14 @@ static int check_nlinks_update_hardlinks(struct bch_fs *c,
 			       struct nlink_table *links,
 			       u64 range_start, u64 range_end)
 {
+	CLASS(btree_trans, trans)(c);
 	size_t idx = 0;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS(0, range_start),
 				BTREE_ITER_intent|BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_nlinks_update_inode(trans, &iter, k, links, &idx, range_end)));
+			check_nlinks_update_inode(trans, &iter, k, links, &idx, range_end));
 	if (ret < 0) {
 		bch_err(c, "error in fsck walking inodes: %s", bch2_err_str(ret));
 		return ret;
@@ -3187,13 +3151,13 @@ int bch2_fix_reflink_p(struct bch_fs *c)
 	if (c->sb.version >= bcachefs_metadata_version_reflink_p_fix)
 		return 0;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_extents, POS_MIN,
 				BTREE_ITER_intent|BTREE_ITER_prefetch|
 				BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			fix_reflink_p_key(trans, &iter, k)));
+			fix_reflink_p_key(trans, &iter, k));
 	bch_err_fn(c, ret);
 	return ret;
 }
-- 
2.51.0


From 984573843a6366bab4ac2fecc3d50aee2b3c4095 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:30:37 -0400
Subject: [PATCH 136/309] bcachefs: convert disk_accounting.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/disk_accounting.c | 253 ++++++++++++++++------------------
 fs/bcachefs/disk_accounting.h |   9 +-
 2 files changed, 121 insertions(+), 141 deletions(-)

diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 2591b4f470fc..2f74e68da699 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -380,11 +380,10 @@ static int __bch2_accounting_mem_insert(struct bch_fs *c, struct bkey_s_c_accoun
 			accounting_pos_cmp, NULL);
 
 	if (trace_accounting_mem_insert_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_accounting_to_text(&buf, c, a.s_c);
 		trace_accounting_mem_insert(c, buf.buf);
-		printbuf_exit(&buf);
 	}
 	return 0;
 err:
@@ -404,9 +403,9 @@ int bch2_accounting_mem_insert(struct bch_fs *c, struct bkey_s_c_accounting a,
 		return bch_err_throw(c, btree_insert_need_mark_replicas);
 
 	percpu_up_read(&c->mark_lock);
-	percpu_down_write(&c->mark_lock);
-	int ret = __bch2_accounting_mem_insert(c, a);
-	percpu_up_write(&c->mark_lock);
+	int ret;
+	scoped_guard(percpu_write, &c->mark_lock)
+		ret = __bch2_accounting_mem_insert(c, a);
 	percpu_down_read(&c->mark_lock);
 	return ret;
 }
@@ -438,7 +437,7 @@ void bch2_accounting_mem_gc(struct bch_fs *c)
 {
 	struct bch_accounting_mem *acc = &c->accounting;
 
-	percpu_down_write(&c->mark_lock);
+	guard(percpu_write)(&c->mark_lock);
 	struct accounting_mem_entry *dst = acc->k.data;
 
 	darray_for_each(acc->k, src) {
@@ -453,7 +452,6 @@ void bch2_accounting_mem_gc(struct bch_fs *c)
 	acc->k.nr = dst - acc->k.data;
 	eytzinger0_sort(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
 			accounting_pos_cmp, NULL);
-	percpu_up_write(&c->mark_lock);
 }
 
 /*
@@ -471,7 +469,7 @@ int bch2_fs_replicas_usage_read(struct bch_fs *c, darray_char *usage)
 
 	darray_init(usage);
 
-	percpu_down_read(&c->mark_lock);
+	guard(percpu_read)(&c->mark_lock);
 	darray_for_each(acc->k, i) {
 		union {
 			u8 bytes[struct_size_t(struct bch_replicas_usage, r.devs,
@@ -494,7 +492,6 @@ int bch2_fs_replicas_usage_read(struct bch_fs *c, darray_char *usage)
 		memcpy(&darray_top(*usage), &u.r, replicas_usage_bytes(&u.r));
 		usage->nr += replicas_usage_bytes(&u.r);
 	}
-	percpu_up_read(&c->mark_lock);
 
 	if (ret)
 		darray_exit(usage);
@@ -509,7 +506,7 @@ int bch2_fs_accounting_read(struct bch_fs *c, darray_char *out_buf, unsigned acc
 
 	darray_init(out_buf);
 
-	percpu_down_read(&c->mark_lock);
+	guard(percpu_read)(&c->mark_lock);
 	darray_for_each(acc->k, i) {
 		struct disk_accounting_pos a_p;
 		bpos_to_disk_accounting_pos(&a_p, i->pos);
@@ -533,8 +530,6 @@ int bch2_fs_accounting_read(struct bch_fs *c, darray_char *out_buf, unsigned acc
 			out_buf->nr += bkey_bytes(&a_out->k);
 	}
 
-	percpu_up_read(&c->mark_lock);
-
 	if (ret)
 		darray_exit(out_buf);
 	return ret;
@@ -553,7 +548,7 @@ int bch2_gc_accounting_start(struct bch_fs *c)
 	struct bch_accounting_mem *acc = &c->accounting;
 	int ret = 0;
 
-	percpu_down_write(&c->mark_lock);
+	guard(percpu_write)(&c->mark_lock);
 	darray_for_each(acc->k, e) {
 		e->v[1] = __alloc_percpu_gfp(e->nr_counters * sizeof(u64),
 					     sizeof(u64), GFP_KERNEL);
@@ -565,20 +560,18 @@ int bch2_gc_accounting_start(struct bch_fs *c)
 	}
 
 	acc->gc_running = !ret;
-	percpu_up_write(&c->mark_lock);
-
 	return ret;
 }
 
 int bch2_gc_accounting_done(struct bch_fs *c)
 {
 	struct bch_accounting_mem *acc = &c->accounting;
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct printbuf buf = PRINTBUF;
+	CLASS(btree_trans, trans)(c);
+	CLASS(printbuf, buf)();
 	struct bpos pos = POS_MIN;
 	int ret = 0;
 
-	percpu_down_write(&c->mark_lock);
+	guard(percpu_write)(&c->mark_lock);
 	while (1) {
 		unsigned idx = eytzinger0_find_ge(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
 						  accounting_pos_cmp, &pos);
@@ -638,20 +631,16 @@ int bch2_gc_accounting_done(struct bch_fs *c)
 								bkey_i_to_s_c_accounting(&k_i.k),
 								BCH_ACCOUNTING_normal, true);
 
-					preempt_disable();
+					guard(preempt)();
 					struct bch_fs_usage_base *dst = this_cpu_ptr(c->usage);
 					struct bch_fs_usage_base *src = &trans->fs_usage_delta;
 					acc_u64s((u64 *) dst, (u64 *) src, sizeof(*src) / sizeof(u64));
-					preempt_enable();
 				}
 			}
 		}
 	}
 err:
 fsck_err:
-	percpu_up_write(&c->mark_lock);
-	printbuf_exit(&buf);
-	bch2_trans_put(trans);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -663,11 +652,9 @@ static int accounting_read_key(struct btree_trans *trans, struct bkey_s_c k)
 	if (k.k->type != KEY_TYPE_accounting)
 		return 0;
 
-	percpu_down_read(&c->mark_lock);
-	int ret = bch2_accounting_mem_mod_locked(trans, bkey_s_c_to_accounting(k),
-						 BCH_ACCOUNTING_read, false);
-	percpu_up_read(&c->mark_lock);
-	return ret;
+	guard(percpu_read)(&c->mark_lock);
+	return bch2_accounting_mem_mod_locked(trans, bkey_s_c_to_accounting(k),
+					      BCH_ACCOUNTING_read, false);
 }
 
 static int bch2_disk_accounting_validate_late(struct btree_trans *trans,
@@ -675,7 +662,7 @@ static int bch2_disk_accounting_validate_late(struct btree_trans *trans,
 					      u64 *v, unsigned nr)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0, invalid_dev = -1;
 
 	switch (acc->type) {
@@ -724,7 +711,6 @@ static int bch2_disk_accounting_validate_late(struct btree_trans *trans,
 	}
 
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 invalid_device:
 	if (fsck_err(trans, accounting_to_invalid_device,
@@ -752,8 +738,8 @@ static int bch2_disk_accounting_validate_late(struct btree_trans *trans,
 int bch2_accounting_read(struct bch_fs *c)
 {
 	struct bch_accounting_mem *acc = &c->accounting;
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct printbuf buf = PRINTBUF;
+	CLASS(btree_trans, trans)(c);
+	CLASS(printbuf, buf)();
 
 	/*
 	 * We might run more than once if we rewind to start topology repair or
@@ -762,13 +748,13 @@ int bch2_accounting_read(struct bch_fs *c)
 	 *
 	 * Instead, zero out any accounting we have:
 	 */
-	percpu_down_write(&c->mark_lock);
-	darray_for_each(acc->k, e)
-		percpu_memset(e->v[0], 0, sizeof(u64) * e->nr_counters);
-	for_each_member_device(c, ca)
-		percpu_memset(ca->usage, 0, sizeof(*ca->usage));
-	percpu_memset(c->usage, 0, sizeof(*c->usage));
-	percpu_up_write(&c->mark_lock);
+	scoped_guard(percpu_write, &c->mark_lock) {
+		darray_for_each(acc->k, e)
+			percpu_memset(e->v[0], 0, sizeof(u64) * e->nr_counters);
+		for_each_member_device(c, ca)
+			percpu_memset(ca->usage, 0, sizeof(*ca->usage));
+		percpu_memset(c->usage, 0, sizeof(*c->usage));
+	}
 
 	struct btree_iter iter;
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_accounting, POS_MIN,
@@ -845,7 +831,7 @@ int bch2_accounting_read(struct bch_fs *c)
 	}
 	keys->gap = keys->nr = dst - keys->data;
 
-	percpu_down_write(&c->mark_lock);
+	guard(percpu_write)(&c->mark_lock);
 
 	darray_for_each_reverse(acc->k, i) {
 		struct disk_accounting_pos acc_k;
@@ -883,54 +869,51 @@ int bch2_accounting_read(struct bch_fs *c)
 	eytzinger0_sort(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
 			accounting_pos_cmp, NULL);
 
-	preempt_disable();
-	struct bch_fs_usage_base *usage = this_cpu_ptr(c->usage);
+	scoped_guard(preempt) {
+		struct bch_fs_usage_base *usage = this_cpu_ptr(c->usage);
 
-	for (unsigned i = 0; i < acc->k.nr; i++) {
-		struct disk_accounting_pos k;
-		bpos_to_disk_accounting_pos(&k, acc->k.data[i].pos);
+		for (unsigned i = 0; i < acc->k.nr; i++) {
+			struct disk_accounting_pos k;
+			bpos_to_disk_accounting_pos(&k, acc->k.data[i].pos);
 
-		u64 v[BCH_ACCOUNTING_MAX_COUNTERS];
-		bch2_accounting_mem_read_counters(acc, i, v, ARRAY_SIZE(v), false);
+			u64 v[BCH_ACCOUNTING_MAX_COUNTERS];
+			bch2_accounting_mem_read_counters(acc, i, v, ARRAY_SIZE(v), false);
 
-		switch (k.type) {
-		case BCH_DISK_ACCOUNTING_persistent_reserved:
-			usage->reserved += v[0] * k.persistent_reserved.nr_replicas;
-			break;
-		case BCH_DISK_ACCOUNTING_replicas:
-			fs_usage_data_type_to_base(usage, k.replicas.data_type, v[0]);
-			break;
-		case BCH_DISK_ACCOUNTING_dev_data_type: {
-			guard(rcu)();
-			struct bch_dev *ca = bch2_dev_rcu_noerror(c, k.dev_data_type.dev);
-			if (ca) {
-				struct bch_dev_usage_type __percpu *d = &ca->usage->d[k.dev_data_type.data_type];
-				percpu_u64_set(&d->buckets,	v[0]);
-				percpu_u64_set(&d->sectors,	v[1]);
-				percpu_u64_set(&d->fragmented,	v[2]);
-
-				if (k.dev_data_type.data_type == BCH_DATA_sb ||
-				    k.dev_data_type.data_type == BCH_DATA_journal)
-					usage->hidden += v[0] * ca->mi.bucket_size;
+			switch (k.type) {
+			case BCH_DISK_ACCOUNTING_persistent_reserved:
+				usage->reserved += v[0] * k.persistent_reserved.nr_replicas;
+				break;
+			case BCH_DISK_ACCOUNTING_replicas:
+				fs_usage_data_type_to_base(usage, k.replicas.data_type, v[0]);
+				break;
+			case BCH_DISK_ACCOUNTING_dev_data_type: {
+				guard(rcu)();
+				struct bch_dev *ca = bch2_dev_rcu_noerror(c, k.dev_data_type.dev);
+				if (ca) {
+					struct bch_dev_usage_type __percpu *d = &ca->usage->d[k.dev_data_type.data_type];
+					percpu_u64_set(&d->buckets,	v[0]);
+					percpu_u64_set(&d->sectors,	v[1]);
+					percpu_u64_set(&d->fragmented,	v[2]);
+
+					if (k.dev_data_type.data_type == BCH_DATA_sb ||
+					    k.dev_data_type.data_type == BCH_DATA_journal)
+						usage->hidden += v[0] * ca->mi.bucket_size;
+				}
+				break;
+			}
 			}
-			break;
-		}
 		}
 	}
-	preempt_enable();
 fsck_err:
-	percpu_up_write(&c->mark_lock);
 err:
-	printbuf_exit(&buf);
-	bch2_trans_put(trans);
 	bch_err_fn(c, ret);
 	return ret;
 }
 
 int bch2_dev_usage_remove(struct bch_fs *c, unsigned dev)
 {
-	return bch2_trans_run(c,
-		bch2_btree_write_buffer_flush_sync(trans) ?:
+	CLASS(btree_trans, trans)(c);
+	return bch2_btree_write_buffer_flush_sync(trans) ?:
 		for_each_btree_key_commit(trans, iter, BTREE_ID_accounting, POS_MIN,
 				BTREE_ITER_all_snapshots, k, NULL, NULL, 0, ({
 			struct disk_accounting_pos acc;
@@ -941,15 +924,16 @@ int bch2_dev_usage_remove(struct bch_fs *c, unsigned dev)
 				? bch2_btree_bit_mod_buffered(trans, BTREE_ID_accounting, k.k->p, 0)
 				: 0;
 		})) ?:
-		bch2_btree_write_buffer_flush_sync(trans));
+		bch2_btree_write_buffer_flush_sync(trans);
 }
 
 int bch2_dev_usage_init(struct bch_dev *ca, bool gc)
 {
 	struct bch_fs *c = ca->fs;
+	CLASS(btree_trans, trans)(c);
 	u64 v[3] = { ca->mi.nbuckets - ca->mi.first_bucket, 0, 0 };
 
-	int ret = bch2_trans_do(c, ({
+	int ret = lockrestart_do(trans, ({
 		bch2_disk_accounting_mod2(trans, gc,
 					  v, dev_data_type,
 					  .dev = ca->dev_idx,
@@ -965,78 +949,77 @@ void bch2_verify_accounting_clean(struct bch_fs *c)
 	bool mismatch = false;
 	struct bch_fs_usage_base base = {}, base_inmem = {};
 
-	bch2_trans_run(c,
-		for_each_btree_key(trans, iter,
-				   BTREE_ID_accounting, POS_MIN,
-				   BTREE_ITER_all_snapshots, k, ({
-			u64 v[BCH_ACCOUNTING_MAX_COUNTERS];
-			struct bkey_s_c_accounting a = bkey_s_c_to_accounting(k);
-			unsigned nr = bch2_accounting_counters(k.k);
+	CLASS(btree_trans, trans)(c);
+	for_each_btree_key(trans, iter,
+			   BTREE_ID_accounting, POS_MIN,
+			   BTREE_ITER_all_snapshots, k, ({
+		u64 v[BCH_ACCOUNTING_MAX_COUNTERS];
+		struct bkey_s_c_accounting a = bkey_s_c_to_accounting(k);
+		unsigned nr = bch2_accounting_counters(k.k);
 
-			struct disk_accounting_pos acc_k;
-			bpos_to_disk_accounting_pos(&acc_k, k.k->p);
+		struct disk_accounting_pos acc_k;
+		bpos_to_disk_accounting_pos(&acc_k, k.k->p);
 
-			if (acc_k.type >= BCH_DISK_ACCOUNTING_TYPE_NR)
-				break;
+		if (acc_k.type >= BCH_DISK_ACCOUNTING_TYPE_NR)
+			break;
 
-			if (!bch2_accounting_is_mem(&acc_k)) {
-				struct disk_accounting_pos next;
-				memset(&next, 0, sizeof(next));
-				next.type = acc_k.type + 1;
-				bch2_btree_iter_set_pos(trans, &iter, disk_accounting_pos_to_bpos(&next));
-				continue;
-			}
+		if (!bch2_accounting_is_mem(&acc_k)) {
+			struct disk_accounting_pos next;
+			memset(&next, 0, sizeof(next));
+			next.type = acc_k.type + 1;
+			bch2_btree_iter_set_pos(trans, &iter, disk_accounting_pos_to_bpos(&next));
+			continue;
+		}
 
-			bch2_accounting_mem_read(c, k.k->p, v, nr);
+		bch2_accounting_mem_read(c, k.k->p, v, nr);
 
-			if (memcmp(a.v->d, v, nr * sizeof(u64))) {
-				struct printbuf buf = PRINTBUF;
+		if (memcmp(a.v->d, v, nr * sizeof(u64))) {
+			CLASS(printbuf, buf)();
 
-				bch2_bkey_val_to_text(&buf, c, k);
-				prt_str(&buf, " !=");
-				for (unsigned j = 0; j < nr; j++)
-					prt_printf(&buf, " %llu", v[j]);
+			bch2_bkey_val_to_text(&buf, c, k);
+			prt_str(&buf, " !=");
+			for (unsigned j = 0; j < nr; j++)
+				prt_printf(&buf, " %llu", v[j]);
 
-				pr_err("%s", buf.buf);
-				printbuf_exit(&buf);
-				mismatch = true;
-			}
+			pr_err("%s", buf.buf);
+			mismatch = true;
+		}
 
-			switch (acc_k.type) {
-			case BCH_DISK_ACCOUNTING_persistent_reserved:
-				base.reserved += acc_k.persistent_reserved.nr_replicas * a.v->d[0];
-				break;
-			case BCH_DISK_ACCOUNTING_replicas:
-				fs_usage_data_type_to_base(&base, acc_k.replicas.data_type, a.v->d[0]);
-				break;
-			case BCH_DISK_ACCOUNTING_dev_data_type:
-				{
-					guard(rcu)(); /* scoped guard is a loop, and doesn't play nicely with continue */
-					struct bch_dev *ca = bch2_dev_rcu_noerror(c, acc_k.dev_data_type.dev);
-					if (!ca)
-						continue;
-
-					v[0] = percpu_u64_get(&ca->usage->d[acc_k.dev_data_type.data_type].buckets);
-					v[1] = percpu_u64_get(&ca->usage->d[acc_k.dev_data_type.data_type].sectors);
-					v[2] = percpu_u64_get(&ca->usage->d[acc_k.dev_data_type.data_type].fragmented);
-				}
+		switch (acc_k.type) {
+		case BCH_DISK_ACCOUNTING_persistent_reserved:
+			base.reserved += acc_k.persistent_reserved.nr_replicas * a.v->d[0];
+			break;
+		case BCH_DISK_ACCOUNTING_replicas:
+			fs_usage_data_type_to_base(&base, acc_k.replicas.data_type, a.v->d[0]);
+			break;
+		case BCH_DISK_ACCOUNTING_dev_data_type: {
+			{
+				guard(rcu)(); /* scoped guard is a loop, and doesn't play nicely with continue */
+				struct bch_dev *ca = bch2_dev_rcu_noerror(c, acc_k.dev_data_type.dev);
+				if (!ca)
+					continue;
+
+				v[0] = percpu_u64_get(&ca->usage->d[acc_k.dev_data_type.data_type].buckets);
+				v[1] = percpu_u64_get(&ca->usage->d[acc_k.dev_data_type.data_type].sectors);
+				v[2] = percpu_u64_get(&ca->usage->d[acc_k.dev_data_type.data_type].fragmented);
+			}
 
-				if (memcmp(a.v->d, v, 3 * sizeof(u64))) {
-					struct printbuf buf = PRINTBUF;
+			if (memcmp(a.v->d, v, 3 * sizeof(u64))) {
+				CLASS(printbuf, buf)();
 
-					bch2_bkey_val_to_text(&buf, c, k);
-					prt_str(&buf, " in mem");
-					for (unsigned j = 0; j < nr; j++)
-						prt_printf(&buf, " %llu", v[j]);
+				bch2_bkey_val_to_text(&buf, c, k);
+				prt_str(&buf, " in mem");
+				for (unsigned j = 0; j < nr; j++)
+					prt_printf(&buf, " %llu", v[j]);
 
-					pr_err("dev accounting mismatch: %s", buf.buf);
-					printbuf_exit(&buf);
-					mismatch = true;
-				}
+				pr_err("dev accounting mismatch: %s", buf.buf);
+				mismatch = true;
 			}
+		}
+		}
 
-			0;
-		})));
+		0;
+	}));
 
 	acc_u64s_percpu(&base_inmem.hidden, &c->usage->hidden, sizeof(base_inmem) / sizeof(u64));
 
diff --git a/fs/bcachefs/disk_accounting.h b/fs/bcachefs/disk_accounting.h
index d61abebf3e0b..43f4b21d0aab 100644
--- a/fs/bcachefs/disk_accounting.h
+++ b/fs/bcachefs/disk_accounting.h
@@ -211,10 +211,8 @@ static inline int bch2_accounting_mem_mod_locked(struct btree_trans *trans,
 
 static inline int bch2_accounting_mem_add(struct btree_trans *trans, struct bkey_s_c_accounting a, bool gc)
 {
-	percpu_down_read(&trans->c->mark_lock);
-	int ret = bch2_accounting_mem_mod_locked(trans, a, gc ? BCH_ACCOUNTING_gc : BCH_ACCOUNTING_normal, false);
-	percpu_up_read(&trans->c->mark_lock);
-	return ret;
+	guard(percpu_read)(&trans->c->mark_lock);
+	return bch2_accounting_mem_mod_locked(trans, a, gc ? BCH_ACCOUNTING_gc : BCH_ACCOUNTING_normal, false);
 }
 
 static inline void bch2_accounting_mem_read_counters(struct bch_accounting_mem *acc,
@@ -236,13 +234,12 @@ static inline void bch2_accounting_mem_read_counters(struct bch_accounting_mem *
 static inline void bch2_accounting_mem_read(struct bch_fs *c, struct bpos p,
 					    u64 *v, unsigned nr)
 {
-	percpu_down_read(&c->mark_lock);
+	guard(percpu_read)(&c->mark_lock);
 	struct bch_accounting_mem *acc = &c->accounting;
 	unsigned idx = eytzinger0_find(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
 				       accounting_pos_cmp, &p);
 
 	bch2_accounting_mem_read_counters(acc, idx, v, nr, false);
-	percpu_up_read(&c->mark_lock);
 }
 
 static inline struct bversion journal_pos_to_bversion(struct journal_res *res, unsigned offset)
-- 
2.51.0


From 36c244bb6a705bf014896cb6b3e87d7c3a035a04 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:30:55 -0400
Subject: [PATCH 137/309] bcachefs: convert buckets.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/buckets.c | 212 ++++++++++++++++++------------------------
 1 file changed, 88 insertions(+), 124 deletions(-)

diff --git a/fs/bcachefs/buckets.c b/fs/bcachefs/buckets.c
index f25903c10e8a..5aab527e3e7c 100644
--- a/fs/bcachefs/buckets.c
+++ b/fs/bcachefs/buckets.c
@@ -71,13 +71,8 @@ __bch2_fs_usage_read_short(struct bch_fs *c)
 struct bch_fs_usage_short
 bch2_fs_usage_read_short(struct bch_fs *c)
 {
-	struct bch_fs_usage_short ret;
-
-	percpu_down_read(&c->mark_lock);
-	ret = __bch2_fs_usage_read_short(c);
-	percpu_up_read(&c->mark_lock);
-
-	return ret;
+	guard(percpu_read)(&c->mark_lock);
+	return __bch2_fs_usage_read_short(c);
 }
 
 void bch2_dev_usage_to_text(struct printbuf *out,
@@ -113,10 +108,10 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 			      bool *do_update)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
-	struct bch_dev *ca = bch2_dev_tryget(c, p.ptr.dev);
+	CLASS(bch2_dev_tryget, ca)(c, p.ptr.dev);
 	if (!ca) {
 		if (fsck_err_on(p.ptr.dev != BCH_SB_MEMBER_INVALID,
 				trans, ptr_to_invalid_device,
@@ -138,7 +133,7 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 			     (printbuf_reset(&buf),
 			      bch2_bkey_val_to_text(&buf, c, k), buf.buf)))
 			*do_update = true;
-		goto out;
+		return 0;
 	}
 
 	enum bch_data_type data_type = bch2_bkey_ptr_data_type(k, p, entry);
@@ -158,7 +153,7 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 		} else {
 			/* this pointer will be dropped */
 			*do_update = true;
-			goto out;
+			return 0;
 		}
 	}
 
@@ -208,7 +203,7 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 		*do_update = true;
 
 	if (data_type != BCH_DATA_btree && p.ptr.gen != g->gen)
-		goto out;
+		return 0;
 
 	if (fsck_err_on(bucket_data_type_mismatch(g->data_type, data_type),
 			trans, ptr_bucket_data_type_mismatch,
@@ -224,14 +219,13 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 			switch (g->data_type) {
 			case BCH_DATA_sb:
 				bch_err(c, "btree and superblock in the same bucket - cannot repair");
-				ret = bch_err_throw(c, fsck_repair_unimplemented);
-				goto out;
+				return bch_err_throw(c, fsck_repair_unimplemented);
 			case BCH_DATA_journal:
 				ret = bch2_dev_journal_bucket_delete(ca, PTR_BUCKET_NR(ca, &p.ptr));
 				bch_err_msg(c, ret, "error deleting journal bucket %zu",
 					    PTR_BUCKET_NR(ca, &p.ptr));
 				if (ret)
-					goto out;
+					return ret;
 				break;
 			}
 
@@ -265,10 +259,7 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 				 bch2_bkey_val_to_text(&buf, c, k), buf.buf)))
 			*do_update = true;
 	}
-out:
 fsck_err:
-	bch2_dev_put(ca);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -281,7 +272,7 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 	const union bch_extent_entry *entry_c;
 	struct extent_ptr_decoded p = { 0 };
 	bool do_update = false;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	/* We don't yet do btree key updates correctly for when we're RW */
@@ -290,14 +281,14 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 	bkey_for_each_ptr_decode(k.k, ptrs_c, p, entry_c) {
 		ret = bch2_check_fix_ptr(trans, k, p, entry_c, &do_update);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (do_update) {
 		struct bkey_i *new = bch2_bkey_make_mut_noupdate(trans, k);
 		ret = PTR_ERR_OR_ZERO(new);
 		if (ret)
-			goto err;
+			return ret;
 
 		scoped_guard(rcu)
 			bch2_bkey_drop_ptrs(bkey_i_to_s(new), ptr, !bch2_dev_exists(c, ptr->dev));
@@ -387,7 +378,7 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 						  BTREE_TRIGGER_norun);
 			bch2_trans_iter_exit(trans, &iter);
 			if (ret)
-				goto err;
+				return ret;
 
 			if (level)
 				bch2_btree_node_update_key_early(trans, btree, level - 1, k, new);
@@ -396,7 +387,7 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 					       jset_u64s(new->k.u64s));
 			ret = PTR_ERR_OR_ZERO(e);
 			if (ret)
-				goto err;
+				return ret;
 
 			journal_entry_set(e,
 					  BCH_JSET_ENTRY_btree_root,
@@ -413,9 +404,8 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 			bkey_copy(&b->key, new);
 		}
 	}
-err:
-	printbuf_exit(&buf);
-	return ret;
+
+	return 0;
 }
 
 static int bucket_ref_update_err(struct btree_trans *trans, struct printbuf *buf,
@@ -460,9 +450,8 @@ int bch2_bucket_ref_update(struct btree_trans *trans, struct bch_dev *ca,
 {
 	struct bch_fs *c = trans->c;
 	size_t bucket_nr = PTR_BUCKET_NR(ca, ptr);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool inserting = sectors > 0;
-	int ret = 0;
 
 	BUG_ON(!sectors);
 
@@ -474,9 +463,8 @@ int bch2_bucket_ref_update(struct btree_trans *trans, struct bch_dev *ca,
 			bch2_data_type_str(bucket_data_type ?: ptr_data_type),
 			ptr->gen);
 
-		ret = bucket_ref_update_err(trans, &buf, k, inserting,
-					    BCH_FSCK_ERR_ptr_gen_newer_than_bucket_gen);
-		goto out;
+		return bucket_ref_update_err(trans, &buf, k, inserting,
+					     BCH_FSCK_ERR_ptr_gen_newer_than_bucket_gen);
 	}
 
 	if (unlikely(gen_cmp(b_gen, ptr->gen) > BUCKET_GC_GEN_MAX)) {
@@ -487,15 +475,12 @@ int bch2_bucket_ref_update(struct btree_trans *trans, struct bch_dev *ca,
 			bch2_data_type_str(bucket_data_type ?: ptr_data_type),
 			ptr->gen);
 
-		ret = bucket_ref_update_err(trans, &buf, k, inserting,
-					    BCH_FSCK_ERR_ptr_too_stale);
-		goto out;
+		return bucket_ref_update_err(trans, &buf, k, inserting,
+					     BCH_FSCK_ERR_ptr_too_stale);
 	}
 
-	if (b_gen != ptr->gen && ptr->cached) {
-		ret = 1;
-		goto out;
-	}
+	if (b_gen != ptr->gen && ptr->cached)
+		return 1;
 
 	if (unlikely(b_gen != ptr->gen)) {
 		bch2_log_msg_start(c, &buf);
@@ -506,9 +491,8 @@ int bch2_bucket_ref_update(struct btree_trans *trans, struct bch_dev *ca,
 			bch2_data_type_str(bucket_data_type ?: ptr_data_type),
 			ptr->gen);
 
-		ret = bucket_ref_update_err(trans, &buf, k, inserting,
-					    BCH_FSCK_ERR_stale_dirty_ptr);
-		goto out;
+		return bucket_ref_update_err(trans, &buf, k, inserting,
+					     BCH_FSCK_ERR_stale_dirty_ptr);
 	}
 
 	if (unlikely(bucket_data_type_mismatch(bucket_data_type, ptr_data_type))) {
@@ -518,9 +502,8 @@ int bch2_bucket_ref_update(struct btree_trans *trans, struct bch_dev *ca,
 			   bch2_data_type_str(bucket_data_type),
 			   bch2_data_type_str(ptr_data_type));
 
-		ret = bucket_ref_update_err(trans, &buf, k, inserting,
+		return bucket_ref_update_err(trans, &buf, k, inserting,
 					    BCH_FSCK_ERR_ptr_bucket_data_type_mismatch);
-		goto out;
 	}
 
 	if (unlikely((u64) *bucket_sectors + sectors > U32_MAX)) {
@@ -531,16 +514,13 @@ int bch2_bucket_ref_update(struct btree_trans *trans, struct bch_dev *ca,
 			bch2_data_type_str(bucket_data_type ?: ptr_data_type),
 			*bucket_sectors, sectors);
 
-		ret = bucket_ref_update_err(trans, &buf, k, inserting,
-					    BCH_FSCK_ERR_bucket_sector_count_overflow);
 		sectors = -*bucket_sectors;
-		goto out;
+		return bucket_ref_update_err(trans, &buf, k, inserting,
+					    BCH_FSCK_ERR_bucket_sector_count_overflow);
 	}
 
 	*bucket_sectors += sectors;
-out:
-	printbuf_exit(&buf);
-	return ret;
+	return 0;
 }
 
 void bch2_trans_account_disk_usage_change(struct btree_trans *trans)
@@ -550,7 +530,7 @@ void bch2_trans_account_disk_usage_change(struct btree_trans *trans)
 	static int warned_disk_usage = 0;
 	bool warn = false;
 
-	percpu_down_read(&c->mark_lock);
+	guard(percpu_read)(&c->mark_lock);
 	struct bch_fs_usage_base *src = &trans->fs_usage_delta;
 
 	s64 added = src->btree + src->data + src->reserved;
@@ -578,11 +558,10 @@ void bch2_trans_account_disk_usage_change(struct btree_trans *trans)
 		this_cpu_sub(*c->online_reserved, added);
 	}
 
-	preempt_disable();
-	struct bch_fs_usage_base *dst = this_cpu_ptr(c->usage);
-	acc_u64s((u64 *) dst, (u64 *) src, sizeof(*src) / sizeof(u64));
-	preempt_enable();
-	percpu_up_read(&c->mark_lock);
+	scoped_guard(preempt) {
+		struct bch_fs_usage_base *dst = this_cpu_ptr(c->usage);
+		acc_u64s((u64 *) dst, (u64 *) src, sizeof(*src) / sizeof(u64));
+	}
 
 	if (unlikely(warn) && !xchg(&warned_disk_usage, 1))
 		bch2_trans_inconsistent(trans,
@@ -621,40 +600,34 @@ static int bch2_trigger_pointer(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	bool insert = !(flags & BTREE_TRIGGER_overwrite);
-	struct printbuf buf = PRINTBUF;
-	int ret = 0;
+	CLASS(printbuf, buf)();
 
 	struct bkey_i_backpointer bp;
 	bch2_extent_ptr_to_bp(c, btree_id, level, k, p, entry, &bp);
 
 	*sectors = insert ? bp.v.bucket_len : -(s64) bp.v.bucket_len;
 
-	struct bch_dev *ca = bch2_dev_tryget(c, p.ptr.dev);
+	CLASS(bch2_dev_tryget, ca)(c, p.ptr.dev);
 	if (unlikely(!ca)) {
 		if (insert && p.ptr.dev != BCH_SB_MEMBER_INVALID)
-			ret = bch_err_throw(c, trigger_pointer);
-		goto err;
+			return bch_err_throw(c, trigger_pointer);
+		return 0;
 	}
 
 	struct bpos bucket = PTR_BUCKET_POS(ca, &p.ptr);
 	if (!bucket_valid(ca, bucket.offset)) {
 		if (insert) {
 			bch2_dev_bucket_missing(ca, bucket.offset);
-			ret = bch_err_throw(c, trigger_pointer);
+			return bch_err_throw(c, trigger_pointer);
 		}
-		goto err;
+		return 0;
 	}
 
 	if (flags & BTREE_TRIGGER_transactional) {
 		struct bkey_i_alloc_v4 *a = bch2_trans_start_alloc_update(trans, bucket, 0);
-		ret = PTR_ERR_OR_ZERO(a) ?:
-			__mark_pointer(trans, ca, k, &p, *sectors, bp.v.data_type, &a->v, insert);
-		if (ret)
-			goto err;
-
-		ret = bch2_bucket_backpointer_mod(trans, k, &bp, insert);
-		if (ret)
-			goto err;
+		return PTR_ERR_OR_ZERO(a) ?:
+			__mark_pointer(trans, ca, k, &p, *sectors, bp.v.data_type, &a->v, insert) ?:
+			bch2_bucket_backpointer_mod(trans, k, &bp, insert);
 	}
 
 	if (flags & BTREE_TRIGGER_gc) {
@@ -662,23 +635,22 @@ static int bch2_trigger_pointer(struct btree_trans *trans,
 		if (bch2_fs_inconsistent_on(!g, c, "reference to invalid bucket on device %u\n  %s",
 					    p.ptr.dev,
 					    (bch2_bkey_val_to_text(&buf, c, k), buf.buf))) {
-			ret = bch_err_throw(c, trigger_pointer);
-			goto err;
+			return bch_err_throw(c, trigger_pointer);
 		}
 
 		bucket_lock(g);
 		struct bch_alloc_v4 old = bucket_m_to_alloc(*g), new = old;
-		ret = __mark_pointer(trans, ca, k, &p, *sectors, bp.v.data_type, &new, insert);
+		int ret = __mark_pointer(trans, ca, k, &p, *sectors, bp.v.data_type, &new, insert);
 		alloc_to_bucket(g, new);
 		bucket_unlock(g);
 
-		if (!ret)
-			ret = bch2_alloc_key_to_dev_counters(trans, ca, &old, &new, flags);
+		if (ret)
+			return ret;
+
+		return bch2_alloc_key_to_dev_counters(trans, ca, &old, &new, flags);
 	}
-err:
-	bch2_dev_put(ca);
-	printbuf_exit(&buf);
-	return ret;
+
+	return 0;
 }
 
 static int bch2_trigger_stripe_ptr(struct btree_trans *trans,
@@ -738,14 +710,13 @@ static int bch2_trigger_stripe_ptr(struct btree_trans *trans,
 
 		if (!m || !m->alive) {
 			gc_stripe_unlock(m);
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			bch2_log_msg_start(c, &buf);
 			prt_printf(&buf, "pointer to nonexistent stripe %llu\n  while marking ",
 				   (u64) p.ec.idx);
 			bch2_bkey_val_to_text(&buf, c, k);
 			__bch2_inconsistent_error(c, &buf);
 			bch2_print_str(c, KERN_ERR, buf.buf);
-			printbuf_exit(&buf);
 			return bch_err_throw(c, trigger_stripe_pointer);
 		}
 
@@ -996,7 +967,7 @@ static int __bch2_trans_mark_metadata_bucket(struct btree_trans *trans,
 		return PTR_ERR(a);
 
 	if (a->v.data_type && type && a->v.data_type != type) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 		prt_printf(&buf, "bucket %llu:%llu gen %u different types of data in same bucket: %s, %s\n"
 			   "while marking %s\n",
@@ -1012,7 +983,6 @@ static int __bch2_trans_mark_metadata_bucket(struct btree_trans *trans,
 
 		/* Always print, this is always fatal */
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 		if (!ret)
 			ret = bch_err_throw(c, metadata_bucket_inconsistency);
 		goto err;
@@ -1034,7 +1004,6 @@ static int bch2_mark_metadata_bucket(struct btree_trans *trans, struct bch_dev *
 			enum btree_iter_update_trigger_flags flags)
 {
 	struct bch_fs *c = trans->c;
-	int ret = 0;
 
 	struct bucket *g = gc_bucket(ca, b);
 	if (bch2_fs_inconsistent_on(!g, c, "reference to invalid bucket on device %u when marking metadata type %s",
@@ -1062,8 +1031,7 @@ static int bch2_mark_metadata_bucket(struct btree_trans *trans, struct bch_dev *
 	g->dirty_sectors += sectors;
 	struct bch_alloc_v4 new = bucket_m_to_alloc(*g);
 	bucket_unlock(g);
-	ret = bch2_alloc_key_to_dev_counters(trans, ca, &old, &new, flags);
-	return ret;
+	return bch2_alloc_key_to_dev_counters(trans, ca, &old, &new, flags);
 err_unlock:
 	bucket_unlock(g);
 err:
@@ -1125,10 +1093,10 @@ static int __bch2_trans_mark_dev_sb(struct btree_trans *trans, struct bch_dev *c
 			enum btree_iter_update_trigger_flags flags)
 {
 	struct bch_fs *c = trans->c;
+	struct bch_sb_layout layout;
 
-	mutex_lock(&c->sb_lock);
-	struct bch_sb_layout layout = ca->disk_sb.sb->layout;
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock)
+		layout = ca->disk_sb.sb->layout;
 
 	u64 bucket = 0;
 	unsigned i, bucket_sectors = 0;
@@ -1173,8 +1141,8 @@ static int __bch2_trans_mark_dev_sb(struct btree_trans *trans, struct bch_dev *c
 int bch2_trans_mark_dev_sb(struct bch_fs *c, struct bch_dev *ca,
 			enum btree_iter_update_trigger_flags flags)
 {
-	int ret = bch2_trans_run(c,
-		__bch2_trans_mark_dev_sb(trans, ca, flags));
+	CLASS(btree_trans, trans)(c);
+	int ret = __bch2_trans_mark_dev_sb(trans, ca, flags);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1227,15 +1195,38 @@ bool bch2_is_superblock_bucket(struct bch_dev *ca, u64 b)
 
 #define SECTORS_CACHE	1024
 
+static int disk_reservation_recalc_sectors_available(struct bch_fs *c,
+			struct disk_reservation *res,
+			u64 sectors, enum bch_reservation_flags flags)
+{
+	guard(mutex)(&c->sectors_available_lock);
+
+	percpu_u64_set(&c->pcpu->sectors_available, 0);
+	u64 sectors_available = avail_factor(__bch2_fs_usage_read_short(c).free);
+
+	if (sectors_available && (flags & BCH_DISK_RESERVATION_PARTIAL))
+		sectors = min(sectors, sectors_available);
+
+	if (sectors <= sectors_available ||
+	    (flags & BCH_DISK_RESERVATION_NOFAIL)) {
+		atomic64_set(&c->sectors_available,
+			     max_t(s64, 0, sectors_available - sectors));
+		this_cpu_add(*c->online_reserved, sectors);
+		res->sectors			+= sectors;
+		return 0;
+	} else {
+		atomic64_set(&c->sectors_available, sectors_available);
+		return bch_err_throw(c, ENOSPC_disk_reservation);
+	}
+}
+
 int __bch2_disk_reservation_add(struct bch_fs *c, struct disk_reservation *res,
 				u64 sectors, enum bch_reservation_flags flags)
 {
 	struct bch_fs_pcpu *pcpu;
 	u64 old, get;
-	u64 sectors_available;
-	int ret;
 
-	percpu_down_read(&c->mark_lock);
+	guard(percpu_read)(&c->mark_lock);
 	preempt_disable();
 	pcpu = this_cpu_ptr(c->pcpu);
 
@@ -1246,9 +1237,10 @@ int __bch2_disk_reservation_add(struct bch_fs *c, struct disk_reservation *res,
 	do {
 		get = min((u64) sectors + SECTORS_CACHE, old);
 
-		if (get < sectors) {
+		if (unlikely(get < sectors)) {
 			preempt_enable();
-			goto recalculate;
+			return disk_reservation_recalc_sectors_available(c,
+							res, sectors, flags);
 		}
 	} while (!atomic64_try_cmpxchg(&c->sectors_available,
 				       &old, old - get));
@@ -1259,36 +1251,8 @@ int __bch2_disk_reservation_add(struct bch_fs *c, struct disk_reservation *res,
 	pcpu->sectors_available		-= sectors;
 	this_cpu_add(*c->online_reserved, sectors);
 	res->sectors			+= sectors;
-
 	preempt_enable();
-	percpu_up_read(&c->mark_lock);
 	return 0;
-
-recalculate:
-	mutex_lock(&c->sectors_available_lock);
-
-	percpu_u64_set(&c->pcpu->sectors_available, 0);
-	sectors_available = avail_factor(__bch2_fs_usage_read_short(c).free);
-
-	if (sectors_available && (flags & BCH_DISK_RESERVATION_PARTIAL))
-		sectors = min(sectors, sectors_available);
-
-	if (sectors <= sectors_available ||
-	    (flags & BCH_DISK_RESERVATION_NOFAIL)) {
-		atomic64_set(&c->sectors_available,
-			     max_t(s64, 0, sectors_available - sectors));
-		this_cpu_add(*c->online_reserved, sectors);
-		res->sectors			+= sectors;
-		ret = 0;
-	} else {
-		atomic64_set(&c->sectors_available, sectors_available);
-		ret = bch_err_throw(c, ENOSPC_disk_reservation);
-	}
-
-	mutex_unlock(&c->sectors_available_lock);
-	percpu_up_read(&c->mark_lock);
-
-	return ret;
 }
 
 /* Startup/shutdown: */
-- 
2.51.0


From 3e129e7487ad759d619f1a81b5722c0774927d83 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:31:15 -0400
Subject: [PATCH 138/309] bcachefs: convert ec.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/ec.c | 224 ++++++++++++++++++-----------------------------
 fs/bcachefs/ec.h |   2 +-
 2 files changed, 87 insertions(+), 139 deletions(-)

diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index 6150232b2c61..62dda821247e 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -197,8 +197,7 @@ static int __mark_stripe_bucket(struct btree_trans *trans,
 	bool parity = ptr_idx >= nr_data;
 	enum bch_data_type data_type = parity ? BCH_DATA_parity : BCH_DATA_stripe;
 	s64 sectors = parity ? le16_to_cpu(s.v->sectors) : 0;
-	struct printbuf buf = PRINTBUF;
-	int ret = 0;
+	CLASS(printbuf, buf)();
 
 	struct bch_fs *c = trans->c;
 	if (deleting)
@@ -212,10 +211,8 @@ static int __mark_stripe_bucket(struct btree_trans *trans,
 				bch2_data_type_str(a->data_type),
 				a->dirty_sectors,
 				a->stripe, s.k->p.offset,
-				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf))) {
-			ret = bch_err_throw(c, mark_stripe);
-			goto err;
-		}
+				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf)))
+			return bch_err_throw(c, mark_stripe);
 
 		if (bch2_trans_inconsistent_on(parity && bch2_bucket_sectors_total(*a), trans,
 				"bucket %llu:%llu gen %u data type %s dirty_sectors %u cached_sectors %u: data already in parity bucket\n%s",
@@ -223,30 +220,24 @@ static int __mark_stripe_bucket(struct btree_trans *trans,
 				bch2_data_type_str(a->data_type),
 				a->dirty_sectors,
 				a->cached_sectors,
-				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf))) {
-			ret = bch_err_throw(c, mark_stripe);
-			goto err;
-		}
+				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf)))
+			return bch_err_throw(c, mark_stripe);
 	} else {
 		if (bch2_trans_inconsistent_on(a->stripe != s.k->p.offset ||
 					       a->stripe_redundancy != s.v->nr_redundant, trans,
 				"bucket %llu:%llu gen %u: not marked as stripe when deleting stripe (got %u)\n%s",
 				bucket.inode, bucket.offset, a->gen,
 				a->stripe,
-				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf))) {
-			ret = bch_err_throw(c, mark_stripe);
-			goto err;
-		}
+				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf)))
+			return bch_err_throw(c, mark_stripe);
 
 		if (bch2_trans_inconsistent_on(a->data_type != data_type, trans,
 				"bucket %llu:%llu gen %u data type %s: wrong data type when stripe, should be %s\n%s",
 				bucket.inode, bucket.offset, a->gen,
 				bch2_data_type_str(a->data_type),
 				bch2_data_type_str(data_type),
-				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf))) {
-			ret = bch_err_throw(c, mark_stripe);
-			goto err;
-		}
+				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf)))
+			return bch_err_throw(c, mark_stripe);
 
 		if (bch2_trans_inconsistent_on(parity &&
 					       (a->dirty_sectors != -sectors ||
@@ -255,17 +246,15 @@ static int __mark_stripe_bucket(struct btree_trans *trans,
 				bucket.inode, bucket.offset, a->gen,
 				a->dirty_sectors,
 				a->cached_sectors,
-				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf))) {
-			ret = bch_err_throw(c, mark_stripe);
-			goto err;
-		}
+				(bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf)))
+			return bch_err_throw(c, mark_stripe);
 	}
 
 	if (sectors) {
-		ret = bch2_bucket_ref_update(trans, ca, s.s_c, ptr, sectors, data_type,
-					     a->gen, a->data_type, &a->dirty_sectors);
+		int ret = bch2_bucket_ref_update(trans, ca, s.s_c, ptr, sectors, data_type,
+						 a->gen, a->data_type, &a->dirty_sectors);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (!deleting) {
@@ -277,9 +266,8 @@ static int __mark_stripe_bucket(struct btree_trans *trans,
 		a->stripe_redundancy	= 0;
 		alloc_data_type_set(a, BCH_DATA_user);
 	}
-err:
-	printbuf_exit(&buf);
-	return ret;
+
+	return 0;
 }
 
 static int mark_stripe_bucket(struct btree_trans *trans,
@@ -289,14 +277,13 @@ static int mark_stripe_bucket(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	const struct bch_extent_ptr *ptr = s.v->ptrs + ptr_idx;
-	struct printbuf buf = PRINTBUF;
-	int ret = 0;
+	CLASS(printbuf, buf)();
 
-	struct bch_dev *ca = bch2_dev_tryget(c, ptr->dev);
+	CLASS(bch2_dev_tryget, ca)(c, ptr->dev);
 	if (unlikely(!ca)) {
 		if (ptr->dev != BCH_SB_MEMBER_INVALID && !(flags & BTREE_TRIGGER_overwrite))
-			ret = bch_err_throw(c, mark_stripe);
-		goto err;
+			return bch_err_throw(c, mark_stripe);
+		return 0;
 	}
 
 	struct bpos bucket = PTR_BUCKET_POS(ca, ptr);
@@ -312,36 +299,32 @@ static int mark_stripe_bucket(struct btree_trans *trans,
 
 		struct bkey_i_alloc_v4 *a =
 			bch2_trans_start_alloc_update(trans, bucket, 0);
-		ret   = PTR_ERR_OR_ZERO(a) ?:
+		int ret = PTR_ERR_OR_ZERO(a) ?:
 			__mark_stripe_bucket(trans, ca, s, ptr_idx, deleting, bucket, &a->v, flags) ?:
 			bch2_bucket_backpointer_mod(trans, s.s_c, &bp,
 						    !(flags & BTREE_TRIGGER_overwrite));
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (flags & BTREE_TRIGGER_gc) {
 		struct bucket *g = gc_bucket(ca, bucket.offset);
 		if (bch2_fs_inconsistent_on(!g, c, "reference to invalid bucket on device %u\n%s",
 					    ptr->dev,
-					    (bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf))) {
-			ret = bch_err_throw(c, mark_stripe);
-			goto err;
-		}
+					    (bch2_bkey_val_to_text(&buf, c, s.s_c), buf.buf)))
+			return bch_err_throw(c, mark_stripe);
 
 		bucket_lock(g);
 		struct bch_alloc_v4 old = bucket_m_to_alloc(*g), new = old;
-		ret = __mark_stripe_bucket(trans, ca, s, ptr_idx, deleting, bucket, &new, flags);
+		int ret = __mark_stripe_bucket(trans, ca, s, ptr_idx, deleting, bucket, &new, flags);
 		alloc_to_bucket(g, new);
 		bucket_unlock(g);
 
 		if (!ret)
 			ret = bch2_alloc_key_to_dev_counters(trans, ca, &old, &new, flags);
 	}
-err:
-	bch2_dev_put(ca);
-	printbuf_exit(&buf);
-	return ret;
+
+	return 0;
 }
 
 static int mark_stripe_buckets(struct btree_trans *trans,
@@ -630,16 +613,15 @@ static void ec_validate_checksums(struct bch_fs *c, struct ec_stripe_buf *buf)
 			struct bch_csum got = ec_block_checksum(buf, i, offset);
 
 			if (bch2_crc_cmp(want, got)) {
-				struct bch_dev *ca = bch2_dev_tryget(c, v->ptrs[i].dev);
+				CLASS(bch2_dev_tryget, ca)(c, v->ptrs[i].dev);
 				if (ca) {
-					struct printbuf err = PRINTBUF;
+					CLASS(printbuf, err)();
 
 					prt_str(&err, "stripe ");
 					bch2_csum_err_msg(&err, v->csum_type, want, got);
 					prt_printf(&err, "  for %ps at %u of\n  ", (void *) _RET_IP_, i);
 					bch2_bkey_val_to_text(&err, c, bkey_i_to_s_c(&buf->key));
 					bch_err_ratelimited(ca, "%s", err.buf);
-					printbuf_exit(&err);
 
 					bch2_io_error(ca, BCH_MEMBER_ERROR_checksum);
 				}
@@ -832,7 +814,7 @@ int bch2_ec_read_extent(struct btree_trans *trans, struct bch_read_bio *rbio,
 	struct bch_stripe *v;
 	unsigned i, offset;
 	const char *msg = NULL;
-	struct printbuf msgbuf = PRINTBUF;
+	CLASS(printbuf, msgbuf)();
 	int ret = 0;
 
 	closure_init_stack(&cl);
@@ -894,7 +876,6 @@ int bch2_ec_read_extent(struct btree_trans *trans, struct bch_read_bio *rbio,
 	bch2_bkey_val_to_text(&msgbuf, c, orig_k);
 	bch_err_ratelimited(c,
 			    "error doing reconstruct read: %s\n  %s", msg, msgbuf.buf);
-	printbuf_exit(&msgbuf);
 	ret = bch_err_throw(c, stripe_reconstruct);
 	goto out;
 }
@@ -936,31 +917,22 @@ static bool __bch2_stripe_is_open(struct bch_fs *c, u64 idx)
 
 static bool bch2_stripe_is_open(struct bch_fs *c, u64 idx)
 {
-	bool ret = false;
-
-	spin_lock(&c->ec_stripes_new_lock);
-	ret = __bch2_stripe_is_open(c, idx);
-	spin_unlock(&c->ec_stripes_new_lock);
-
-	return ret;
+	guard(spinlock)(&c->ec_stripes_new_lock);
+	return __bch2_stripe_is_open(c, idx);
 }
 
 static bool bch2_try_open_stripe(struct bch_fs *c,
 				 struct ec_stripe_new *s,
 				 u64 idx)
 {
-	bool ret;
-
-	spin_lock(&c->ec_stripes_new_lock);
-	ret = !__bch2_stripe_is_open(c, idx);
+	guard(spinlock)(&c->ec_stripes_new_lock);
+	bool ret = !__bch2_stripe_is_open(c, idx);
 	if (ret) {
 		unsigned hash = hash_64(idx, ilog2(ARRAY_SIZE(c->ec_stripes_new)));
 
 		s->idx = idx;
 		hlist_add_head(&s->hash, &c->ec_stripes_new[hash]);
 	}
-	spin_unlock(&c->ec_stripes_new_lock);
-
 	return ret;
 }
 
@@ -968,9 +940,8 @@ static void bch2_stripe_close(struct bch_fs *c, struct ec_stripe_new *s)
 {
 	BUG_ON(!s->idx);
 
-	spin_lock(&c->ec_stripes_new_lock);
+	guard(spinlock)(&c->ec_stripes_new_lock);
 	hlist_del_init(&s->hash);
-	spin_unlock(&c->ec_stripes_new_lock);
 
 	s->idx = 0;
 }
@@ -1063,7 +1034,7 @@ static int ec_stripe_key_update(struct btree_trans *trans,
 			unsigned sectors = stripe_blockcount_get(v, i);
 
 			if (!bch2_extent_ptr_eq(old->v.ptrs[i], new->v.ptrs[i]) && sectors) {
-				struct printbuf buf = PRINTBUF;
+				CLASS(printbuf, buf)();
 
 				prt_printf(&buf, "stripe changed nonempty block %u", i);
 				prt_str(&buf, "\nold: ");
@@ -1071,7 +1042,6 @@ static int ec_stripe_key_update(struct btree_trans *trans,
 				prt_str(&buf, "\nnew: ");
 				bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&new->k_i));
 				bch2_fs_inconsistent(c, "%s", buf.buf);
-				printbuf_exit(&buf);
 				ret = -EINVAL;
 				goto err;
 			}
@@ -1115,21 +1085,18 @@ static int ec_stripe_update_extent(struct btree_trans *trans,
 	int ret, dev, block;
 
 	if (bp.v->level) {
-		struct printbuf buf = PRINTBUF;
 		struct btree_iter node_iter;
-		struct btree *b;
-
-		b = bch2_backpointer_get_node(trans, bp, &node_iter, last_flushed);
+		struct btree *b = bch2_backpointer_get_node(trans, bp, &node_iter, last_flushed);
 		bch2_trans_iter_exit(trans, &node_iter);
 
 		if (!b)
 			return 0;
 
+		CLASS(printbuf, buf)();
 		prt_printf(&buf, "found btree node in erasure coded bucket: b=%px\n", b);
 		bch2_bkey_val_to_text(&buf, c, bp.s_c);
 
 		bch2_fs_inconsistent(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 		return bch_err_throw(c, erasure_coding_found_btree_node);
 	}
 
@@ -1194,7 +1161,7 @@ static int ec_stripe_update_bucket(struct btree_trans *trans, struct ec_stripe_b
 	struct bch_extent_ptr ptr = v->ptrs[block];
 	int ret = 0;
 
-	struct bch_dev *ca = bch2_dev_tryget(c, ptr.dev);
+	CLASS(bch2_dev_tryget, ca)(c, ptr.dev);
 	if (!ca)
 		return bch_err_throw(c, ENOENT_dev_not_found);
 
@@ -1225,28 +1192,26 @@ static int ec_stripe_update_bucket(struct btree_trans *trans, struct ec_stripe_b
 	}));
 
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch2_dev_put(ca);
 	return ret;
 }
 
 static int ec_stripe_update_extents(struct bch_fs *c, struct ec_stripe_buf *s)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct bch_stripe *v = &bkey_i_to_stripe(&s->key)->v;
 	unsigned nr_data = v->nr_blocks - v->nr_redundant;
 
 	int ret = bch2_btree_write_buffer_flush_sync(trans);
 	if (ret)
-		goto err;
+		return ret;
 
 	for (unsigned i = 0; i < nr_data; i++) {
 		ret = ec_stripe_update_bucket(trans, s, i);
 		if (ret)
-			break;
+			return ret;
 	}
-err:
-	bch2_trans_put(trans);
-	return ret;
+
+	return 0;
 }
 
 static void zero_out_rest_of_ec_bucket(struct bch_fs *c,
@@ -1385,9 +1350,8 @@ static void ec_stripe_create(struct ec_stripe_new *s)
 			}
 		}
 
-	mutex_lock(&c->ec_stripe_new_lock);
-	list_del(&s->list);
-	mutex_unlock(&c->ec_stripe_new_lock);
+	scoped_guard(mutex, &c->ec_stripe_new_lock)
+		list_del(&s->list);
 	wake_up(&c->ec_stripe_new_wait);
 
 	ec_stripe_buf_exit(&s->existing_stripe);
@@ -1401,15 +1365,11 @@ static struct ec_stripe_new *get_pending_stripe(struct bch_fs *c)
 {
 	struct ec_stripe_new *s;
 
-	mutex_lock(&c->ec_stripe_new_lock);
+	guard(mutex)(&c->ec_stripe_new_lock);
 	list_for_each_entry(s, &c->ec_stripe_new_list, list)
 		if (!atomic_read(&s->ref[STRIPE_REF_io]))
-			goto out;
-	s = NULL;
-out:
-	mutex_unlock(&c->ec_stripe_new_lock);
-
-	return s;
+			return s;
+	return NULL;
 }
 
 static void ec_stripe_create_work(struct work_struct *work)
@@ -1443,9 +1403,8 @@ static void ec_stripe_new_set_pending(struct bch_fs *c, struct ec_stripe_head *h
 	h->s		= NULL;
 	s->pending	= true;
 
-	mutex_lock(&c->ec_stripe_new_lock);
-	list_add(&s->list, &c->ec_stripe_new_list);
-	mutex_unlock(&c->ec_stripe_new_lock);
+	scoped_guard(mutex, &c->ec_stripe_new_lock)
+		list_add(&s->list, &c->ec_stripe_new_list);
 
 	ec_stripe_new_put(c, s, STRIPE_REF_io);
 }
@@ -2199,13 +2158,13 @@ static int bch2_invalidate_stripe_to_dev_from_alloc(struct btree_trans *trans, s
 
 int bch2_dev_remove_stripes(struct bch_fs *c, unsigned dev_idx, unsigned flags)
 {
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_max_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_max_commit(trans, iter,
 				  BTREE_ID_alloc, POS(dev_idx, 0), POS(dev_idx, U64_MAX),
 				  BTREE_ITER_intent, k,
 				  NULL, NULL, 0, ({
 			bch2_invalidate_stripe_to_dev_from_alloc(trans, k, flags);
-	})));
+	}));
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -2215,33 +2174,28 @@ int bch2_dev_remove_stripes(struct bch_fs *c, unsigned dev_idx, unsigned flags)
 static void __bch2_ec_stop(struct bch_fs *c, struct bch_dev *ca)
 {
 	struct ec_stripe_head *h;
-	struct open_bucket *ob;
-	unsigned i;
 
-	mutex_lock(&c->ec_stripe_head_lock);
+	guard(mutex)(&c->ec_stripe_head_lock);
 	list_for_each_entry(h, &c->ec_stripe_head_list, list) {
-		mutex_lock(&h->lock);
+		guard(mutex)(&h->lock);
 		if (!h->s)
-			goto unlock;
+			continue;
 
 		if (!ca)
 			goto found;
 
-		for (i = 0; i < bkey_i_to_stripe(&h->s->new_stripe.key)->v.nr_blocks; i++) {
+		for (unsigned i = 0; i < bkey_i_to_stripe(&h->s->new_stripe.key)->v.nr_blocks; i++) {
 			if (!h->s->blocks[i])
 				continue;
 
-			ob = c->open_buckets + h->s->blocks[i];
+			struct open_bucket *ob = c->open_buckets + h->s->blocks[i];
 			if (ob->dev == ca->dev_idx)
 				goto found;
 		}
-		goto unlock;
+		continue;
 found:
 		ec_stripe_new_cancel(c, h, -BCH_ERR_erofs_no_writes);
-unlock:
-		mutex_unlock(&h->lock);
 	}
-	mutex_unlock(&c->ec_stripe_head_lock);
 }
 
 void bch2_ec_stop_dev(struct bch_fs *c, struct bch_dev *ca)
@@ -2258,11 +2212,8 @@ static bool bch2_fs_ec_flush_done(struct bch_fs *c)
 {
 	sched_annotate_sleep();
 
-	mutex_lock(&c->ec_stripe_new_lock);
-	bool ret = list_empty(&c->ec_stripe_new_list);
-	mutex_unlock(&c->ec_stripe_new_lock);
-
-	return ret;
+	guard(mutex)(&c->ec_stripe_new_lock);
+	return list_empty(&c->ec_stripe_new_list);
 }
 
 void bch2_fs_ec_flush(struct bch_fs *c)
@@ -2299,41 +2250,40 @@ void bch2_new_stripes_to_text(struct printbuf *out, struct bch_fs *c)
 	struct ec_stripe_head *h;
 	struct ec_stripe_new *s;
 
-	mutex_lock(&c->ec_stripe_head_lock);
-	list_for_each_entry(h, &c->ec_stripe_head_list, list) {
-		prt_printf(out, "disk label %u algo %u redundancy %u %s nr created %llu:\n",
-		       h->disk_label, h->algo, h->redundancy,
-		       bch2_watermarks[h->watermark],
-		       h->nr_created);
+	scoped_guard(mutex, &c->ec_stripe_head_lock)
+		list_for_each_entry(h, &c->ec_stripe_head_list, list) {
+			prt_printf(out, "disk label %u algo %u redundancy %u %s nr created %llu:\n",
+			       h->disk_label, h->algo, h->redundancy,
+			       bch2_watermarks[h->watermark],
+			       h->nr_created);
 
-		if (h->s)
-			bch2_new_stripe_to_text(out, c, h->s);
-	}
-	mutex_unlock(&c->ec_stripe_head_lock);
+			if (h->s)
+				bch2_new_stripe_to_text(out, c, h->s);
+		}
 
 	prt_printf(out, "in flight:\n");
 
-	mutex_lock(&c->ec_stripe_new_lock);
-	list_for_each_entry(s, &c->ec_stripe_new_list, list)
-		bch2_new_stripe_to_text(out, c, s);
-	mutex_unlock(&c->ec_stripe_new_lock);
+	scoped_guard(mutex, &c->ec_stripe_new_lock)
+		list_for_each_entry(s, &c->ec_stripe_new_list, list)
+			bch2_new_stripe_to_text(out, c, s);
 }
 
 void bch2_fs_ec_exit(struct bch_fs *c)
 {
-	struct ec_stripe_head *h;
-	unsigned i;
 
 	while (1) {
-		mutex_lock(&c->ec_stripe_head_lock);
-		h = list_pop_entry(&c->ec_stripe_head_list, struct ec_stripe_head, list);
-		mutex_unlock(&c->ec_stripe_head_lock);
+		struct ec_stripe_head *h;
+
+		scoped_guard(mutex, &c->ec_stripe_head_lock)
+			h = list_pop_entry(&c->ec_stripe_head_list, struct ec_stripe_head, list);
 
 		if (!h)
 			break;
 
 		if (h->s) {
-			for (i = 0; i < bkey_i_to_stripe(&h->s->new_stripe.key)->v.nr_blocks; i++)
+			for (unsigned i = 0;
+			     i < bkey_i_to_stripe(&h->s->new_stripe.key)->v.nr_blocks;
+			     i++)
 				BUG_ON(h->s->blocks[i]);
 
 			kfree(h->s);
@@ -2386,20 +2336,18 @@ static int bch2_check_stripe_to_lru_ref(struct btree_trans *trans,
 	return 0;
 }
 
-int bch2_check_stripe_to_lru_refs(struct bch_fs *c)
+int bch2_check_stripe_to_lru_refs(struct btree_trans *trans)
 {
 	struct bkey_buf last_flushed;
-
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_stripes,
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_stripes,
 				POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_check_stripe_to_lru_ref(trans, k, &last_flushed)));
+			bch2_check_stripe_to_lru_ref(trans, k, &last_flushed));
 
-	bch2_bkey_buf_exit(&last_flushed, c);
-	bch_err_fn(c, ret);
+	bch2_bkey_buf_exit(&last_flushed, trans->c);
+	bch_err_fn(trans->c, ret);
 	return ret;
 }
diff --git a/fs/bcachefs/ec.h b/fs/bcachefs/ec.h
index 548048adf0d5..e807e7027d7a 100644
--- a/fs/bcachefs/ec.h
+++ b/fs/bcachefs/ec.h
@@ -304,6 +304,6 @@ void bch2_fs_ec_exit(struct bch_fs *);
 void bch2_fs_ec_init_early(struct bch_fs *);
 int bch2_fs_ec_init(struct bch_fs *);
 
-int bch2_check_stripe_to_lru_refs(struct bch_fs *);
+int bch2_check_stripe_to_lru_refs(struct btree_trans *);
 
 #endif /* _BCACHEFS_EC_H */
-- 
2.51.0


From 9224c84e2c2212d41f86b59b28671672f5eb7be7 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:32:07 -0400
Subject: [PATCH 139/309] bcachefs: convert backpointers.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 55 +++++++++++++++-----------------------
 1 file changed, 21 insertions(+), 34 deletions(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index bc277f42cf5f..7bb9d0cab289 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -108,7 +108,7 @@ static noinline int backpointer_mod_err(struct btree_trans *trans,
 					bool insert)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool will_check = c->recovery.passes_to_run &
 		BIT_ULL(BCH_RECOVERY_PASS_check_extents_to_backpointers);
 	int ret = 0;
@@ -146,7 +146,6 @@ static noinline int backpointer_mod_err(struct btree_trans *trans,
 
 	if (buf.buf)
 		bch_err(c, "%s", buf.buf);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -209,7 +208,7 @@ static int backpointer_target_not_found(struct btree_trans *trans,
 				  bool commit)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	/*
@@ -245,7 +244,7 @@ static int backpointer_target_not_found(struct btree_trans *trans,
 		     "%s", buf.buf)) {
 		ret = bch2_backpointer_del(trans, bp.k->p);
 		if (ret || !commit)
-			goto out;
+			return ret;
 
 		/*
 		 * Normally, on transaction commit from inside a transaction,
@@ -263,9 +262,7 @@ static int backpointer_target_not_found(struct btree_trans *trans,
 		 */
 		ret = bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc);
 	}
-out:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -389,7 +386,7 @@ static int bch2_check_backpointer_has_valid_bucket(struct btree_trans *trans, st
 	struct bch_fs *c = trans->c;
 	struct btree_iter alloc_iter = {};
 	struct bkey_s_c alloc_k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	struct bpos bucket;
@@ -424,7 +421,6 @@ static int bch2_check_backpointer_has_valid_bucket(struct btree_trans *trans, st
 out:
 fsck_err:
 	bch2_trans_iter_exit(trans, &alloc_iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -435,11 +431,11 @@ int bch2_check_btree_backpointers(struct bch_fs *c)
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter,
 			BTREE_ID_backpointers, POS_MIN, 0, k,
 			NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-		  bch2_check_backpointer_has_valid_bucket(trans, k, &last_flushed)));
+		  bch2_check_backpointer_has_valid_bucket(trans, k, &last_flushed));
 
 	bch2_bkey_buf_exit(&last_flushed, c);
 	bch_err_fn(c, ret);
@@ -472,7 +468,7 @@ static int check_extent_checksum(struct btree_trans *trans,
 	struct bkey_ptrs_c ptrs = bch2_bkey_ptrs_c(extent);
 	const union bch_extent_entry *entry;
 	struct extent_ptr_decoded p;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	void *data_buf = NULL;
 	struct bio *bio = NULL;
 	size_t bytes;
@@ -531,7 +527,6 @@ static int check_extent_checksum(struct btree_trans *trans,
 	kvfree(data_buf);
 	enumerated_ref_put(&ca->io_ref[READ],
 			   BCH_DEV_READ_REF_check_extent_checksums);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -542,7 +537,7 @@ static int check_bp_exists(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter other_extent_iter = {};
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	if (bpos_lt(bp->k.p, s->bp_start) ||
 	    bpos_gt(bp->k.p, s->bp_end))
@@ -567,7 +562,6 @@ static int check_bp_exists(struct btree_trans *trans,
 fsck_err:
 	bch2_trans_iter_exit(trans, &other_extent_iter);
 	bch2_trans_iter_exit(trans, &bp_iter);
-	printbuf_exit(&buf);
 	return ret;
 check_existing_bp:
 	/* Do we have a backpointer for a different extent? */
@@ -896,7 +890,7 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 	u32 sectors[ALLOC_SECTORS_NR];
 	memset(sectors, 0, sizeof(sectors));
 
-	struct bch_dev *ca = bch2_dev_bucket_tryget_noerror(trans->c, alloc_k.k->p);
+	CLASS(bch2_dev_bucket_tryget_noerror, ca)(trans->c, alloc_k.k->p);
 	if (!ca)
 		return 0;
 
@@ -933,12 +927,12 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 	};
 	bch2_trans_iter_exit(trans, &iter);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (need_commit) {
 		ret = bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (sectors[ALLOC_dirty]  != a->dirty_sectors ||
@@ -947,15 +941,14 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 		if (c->sb.version_upgrade_complete >= bcachefs_metadata_version_backpointer_bucket_gen) {
 			ret = bch2_backpointers_maybe_flush(trans, alloc_k, last_flushed);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		if (sectors[ALLOC_dirty]  > a->dirty_sectors ||
 		    sectors[ALLOC_cached] > a->cached_sectors ||
 		    sectors[ALLOC_stripe] > a->stripe_sectors) {
-			ret = check_bucket_backpointers_to_extents(trans, ca, alloc_k.k->p) ?:
+			return check_bucket_backpointers_to_extents(trans, ca, alloc_k.k->p) ?:
 				bch_err_throw(c, transaction_restart_nested);
-			goto err;
 		}
 
 		bool empty = (sectors[ALLOC_dirty] +
@@ -971,9 +964,8 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 
 		*had_mismatch = true;
 	}
-err:
-	bch2_dev_put(ca);
-	return ret;
+
+	return 0;
 }
 
 static bool backpointer_node_has_missing(struct bch_fs *c, struct bkey_s_c k)
@@ -1108,7 +1100,7 @@ int bch2_check_extents_to_backpointers(struct bch_fs *c)
 {
 	int ret = 0;
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct extents_to_bp_state s = { .bp_start = POS_MIN };
 
 	bch2_bkey_buf_init(&s.last_flushed);
@@ -1147,7 +1139,7 @@ int bch2_check_extents_to_backpointers(struct bch_fs *c)
 
 		if (!bpos_eq(s.bp_start, POS_MIN) ||
 		    !bpos_eq(s.bp_end, SPOS_MAX)) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 
 			prt_str(&buf, "check_extents_to_backpointers(): ");
 			bch2_bpos_to_text(&buf, s.bp_start);
@@ -1155,7 +1147,6 @@ int bch2_check_extents_to_backpointers(struct bch_fs *c)
 			bch2_bpos_to_text(&buf, s.bp_end);
 
 			bch_verbose(c, "%s", buf.buf);
-			printbuf_exit(&buf);
 		}
 
 		ret = bch2_check_extents_to_backpointers_pass(trans, &s);
@@ -1170,7 +1161,6 @@ int bch2_check_extents_to_backpointers(struct bch_fs *c)
 		bch2_bucket_bitmap_free(&ca->bucket_backpointer_empty);
 	}
 err:
-	bch2_trans_put(trans);
 	bch2_bkey_buf_exit(&s.last_flushed, c);
 	bch2_btree_cache_unpin(c);
 
@@ -1212,7 +1202,7 @@ int bch2_check_bucket_backpointer_mismatch(struct btree_trans *trans,
 	u64 nr = ca->bucket_backpointer_mismatch.nr;
 	u64 allowed = copygc ? ca->mi.nbuckets >> 7 : 0;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	__bch2_log_msg_start(ca->name, &buf);
 
 	prt_printf(&buf, "Detected missing backpointers in bucket %llu, now have %llu/%llu with missing\n",
@@ -1223,7 +1213,6 @@ int bch2_check_bucket_backpointer_mismatch(struct btree_trans *trans,
 			nr < allowed ? RUN_RECOVERY_PASS_ratelimit : 0);
 
 	bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 	return 0;
 }
 
@@ -1300,7 +1289,7 @@ static int bch2_check_backpointers_to_extents_pass(struct btree_trans *trans,
 
 int bch2_check_backpointers_to_extents(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct bbpos start = (struct bbpos) { .btree = 0, .pos = POS_MIN, }, end;
 	int ret;
 
@@ -1320,7 +1309,7 @@ int bch2_check_backpointers_to_extents(struct bch_fs *c)
 
 		if (bbpos_cmp(start, BBPOS_MIN) ||
 		    bbpos_cmp(end, BBPOS_MAX)) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 
 			prt_str(&buf, "check_backpointers_to_extents(): ");
 			bch2_bbpos_to_text(&buf, start);
@@ -1328,7 +1317,6 @@ int bch2_check_backpointers_to_extents(struct bch_fs *c)
 			bch2_bbpos_to_text(&buf, end);
 
 			bch_verbose(c, "%s", buf.buf);
-			printbuf_exit(&buf);
 		}
 
 		ret = bch2_check_backpointers_to_extents_pass(trans, start, end);
@@ -1337,7 +1325,6 @@ int bch2_check_backpointers_to_extents(struct bch_fs *c)
 
 		start = bbpos_successor(end);
 	}
-	bch2_trans_put(trans);
 
 	bch2_btree_cache_unpin(c);
 
-- 
2.51.0


From 7f32c1f3cd80b068accba940013105d394dd1efa Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:39:56 -0400
Subject: [PATCH 140/309] bcachefs: convert alloc_background.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 239 +++++++++++++--------------------
 1 file changed, 94 insertions(+), 145 deletions(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index d64839c756bc..58706dfcdfe0 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -565,11 +565,11 @@ void bch2_bucket_gens_to_text(struct printbuf *out, struct bch_fs *c, struct bke
 
 int bch2_bucket_gens_init(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
 	struct bkey_i_bucket_gens g;
 	bool have_bucket_gens_key = false;
 	int ret;
 
+	CLASS(btree_trans, trans)(c);
 	ret = for_each_btree_key(trans, iter, BTREE_ID_alloc, POS_MIN,
 				 BTREE_ITER_prefetch, k, ({
 		/*
@@ -609,17 +609,15 @@ int bch2_bucket_gens_init(struct bch_fs *c)
 				BCH_TRANS_COMMIT_no_enospc,
 			bch2_btree_insert_trans(trans, BTREE_ID_bucket_gens, &g.k_i, 0));
 
-	bch2_trans_put(trans);
-
 	bch_err_fn(c, ret);
 	return ret;
 }
 
 int bch2_alloc_read(struct bch_fs *c)
 {
-	down_read(&c->state_lock);
+	guard(rwsem_read)(&c->state_lock);
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct bch_dev *ca = NULL;
 	int ret;
 
@@ -680,9 +678,6 @@ int bch2_alloc_read(struct bch_fs *c)
 	}
 
 	bch2_dev_put(ca);
-	bch2_trans_put(trans);
-
-	up_read(&c->state_lock);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -699,7 +694,7 @@ static int __need_discard_or_freespace_err(struct btree_trans *trans,
 		? BCH_FSCK_ERR_need_discard_key_wrong
 		: BCH_FSCK_ERR_freespace_key_wrong;
 	enum btree_id btree = discard ? BTREE_ID_need_discard : BTREE_ID_freespace;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_bkey_val_to_text(&buf, c, alloc_k);
 
@@ -711,8 +706,6 @@ static int __need_discard_or_freespace_err(struct btree_trans *trans,
 	if (bch2_err_matches(ret, BCH_ERR_fsck_ignore) ||
 	    bch2_err_matches(ret, BCH_ERR_fsck_errors_not_fixed))
 		ret = 0;
-
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -860,10 +853,10 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 		       enum btree_iter_update_trigger_flags flags)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
-	struct bch_dev *ca = bch2_dev_bucket_tryget(c, new.k->p);
+	CLASS(bch2_dev_bucket_tryget, ca)(c, new.k->p);
 	if (!ca)
 		return bch_err_throw(c, trigger_alloc);
 
@@ -879,7 +872,7 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 		struct bkey_i_alloc_v4 *new_ka = bch2_alloc_to_v4_mut_inlined(trans, new.s_c);
 		ret = PTR_ERR_OR_ZERO(new_ka);
 		if (unlikely(ret))
-			goto err;
+			return ret;
 		new_a = &new_ka->v;
 	}
 
@@ -913,7 +906,7 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 			ret =   bch2_bucket_do_index(trans, ca, old, old_a, false) ?:
 				bch2_bucket_do_index(trans, ca, new.s_c, new_a, true);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		if (new_a->data_type == BCH_DATA_cached &&
@@ -925,7 +918,7 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 				      alloc_lru_idx_read(*old_a),
 				      alloc_lru_idx_read(*new_a));
 		if (ret)
-			goto err;
+			return ret;
 
 		ret = bch2_lru_change(trans,
 				      BCH_LRU_BUCKET_FRAGMENTATION,
@@ -933,17 +926,17 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 				      alloc_lru_idx_fragmentation(*old_a, ca),
 				      alloc_lru_idx_fragmentation(*new_a, ca));
 		if (ret)
-			goto err;
+			return ret;
 
 		if (old_a->gen != new_a->gen) {
 			ret = bch2_bucket_gen_update(trans, new.k->p, new_a->gen);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		ret = bch2_alloc_key_to_dev_counters(trans, ca, old_a, new_a, flags);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if ((flags & BTREE_TRIGGER_atomic) && (flags & BTREE_TRIGGER_insert)) {
@@ -994,7 +987,7 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 				if (bch2_fs_fatal_err_on(ret, c,
 						"setting bucket_needs_journal_commit: %s",
 						bch2_err_str(ret)))
-					goto err;
+					return ret;
 			}
 		}
 
@@ -1036,16 +1029,12 @@ int bch2_trigger_alloc(struct btree_trans *trans,
 		g->gen_valid	= 1;
 		g->gen		= new_a->gen;
 	}
-err:
 fsck_err:
-	printbuf_exit(&buf);
-	bch2_dev_put(ca);
 	return ret;
 invalid_bucket:
 	bch2_fs_inconsistent(c, "reference to invalid bucket\n%s",
 			     (bch2_bkey_val_to_text(&buf, c, new.s_c), buf.buf));
-	ret = bch_err_throw(c, trigger_alloc);
-	goto err;
+	return bch_err_throw(c, trigger_alloc);
 }
 
 /*
@@ -1164,10 +1153,10 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 	const struct bch_alloc_v4 *a;
 	unsigned gens_offset;
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
-	struct bch_dev *ca = bch2_dev_bucket_tryget_noerror(c, alloc_k.k->p);
+	CLASS(bch2_dev_bucket_tryget_noerror, ca)(c, alloc_k.k->p);
 	if (fsck_err_on(!ca,
 			trans, alloc_key_to_missing_dev_bucket,
 			"alloc key for invalid device:bucket %llu:%llu",
@@ -1177,7 +1166,7 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 		return ret;
 
 	if (!ca->mi.freespace_initialized)
-		goto out;
+		return 0;
 
 	a = bch2_alloc_to_v4(alloc_k, &a_convert);
 
@@ -1185,35 +1174,35 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 	k = bch2_btree_iter_peek_slot(trans, discard_iter);
 	ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	bool is_discarded = a->data_type == BCH_DATA_need_discard;
 	if (need_discard_or_freespace_err_on(!!k.k->type != is_discarded,
 					     trans, alloc_k, !is_discarded, true, true)) {
 		ret = bch2_btree_bit_mod_iter(trans, discard_iter, is_discarded);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	bch2_btree_iter_set_pos(trans, freespace_iter, alloc_freespace_pos(alloc_k.k->p, *a));
 	k = bch2_btree_iter_peek_slot(trans, freespace_iter);
 	ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	bool is_free = a->data_type == BCH_DATA_free;
 	if (need_discard_or_freespace_err_on(!!k.k->type != is_free,
 					     trans, alloc_k, !is_free, false, true)) {
 		ret = bch2_btree_bit_mod_iter(trans, freespace_iter, is_free);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	bch2_btree_iter_set_pos(trans, bucket_gens_iter, alloc_gens_pos(alloc_k.k->p, &gens_offset));
 	k = bch2_btree_iter_peek_slot(trans, bucket_gens_iter);
 	ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (fsck_err_on(a->gen != alloc_gen(k, gens_offset),
 			trans, bucket_gens_key_wrong,
@@ -1226,7 +1215,7 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 
 		ret = PTR_ERR_OR_ZERO(g);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (k.k->type == KEY_TYPE_bucket_gens) {
 			bkey_reassemble(&g->k_i, k);
@@ -1239,13 +1228,9 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 
 		ret = bch2_trans_update(trans, bucket_gens_iter, &g->k_i, 0);
 		if (ret)
-			goto err;
+			return ret;
 	}
-out:
-err:
 fsck_err:
-	bch2_dev_put(ca);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1257,7 +1242,7 @@ int bch2_check_alloc_hole_freespace(struct btree_trans *trans,
 				    struct btree_iter *freespace_iter)
 {
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret;
 
 	if (!ca->mi.freespace_initialized)
@@ -1268,7 +1253,7 @@ int bch2_check_alloc_hole_freespace(struct btree_trans *trans,
 	k = bch2_btree_iter_peek_slot(trans, freespace_iter);
 	ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	*end = bkey_min(k.k->p, *end);
 
@@ -1281,10 +1266,9 @@ int bch2_check_alloc_hole_freespace(struct btree_trans *trans,
 			end->offset)) {
 		struct bkey_i *update =
 			bch2_trans_kmalloc(trans, sizeof(*update));
-
 		ret = PTR_ERR_OR_ZERO(update);
 		if (ret)
-			goto err;
+			return ret;
 
 		bkey_init(&update->k);
 		update->k.type	= KEY_TYPE_set;
@@ -1295,11 +1279,9 @@ int bch2_check_alloc_hole_freespace(struct btree_trans *trans,
 
 		ret = bch2_trans_update(trans, freespace_iter, update, 0);
 		if (ret)
-			goto err;
+			return ret;
 	}
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1310,7 +1292,7 @@ int bch2_check_alloc_hole_bucket_gens(struct btree_trans *trans,
 				      struct btree_iter *bucket_gens_iter)
 {
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	unsigned i, gens_offset, gens_end_offset;
 	int ret;
 
@@ -1319,7 +1301,7 @@ int bch2_check_alloc_hole_bucket_gens(struct btree_trans *trans,
 	k = bch2_btree_iter_peek_slot(trans, bucket_gens_iter);
 	ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (bkey_cmp(alloc_gens_pos(start, &gens_offset),
 		     alloc_gens_pos(*end,  &gens_end_offset)))
@@ -1345,23 +1327,20 @@ int bch2_check_alloc_hole_bucket_gens(struct btree_trans *trans,
 
 		if (need_update) {
 			struct bkey_i *u = bch2_trans_kmalloc(trans, sizeof(g));
-
 			ret = PTR_ERR_OR_ZERO(u);
 			if (ret)
-				goto err;
+				return ret;
 
 			memcpy(u, &g, sizeof(g));
 
 			ret = bch2_trans_update(trans, bucket_gens_iter, u, 0);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	}
 
 	*end = bkey_min(*end, bucket_gens_pos_to_alloc(bpos_nosnap_successor(k.k->p), 0));
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1404,7 +1383,7 @@ int __bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_i
 	enum bch_data_type state = iter->btree_id == BTREE_ID_need_discard
 		? BCH_DATA_need_discard
 		: BCH_DATA_free;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bool async_repair = fsck_flags & FSCK_ERR_NO_LOG;
 	fsck_flags |= FSCK_CAN_FIX|FSCK_CAN_IGNORE;
@@ -1456,7 +1435,6 @@ int __bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_i
 fsck_err:
 	bch2_set_btree_iter_dontneed(trans, &alloc_iter);
 	bch2_trans_iter_exit(trans, &alloc_iter);
-	printbuf_exit(&buf);
 	return ret;
 delete:
 	if (!async_repair) {
@@ -1513,19 +1491,19 @@ int bch2_check_bucket_gens_key(struct btree_trans *trans,
 	u64 end = bucket_gens_pos_to_alloc(bpos_nosnap_successor(k.k->p), 0).offset;
 	u64 b;
 	bool need_update = false;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	BUG_ON(k.k->type != KEY_TYPE_bucket_gens);
 	bkey_reassemble(&g.k_i, k);
 
-	struct bch_dev *ca = bch2_dev_tryget_noerror(c, k.k->p.inode);
+	CLASS(bch2_dev_tryget_noerror, ca)(c, k.k->p.inode);
 	if (!ca) {
 		if (fsck_err(trans, bucket_gens_to_invalid_dev,
 			     "bucket_gens key for invalid device:\n%s",
 			     (bch2_bkey_val_to_text(&buf, c, k), buf.buf)))
-			ret = bch2_btree_delete_at(trans, iter, 0);
-		goto out;
+			return bch2_btree_delete_at(trans, iter, 0);
+		return 0;
 	}
 
 	if (fsck_err_on(end <= ca->mi.first_bucket ||
@@ -1533,8 +1511,7 @@ int bch2_check_bucket_gens_key(struct btree_trans *trans,
 			trans, bucket_gens_to_invalid_buckets,
 			"bucket_gens key for invalid buckets:\n%s",
 			(bch2_bkey_val_to_text(&buf, c, k), buf.buf))) {
-		ret = bch2_btree_delete_at(trans, iter, 0);
-		goto out;
+		return bch2_btree_delete_at(trans, iter, 0);
 	}
 
 	for (b = start; b < ca->mi.first_bucket; b++)
@@ -1555,30 +1532,26 @@ int bch2_check_bucket_gens_key(struct btree_trans *trans,
 
 	if (need_update) {
 		struct bkey_i *u = bch2_trans_kmalloc(trans, sizeof(g));
-
 		ret = PTR_ERR_OR_ZERO(u);
 		if (ret)
-			goto out;
+			return ret;
 
 		memcpy(u, &g, sizeof(g));
-		ret = bch2_trans_update(trans, iter, u, 0);
+		return bch2_trans_update(trans, iter, u, 0);
 	}
-out:
 fsck_err:
-	bch2_dev_put(ca);
-	printbuf_exit(&buf);
 	return ret;
 }
 
 int bch2_check_alloc_info(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
 	struct btree_iter iter, discard_iter, freespace_iter, bucket_gens_iter;
 	struct bch_dev *ca = NULL;
 	struct bkey hole;
 	struct bkey_s_c k;
 	int ret = 0;
 
+	CLASS(btree_trans, trans)(c);
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_alloc, POS_MIN,
 			     BTREE_ITER_prefetch);
 	bch2_trans_iter_init(trans, &discard_iter, BTREE_ID_need_discard, POS_MIN,
@@ -1670,11 +1643,9 @@ int bch2_check_alloc_info(struct bch_fs *c)
 			continue;
 		}
 		if (ret) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			bch2_bkey_val_to_text(&buf, c, k);
-
 			bch_err(c, "while checking %s", buf.buf);
-			printbuf_exit(&buf);
 			break;
 		}
 
@@ -1690,7 +1661,6 @@ int bch2_check_alloc_info(struct bch_fs *c)
 			NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 		bch2_check_bucket_gens_key(trans, &iter, k));
 err:
-	bch2_trans_put(trans);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1703,7 +1673,7 @@ static int bch2_check_alloc_to_lru_ref(struct btree_trans *trans,
 	struct bch_alloc_v4 a_convert;
 	const struct bch_alloc_v4 *a;
 	struct bkey_s_c alloc_k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret;
 
 	alloc_k = bch2_btree_iter_peek(trans, alloc_iter);
@@ -1714,7 +1684,7 @@ static int bch2_check_alloc_to_lru_ref(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	struct bch_dev *ca = bch2_dev_tryget_noerror(c, alloc_k.k->p.inode);
+	CLASS(bch2_dev_tryget_noerror, ca)(c, alloc_k.k->p.inode);
 	if (!ca)
 		return 0;
 
@@ -1726,58 +1696,51 @@ static int bch2_check_alloc_to_lru_ref(struct btree_trans *trans,
 					 bucket_to_u64(alloc_k.k->p),
 					 lru_idx, alloc_k, last_flushed);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
-	if (a->data_type != BCH_DATA_cached)
-		goto err;
+	if (a->data_type == BCH_DATA_cached) {
+		if (fsck_err_on(!a->io_time[READ],
+				trans, alloc_key_cached_but_read_time_zero,
+				"cached bucket with read_time 0\n%s",
+			(printbuf_reset(&buf),
+			 bch2_bkey_val_to_text(&buf, c, alloc_k), buf.buf))) {
+			struct bkey_i_alloc_v4 *a_mut =
+				bch2_alloc_to_v4_mut(trans, alloc_k);
+			ret = PTR_ERR_OR_ZERO(a_mut);
+			if (ret)
+				return ret;
 
-	if (fsck_err_on(!a->io_time[READ],
-			trans, alloc_key_cached_but_read_time_zero,
-			"cached bucket with read_time 0\n%s",
-		(printbuf_reset(&buf),
-		 bch2_bkey_val_to_text(&buf, c, alloc_k), buf.buf))) {
-		struct bkey_i_alloc_v4 *a_mut =
-			bch2_alloc_to_v4_mut(trans, alloc_k);
-		ret = PTR_ERR_OR_ZERO(a_mut);
-		if (ret)
-			goto err;
+			a_mut->v.io_time[READ] = bch2_current_io_time(c, READ);
+			ret = bch2_trans_update(trans, alloc_iter,
+						&a_mut->k_i, BTREE_TRIGGER_norun);
+			if (ret)
+				return ret;
 
-		a_mut->v.io_time[READ] = bch2_current_io_time(c, READ);
-		ret = bch2_trans_update(trans, alloc_iter,
-					&a_mut->k_i, BTREE_TRIGGER_norun);
-		if (ret)
-			goto err;
+			a = &a_mut->v;
+		}
 
-		a = &a_mut->v;
+		ret = bch2_lru_check_set(trans, alloc_k.k->p.inode,
+					 bucket_to_u64(alloc_k.k->p),
+					 a->io_time[READ],
+					 alloc_k, last_flushed);
 	}
-
-	ret = bch2_lru_check_set(trans, alloc_k.k->p.inode,
-				 bucket_to_u64(alloc_k.k->p),
-				 a->io_time[READ],
-				 alloc_k, last_flushed);
-	if (ret)
-		goto err;
-err:
 fsck_err:
-	bch2_dev_put(ca);
-	printbuf_exit(&buf);
 	return ret;
 }
 
 int bch2_check_alloc_to_lru_refs(struct bch_fs *c)
 {
 	struct bkey_buf last_flushed;
-
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter, BTREE_ID_alloc,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_alloc,
 				POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_check_alloc_to_lru_ref(trans, &iter, &last_flushed))) ?:
-		bch2_check_stripe_to_lru_refs(c);
+			bch2_check_alloc_to_lru_ref(trans, &iter, &last_flushed)) ?:
+		bch2_check_stripe_to_lru_refs(trans);
 
 	bch2_bkey_buf_exit(&last_flushed, c);
 	bch_err_fn(c, ret);
@@ -1787,34 +1750,27 @@ int bch2_check_alloc_to_lru_refs(struct bch_fs *c)
 static int discard_in_flight_add(struct bch_dev *ca, u64 bucket, bool in_progress)
 {
 	struct bch_fs *c = ca->fs;
-	int ret;
 
-	mutex_lock(&ca->discard_buckets_in_flight_lock);
+	guard(mutex)(&ca->discard_buckets_in_flight_lock);
 	struct discard_in_flight *i =
 		darray_find_p(ca->discard_buckets_in_flight, i, i->bucket == bucket);
-	if (i) {
-		ret = bch_err_throw(c, EEXIST_discard_in_flight_add);
-		goto out;
-	}
+	if (i)
+		return bch_err_throw(c, EEXIST_discard_in_flight_add);
 
-	ret = darray_push(&ca->discard_buckets_in_flight, ((struct discard_in_flight) {
+	return darray_push(&ca->discard_buckets_in_flight, ((struct discard_in_flight) {
 			   .in_progress = in_progress,
 			   .bucket	= bucket,
 	}));
-out:
-	mutex_unlock(&ca->discard_buckets_in_flight_lock);
-	return ret;
 }
 
 static void discard_in_flight_remove(struct bch_dev *ca, u64 bucket)
 {
-	mutex_lock(&ca->discard_buckets_in_flight_lock);
+	guard(mutex)(&ca->discard_buckets_in_flight_lock);
 	struct discard_in_flight *i =
 		darray_find_p(ca->discard_buckets_in_flight, i, i->bucket == bucket);
 	BUG_ON(!i || !i->in_progress);
 
 	darray_remove_item(&ca->discard_buckets_in_flight, i);
-	mutex_unlock(&ca->discard_buckets_in_flight_lock);
 }
 
 struct discard_buckets_state {
@@ -1836,7 +1792,7 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 	struct btree_iter iter = {};
 	struct bkey_s_c k;
 	struct bkey_i_alloc_v4 *a;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool discard_locked = false;
 	int ret = 0;
 
@@ -1927,7 +1883,6 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 	if (!ret)
 		s->seen++;
 	bch2_trans_iter_exit(trans, &iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -2024,17 +1979,16 @@ static void bch2_do_discards_fast_work(struct work_struct *work)
 		bool got_bucket = false;
 		u64 bucket;
 
-		mutex_lock(&ca->discard_buckets_in_flight_lock);
-		darray_for_each(ca->discard_buckets_in_flight, i) {
-			if (i->in_progress)
-				continue;
+		scoped_guard(mutex, &ca->discard_buckets_in_flight_lock)
+			darray_for_each(ca->discard_buckets_in_flight, i) {
+				if (i->in_progress)
+					continue;
 
-			got_bucket = true;
-			bucket = i->bucket;
-			i->in_progress = true;
-			break;
-		}
-		mutex_unlock(&ca->discard_buckets_in_flight_lock);
+				got_bucket = true;
+				bucket = i->bucket;
+				i->in_progress = true;
+				break;
+			}
 
 		if (!got_bucket)
 			break;
@@ -2142,7 +2096,7 @@ static int invalidate_one_bucket(struct btree_trans *trans,
 				 s64 *nr_to_invalidate)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct bpos bucket = u64_to_bucket(lru_k.k->p.offset);
 	struct btree_iter alloc_iter = {};
 	int ret = 0;
@@ -2203,7 +2157,6 @@ static int invalidate_one_bucket(struct btree_trans *trans,
 out:
 fsck_err:
 	bch2_trans_iter_exit(trans, &alloc_iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -2226,7 +2179,7 @@ static void bch2_do_invalidates_work(struct work_struct *work)
 {
 	struct bch_dev *ca = container_of(work, struct bch_dev, invalidate_work);
 	struct bch_fs *c = ca->fs;
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	int ret = 0;
 
 	struct bkey_buf last_flushed;
@@ -2268,7 +2221,6 @@ static void bch2_do_invalidates_work(struct work_struct *work)
 	}
 	bch2_trans_iter_exit(trans, &iter);
 err:
-	bch2_trans_put(trans);
 	bch2_bkey_buf_exit(&last_flushed, c);
 	enumerated_ref_put(&ca->io_ref[WRITE], BCH_DEV_WRITE_REF_do_invalidates);
 	enumerated_ref_put(&c->writes, BCH_WRITE_REF_invalidate);
@@ -2301,18 +2253,17 @@ void bch2_do_invalidates(struct bch_fs *c)
 int bch2_dev_freespace_init(struct bch_fs *c, struct bch_dev *ca,
 			    u64 bucket_start, u64 bucket_end)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
 	struct btree_iter iter;
 	struct bkey_s_c k;
 	struct bkey hole;
 	struct bpos end = POS(ca->dev_idx, bucket_end);
-	struct bch_member *m;
 	unsigned long last_updated = jiffies;
 	int ret;
 
 	BUG_ON(bucket_start > bucket_end);
 	BUG_ON(bucket_end > ca->mi.nbuckets);
 
+	CLASS(btree_trans, trans)(c);
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_alloc,
 		POS(ca->dev_idx, max_t(u64, ca->mi.first_bucket, bucket_start)),
 		BTREE_ITER_prefetch);
@@ -2383,17 +2334,16 @@ int bch2_dev_freespace_init(struct bch_fs *c, struct bch_dev *ca,
 	}
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 
 	if (ret < 0) {
 		bch_err_msg(ca, ret, "initializing free space");
 		return ret;
 	}
 
-	mutex_lock(&c->sb_lock);
-	m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
-	SET_BCH_MEMBER_FREESPACE_INITIALIZED(m, true);
-	mutex_unlock(&c->sb_lock);
+	scoped_guard(mutex, &c->sb_lock) {
+		struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
+		SET_BCH_MEMBER_FREESPACE_INITIALIZED(m, true);
+	}
 
 	return 0;
 }
@@ -2428,9 +2378,8 @@ int bch2_fs_freespace_init(struct bch_fs *c)
 	}
 
 	if (doing_init) {
-		mutex_lock(&c->sb_lock);
+		guard(mutex)(&c->sb_lock);
 		bch2_write_super(c);
-		mutex_unlock(&c->sb_lock);
 		bch_verbose(c, "done initializing freespace");
 	}
 
-- 
2.51.0


From 85dec4080c04fc88441a9bfad22e0a983929e018 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:40:11 -0400
Subject: [PATCH 141/309] bcachefs: convert alloc_foreground.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_foreground.c | 207 ++++++++++++++-------------------
 fs/bcachefs/alloc_foreground.h |   9 +-
 2 files changed, 89 insertions(+), 127 deletions(-)

diff --git a/fs/bcachefs/alloc_foreground.c b/fs/bcachefs/alloc_foreground.c
index 77406394127c..fd1415524e46 100644
--- a/fs/bcachefs/alloc_foreground.c
+++ b/fs/bcachefs/alloc_foreground.c
@@ -106,20 +106,20 @@ void __bch2_open_bucket_put(struct bch_fs *c, struct open_bucket *ob)
 		return;
 	}
 
-	spin_lock(&ob->lock);
-	ob->valid = false;
-	ob->data_type = 0;
-	spin_unlock(&ob->lock);
+	scoped_guard(spinlock, &ob->lock) {
+		ob->valid = false;
+		ob->data_type = 0;
+	}
 
-	spin_lock(&c->freelist_lock);
-	bch2_open_bucket_hash_remove(c, ob);
+	scoped_guard(spinlock, &c->freelist_lock) {
+		bch2_open_bucket_hash_remove(c, ob);
 
-	ob->freelist = c->open_buckets_freelist;
-	c->open_buckets_freelist = ob - c->open_buckets;
+		ob->freelist = c->open_buckets_freelist;
+		c->open_buckets_freelist = ob - c->open_buckets;
 
-	c->open_buckets_nr_free++;
-	ca->nr_open_buckets--;
-	spin_unlock(&c->freelist_lock);
+		c->open_buckets_nr_free++;
+		ca->nr_open_buckets--;
+	}
 
 	closure_wake_up(&c->open_buckets_wait);
 }
@@ -164,14 +164,14 @@ static void open_bucket_free_unused(struct bch_fs *c, struct open_bucket *ob)
 	BUG_ON(c->open_buckets_partial_nr >=
 	       ARRAY_SIZE(c->open_buckets_partial));
 
-	spin_lock(&c->freelist_lock);
-	scoped_guard(rcu)
+	scoped_guard(spinlock, &c->freelist_lock) {
+		guard(rcu)();
 		bch2_dev_rcu(c, ob->dev)->nr_partial_buckets++;
 
-	ob->on_partial_list = true;
-	c->open_buckets_partial[c->open_buckets_partial_nr++] =
-		ob - c->open_buckets;
-	spin_unlock(&c->freelist_lock);
+		ob->on_partial_list = true;
+		c->open_buckets_partial[c->open_buckets_partial_nr++] =
+			ob - c->open_buckets;
+	}
 
 	closure_wake_up(&c->open_buckets_wait);
 	closure_wake_up(&c->freelist_wait);
@@ -219,33 +219,31 @@ static struct open_bucket *__try_alloc_bucket(struct bch_fs *c,
 		return NULL;
 	}
 
-	spin_lock(&c->freelist_lock);
+	guard(spinlock)(&c->freelist_lock);
 
 	if (unlikely(c->open_buckets_nr_free <= bch2_open_buckets_reserved(req->watermark))) {
 		if (cl)
 			closure_wait(&c->open_buckets_wait, cl);
 
 		track_event_change(&c->times[BCH_TIME_blocked_allocate_open_bucket], true);
-		spin_unlock(&c->freelist_lock);
 		return ERR_PTR(bch_err_throw(c, open_buckets_empty));
 	}
 
 	/* Recheck under lock: */
 	if (bch2_bucket_is_open(c, ca->dev_idx, bucket)) {
-		spin_unlock(&c->freelist_lock);
 		req->counters.skipped_open++;
 		return NULL;
 	}
 
 	struct open_bucket *ob = bch2_open_bucket_alloc(c);
 
-	spin_lock(&ob->lock);
-	ob->valid	= true;
-	ob->sectors_free = ca->mi.bucket_size;
-	ob->dev		= ca->dev_idx;
-	ob->gen		= gen;
-	ob->bucket	= bucket;
-	spin_unlock(&ob->lock);
+	scoped_guard(spinlock, &ob->lock) {
+		ob->valid	= true;
+		ob->sectors_free = ca->mi.bucket_size;
+		ob->dev		= ca->dev_idx;
+		ob->gen		= gen;
+		ob->bucket	= bucket;
+	}
 
 	ca->nr_open_buckets++;
 	bch2_open_bucket_hash_add(c, ob);
@@ -253,7 +251,6 @@ static struct open_bucket *__try_alloc_bucket(struct bch_fs *c,
 	track_event_change(&c->times[BCH_TIME_blocked_allocate_open_bucket], false);
 	track_event_change(&c->times[BCH_TIME_blocked_allocate], false);
 
-	spin_unlock(&c->freelist_lock);
 	return ob;
 }
 
@@ -453,7 +450,7 @@ static noinline void trace_bucket_alloc2(struct bch_fs *c,
 					 struct closure *cl,
 					 struct open_bucket *ob)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	printbuf_tabstop_push(&buf, 24);
 
@@ -480,8 +477,6 @@ static noinline void trace_bucket_alloc2(struct bch_fs *c,
 		prt_printf(&buf, "err\t%s\n", bch2_err_str(PTR_ERR(ob)));
 		trace_bucket_alloc_fail(c, buf.buf);
 	}
-
-	printbuf_exit(&buf);
 }
 
 /**
@@ -589,7 +584,8 @@ struct open_bucket *bch2_bucket_alloc(struct bch_fs *c, struct bch_dev *ca,
 		.ca		= ca,
 	};
 
-	bch2_trans_do(c,
+	CLASS(btree_trans, trans)(c);
+	lockrestart_do(trans,
 		PTR_ERR_OR_ZERO(ob = bch2_bucket_alloc_trans(trans, &req, cl, false)));
 	return ob;
 }
@@ -848,17 +844,15 @@ static int bucket_alloc_set_writepoint(struct bch_fs *c,
 static int bucket_alloc_set_partial(struct bch_fs *c,
 				    struct alloc_request *req)
 {
-	int i, ret = 0;
-
 	if (!c->open_buckets_partial_nr)
 		return 0;
 
-	spin_lock(&c->freelist_lock);
+	guard(spinlock)(&c->freelist_lock);
 
 	if (!c->open_buckets_partial_nr)
-		goto unlock;
+		return 0;
 
-	for (i = c->open_buckets_partial_nr - 1; i >= 0; --i) {
+	for (int i = c->open_buckets_partial_nr - 1; i >= 0; --i) {
 		struct open_bucket *ob = c->open_buckets + c->open_buckets_partial[i];
 
 		if (want_bucket(c, req, ob)) {
@@ -878,14 +872,13 @@ static int bucket_alloc_set_partial(struct bch_fs *c,
 			scoped_guard(rcu)
 				bch2_dev_rcu(c, ob->dev)->nr_partial_buckets--;
 
-			ret = add_new_bucket(c, req, ob);
+			int ret = add_new_bucket(c, req, ob);
 			if (ret)
-				break;
+				return ret;
 		}
 	}
-unlock:
-	spin_unlock(&c->freelist_lock);
-	return ret;
+
+	return 0;
 }
 
 static int __open_bucket_add_buckets(struct btree_trans *trans,
@@ -981,23 +974,18 @@ static bool should_drop_bucket(struct open_bucket *ob, struct bch_fs *c,
 		return ob->ec != NULL;
 	} else if (ca) {
 		bool drop = ob->dev == ca->dev_idx;
-		struct open_bucket *ob2;
-		unsigned i;
 
 		if (!drop && ob->ec) {
-			unsigned nr_blocks;
+			guard(mutex)(&ob->ec->lock);
+			unsigned nr_blocks = bkey_i_to_stripe(&ob->ec->new_stripe.key)->v.nr_blocks;
 
-			mutex_lock(&ob->ec->lock);
-			nr_blocks = bkey_i_to_stripe(&ob->ec->new_stripe.key)->v.nr_blocks;
-
-			for (i = 0; i < nr_blocks; i++) {
+			for (unsigned i = 0; i < nr_blocks; i++) {
 				if (!ob->ec->blocks[i])
 					continue;
 
-				ob2 = c->open_buckets + ob->ec->blocks[i];
+				struct open_bucket *ob2 = c->open_buckets + ob->ec->blocks[i];
 				drop |= ob2->dev == ca->dev_idx;
 			}
-			mutex_unlock(&ob->ec->lock);
 		}
 
 		return drop;
@@ -1013,14 +1001,13 @@ static void bch2_writepoint_stop(struct bch_fs *c, struct bch_dev *ca,
 	struct open_bucket *ob;
 	unsigned i;
 
-	mutex_lock(&wp->lock);
+	guard(mutex)(&wp->lock);
 	open_bucket_for_each(c, &wp->ptrs, ob, i)
 		if (should_drop_bucket(ob, c, ca, ec))
 			bch2_open_bucket_put(c, ob);
 		else
 			ob_push(c, &ptrs, ob);
 	wp->ptrs = ptrs;
-	mutex_unlock(&wp->lock);
 }
 
 void bch2_open_buckets_stop(struct bch_fs *c, struct bch_dev *ca,
@@ -1036,39 +1023,37 @@ void bch2_open_buckets_stop(struct bch_fs *c, struct bch_dev *ca,
 	bch2_writepoint_stop(c, ca, ec, &c->rebalance_write_point);
 	bch2_writepoint_stop(c, ca, ec, &c->btree_write_point);
 
-	mutex_lock(&c->btree_reserve_cache_lock);
-	while (c->btree_reserve_cache_nr) {
-		struct btree_alloc *a =
-			&c->btree_reserve_cache[--c->btree_reserve_cache_nr];
+	scoped_guard(mutex, &c->btree_reserve_cache_lock)
+		while (c->btree_reserve_cache_nr) {
+			struct btree_alloc *a =
+				&c->btree_reserve_cache[--c->btree_reserve_cache_nr];
 
-		bch2_open_buckets_put(c, &a->ob);
-	}
-	mutex_unlock(&c->btree_reserve_cache_lock);
+			bch2_open_buckets_put(c, &a->ob);
+		}
 
-	spin_lock(&c->freelist_lock);
 	i = 0;
-	while (i < c->open_buckets_partial_nr) {
-		struct open_bucket *ob =
-			c->open_buckets + c->open_buckets_partial[i];
-
-		if (should_drop_bucket(ob, c, ca, ec)) {
-			--c->open_buckets_partial_nr;
-			swap(c->open_buckets_partial[i],
-			     c->open_buckets_partial[c->open_buckets_partial_nr]);
-
-			ob->on_partial_list = false;
-
-			scoped_guard(rcu)
-				bch2_dev_rcu(c, ob->dev)->nr_partial_buckets--;
-
-			spin_unlock(&c->freelist_lock);
-			bch2_open_bucket_put(c, ob);
-			spin_lock(&c->freelist_lock);
-		} else {
-			i++;
+	scoped_guard(spinlock, &c->freelist_lock)
+		while (i < c->open_buckets_partial_nr) {
+			struct open_bucket *ob =
+				c->open_buckets + c->open_buckets_partial[i];
+
+			if (should_drop_bucket(ob, c, ca, ec)) {
+				--c->open_buckets_partial_nr;
+				swap(c->open_buckets_partial[i],
+				     c->open_buckets_partial[c->open_buckets_partial_nr]);
+
+				ob->on_partial_list = false;
+
+				scoped_guard(rcu)
+					bch2_dev_rcu(c, ob->dev)->nr_partial_buckets--;
+
+				spin_unlock(&c->freelist_lock);
+				bch2_open_bucket_put(c, ob);
+				spin_lock(&c->freelist_lock);
+			} else {
+				i++;
+			}
 		}
-	}
-	spin_unlock(&c->freelist_lock);
 
 	bch2_ec_stop_dev(c, ca);
 }
@@ -1122,22 +1107,17 @@ static noinline bool try_decrease_writepoints(struct btree_trans *trans, unsigne
 	struct open_bucket *ob;
 	unsigned i;
 
-	mutex_lock(&c->write_points_hash_lock);
-	if (c->write_points_nr < old_nr) {
-		mutex_unlock(&c->write_points_hash_lock);
-		return true;
-	}
-
-	if (c->write_points_nr == 1 ||
-	    !too_many_writepoints(c, 8)) {
-		mutex_unlock(&c->write_points_hash_lock);
-		return false;
-	}
+	scoped_guard(mutex, &c->write_points_hash_lock) {
+		if (c->write_points_nr < old_nr)
+			return true;
 
-	wp = c->write_points + --c->write_points_nr;
+		if (c->write_points_nr == 1 ||
+		    !too_many_writepoints(c, 8))
+			return false;
 
-	hlist_del_rcu(&wp->node);
-	mutex_unlock(&c->write_points_hash_lock);
+		wp = c->write_points + --c->write_points_nr;
+		hlist_del_rcu(&wp->node);
+	}
 
 	bch2_trans_mutex_lock_norelock(trans, &wp->lock);
 	open_bucket_for_each(c, &wp->ptrs, ob, i)
@@ -1471,35 +1451,25 @@ void bch2_open_bucket_to_text(struct printbuf *out, struct bch_fs *c, struct ope
 void bch2_open_buckets_to_text(struct printbuf *out, struct bch_fs *c,
 			       struct bch_dev *ca)
 {
-	struct open_bucket *ob;
-
-	out->atomic++;
+	guard(printbuf_atomic)(out);
 
-	for (ob = c->open_buckets;
+	for (struct open_bucket *ob = c->open_buckets;
 	     ob < c->open_buckets + ARRAY_SIZE(c->open_buckets);
 	     ob++) {
-		spin_lock(&ob->lock);
+		guard(spinlock)(&ob->lock);
 		if (ob->valid && (!ca || ob->dev == ca->dev_idx))
 			bch2_open_bucket_to_text(out, c, ob);
-		spin_unlock(&ob->lock);
 	}
-
-	--out->atomic;
 }
 
 void bch2_open_buckets_partial_to_text(struct printbuf *out, struct bch_fs *c)
 {
-	unsigned i;
-
-	out->atomic++;
-	spin_lock(&c->freelist_lock);
+	guard(printbuf_atomic)(out);
+	guard(spinlock)(&c->freelist_lock);
 
-	for (i = 0; i < c->open_buckets_partial_nr; i++)
+	for (unsigned i = 0; i < c->open_buckets_partial_nr; i++)
 		bch2_open_bucket_to_text(out, c,
 				c->open_buckets + c->open_buckets_partial[i]);
-
-	spin_unlock(&c->freelist_lock);
-	--out->atomic;
 }
 
 static const char * const bch2_write_point_states[] = {
@@ -1515,7 +1485,7 @@ static void bch2_write_point_to_text(struct printbuf *out, struct bch_fs *c,
 	struct open_bucket *ob;
 	unsigned i;
 
-	mutex_lock(&wp->lock);
+	guard(mutex)(&wp->lock);
 
 	prt_printf(out, "%lu: ", wp->write_point);
 	prt_human_readable_u64(out, wp->sectors_allocated << 9);
@@ -1534,8 +1504,6 @@ static void bch2_write_point_to_text(struct printbuf *out, struct bch_fs *c,
 	open_bucket_for_each(c, &wp->ptrs, ob, i)
 		bch2_open_bucket_to_text(out, c, ob);
 	printbuf_indent_sub(out, 2);
-
-	mutex_unlock(&wp->lock);
 }
 
 void bch2_write_points_to_text(struct printbuf *out, struct bch_fs *c)
@@ -1622,7 +1590,7 @@ void bch2_dev_alloc_debug_to_text(struct printbuf *out, struct bch_dev *ca)
 
 static noinline void bch2_print_allocator_stuck(struct bch_fs *c)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_printf(&buf, "Allocator stuck? Waited for %u seconds\n",
 		   c->opts.allocator_stuck_timeout);
@@ -1635,8 +1603,8 @@ static noinline void bch2_print_allocator_stuck(struct bch_fs *c)
 
 	bch2_printbuf_make_room(&buf, 4096);
 
-	buf.atomic++;
-	scoped_guard(rcu)
+	scoped_guard(rcu) {
+		guard(printbuf_atomic)(&buf);
 		for_each_online_member_rcu(c, ca) {
 			prt_printf(&buf, "Dev %u:\n", ca->dev_idx);
 			printbuf_indent_add(&buf, 2);
@@ -1644,7 +1612,7 @@ static noinline void bch2_print_allocator_stuck(struct bch_fs *c)
 			printbuf_indent_sub(&buf, 2);
 			prt_newline(&buf);
 		}
-	--buf.atomic;
+	}
 
 	prt_printf(&buf, "Copygc debug:\n");
 	printbuf_indent_add(&buf, 2);
@@ -1658,7 +1626,6 @@ static noinline void bch2_print_allocator_stuck(struct bch_fs *c)
 	printbuf_indent_sub(&buf, 2);
 
 	bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 }
 
 static inline unsigned allocator_wait_timeout(struct bch_fs *c)
diff --git a/fs/bcachefs/alloc_foreground.h b/fs/bcachefs/alloc_foreground.h
index 1b3fc8460096..02aef66859c3 100644
--- a/fs/bcachefs/alloc_foreground.h
+++ b/fs/bcachefs/alloc_foreground.h
@@ -210,16 +210,11 @@ static inline bool bch2_bucket_is_open(struct bch_fs *c, unsigned dev, u64 bucke
 
 static inline bool bch2_bucket_is_open_safe(struct bch_fs *c, unsigned dev, u64 bucket)
 {
-	bool ret;
-
 	if (bch2_bucket_is_open(c, dev, bucket))
 		return true;
 
-	spin_lock(&c->freelist_lock);
-	ret = bch2_bucket_is_open(c, dev, bucket);
-	spin_unlock(&c->freelist_lock);
-
-	return ret;
+	guard(spinlock)(&c->freelist_lock);
+	return bch2_bucket_is_open(c, dev, bucket);
 }
 
 enum bch_write_flags;
-- 
2.51.0


From 5c45fe1d871c16befed7aa831f3cae91d4e200c4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:40:55 -0400
Subject: [PATCH 142/309] bcachefs: convert fs.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs.c | 160 +++++++++++++++++------------------------------
 1 file changed, 59 insertions(+), 101 deletions(-)

diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index 3b0783f117ae..2789b30add10 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -106,14 +106,13 @@ int __must_check bch2_write_inode(struct bch_fs *c,
 				  inode_set_fn set,
 				  void *p, unsigned fields)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct btree_iter iter = {};
-	struct bch_inode_unpacked inode_u;
-	int ret;
+	CLASS(btree_trans, trans)(c);
 retry:
 	bch2_trans_begin(trans);
 
-	ret = bch2_inode_peek(trans, &iter, &inode_u, inode_inum(inode), BTREE_ITER_intent);
+	struct btree_iter iter = {};
+	struct bch_inode_unpacked inode_u;
+	int ret = bch2_inode_peek(trans, &iter, &inode_u, inode_inum(inode), BTREE_ITER_intent);
 	if (ret)
 		goto err;
 
@@ -156,7 +155,6 @@ int __must_check bch2_write_inode(struct bch_fs *c,
 			     inode_inum(inode).subvol,
 			     inode_inum(inode).inum);
 
-	bch2_trans_put(trans);
 	return ret < 0 ? ret : 0;
 }
 
@@ -166,32 +164,27 @@ int bch2_fs_quota_transfer(struct bch_fs *c,
 			   unsigned qtypes,
 			   enum quota_acct_mode mode)
 {
-	unsigned i;
-	int ret;
-
 	qtypes &= enabled_qtypes(c);
 
-	for (i = 0; i < QTYP_NR; i++)
+	for (unsigned i = 0; i < QTYP_NR; i++)
 		if (new_qid.q[i] == inode->ei_qid.q[i])
 			qtypes &= ~(1U << i);
 
 	if (!qtypes)
 		return 0;
 
-	mutex_lock(&inode->ei_quota_lock);
+	guard(mutex)(&inode->ei_quota_lock);
 
-	ret = bch2_quota_transfer(c, qtypes, new_qid,
+	int ret = bch2_quota_transfer(c, qtypes, new_qid,
 				  inode->ei_qid,
 				  inode->v.i_blocks +
 				  inode->ei_quota_reserved,
 				  mode);
 	if (!ret)
-		for (i = 0; i < QTYP_NR; i++)
+		for (unsigned i = 0; i < QTYP_NR; i++)
 			if (qtypes & (1 << i))
 				inode->ei_qid.q[i] = new_qid.q[i];
 
-	mutex_unlock(&inode->ei_quota_lock);
-
 	return ret;
 }
 
@@ -241,7 +234,7 @@ int bch2_inode_or_descendents_is_open(struct btree_trans *trans, struct bpos p)
 	struct bch_fs *c = trans->c;
 	struct rhltable *ht = &c->vfs_inodes_by_inum_table;
 	u64 inum = p.offset;
-	DARRAY(u32) subvols;
+	CLASS(darray_u32, subvols)();
 	int ret = 0;
 
 	if (!test_bit(BCH_FS_started, &c->flags))
@@ -280,7 +273,7 @@ int bch2_inode_or_descendents_is_open(struct btree_trans *trans, struct bpos p)
 					rcu_read_unlock();
 					ret = darray_make_room(&subvols, 1);
 					if (ret)
-						goto err;
+						return ret;
 					subvols.nr = 0;
 					goto restart_from_top;
 				}
@@ -303,14 +296,13 @@ int bch2_inode_or_descendents_is_open(struct btree_trans *trans, struct bpos p)
 		u32 snap;
 		ret = bch2_subvolume_get_snapshot(trans, *i, &snap);
 		if (ret)
-			goto err;
+			return ret;
 
 		ret = bch2_snapshot_is_ancestor(c, snap, p.snapshot);
 		if (ret)
 			break;
 	}
-err:
-	darray_exit(&subvols);
+
 	return ret;
 }
 
@@ -367,9 +359,9 @@ static struct bch_inode_info *bch2_inode_hash_find(struct bch_fs *c, struct btre
 
 static void bch2_inode_hash_remove(struct bch_fs *c, struct bch_inode_info *inode)
 {
-	spin_lock(&inode->v.i_lock);
-	bool remove = test_and_clear_bit(EI_INODE_HASHED, &inode->ei_flags);
-	spin_unlock(&inode->v.i_lock);
+	bool remove;
+	scoped_guard(spinlock, &inode->v.i_lock)
+		remove = test_and_clear_bit(EI_INODE_HASHED, &inode->ei_flags);
 
 	if (remove) {
 		int ret = rhltable_remove(&c->vfs_inodes_by_inum_table,
@@ -430,9 +422,8 @@ static struct bch_inode_info *bch2_inode_hash_insert(struct bch_fs *c,
 
 		inode_sb_list_add(&inode->v);
 
-		mutex_lock(&c->vfs_inodes_lock);
-		list_add(&inode->ei_vfs_inode_list, &c->vfs_inodes_list);
-		mutex_unlock(&c->vfs_inodes_lock);
+		scoped_guard(mutex, &c->vfs_inodes_lock)
+			list_add(&inode->ei_vfs_inode_list, &c->vfs_inodes_list);
 		return inode;
 	}
 }
@@ -514,7 +505,7 @@ struct inode *bch2_vfs_inode_get(struct bch_fs *c, subvol_inum inum)
 	if (inode)
 		return &inode->v;
 
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	struct bch_inode_unpacked inode_u;
 	struct bch_subvolume subvol;
@@ -522,7 +513,6 @@ struct inode *bch2_vfs_inode_get(struct bch_fs *c, subvol_inum inum)
 		bch2_subvolume_get(trans, inum.subvol, true, &subvol) ?:
 		bch2_inode_find_by_inum_trans(trans, inum, &inode_u)) ?:
 		PTR_ERR_OR_ZERO(inode = bch2_inode_hash_init_insert(trans, inum, &inode_u, &subvol));
-	bch2_trans_put(trans);
 
 	return ret ? ERR_PTR(ret) : &inode->v;
 }
@@ -534,7 +524,6 @@ __bch2_create(struct mnt_idmap *idmap,
 	      unsigned flags)
 {
 	struct bch_fs *c = dir->v.i_sb->s_fs_info;
-	struct btree_trans *trans;
 	struct bch_inode_unpacked dir_u;
 	struct bch_inode_info *inode;
 	struct bch_inode_unpacked inode_u;
@@ -555,18 +544,23 @@ __bch2_create(struct mnt_idmap *idmap,
 	if (ret)
 		return ERR_PTR(ret);
 #endif
+
 	inode = __bch2_new_inode(c, GFP_NOFS);
 	if (unlikely(!inode)) {
-		inode = ERR_PTR(-ENOMEM);
-		goto err;
+		posix_acl_release(default_acl);
+		posix_acl_release(acl);
+		return ERR_PTR(-ENOMEM);
 	}
 
 	bch2_inode_init_early(c, &inode_u);
 
 	if (!(flags & BCH_CREATE_TMPFILE))
 		mutex_lock(&dir->ei_update_lock);
-
-	trans = bch2_trans_get(c);
+	/*
+	 * posix_acl_create() calls get_acl -> btree transaction, don't start
+	 * ours until after, ei->update_lock must also be taken first:
+	 */
+	CLASS(btree_trans, trans)(c);
 retry:
 	bch2_trans_begin(trans);
 
@@ -625,7 +619,6 @@ __bch2_create(struct mnt_idmap *idmap,
 	 * restart here.
 	 */
 	inode = bch2_inode_hash_insert(c, NULL, inode);
-	bch2_trans_put(trans);
 err:
 	posix_acl_release(default_acl);
 	posix_acl_release(acl);
@@ -634,7 +627,6 @@ __bch2_create(struct mnt_idmap *idmap,
 	if (!(flags & BCH_CREATE_TMPFILE))
 		mutex_unlock(&dir->ei_update_lock);
 
-	bch2_trans_put(trans);
 	make_bad_inode(&inode->v);
 	iput(&inode->v);
 	inode = ERR_PTR(ret);
@@ -649,7 +641,7 @@ static struct bch_inode_info *bch2_lookup_trans(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	subvol_inum inum = {};
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	struct qstr lookup_name;
 	int ret = bch2_maybe_casefold(trans, dir_hash_info, name, &lookup_name);
@@ -701,7 +693,6 @@ static struct bch_inode_info *bch2_lookup_trans(struct btree_trans *trans,
 		goto err;
 out:
 	bch2_trans_iter_exit(trans, &dirent_iter);
-	printbuf_exit(&buf);
 	return inode;
 err:
 	inode = ERR_PTR(ret);
@@ -770,8 +761,8 @@ static int __bch2_link(struct bch_fs *c,
 	struct bch_inode_unpacked dir_u, inode_u;
 	int ret;
 
-	mutex_lock(&inode->ei_update_lock);
-	struct btree_trans *trans = bch2_trans_get(c);
+	guard(mutex)(&inode->ei_update_lock);
+	CLASS(btree_trans, trans)(c);
 
 	ret = commit_do(trans, NULL, NULL, 0,
 			bch2_link_trans(trans,
@@ -785,8 +776,6 @@ static int __bch2_link(struct bch_fs *c,
 		bch2_inode_update_after_write(trans, inode, &inode_u, ATTR_CTIME);
 	}
 
-	bch2_trans_put(trans);
-	mutex_unlock(&inode->ei_update_lock);
 	return ret;
 }
 
@@ -821,8 +810,7 @@ int __bch2_unlink(struct inode *vdir, struct dentry *dentry,
 	int ret;
 
 	bch2_lock_inodes(INODE_UPDATE_LOCK, dir, inode);
-
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	ret = commit_do(trans, NULL, NULL,
 			BCH_TRANS_COMMIT_no_enospc,
@@ -849,7 +837,6 @@ int __bch2_unlink(struct inode *vdir, struct dentry *dentry,
 	if (IS_CASEFOLDED(vdir))
 		d_invalidate(dentry);
 err:
-	bch2_trans_put(trans);
 	bch2_unlock_inodes(INODE_UPDATE_LOCK, dir, inode);
 
 	return ret;
@@ -918,7 +905,6 @@ static int bch2_rename2(struct mnt_idmap *idmap,
 	struct bch_inode_info *dst_inode = to_bch_ei(dst_dentry->d_inode);
 	struct bch_inode_unpacked dst_dir_u, src_dir_u;
 	struct bch_inode_unpacked src_inode_u, dst_inode_u, *whiteout_inode_u;
-	struct btree_trans *trans;
 	enum bch_rename_mode mode = flags & RENAME_EXCHANGE
 		? BCH_RENAME_EXCHANGE
 		: dst_dentry->d_inode
@@ -942,7 +928,7 @@ static int bch2_rename2(struct mnt_idmap *idmap,
 			 src_inode,
 			 dst_inode);
 
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	ret   = bch2_subvol_is_ro_trans(trans, src_dir->ei_inum.subvol) ?:
 		bch2_subvol_is_ro_trans(trans, dst_dir->ei_inum.subvol);
@@ -1028,8 +1014,6 @@ static int bch2_rename2(struct mnt_idmap *idmap,
 		bch2_inode_update_after_write(trans, dst_inode, &dst_inode_u,
 					      ATTR_CTIME);
 err:
-	bch2_trans_put(trans);
-
 	bch2_fs_quota_transfer(c, src_inode,
 			       bch_qid(&src_inode->ei_inode),
 			       1 << QTYP_PRJ,
@@ -1097,7 +1081,6 @@ int bch2_setattr_nonsize(struct mnt_idmap *idmap,
 {
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
 	struct bch_qid qid;
-	struct btree_trans *trans;
 	struct btree_iter inode_iter = {};
 	struct bch_inode_unpacked inode_u;
 	struct posix_acl *acl = NULL;
@@ -1105,7 +1088,7 @@ int bch2_setattr_nonsize(struct mnt_idmap *idmap,
 	kgid_t kgid;
 	int ret;
 
-	mutex_lock(&inode->ei_update_lock);
+	guard(mutex)(&inode->ei_update_lock);
 
 	qid = inode->ei_qid;
 
@@ -1122,9 +1105,9 @@ int bch2_setattr_nonsize(struct mnt_idmap *idmap,
 	ret = bch2_fs_quota_transfer(c, inode, qid, ~0,
 				     KEY_TYPE_QUOTA_PREALLOC);
 	if (ret)
-		goto err;
+		return ret;
 
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 retry:
 	bch2_trans_begin(trans);
 	kfree(acl);
@@ -1153,18 +1136,13 @@ int bch2_setattr_nonsize(struct mnt_idmap *idmap,
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 	if (unlikely(ret))
-		goto err_trans;
+		return ret;
 
 	bch2_inode_update_after_write(trans, inode, &inode_u, attr->ia_valid);
 
 	if (acl)
 		set_cached_acl(&inode->v, ACL_TYPE_ACCESS, acl);
-err_trans:
-	bch2_trans_put(trans);
-err:
-	mutex_unlock(&inode->ei_update_lock);
-
-	return bch2_err_class(ret);
+	return 0;
 }
 
 static int bch2_getattr(struct mnt_idmap *idmap,
@@ -1228,18 +1206,16 @@ static int bch2_setattr(struct mnt_idmap *idmap,
 {
 	struct bch_inode_info *inode = to_bch_ei(dentry->d_inode);
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	int ret;
 
 	lockdep_assert_held(&inode->v.i_rwsem);
 
-	ret   = bch2_subvol_is_ro(c, inode->ei_inum.subvol) ?:
-		setattr_prepare(idmap, dentry, iattr);
-	if (ret)
-		return ret;
+	int ret = bch2_subvol_is_ro(c, inode->ei_inum.subvol) ?:
+		setattr_prepare(idmap, dentry, iattr) ?:
+		(iattr->ia_valid & ATTR_SIZE
+		 ? bchfs_truncate(idmap, inode, iattr)
+		 : bch2_setattr_nonsize(idmap, inode, iattr));
 
-	return iattr->ia_valid & ATTR_SIZE
-		? bchfs_truncate(idmap, inode, iattr)
-		: bch2_setattr_nonsize(idmap, inode, iattr);
+	return bch2_err_class(ret);
 }
 
 static int bch2_tmpfile(struct mnt_idmap *idmap,
@@ -1487,7 +1463,6 @@ static int bch2_fiemap(struct inode *vinode, struct fiemap_extent_info *info,
 {
 	struct bch_fs *c = vinode->i_sb->s_fs_info;
 	struct bch_inode_info *ei = to_bch_ei(vinode);
-	struct btree_trans *trans;
 	struct bch_fiemap_extent cur, prev;
 	int ret = 0;
 
@@ -1505,7 +1480,7 @@ static int bch2_fiemap(struct inode *vinode, struct fiemap_extent_info *info,
 	bch2_bkey_buf_init(&prev.kbuf);
 	bkey_init(&prev.kbuf.k->k);
 
-	trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 
 	while (start < end) {
 		ret = lockrestart_do(trans,
@@ -1538,7 +1513,6 @@ static int bch2_fiemap(struct inode *vinode, struct fiemap_extent_info *info,
 		ret = bch2_fill_extent(c, info, &prev);
 	}
 err:
-	bch2_trans_put(trans);
 	bch2_bkey_buf_exit(&cur.kbuf, c);
 	bch2_bkey_buf_exit(&prev.kbuf, c);
 
@@ -1968,7 +1942,6 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 	struct bch_inode_info *inode	= to_bch_ei(child->d_inode);
 	struct bch_inode_info *dir	= to_bch_ei(parent->d_inode);
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	struct btree_trans *trans;
 	struct btree_iter iter1;
 	struct btree_iter iter2;
 	struct bkey_s_c k;
@@ -1983,8 +1956,7 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 	if (!S_ISDIR(dir->v.i_mode))
 		return -EINVAL;
 
-	trans = bch2_trans_get(c);
-
+	CLASS(btree_trans, trans)(c);
 	bch2_trans_iter_init(trans, &iter1, BTREE_ID_dirents,
 			     POS(dir->ei_inode.bi_inum, 0), 0);
 	bch2_trans_iter_init(trans, &iter2, BTREE_ID_dirents,
@@ -2063,8 +2035,6 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 
 	bch2_trans_iter_exit(trans, &iter1);
 	bch2_trans_iter_exit(trans, &iter2);
-	bch2_trans_put(trans);
-
 	return ret;
 }
 
@@ -2148,12 +2118,11 @@ static int bch2_vfs_write_inode(struct inode *vinode,
 {
 	struct bch_fs *c = vinode->i_sb->s_fs_info;
 	struct bch_inode_info *inode = to_bch_ei(vinode);
-	int ret;
 
-	mutex_lock(&inode->ei_update_lock);
-	ret = bch2_write_inode(c, inode, inode_update_times_fn, NULL,
-			       ATTR_ATIME|ATTR_MTIME|ATTR_CTIME);
-	mutex_unlock(&inode->ei_update_lock);
+	guard(mutex)(&inode->ei_update_lock);
+
+	int ret = bch2_write_inode(c, inode, inode_update_times_fn, NULL,
+				   ATTR_ATIME|ATTR_MTIME|ATTR_CTIME);
 
 	return bch2_err_class(ret);
 }
@@ -2200,9 +2169,8 @@ static void bch2_evict_inode(struct inode *vinode)
 		bch2_inode_hash_remove(c, inode);
 	}
 
-	mutex_lock(&c->vfs_inodes_lock);
-	list_del_init(&inode->ei_vfs_inode_list);
-	mutex_unlock(&c->vfs_inodes_lock);
+	scoped_guard(mutex, &c->vfs_inodes_lock)
+		list_del_init(&inode->ei_vfs_inode_list);
 }
 
 void bch2_evict_subvolume_inodes(struct bch_fs *c, snapshot_id_list *s)
@@ -2352,16 +2320,14 @@ static int bch2_show_devname(struct seq_file *seq, struct dentry *root)
 static int bch2_show_options(struct seq_file *seq, struct dentry *root)
 {
 	struct bch_fs *c = root->d_sb->s_fs_info;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_opts_to_text(&buf, c->opts, c, c->disk_sb.sb,
 			  OPT_MOUNT, OPT_HIDDEN, OPT_SHOW_MOUNT_STYLE);
 	printbuf_nul_terminate(&buf);
 	seq_printf(seq, ",%s", buf.buf);
 
-	int ret = buf.allocation_failure ? -ENOMEM : 0;
-	printbuf_exit(&buf);
-	return ret;
+	return buf.allocation_failure ? -ENOMEM : 0;
 }
 
 static void bch2_put_super(struct super_block *sb)
@@ -2383,24 +2349,20 @@ static int bch2_freeze(struct super_block *sb)
 {
 	struct bch_fs *c = sb->s_fs_info;
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 	bch2_fs_read_only(c);
-	up_write(&c->state_lock);
 	return 0;
 }
 
 static int bch2_unfreeze(struct super_block *sb)
 {
 	struct bch_fs *c = sb->s_fs_info;
-	int ret;
 
 	if (test_bit(BCH_FS_emergency_ro, &c->flags))
 		return 0;
 
-	down_write(&c->state_lock);
-	ret = bch2_fs_read_write(c);
-	up_write(&c->state_lock);
-	return ret;
+	guard(rwsem_write)(&c->state_lock);
+	return bch2_fs_read_write(c);
 }
 
 static const struct super_operations bch_super_operations = {
@@ -2671,7 +2633,7 @@ static int bch2_fs_reconfigure(struct fs_context *fc)
 	opt_set(opts->opts, read_only, (fc->sb_flags & SB_RDONLY) != 0);
 
 	if (opts->opts.read_only != c->opts.read_only) {
-		down_write(&c->state_lock);
+		guard(rwsem_write)(&c->state_lock);
 
 		if (opts->opts.read_only) {
 			bch2_fs_read_only(c);
@@ -2681,22 +2643,18 @@ static int bch2_fs_reconfigure(struct fs_context *fc)
 			ret = bch2_fs_read_write(c);
 			if (ret) {
 				bch_err(c, "error going rw: %i", ret);
-				up_write(&c->state_lock);
-				ret = -EINVAL;
-				goto err;
+				return -EINVAL;
 			}
 
 			sb->s_flags &= ~SB_RDONLY;
 		}
 
 		c->opts.read_only = opts->opts.read_only;
-
-		up_write(&c->state_lock);
 	}
 
 	if (opt_defined(opts->opts, errors))
 		c->opts.errors = opts->opts.errors;
-err:
+
 	return bch2_err_class(ret);
 }
 
-- 
2.51.0


From 0cbad02f5828d623cb53b3d2e5c4a500f1f11c10 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:41:03 -0400
Subject: [PATCH 143/309] bcachefs: convert fs-io.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io.c | 125 ++++++++++++++++++++------------------------
 fs/bcachefs/fs-io.h |  19 +++----
 2 files changed, 66 insertions(+), 78 deletions(-)

diff --git a/fs/bcachefs/fs-io.c b/fs/bcachefs/fs-io.c
index dc5f713e209c..93ad33f0953a 100644
--- a/fs/bcachefs/fs-io.c
+++ b/fs/bcachefs/fs-io.c
@@ -148,7 +148,7 @@ void __bch2_i_sectors_acct(struct bch_fs *c, struct bch_inode_info *inode,
 			   struct quota_res *quota_res, s64 sectors)
 {
 	if (unlikely((s64) inode->v.i_blocks + sectors < 0)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 		prt_printf(&buf, "inode %lu i_blocks underflow: %llu + %lli < 0 (ondisk %lli)",
 			   inode->v.i_ino, (u64) inode->v.i_blocks, sectors,
@@ -157,7 +157,6 @@ void __bch2_i_sectors_acct(struct bch_fs *c, struct bch_inode_info *inode,
 		bool print = bch2_count_fsck_err(c, vfs_inode_i_blocks_underflow, &buf);
 		if (print)
 			bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 
 		if (sectors < 0)
 			sectors = -inode->v.i_blocks;
@@ -187,7 +186,6 @@ void __bch2_i_sectors_acct(struct bch_fs *c, struct bch_inode_info *inode,
 static int bch2_get_inode_journal_seq_trans(struct btree_trans *trans, subvol_inum inum,
 					    u64 *seq)
 {
-	struct printbuf buf = PRINTBUF;
 	struct bch_inode_unpacked u;
 	struct btree_iter iter;
 	int ret = bch2_inode_peek(trans, &iter, &u, inum, 0);
@@ -197,6 +195,7 @@ static int bch2_get_inode_journal_seq_trans(struct btree_trans *trans, subvol_in
 	u64 cur_seq = journal_cur_seq(&trans->c->journal);
 	*seq = min(cur_seq, u.bi_journal_seq);
 
+	CLASS(printbuf, buf)();
 	if (fsck_err_on(u.bi_journal_seq > cur_seq,
 			trans, inode_journal_seq_in_future,
 			"inode journal seq in future (currently at %llu)\n%s",
@@ -208,7 +207,6 @@ static int bch2_get_inode_journal_seq_trans(struct btree_trans *trans, subvol_in
 	}
 fsck_err:
 	bch2_trans_iter_exit(trans, &iter);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -227,7 +225,7 @@ static int bch2_flush_inode(struct bch_fs *c,
 
 	u64 seq;
 	int ret = bch2_trans_commit_do(c, NULL, NULL, 0,
-			bch2_get_inode_journal_seq_trans(trans, inode_inum(inode), &seq)) ?:
+			    bch2_get_inode_journal_seq_trans(trans, inode_inum(inode), &seq)) ?:
 		  bch2_journal_flush_seq(&c->journal, seq, TASK_INTERRUPTIBLE) ?:
 		  bch2_inode_flush_nocow_writes(c, inode);
 	enumerated_ref_put(&c->writes, BCH_WRITE_REF_fsync);
@@ -267,11 +265,11 @@ static inline int range_has_data(struct bch_fs *c, u32 subvol,
 				 struct bpos start,
 				 struct bpos end)
 {
-	return bch2_trans_run(c,
-		for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_extents, start, end,
+	CLASS(btree_trans, trans)(c);
+	return for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_extents, start, end,
 						    subvol, 0, k, ({
-			bkey_extent_is_data(k.k) && !bkey_extent_is_unwritten(k);
-		})));
+		bkey_extent_is_data(k.k) && !bkey_extent_is_unwritten(k);
+	}));
 }
 
 static int __bch2_truncate_folio(struct bch_inode_info *inode,
@@ -521,7 +519,7 @@ int bchfs_truncate(struct mnt_idmap *idmap,
 
 	if (unlikely(!inode->v.i_size && inode->v.i_blocks &&
 		     !bch2_journal_error(&c->journal))) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 		prt_printf(&buf,
 			   "inode %lu truncated to 0 but i_blocks %llu (ondisk %lli)",
@@ -531,7 +529,6 @@ int bchfs_truncate(struct mnt_idmap *idmap,
 		bool print = bch2_count_fsck_err(c, vfs_inode_i_blocks_not_zero_at_truncate, &buf);
 		if (print)
 			bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	ret = bch2_setattr_nonsize(idmap, inode, iattr);
@@ -559,11 +556,10 @@ static noinline long bchfs_fpunch(struct bch_inode_info *inode, loff_t offset, l
 	u64 block_start	= round_up(offset, block_bytes(c));
 	u64 block_end	= round_down(end, block_bytes(c));
 	bool truncated_last_page;
-	int ret = 0;
 
-	ret = bch2_truncate_folios(inode, offset, end);
+	int ret = bch2_truncate_folios(inode, offset, end);
 	if (unlikely(ret < 0))
-		goto err;
+		return ret;
 
 	truncated_last_page = ret;
 
@@ -576,19 +572,18 @@ static noinline long bchfs_fpunch(struct bch_inode_info *inode, loff_t offset, l
 				  block_start >> 9, block_end >> 9,
 				  &i_sectors_delta);
 		bch2_i_sectors_acct(c, inode, NULL, i_sectors_delta);
+
+		if (ret)
+			return ret;
 	}
 
-	mutex_lock(&inode->ei_update_lock);
-	if (end >= inode->v.i_size && !truncated_last_page) {
-		ret = bch2_write_inode_size(c, inode, inode->v.i_size,
-					    ATTR_MTIME|ATTR_CTIME);
-	} else {
-		ret = bch2_write_inode(c, inode, inode_update_times_fn, NULL,
+	guard(mutex)(&inode->ei_update_lock);
+	if (end >= inode->v.i_size && !truncated_last_page)
+		return bch2_write_inode_size(c, inode, inode->v.i_size,
+					     ATTR_MTIME|ATTR_CTIME);
+	else
+		return bch2_write_inode(c, inode, inode_update_times_fn, NULL,
 				       ATTR_MTIME|ATTR_CTIME);
-	}
-	mutex_unlock(&inode->ei_update_lock);
-err:
-	return ret;
 }
 
 static noinline long bchfs_fcollapse_finsert(struct bch_inode_info *inode,
@@ -631,7 +626,7 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 			     u64 start_sector, u64 end_sector)
 {
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bpos end_pos = POS(inode->v.i_ino, end_sector);
 	struct bch_io_opts opts;
@@ -753,7 +748,6 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 	}
 
 	bch2_trans_iter_exit(trans, &iter);
-	bch2_trans_put(trans);
 	return ret;
 }
 
@@ -802,13 +796,11 @@ static noinline long bchfs_fallocate(struct bch_inode_info *inode, int mode,
 	if (end >= inode->v.i_size &&
 	    (((mode & FALLOC_FL_ZERO_RANGE) && !truncated_last_page) ||
 	     !(mode & FALLOC_FL_KEEP_SIZE))) {
-		spin_lock(&inode->v.i_lock);
-		i_size_write(&inode->v, end);
-		spin_unlock(&inode->v.i_lock);
+		scoped_guard(spinlock, &inode->v.i_lock)
+			i_size_write(&inode->v, end);
 
-		mutex_lock(&inode->ei_update_lock);
-		ret2 = bch2_write_inode_size(c, inode, end, 0);
-		mutex_unlock(&inode->ei_update_lock);
+		scoped_guard(mutex, &inode->ei_update_lock)
+			ret2 = bch2_write_inode_size(c, inode, end, 0);
 	}
 
 	return ret ?: ret2;
@@ -861,8 +853,8 @@ static int quota_reserve_range(struct bch_inode_info *inode,
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
 	u64 sectors = end - start;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_in_subvolume_max(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_in_subvolume_max(trans, iter,
 				BTREE_ID_extents,
 				POS(inode->v.i_ino, start),
 				POS(inode->v.i_ino, end - 1),
@@ -875,7 +867,7 @@ static int quota_reserve_range(struct bch_inode_info *inode,
 			}
 
 			0;
-		})));
+		}));
 
 	return ret ?: bch2_quota_reservation_add(c, inode, res, sectors, true);
 }
@@ -955,10 +947,9 @@ loff_t bch2_remap_file_range(struct file *file_src, loff_t pos_src,
 
 	bch2_i_sectors_acct(c, dst, &quota_res, i_sectors_delta);
 
-	spin_lock(&dst->v.i_lock);
-	if (pos_dst + ret > dst->v.i_size)
-		i_size_write(&dst->v, pos_dst + ret);
-	spin_unlock(&dst->v.i_lock);
+	scoped_guard(spinlock, &dst->v.i_lock)
+		if (pos_dst + ret > dst->v.i_size)
+			i_size_write(&dst->v, pos_dst + ret);
 
 	if ((file_dst->f_flags & (__O_SYNC | O_DSYNC)) ||
 	    IS_SYNC(file_inode(file_dst)))
@@ -1020,38 +1011,38 @@ static loff_t bch2_seek_hole(struct file *file, u64 offset)
 	if (offset >= isize)
 		return -ENXIO;
 
-	int ret = bch2_trans_run(c,
-		for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_extents,
+	CLASS(btree_trans, trans)(c);
+	int ret = for_each_btree_key_in_subvolume_max(trans, iter, BTREE_ID_extents,
 				   POS(inode->v.i_ino, offset >> 9),
 				   POS(inode->v.i_ino, U64_MAX),
 				   inum.subvol, BTREE_ITER_slots, k, ({
-			if (k.k->p.inode != inode->v.i_ino ||
-			    !bkey_extent_is_data(k.k)) {
-				loff_t start_offset = k.k->p.inode == inode->v.i_ino
-					? max(offset, bkey_start_offset(k.k) << 9)
-					: offset;
-				loff_t end_offset = k.k->p.inode == inode->v.i_ino
-					? MAX_LFS_FILESIZE
-					: k.k->p.offset << 9;
-
-				/*
-				 * Found a hole in the btree, now make sure it's
-				 * a hole in the pagecache. We might have to
-				 * keep searching if this hole is entirely dirty
-				 * in the page cache:
-				 */
-				bch2_trans_unlock(trans);
-				loff_t pagecache_hole = bch2_seek_pagecache_hole(&inode->v,
-								start_offset, end_offset, 0, false);
-				if (pagecache_hole < end_offset) {
-					next_hole = pagecache_hole;
-					break;
-				}
-			} else {
-				offset = max(offset, bkey_start_offset(k.k) << 9);
+		if (k.k->p.inode != inode->v.i_ino ||
+		    !bkey_extent_is_data(k.k)) {
+			loff_t start_offset = k.k->p.inode == inode->v.i_ino
+				? max(offset, bkey_start_offset(k.k) << 9)
+				: offset;
+			loff_t end_offset = k.k->p.inode == inode->v.i_ino
+				? MAX_LFS_FILESIZE
+				: k.k->p.offset << 9;
+
+			/*
+			 * Found a hole in the btree, now make sure it's
+			 * a hole in the pagecache. We might have to
+			 * keep searching if this hole is entirely dirty
+			 * in the page cache:
+			 */
+			bch2_trans_unlock(trans);
+			loff_t pagecache_hole = bch2_seek_pagecache_hole(&inode->v,
+							start_offset, end_offset, 0, false);
+			if (pagecache_hole < end_offset) {
+				next_hole = pagecache_hole;
+				break;
 			}
-			0;
-		})));
+		} else {
+			offset = max(offset, bkey_start_offset(k.k) << 9);
+		}
+		0;
+	}));
 	if (ret)
 		return ret;
 
diff --git a/fs/bcachefs/fs-io.h b/fs/bcachefs/fs-io.h
index ca70346e68dc..d229f7225da1 100644
--- a/fs/bcachefs/fs-io.h
+++ b/fs/bcachefs/fs-io.h
@@ -77,9 +77,8 @@ static inline void bch2_quota_reservation_put(struct bch_fs *c,
 				       struct quota_res *res)
 {
 	if (res->sectors) {
-		mutex_lock(&inode->ei_quota_lock);
+		guard(mutex)(&inode->ei_quota_lock);
 		__bch2_quota_reservation_put(c, inode, res);
-		mutex_unlock(&inode->ei_quota_lock);
 	}
 }
 
@@ -94,16 +93,15 @@ static inline int bch2_quota_reservation_add(struct bch_fs *c,
 	if (test_bit(EI_INODE_SNAPSHOT, &inode->ei_flags))
 		return 0;
 
-	mutex_lock(&inode->ei_quota_lock);
+	guard(mutex)(&inode->ei_quota_lock);
 	ret = bch2_quota_acct(c, inode->ei_qid, Q_SPC, sectors,
 			      check_enospc ? KEY_TYPE_QUOTA_PREALLOC : KEY_TYPE_QUOTA_NOCHECK);
-	if (likely(!ret)) {
-		inode->ei_quota_reserved += sectors;
-		res->sectors += sectors;
-	}
-	mutex_unlock(&inode->ei_quota_lock);
+	if (ret)
+		return ret;
 
-	return ret;
+	inode->ei_quota_reserved += sectors;
+	res->sectors += sectors;
+	return 0;
 }
 
 #else
@@ -134,9 +132,8 @@ static inline void bch2_i_sectors_acct(struct bch_fs *c, struct bch_inode_info *
 				       struct quota_res *quota_res, s64 sectors)
 {
 	if (sectors) {
-		mutex_lock(&inode->ei_quota_lock);
+		guard(mutex)(&inode->ei_quota_lock);
 		__bch2_i_sectors_acct(c, inode, quota_res, sectors);
-		mutex_unlock(&inode->ei_quota_lock);
 	}
 }
 
-- 
2.51.0


From 581133cb7505bfff2243a3ae329e14e68d258c2f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:41:11 -0400
Subject: [PATCH 144/309] bcachefs: convert fs-io-pagecache.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-pagecache.c | 53 +++++++++++++++--------------------
 1 file changed, 22 insertions(+), 31 deletions(-)

diff --git a/fs/bcachefs/fs-io-pagecache.c b/fs/bcachefs/fs-io-pagecache.c
index c2cc405822f2..2a6705186c44 100644
--- a/fs/bcachefs/fs-io-pagecache.c
+++ b/fs/bcachefs/fs-io-pagecache.c
@@ -125,11 +125,9 @@ folio_sector_reserve(enum bch_folio_sector_state state)
 /* for newly allocated folios: */
 struct bch_folio *__bch2_folio_create(struct folio *folio, gfp_t gfp)
 {
-	struct bch_folio *s;
-
-	s = kzalloc(sizeof(*s) +
-		    sizeof(struct bch_folio_sector) *
-		    folio_sectors(folio), gfp);
+	struct bch_folio *s = kzalloc(sizeof(*s) +
+				      sizeof(struct bch_folio_sector) *
+				      folio_sectors(folio), gfp);
 	if (!s)
 		return NULL;
 
@@ -162,7 +160,7 @@ static void __bch2_folio_set(struct folio *folio,
 	BUG_ON(pg_offset >= sectors);
 	BUG_ON(pg_offset + pg_len > sectors);
 
-	spin_lock(&s->lock);
+	guard(spinlock)(&s->lock);
 
 	for (i = pg_offset; i < pg_offset + pg_len; i++) {
 		s->s[i].nr_replicas	= nr_ptrs;
@@ -171,8 +169,6 @@ static void __bch2_folio_set(struct folio *folio,
 
 	if (i == sectors)
 		s->uptodate = true;
-
-	spin_unlock(&s->lock);
 }
 
 /*
@@ -276,10 +272,9 @@ void bch2_mark_pagecache_unallocated(struct bch_inode_info *inode,
 			s = bch2_folio(folio);
 
 			if (s) {
-				spin_lock(&s->lock);
+				guard(spinlock)(&s->lock);
 				for (j = folio_offset; j < folio_offset + folio_len; j++)
 					s->s[j].nr_replicas = 0;
-				spin_unlock(&s->lock);
 			}
 
 			folio_unlock(folio);
@@ -330,13 +325,12 @@ int bch2_mark_pagecache_reserved(struct bch_inode_info *inode,
 				unsigned folio_offset = max(*start, folio_start) - folio_start;
 				unsigned folio_len = min(end, folio_end) - folio_offset - folio_start;
 
-				spin_lock(&s->lock);
+				guard(spinlock)(&s->lock);
 				for (unsigned j = folio_offset; j < folio_offset + folio_len; j++) {
 					i_sectors_delta -= s->s[j].state == SECTOR_dirty;
 					bch2_folio_sector_set(folio, s, j,
 						folio_sector_reserve(s->s[j].state));
 				}
-				spin_unlock(&s->lock);
 			}
 
 			folio_unlock(folio);
@@ -529,29 +523,26 @@ void bch2_set_folio_dirty(struct bch_fs *c,
 
 	BUG_ON(!s->uptodate);
 
-	spin_lock(&s->lock);
-
-	for (i = round_down(offset, block_bytes(c)) >> 9;
-	     i < round_up(offset + len, block_bytes(c)) >> 9;
-	     i++) {
-		unsigned sectors = sectors_to_reserve(&s->s[i],
-						res->disk.nr_replicas);
-
-		/*
-		 * This can happen if we race with the error path in
-		 * bch2_writepage_io_done():
-		 */
-		sectors = min_t(unsigned, sectors, res->disk.sectors);
+	scoped_guard(spinlock, &s->lock)
+		for (i = round_down(offset, block_bytes(c)) >> 9;
+		     i < round_up(offset + len, block_bytes(c)) >> 9;
+		     i++) {
+			unsigned sectors = sectors_to_reserve(&s->s[i],
+							res->disk.nr_replicas);
 
-		s->s[i].replicas_reserved += sectors;
-		res->disk.sectors -= sectors;
+			/*
+			 * This can happen if we race with the error path in
+			 * bch2_writepage_io_done():
+			 */
+			sectors = min_t(unsigned, sectors, res->disk.sectors);
 
-		dirty_sectors += s->s[i].state == SECTOR_unallocated;
+			s->s[i].replicas_reserved += sectors;
+			res->disk.sectors -= sectors;
 
-		bch2_folio_sector_set(folio, s, i, folio_sector_dirty(s->s[i].state));
-	}
+			dirty_sectors += s->s[i].state == SECTOR_unallocated;
 
-	spin_unlock(&s->lock);
+			bch2_folio_sector_set(folio, s, i, folio_sector_dirty(s->s[i].state));
+		}
 
 	bch2_i_sectors_acct(c, inode, &res->quota, dirty_sectors);
 
-- 
2.51.0


From 48f6da2611cde28c46fe73a57241b3c9f449c014 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:41:19 -0400
Subject: [PATCH 145/309] bcachefs: convert fs-io-buffered.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 67 ++++++++++++++++--------------------
 1 file changed, 30 insertions(+), 37 deletions(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index 4e82dfa6c03f..f2389054693a 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -254,12 +254,11 @@ static void bchfs_read(struct btree_trans *trans,
 	bch2_trans_iter_exit(trans, &iter);
 
 	if (ret) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		lockrestart_do(trans,
 			bch2_inum_offset_err_msg_trans(trans, &buf, inum, iter.pos.offset << 9));
 		prt_printf(&buf, "read error %s from btree lookup", bch2_err_str(ret));
 		bch_err_ratelimited(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 
 		rbio->bio.bi_status = BLK_STS_IOERR;
 		bio_endio(&rbio->bio);
@@ -425,27 +424,23 @@ static void bch2_writepage_io_done(struct bch_write_op *op)
 		set_bit(EI_INODE_ERROR, &io->inode->ei_flags);
 
 		bio_for_each_folio_all(fi, bio) {
-			struct bch_folio *s;
-
 			mapping_set_error(fi.folio->mapping, -EIO);
 
-			s = __bch2_folio(fi.folio);
-			spin_lock(&s->lock);
+			struct bch_folio *s = __bch2_folio(fi.folio);
+			guard(spinlock)(&s->lock);
+
 			for (i = 0; i < folio_sectors(fi.folio); i++)
 				s->s[i].nr_replicas = 0;
-			spin_unlock(&s->lock);
 		}
 	}
 
 	if (io->op.flags & BCH_WRITE_wrote_data_inline) {
 		bio_for_each_folio_all(fi, bio) {
-			struct bch_folio *s;
+			struct bch_folio *s = __bch2_folio(fi.folio);
+			guard(spinlock)(&s->lock);
 
-			s = __bch2_folio(fi.folio);
-			spin_lock(&s->lock);
 			for (i = 0; i < folio_sectors(fi.folio); i++)
 				s->s[i].nr_replicas = 0;
-			spin_unlock(&s->lock);
 		}
 	}
 
@@ -571,30 +566,30 @@ static int __bch2_writepage(struct folio *folio,
 	BUG_ON(ret);
 
 	/* Before unlocking the page, get copy of reservations: */
-	spin_lock(&s->lock);
-	memcpy(w->tmp, s->s, sizeof(struct bch_folio_sector) * f_sectors);
+	scoped_guard(spinlock, &s->lock) {
+		memcpy(w->tmp, s->s, sizeof(struct bch_folio_sector) * f_sectors);
 
-	for (i = 0; i < f_sectors; i++) {
-		if (s->s[i].state < SECTOR_dirty)
-			continue;
+		for (i = 0; i < f_sectors; i++) {
+			if (s->s[i].state < SECTOR_dirty)
+				continue;
 
-		nr_replicas_this_write =
-			min_t(unsigned, nr_replicas_this_write,
-			      s->s[i].nr_replicas +
-			      s->s[i].replicas_reserved);
-	}
+			nr_replicas_this_write =
+				min_t(unsigned, nr_replicas_this_write,
+				      s->s[i].nr_replicas +
+				      s->s[i].replicas_reserved);
+		}
 
-	for (i = 0; i < f_sectors; i++) {
-		if (s->s[i].state < SECTOR_dirty)
-			continue;
+		for (i = 0; i < f_sectors; i++) {
+			if (s->s[i].state < SECTOR_dirty)
+				continue;
 
-		s->s[i].nr_replicas = w->opts.compression
-			? 0 : nr_replicas_this_write;
+			s->s[i].nr_replicas = w->opts.compression
+				? 0 : nr_replicas_this_write;
 
-		s->s[i].replicas_reserved = 0;
-		bch2_folio_sector_set(folio, s, i, SECTOR_allocated);
+			s->s[i].replicas_reserved = 0;
+			bch2_folio_sector_set(folio, s, i, SECTOR_allocated);
+		}
 	}
-	spin_unlock(&s->lock);
 
 	BUG_ON(atomic_read(&s->write_count));
 	atomic_set(&s->write_count, 1);
@@ -780,10 +775,9 @@ int bch2_write_end(struct file *file, struct address_space *mapping,
 		copied = 0;
 	}
 
-	spin_lock(&inode->v.i_lock);
-	if (pos + copied > inode->v.i_size)
-		i_size_write(&inode->v, pos + copied);
-	spin_unlock(&inode->v.i_lock);
+	scoped_guard(spinlock, &inode->v.i_lock)
+		if (pos + copied > inode->v.i_size)
+			i_size_write(&inode->v, pos + copied);
 
 	if (copied) {
 		if (!folio_test_uptodate(folio))
@@ -942,10 +936,9 @@ static int __bch2_buffered_write(struct bch_inode_info *inode,
 
 	end = pos + copied;
 
-	spin_lock(&inode->v.i_lock);
-	if (end > inode->v.i_size)
-		i_size_write(&inode->v, end);
-	spin_unlock(&inode->v.i_lock);
+	scoped_guard(spinlock, &inode->v.i_lock)
+		if (end > inode->v.i_size)
+			i_size_write(&inode->v, end);
 
 	f_pos = pos;
 	f_offset = pos - folio_pos(darray_first(fs));
-- 
2.51.0


From d1abc771d8050c38da46da0e20559dcd531d1bac Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:41:28 -0400
Subject: [PATCH 146/309] bcachefs: convert fs-io-direct.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-direct.c | 9 +++------
 1 file changed, 3 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/fs-io-direct.c b/fs/bcachefs/fs-io-direct.c
index 1f5154d9676b..73d44875faf2 100644
--- a/fs/bcachefs/fs-io-direct.c
+++ b/fs/bcachefs/fs-io-direct.c
@@ -252,7 +252,7 @@ static bool bch2_check_range_allocated(struct bch_fs *c, subvol_inum inum,
 				       u64 offset, u64 size,
 				       unsigned nr_replicas, bool compressed)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct btree_iter iter;
 	struct bkey_s_c k;
 	u64 end = offset + size;
@@ -285,7 +285,6 @@ static bool bch2_check_range_allocated(struct bch_fs *c, subvol_inum inum,
 err:
 	if (bch2_err_matches(err, BCH_ERR_transaction_restart))
 		goto retry;
-	bch2_trans_put(trans);
 
 	return err ? false : ret;
 }
@@ -428,17 +427,15 @@ static __always_inline void bch2_dio_write_end(struct dio_write *dio)
 	dio->written	+= dio->op.written;
 
 	if (dio->extending) {
-		spin_lock(&inode->v.i_lock);
+		guard(spinlock)(&inode->v.i_lock);
 		if (req->ki_pos > inode->v.i_size)
 			i_size_write(&inode->v, req->ki_pos);
-		spin_unlock(&inode->v.i_lock);
 	}
 
 	if (dio->op.i_sectors_delta || dio->quota_res.sectors) {
-		mutex_lock(&inode->ei_quota_lock);
+		guard(mutex)(&inode->ei_quota_lock);
 		__bch2_i_sectors_acct(c, inode, &dio->quota_res, dio->op.i_sectors_delta);
 		__bch2_quota_reservation_put(c, inode, &dio->quota_res);
-		mutex_unlock(&inode->ei_quota_lock);
 	}
 
 	bio_release_pages(bio, false);
-- 
2.51.0


From c65f74d06e6d671809fb4edfc6fd8d4b79554adc Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:41:56 -0400
Subject: [PATCH 147/309] bcachefs: convert btree_node_scan.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_node_scan.c | 15 +++++----------
 1 file changed, 5 insertions(+), 10 deletions(-)

diff --git a/fs/bcachefs/btree_node_scan.c b/fs/bcachefs/btree_node_scan.c
index 598605448a26..6c0accafa44e 100644
--- a/fs/bcachefs/btree_node_scan.c
+++ b/fs/bcachefs/btree_node_scan.c
@@ -196,17 +196,15 @@ static void try_read_btree_node(struct find_btree_nodes *f, struct bch_dev *ca,
 		n.journal_seq		= le64_to_cpu(bn->keys.journal_seq),
 		n.sectors_written	= b->written;
 
-		mutex_lock(&f->lock);
+		guard(mutex)(&f->lock);
 		if (BSET_BIG_ENDIAN(&bn->keys) != CPU_BIG_ENDIAN) {
 			bch_err(c, "try_read_btree_node() can't handle endian conversion");
 			f->ret = -EINVAL;
-			goto unlock;
+			return;
 		}
 
 		if (darray_push(&f->nodes, n))
 			f->ret = -ENOMEM;
-unlock:
-		mutex_unlock(&f->lock);
 	}
 }
 
@@ -361,7 +359,7 @@ static int handle_overwrites(struct bch_fs *c,
 int bch2_scan_for_btree_nodes(struct bch_fs *c)
 {
 	struct find_btree_nodes *f = &c->found_btree_nodes;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	found_btree_nodes nodes_heap = {};
 	size_t dst;
 	int ret = 0;
@@ -468,7 +466,6 @@ int bch2_scan_for_btree_nodes(struct bch_fs *c)
 	eytzinger0_sort(f->nodes.data, f->nodes.nr, sizeof(f->nodes.data[0]), found_btree_node_cmp_pos, NULL);
 err:
 	darray_exit(&nodes_heap);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -540,7 +537,7 @@ int bch2_get_scanned_nodes(struct bch_fs *c, enum btree_id btree,
 		return ret;
 
 	if (c->opts.verbose) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_str(&buf, "recovery ");
 		bch2_btree_id_level_to_text(&buf, btree, level);
@@ -550,7 +547,6 @@ int bch2_get_scanned_nodes(struct bch_fs *c, enum btree_id btree,
 		bch2_bpos_to_text(&buf, node_max);
 
 		bch_info(c, "%s(): %s", __func__, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	struct found_btree_node search = {
@@ -574,10 +570,9 @@ int bch2_get_scanned_nodes(struct bch_fs *c, enum btree_id btree,
 		found_btree_node_to_key(&tmp.k, &n);
 
 		if (c->opts.verbose) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&tmp.k));
 			bch_verbose(c, "%s(): recovering %s", __func__, buf.buf);
-			printbuf_exit(&buf);
 		}
 
 		BUG_ON(bch2_bkey_validate(c, bkey_i_to_s_c(&tmp.k),
-- 
2.51.0


From 5536ebefb5349a26cf713e0e13c158c90bb5c241 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:42:10 -0400
Subject: [PATCH 148/309] bcachefs: convert journal.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c | 215 ++++++++++++++++++------------------------
 fs/bcachefs/journal.h |   3 +-
 2 files changed, 91 insertions(+), 127 deletions(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index 3dfdccfafbf4..c0c594c783c0 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -88,7 +88,7 @@ static void bch2_journal_buf_to_text(struct printbuf *out, struct journal *j, u6
 static void bch2_journal_bufs_to_text(struct printbuf *out, struct journal *j)
 {
 	lockdep_assert_held(&j->lock);
-	out->atomic++;
+	guard(printbuf_atomic)(out);
 
 	if (!out->nr_tabstops)
 		printbuf_tabstop_push(out, 24);
@@ -98,8 +98,6 @@ static void bch2_journal_bufs_to_text(struct printbuf *out, struct journal *j)
 	     seq++)
 		bch2_journal_buf_to_text(out, j, seq);
 	prt_printf(out, "last buf %s\n", journal_entry_is_open(j) ? "open" : "closed");
-
-	--out->atomic;
 }
 
 static inline struct journal_buf *
@@ -140,9 +138,9 @@ journal_error_check_stuck(struct journal *j, int error, unsigned flags)
 {
 	struct bch_fs *c = container_of(j, struct bch_fs, journal);
 	bool stuck = false;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
-	buf.atomic++;
+	guard(printbuf_atomic)(&buf);
 
 	if (!(error == -BCH_ERR_journal_full ||
 	      error == -BCH_ERR_journal_pin_full) ||
@@ -150,28 +148,24 @@ journal_error_check_stuck(struct journal *j, int error, unsigned flags)
 	    (flags & BCH_WATERMARK_MASK) != BCH_WATERMARK_reclaim)
 		return stuck;
 
-	spin_lock(&j->lock);
+	scoped_guard(spinlock, &j->lock) {
+		if (j->can_discard)
+			return stuck;
 
-	if (j->can_discard) {
-		spin_unlock(&j->lock);
-		return stuck;
-	}
+		stuck = true;
 
-	stuck = true;
+		/*
+		 * The journal shutdown path will set ->err_seq, but do it here first to
+		 * serialize against concurrent failures and avoid duplicate error
+		 * reports.
+		 */
+		if (j->err_seq)
+			return stuck;
 
-	/*
-	 * The journal shutdown path will set ->err_seq, but do it here first to
-	 * serialize against concurrent failures and avoid duplicate error
-	 * reports.
-	 */
-	if (j->err_seq) {
-		spin_unlock(&j->lock);
-		return stuck;
-	}
-	j->err_seq = journal_cur_seq(j);
+		j->err_seq = journal_cur_seq(j);
 
-	__bch2_journal_debug_to_text(&buf, j);
-	spin_unlock(&j->lock);
+		__bch2_journal_debug_to_text(&buf, j);
+	}
 	prt_printf(&buf, bch2_fmt(c, "Journal stuck! Hava a pre-reservation but journal full (error %s)"),
 				  bch2_err_str(error));
 	bch2_print_str(c, KERN_ERR, buf.buf);
@@ -179,7 +173,6 @@ journal_error_check_stuck(struct journal *j, int error, unsigned flags)
 	printbuf_reset(&buf);
 	bch2_journal_pins_to_text(&buf, j);
 	bch_err(c, "Journal pins:\n%s", buf.buf);
-	printbuf_exit(&buf);
 
 	bch2_fatal_error(c);
 	dump_stack();
@@ -272,22 +265,21 @@ static void __journal_entry_close(struct journal *j, unsigned closed_val, bool t
 	buf->data->u64s		= cpu_to_le32(old.cur_entry_offset);
 
 	if (trace_journal_entry_close_enabled() && trace) {
-		struct printbuf pbuf = PRINTBUF;
-		pbuf.atomic++;
-
-		prt_str(&pbuf, "entry size: ");
-		prt_human_readable_u64(&pbuf, vstruct_bytes(buf->data));
-		prt_newline(&pbuf);
-		bch2_prt_task_backtrace(&pbuf, current, 1, GFP_NOWAIT);
-		trace_journal_entry_close(c, pbuf.buf);
-		printbuf_exit(&pbuf);
+		CLASS(printbuf, err)();
+		guard(printbuf_atomic)(&err);
+
+		prt_str(&err, "entry size: ");
+		prt_human_readable_u64(&err, vstruct_bytes(buf->data));
+		prt_newline(&err);
+		bch2_prt_task_backtrace(&err, current, 1, GFP_NOWAIT);
+		trace_journal_entry_close(c, err.buf);
 	}
 
 	sectors = vstruct_blocks_plus(buf->data, c->block_bits,
 				      buf->u64s_reserved) << c->block_bits;
 	if (unlikely(sectors > buf->sectors)) {
-		struct printbuf err = PRINTBUF;
-		err.atomic++;
+		CLASS(printbuf, err)();
+		guard(printbuf_atomic)(&err);
 
 		prt_printf(&err, "journal entry overran reserved space: %u > %u\n",
 			   sectors, buf->sectors);
@@ -299,7 +291,6 @@ static void __journal_entry_close(struct journal *j, unsigned closed_val, bool t
 		bch2_journal_halt_locked(j);
 
 		bch_err(c, "%s", err.buf);
-		printbuf_exit(&err);
 		return;
 	}
 
@@ -347,9 +338,8 @@ void bch2_journal_halt_locked(struct journal *j)
 
 void bch2_journal_halt(struct journal *j)
 {
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 	bch2_journal_halt_locked(j);
-	spin_unlock(&j->lock);
 }
 
 static bool journal_entry_want_write(struct journal *j)
@@ -374,13 +364,8 @@ static bool journal_entry_want_write(struct journal *j)
 
 bool bch2_journal_entry_close(struct journal *j)
 {
-	bool ret;
-
-	spin_lock(&j->lock);
-	ret = journal_entry_want_write(j);
-	spin_unlock(&j->lock);
-
-	return ret;
+	guard(spinlock)(&j->lock);
+	return journal_entry_want_write(j);
 }
 
 /*
@@ -545,7 +530,7 @@ static void journal_write_work(struct work_struct *work)
 {
 	struct journal *j = container_of(work, struct journal, write_work.work);
 
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 	if (__journal_entry_is_open(j->reservations)) {
 		long delta = journal_cur_buf(j)->expires - jiffies;
 
@@ -554,7 +539,6 @@ static void journal_write_work(struct work_struct *work)
 		else
 			__journal_entry_close(j, JOURNAL_ENTRY_CLOSED_VAL, true);
 	}
-	spin_unlock(&j->lock);
 }
 
 static void journal_buf_prealloc(struct journal *j)
@@ -655,34 +639,32 @@ static int __journal_res_get(struct journal *j, struct journal_res *res,
 	if (ret == -BCH_ERR_journal_max_in_flight &&
 	    track_event_change(&c->times[BCH_TIME_blocked_journal_max_in_flight], true) &&
 	    trace_journal_entry_full_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_printbuf_make_room(&buf, 4096);
 
-		spin_lock(&j->lock);
-		prt_printf(&buf, "seq %llu\n", journal_cur_seq(j));
-		bch2_journal_bufs_to_text(&buf, j);
-		spin_unlock(&j->lock);
+		scoped_guard(spinlock, &j->lock) {
+			prt_printf(&buf, "seq %llu\n", journal_cur_seq(j));
+			bch2_journal_bufs_to_text(&buf, j);
+		}
 
 		trace_journal_entry_full(c, buf.buf);
-		printbuf_exit(&buf);
 		count_event(c, journal_entry_full);
 	}
 
 	if (ret == -BCH_ERR_journal_max_open &&
 	    track_event_change(&c->times[BCH_TIME_blocked_journal_max_open], true) &&
 	    trace_journal_entry_full_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_printbuf_make_room(&buf, 4096);
 
-		spin_lock(&j->lock);
-		prt_printf(&buf, "seq %llu\n", journal_cur_seq(j));
-		bch2_journal_bufs_to_text(&buf, j);
-		spin_unlock(&j->lock);
+		scoped_guard(spinlock, &j->lock) {
+			prt_printf(&buf, "seq %llu\n", journal_cur_seq(j));
+			bch2_journal_bufs_to_text(&buf, j);
+		}
 
 		trace_journal_entry_full(c, buf.buf);
-		printbuf_exit(&buf);
 		count_event(c, journal_entry_full);
 	}
 
@@ -754,11 +736,10 @@ int bch2_journal_res_get_slowpath(struct journal *j, struct journal_res *res,
 		   remaining_wait))
 		return ret;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_journal_debug_to_text(&buf, j);
 	bch2_print_str(c, KERN_ERR, buf.buf);
 	prt_printf(&buf, bch2_fmt(c, "Journal stuck? Waited for 10 seconds, err %s"), bch2_err_str(ret));
-	printbuf_exit(&buf);
 
 	closure_wait_event(&j->async_wait,
 		   !bch2_err_matches(ret = __journal_res_get(j, res, flags), BCH_ERR_operation_blocked) ||
@@ -775,11 +756,13 @@ void bch2_journal_entry_res_resize(struct journal *j,
 	union journal_res_state state;
 	int d = new_u64s - res->u64s;
 
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
+
+	j->entry_u64s_reserved	+= d;
+	res->u64s		+= d;
 
-	j->entry_u64s_reserved += d;
 	if (d <= 0)
-		goto out;
+		return;
 
 	j->cur_entry_u64s = max_t(int, 0, j->cur_entry_u64s - d);
 	state = READ_ONCE(j->reservations);
@@ -794,9 +777,6 @@ void bch2_journal_entry_res_resize(struct journal *j,
 	} else {
 		journal_cur_buf(j)->u64s_reserved += d;
 	}
-out:
-	spin_unlock(&j->lock);
-	res->u64s += d;
 }
 
 /* journal flushing: */
@@ -947,7 +927,6 @@ bool bch2_journal_noflush_seq(struct journal *j, u64 start, u64 end)
 {
 	struct bch_fs *c = container_of(j, struct bch_fs, journal);
 	u64 unwritten_seq;
-	bool ret = false;
 
 	if (!(c->sb.features & (1ULL << BCH_FEATURE_journal_no_flush)))
 		return false;
@@ -955,9 +934,10 @@ bool bch2_journal_noflush_seq(struct journal *j, u64 start, u64 end)
 	if (c->journal.flushed_seq_ondisk >= start)
 		return false;
 
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
+
 	if (c->journal.flushed_seq_ondisk >= start)
-		goto out;
+		return false;
 
 	for (unwritten_seq = journal_last_unwritten_seq(j);
 	     unwritten_seq < end;
@@ -966,15 +946,12 @@ bool bch2_journal_noflush_seq(struct journal *j, u64 start, u64 end)
 
 		/* journal flush already in flight, or flush requseted */
 		if (buf->must_flush)
-			goto out;
+			return false;
 
 		buf->noflush = true;
 	}
 
-	ret = true;
-out:
-	spin_unlock(&j->lock);
-	return ret;
+	return true;
 }
 
 static int __bch2_journal_meta(struct journal *j)
@@ -1013,19 +990,18 @@ int bch2_journal_meta(struct journal *j)
 
 void bch2_journal_unblock(struct journal *j)
 {
-	spin_lock(&j->lock);
-	if (!--j->blocked &&
-	    j->cur_entry_offset_if_blocked < JOURNAL_ENTRY_CLOSED_VAL &&
-	    j->reservations.cur_entry_offset == JOURNAL_ENTRY_BLOCKED_VAL) {
-		union journal_res_state old, new;
-
-		old.v = atomic64_read(&j->reservations.counter);
-		do {
-			new.v = old.v;
-			new.cur_entry_offset = j->cur_entry_offset_if_blocked;
-		} while (!atomic64_try_cmpxchg(&j->reservations.counter, &old.v, new.v));
-	}
-	spin_unlock(&j->lock);
+	scoped_guard(spinlock, &j->lock)
+		if (!--j->blocked &&
+		    j->cur_entry_offset_if_blocked < JOURNAL_ENTRY_CLOSED_VAL &&
+		    j->reservations.cur_entry_offset == JOURNAL_ENTRY_BLOCKED_VAL) {
+			union journal_res_state old, new;
+
+			old.v = atomic64_read(&j->reservations.counter);
+			do {
+				new.v = old.v;
+				new.cur_entry_offset = j->cur_entry_offset_if_blocked;
+			} while (!atomic64_try_cmpxchg(&j->reservations.counter, &old.v, new.v));
+		}
 
 	journal_wake(j);
 }
@@ -1053,9 +1029,8 @@ static void __bch2_journal_block(struct journal *j)
 
 void bch2_journal_block(struct journal *j)
 {
-	spin_lock(&j->lock);
-	__bch2_journal_block(j);
-	spin_unlock(&j->lock);
+	scoped_guard(spinlock, &j->lock)
+		__bch2_journal_block(j);
 
 	journal_quiesce(j);
 }
@@ -1068,7 +1043,7 @@ static struct journal_buf *__bch2_next_write_buffer_flush_journal_buf(struct jou
 	/* We're inside wait_event(), but using mutex_lock(: */
 	sched_annotate_sleep();
 	mutex_lock(&j->buf_lock);
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 	max_seq = min(max_seq, journal_cur_seq(j));
 
 	for (u64 seq = journal_last_unwritten_seq(j);
@@ -1096,7 +1071,6 @@ static struct journal_buf *__bch2_next_write_buffer_flush_journal_buf(struct jou
 		}
 	}
 
-	spin_unlock(&j->lock);
 	if (IS_ERR_OR_NULL(ret))
 		mutex_unlock(&j->buf_lock);
 	return ret;
@@ -1151,10 +1125,10 @@ static int bch2_set_nr_journal_buckets_iter(struct bch_dev *ca, unsigned nr,
 		if (ret)
 			break;
 
-		ret = bch2_trans_run(c,
-			bch2_trans_mark_metadata_bucket(trans, ca,
+		CLASS(btree_trans, trans)(c);
+		ret = bch2_trans_mark_metadata_bucket(trans, ca,
 					ob[nr_got]->bucket, BCH_DATA_journal,
-					ca->mi.bucket_size, BTREE_TRIGGER_transactional));
+					ca->mi.bucket_size, BTREE_TRIGGER_transactional);
 		if (ret) {
 			bch2_open_bucket_put(c, ob[nr_got]);
 			bch_err_msg(c, ret, "marking new journal buckets");
@@ -1228,12 +1202,13 @@ static int bch2_set_nr_journal_buckets_iter(struct bch_dev *ca, unsigned nr,
 		mutex_unlock(&c->sb_lock);
 	}
 
-	if (ret)
+	if (ret) {
+		CLASS(btree_trans, trans)(c);
 		for (i = 0; i < nr_got; i++)
-			bch2_trans_run(c,
-				bch2_trans_mark_metadata_bucket(trans, ca,
+			bch2_trans_mark_metadata_bucket(trans, ca,
 						bu[i], BCH_DATA_free, 0,
-						BTREE_TRIGGER_transactional));
+						BTREE_TRIGGER_transactional);
+	}
 err_free:
 	for (i = 0; i < nr_got; i++)
 		bch2_open_bucket_put(c, ob[i]);
@@ -1298,10 +1273,8 @@ static int bch2_set_nr_journal_buckets_loop(struct bch_fs *c, struct bch_dev *ca
 int bch2_set_nr_journal_buckets(struct bch_fs *c, struct bch_dev *ca,
 				unsigned nr)
 {
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 	int ret = bch2_set_nr_journal_buckets_loop(c, ca, nr, false);
-	up_write(&c->state_lock);
-
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1425,21 +1398,18 @@ int bch2_fs_journal_alloc(struct bch_fs *c)
 
 static bool bch2_journal_writing_to_device(struct journal *j, unsigned dev_idx)
 {
-	bool ret = false;
-	u64 seq;
+	guard(spinlock)(&j->lock);
 
-	spin_lock(&j->lock);
-	for (seq = journal_last_unwritten_seq(j);
-	     seq <= journal_cur_seq(j) && !ret;
+	for (u64 seq = journal_last_unwritten_seq(j);
+	     seq <= journal_cur_seq(j);
 	     seq++) {
 		struct journal_buf *buf = journal_seq_to_buf(j, seq);
 
 		if (bch2_bkey_has_device_c(bkey_i_to_s_c(&buf->key), dev_idx))
-			ret = true;
+			return true;
 	}
-	spin_unlock(&j->lock);
 
-	return ret;
+	return false;
 }
 
 void bch2_dev_journal_stop(struct journal *j, struct bch_dev *ca)
@@ -1558,13 +1528,11 @@ int bch2_fs_journal_start(struct journal *j, u64 last_seq, u64 cur_seq)
 	if (!had_entries)
 		j->last_empty_seq = cur_seq - 1; /* to match j->seq */
 
-	spin_lock(&j->lock);
-	j->last_flush_write = jiffies;
-
-	j->reservations.idx = journal_cur_seq(j);
-
-	c->last_bucket_seq_cleanup = journal_cur_seq(j);
-	spin_unlock(&j->lock);
+	scoped_guard(spinlock, &j->lock) {
+		j->last_flush_write = jiffies;
+		j->reservations.idx = journal_cur_seq(j);
+		c->last_bucket_seq_cleanup = journal_cur_seq(j);
+	}
 
 	return 0;
 }
@@ -1575,13 +1543,12 @@ void bch2_journal_set_replay_done(struct journal *j)
 	 * journal_space_available must happen before setting JOURNAL_running
 	 * JOURNAL_running must happen before JOURNAL_replay_done
 	 */
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 	bch2_journal_space_available(j);
 
 	set_bit(JOURNAL_need_flush_write, &j->flags);
 	set_bit(JOURNAL_running, &j->flags);
 	set_bit(JOURNAL_replay_done, &j->flags);
-	spin_unlock(&j->lock);
 }
 
 /* init/exit: */
@@ -1738,9 +1705,10 @@ void __bch2_journal_debug_to_text(struct printbuf *out, struct journal *j)
 
 	printbuf_tabstops_reset(out);
 	printbuf_tabstop_push(out, 28);
-	out->atomic++;
 
+	guard(printbuf_atomic)(out);
 	guard(rcu)();
+
 	s = READ_ONCE(j->reservations);
 
 	prt_printf(out, "flags:\t");
@@ -1830,13 +1798,10 @@ void __bch2_journal_debug_to_text(struct printbuf *out, struct journal *j)
 	}
 
 	prt_printf(out, "replicas want %u need %u\n", c->opts.metadata_replicas, c->opts.metadata_replicas_required);
-
-	--out->atomic;
 }
 
 void bch2_journal_debug_to_text(struct printbuf *out, struct journal *j)
 {
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 	__bch2_journal_debug_to_text(out, j);
-	spin_unlock(&j->lock);
 }
diff --git a/fs/bcachefs/journal.h b/fs/bcachefs/journal.h
index 977907038d98..b46b9718d841 100644
--- a/fs/bcachefs/journal.h
+++ b/fs/bcachefs/journal.h
@@ -297,9 +297,8 @@ static inline void bch2_journal_buf_put(struct journal *j, u64 seq)
 
 	s = journal_state_buf_put(j, idx);
 	if (!journal_state_count(s, idx)) {
-		spin_lock(&j->lock);
+		guard(spinlock)(&j->lock);
 		bch2_journal_buf_put_final(j, seq);
-		spin_unlock(&j->lock);
 	} else if (unlikely(s.cur_entry_offset == JOURNAL_ENTRY_BLOCKED_VAL))
 		wake_up(&j->wait);
 }
-- 
2.51.0


From 974e5d06773c605d3f5aee1108de7db3e1af5805 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:42:17 -0400
Subject: [PATCH 149/309] bcachefs: convert journal_io.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_io.c | 170 ++++++++++++++++++---------------------
 1 file changed, 78 insertions(+), 92 deletions(-)

diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 798ad8789afc..7d0cd2bb8f94 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -35,7 +35,8 @@ void bch2_journal_pos_from_member_info_set(struct bch_fs *c)
 
 void bch2_journal_pos_from_member_info_resume(struct bch_fs *c)
 {
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
+
 	for_each_member_device(c, ca) {
 		struct bch_member m = bch2_sb_member_get(c->disk_sb.sb, ca->dev_idx);
 
@@ -46,16 +47,14 @@ void bch2_journal_pos_from_member_info_resume(struct bch_fs *c)
 		if (offset <= ca->mi.bucket_size)
 			ca->journal.sectors_free = ca->mi.bucket_size - offset;
 	}
-	mutex_unlock(&c->sb_lock);
 }
 
 static void bch2_journal_ptr_to_text(struct printbuf *out, struct bch_fs *c, struct journal_ptr *p)
 {
-	struct bch_dev *ca = bch2_dev_tryget_noerror(c, p->dev);
+	CLASS(bch2_dev_tryget_noerror, ca)(c, p->dev);
 	prt_printf(out, "%s %u:%u:%u (sector %llu)",
 		   ca ? ca->name : "(invalid dev)",
 		   p->dev, p->bucket, p->bucket_offset, p->sector);
-	bch2_dev_put(ca);
 }
 
 void bch2_journal_ptrs_to_text(struct printbuf *out, struct bch_fs *c, struct journal_replay *j)
@@ -157,7 +156,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 	struct journal_replay **_i, *i, *dup;
 	size_t bytes = vstruct_bytes(j);
 	u64 last_seq = !JSET_NO_FLUSH(j) ? le64_to_cpu(j->last_seq) : 0;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = JOURNAL_ENTRY_ADD_OK;
 
 	if (last_seq && c->opts.journal_rewind)
@@ -223,7 +222,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 
 		ret = darray_push(&dup->ptrs, entry_ptr);
 		if (ret)
-			goto out;
+			return ret;
 
 		bch2_journal_replay_to_text(&buf, c, dup);
 
@@ -240,7 +239,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 		if (entry_ptr.csum_good && !identical)
 			goto replace;
 
-		goto out;
+		return ret;
 	}
 replace:
 	i = kvmalloc(offsetof(struct journal_replay, j) + bytes, GFP_KERNEL);
@@ -263,9 +262,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 	}
 
 	*_i = i;
-out:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -312,7 +309,7 @@ static void journal_entry_err_msg(struct printbuf *out,
 
 #define journal_entry_err(c, version, jset, entry, _err, msg, ...)	\
 ({									\
-	struct printbuf _buf = PRINTBUF;				\
+	CLASS(printbuf, _buf)();					\
 									\
 	journal_entry_err_msg(&_buf, version, jset, entry);		\
 	prt_printf(&_buf, msg, ##__VA_ARGS__);				\
@@ -331,7 +328,6 @@ static void journal_entry_err_msg(struct printbuf *out,
 		break;							\
 	}								\
 									\
-	printbuf_exit(&_buf);						\
 	true;								\
 })
 
@@ -617,7 +613,7 @@ static int journal_entry_data_usage_validate(struct bch_fs *c,
 	struct jset_entry_data_usage *u =
 		container_of(entry, struct jset_entry_data_usage, entry);
 	unsigned bytes = jset_u64s(le16_to_cpu(entry->u64s)) * sizeof(u64);
-	struct printbuf err = PRINTBUF;
+	CLASS(printbuf, err)();
 	int ret = 0;
 
 	if (journal_entry_err_on(bytes < sizeof(*u) ||
@@ -626,7 +622,7 @@ static int journal_entry_data_usage_validate(struct bch_fs *c,
 				 journal_entry_data_usage_bad_size,
 				 "invalid journal entry usage: bad size")) {
 		journal_entry_null_range(entry, vstruct_next(entry));
-		goto out;
+		return 0;
 	}
 
 	if (journal_entry_err_on(bch2_replicas_entry_validate(&u->r, c, &err),
@@ -634,11 +630,9 @@ static int journal_entry_data_usage_validate(struct bch_fs *c,
 				 journal_entry_data_usage_bad_size,
 				 "invalid journal entry usage: %s", err.buf)) {
 		journal_entry_null_range(entry, vstruct_next(entry));
-		goto out;
+		return 0;
 	}
-out:
 fsck_err:
-	printbuf_exit(&err);
 	return ret;
 }
 
@@ -1165,17 +1159,16 @@ static int journal_read_bucket(struct bch_dev *ca,
 			     vstruct_end(j) - (void *) j->encrypted_start);
 		bch2_fs_fatal_err_on(ret, c, "decrypting journal entry: %s", bch2_err_str(ret));
 
-		mutex_lock(&jlist->lock);
-		ret = journal_entry_add(c, ca, (struct journal_ptr) {
-					.csum_good	= csum_good,
-					.csum		= csum,
-					.dev		= ca->dev_idx,
-					.bucket		= bucket,
-					.bucket_offset	= offset -
-						bucket_to_sector(ca, ja->buckets[bucket]),
-					.sector		= offset,
-					}, jlist, j);
-		mutex_unlock(&jlist->lock);
+		scoped_guard(mutex, &jlist->lock)
+			ret = journal_entry_add(c, ca, (struct journal_ptr) {
+						.csum_good	= csum_good,
+						.csum		= csum,
+						.dev		= ca->dev_idx,
+						.bucket		= bucket,
+						.bucket_offset	= offset -
+							bucket_to_sector(ca, ja->buckets[bucket]),
+						.sector		= offset,
+						}, jlist, j);
 
 		switch (ret) {
 		case JOURNAL_ENTRY_ADD_OK:
@@ -1235,16 +1228,15 @@ static CLOSURE_CALLBACK(bch2_journal_read_device)
 	closure_return(cl);
 	return;
 err:
-	mutex_lock(&jlist->lock);
-	jlist->ret = ret;
-	mutex_unlock(&jlist->lock);
+	scoped_guard(mutex, &jlist->lock)
+		jlist->ret = ret;
 	goto out;
 }
 
 noinline_for_stack
 static void bch2_journal_print_checksum_error(struct bch_fs *c, struct journal_replay *j)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	enum bch_csum_type csum_type = JSET_CSUM_TYPE(&j->j);
@@ -1271,7 +1263,6 @@ static void bch2_journal_print_checksum_error(struct bch_fs *c, struct journal_r
 		prt_printf(&buf, "\n(had good copy on another device)");
 
 	bch2_print_str(c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 }
 
 struct u64_range bch2_journal_entry_missing_range(struct bch_fs *c, u64 start, u64 end)
@@ -1299,7 +1290,6 @@ struct u64_range bch2_journal_entry_missing_range(struct bch_fs *c, u64 start, u
 noinline_for_stack
 static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 end_seq)
 {
-	struct printbuf buf = PRINTBUF;
 	int ret = 0;
 
 	struct genradix_iter radix_iter;
@@ -1318,7 +1308,7 @@ static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 e
 		struct u64_range missing;
 
 		while ((missing = bch2_journal_entry_missing_range(c, seq, le64_to_cpu(i->j.seq))).start) {
-			printbuf_reset(&buf);
+			CLASS(printbuf, buf)();
 			prt_printf(&buf, "journal entries %llu-%llu missing! (replaying %llu-%llu)",
 				   missing.start, missing.end - 1,
 				   start_seq, end_seq);
@@ -1342,7 +1332,6 @@ static int bch2_journal_check_for_missing(struct bch_fs *c, u64 start_seq, u64 e
 		seq = le64_to_cpu(i->j.seq) + 1;
 	}
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1354,7 +1343,6 @@ int bch2_journal_read(struct bch_fs *c,
 	struct journal_list jlist;
 	struct journal_replay *i, **_i;
 	struct genradix_iter radix_iter;
-	struct printbuf buf = PRINTBUF;
 	bool degraded = false, last_write_torn = false;
 	u64 seq;
 	int ret = 0;
@@ -1443,24 +1431,27 @@ int bch2_journal_read(struct bch_fs *c,
 		return 0;
 	}
 
-	printbuf_reset(&buf);
-	prt_printf(&buf, "journal read done, replaying entries %llu-%llu",
-		   *last_seq, *blacklist_seq - 1);
-
-	/*
-	 * Drop blacklisted entries and entries older than last_seq (or start of
-	 * journal rewind:
-	 */
 	u64 drop_before = *last_seq;
-	if (c->opts.journal_rewind) {
-		drop_before = min(drop_before, c->opts.journal_rewind);
-		prt_printf(&buf, " (rewinding from %llu)", c->opts.journal_rewind);
+	{
+		CLASS(printbuf, buf)();
+		prt_printf(&buf, "journal read done, replaying entries %llu-%llu",
+			   *last_seq, *blacklist_seq - 1);
+
+		/*
+		 * Drop blacklisted entries and entries older than last_seq (or start of
+		 * journal rewind:
+		 */
+		if (c->opts.journal_rewind) {
+			drop_before = min(drop_before, c->opts.journal_rewind);
+			prt_printf(&buf, " (rewinding from %llu)", c->opts.journal_rewind);
+		}
+
+		*last_seq = drop_before;
+		if (*start_seq != *blacklist_seq)
+			prt_printf(&buf, " (unflushed %llu-%llu)", *blacklist_seq, *start_seq - 1);
+		bch_info(c, "%s", buf.buf);
 	}
 
-	*last_seq = drop_before;
-	if (*start_seq != *blacklist_seq)
-		prt_printf(&buf, " (unflushed %llu-%llu)", *blacklist_seq, *start_seq - 1);
-	bch_info(c, "%s", buf.buf);
 	genradix_for_each(&c->journal_entries, radix_iter, _i) {
 		i = *_i;
 
@@ -1483,7 +1474,7 @@ int bch2_journal_read(struct bch_fs *c,
 
 	ret = bch2_journal_check_for_missing(c, drop_before, *blacklist_seq - 1);
 	if (ret)
-		goto err;
+		return ret;
 
 	genradix_for_each(&c->journal_entries, radix_iter, _i) {
 		union bch_replicas_padded replicas = {
@@ -1512,14 +1503,14 @@ int bch2_journal_read(struct bch_fs *c,
 				    i->ptrs.data[0].sector,
 				    READ);
 		if (ret)
-			goto err;
+			return ret;
 
 		darray_for_each(i->ptrs, ptr)
 			replicas_entry_add_dev(&replicas.e, ptr->dev);
 
 		bch2_replicas_entry_sort(&replicas.e);
 
-		printbuf_reset(&buf);
+		CLASS(printbuf, buf)();
 		bch2_replicas_entry_to_text(&buf, &replicas.e);
 
 		if (!degraded &&
@@ -1530,12 +1521,10 @@ int bch2_journal_read(struct bch_fs *c,
 			      le64_to_cpu(i->j.seq), buf.buf))) {
 			ret = bch2_mark_replicas(c, &replicas.e);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	}
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1695,10 +1684,10 @@ static void journal_buf_realloc(struct journal *j, struct journal_buf *buf)
 
 	memcpy(new_buf, buf->data, buf->buf_size);
 
-	spin_lock(&j->lock);
-	swap(buf->data,		new_buf);
-	swap(buf->buf_size,	new_size);
-	spin_unlock(&j->lock);
+	scoped_guard(spinlock, &j->lock) {
+		swap(buf->data,		new_buf);
+		swap(buf->buf_size,	new_size);
+	}
 
 	kvfree(new_buf);
 }
@@ -1725,7 +1714,7 @@ static CLOSURE_CALLBACK(journal_write_done)
 	}
 
 	if (err && !bch2_journal_error(j)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 
 		if (err == -BCH_ERR_journal_write_err)
@@ -1737,7 +1726,6 @@ static CLOSURE_CALLBACK(journal_write_done)
 		bch2_fs_emergency_read_only2(c, &buf);
 
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	closure_debug_destroy(cl);
@@ -2021,9 +2009,8 @@ static int bch2_journal_write_prep(struct journal *j, struct journal_buf *w)
 		}
 	}
 
-	spin_lock(&c->journal.lock);
-	w->need_flush_to_write_buffer = false;
-	spin_unlock(&c->journal.lock);
+	scoped_guard(spinlock, &c->journal.lock)
+		w->need_flush_to_write_buffer = false;
 
 	start = end = vstruct_last(jset);
 
@@ -2161,21 +2148,21 @@ CLOSURE_CALLBACK(bch2_journal_write)
 
 	j->write_start_time = local_clock();
 
-	spin_lock(&j->lock);
-	if (nr_rw_members > 1)
-		w->separate_flush = true;
+	scoped_guard(spinlock, &j->lock) {
+		if (nr_rw_members > 1)
+			w->separate_flush = true;
 
-	ret = bch2_journal_write_pick_flush(j, w);
-	spin_unlock(&j->lock);
+		ret = bch2_journal_write_pick_flush(j, w);
+	}
 
 	if (unlikely(ret))
 		goto err;
 
-	mutex_lock(&j->buf_lock);
-	journal_buf_realloc(j, w);
+	scoped_guard(mutex, &j->buf_lock) {
+		journal_buf_realloc(j, w);
 
-	ret = bch2_journal_write_prep(j, w);
-	mutex_unlock(&j->buf_lock);
+		ret = bch2_journal_write_prep(j, w);
+	}
 
 	if (unlikely(ret))
 		goto err;
@@ -2196,22 +2183,22 @@ CLOSURE_CALLBACK(bch2_journal_write)
 	if (unlikely(ret))
 		goto err;
 
-	spin_lock(&j->lock);
-	/*
-	 * write is allocated, no longer need to account for it in
-	 * bch2_journal_space_available():
-	 */
-	w->sectors = 0;
-	w->write_allocated = true;
-	j->entry_bytes_written += vstruct_bytes(w->data);
+	scoped_guard(spinlock, &j->lock) {
+		/*
+		 * write is allocated, no longer need to account for it in
+		 * bch2_journal_space_available():
+		 */
+		w->sectors = 0;
+		w->write_allocated = true;
+		j->entry_bytes_written += vstruct_bytes(w->data);
 
-	/*
-	 * journal entry has been compacted and allocated, recalculate space
-	 * available:
-	 */
-	bch2_journal_space_available(j);
-	bch2_journal_do_writes(j);
-	spin_unlock(&j->lock);
+		/*
+		 * journal entry has been compacted and allocated, recalculate space
+		 * available:
+		 */
+		bch2_journal_space_available(j);
+		bch2_journal_do_writes(j);
+	}
 
 	w->devs_written = bch2_bkey_devs(bkey_i_to_s_c(&w->key));
 
@@ -2235,7 +2222,7 @@ CLOSURE_CALLBACK(bch2_journal_write)
 	return;
 err_allocate_write:
 	if (!bch2_journal_error(j)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_journal_debug_to_text(&buf, j);
 		prt_printf(&buf, bch2_fmt(c, "Unable to allocate journal write at seq %llu for %zu sectors: %s"),
@@ -2243,7 +2230,6 @@ CLOSURE_CALLBACK(bch2_journal_write)
 					  vstruct_sectors(w->data, c->block_bits),
 					  bch2_err_str(ret));
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
 err:
 	bch2_fatal_error(c);
-- 
2.51.0


From d906584f1232da23f9eddcde1b03578632fe29a2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:42:26 -0400
Subject: [PATCH 150/309] bcachefs: convert journal_reclaim.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_reclaim.c | 193 ++++++++++++++--------------------
 1 file changed, 81 insertions(+), 112 deletions(-)

diff --git a/fs/bcachefs/journal_reclaim.c b/fs/bcachefs/journal_reclaim.c
index 0042d43b8e57..be50455c7f13 100644
--- a/fs/bcachefs/journal_reclaim.c
+++ b/fs/bcachefs/journal_reclaim.c
@@ -221,8 +221,8 @@ void bch2_journal_space_available(struct journal *j)
 
 	if (nr_online < metadata_replicas_required(c)) {
 		if (!(c->sb.features & BIT_ULL(BCH_FEATURE_small_image))) {
-			struct printbuf buf = PRINTBUF;
-			buf.atomic++;
+			CLASS(printbuf, buf)();
+			guard(printbuf_atomic)(&buf);
 			prt_printf(&buf, "insufficient writeable journal devices available: have %u, need %u\n"
 				   "rw journal devs:", nr_online, metadata_replicas_required(c));
 
@@ -230,7 +230,6 @@ void bch2_journal_space_available(struct journal *j)
 				prt_printf(&buf, " %s", ca->name);
 
 			bch_err(c, "%s", buf.buf);
-			printbuf_exit(&buf);
 		}
 		ret = bch_err_throw(c, insufficient_journal_devices);
 		goto out;
@@ -280,11 +279,8 @@ static bool __should_discard_bucket(struct journal *j, struct journal_device *ja
 
 static bool should_discard_bucket(struct journal *j, struct journal_device *ja)
 {
-	spin_lock(&j->lock);
-	bool ret = __should_discard_bucket(j, ja);
-	spin_unlock(&j->lock);
-
-	return ret;
+	guard(spinlock)(&j->lock);
+	return __should_discard_bucket(j, ja);
 }
 
 /*
@@ -295,7 +291,7 @@ void bch2_journal_do_discards(struct journal *j)
 {
 	struct bch_fs *c = container_of(j, struct bch_fs, journal);
 
-	mutex_lock(&j->discard_lock);
+	guard(mutex)(&j->discard_lock);
 
 	for_each_rw_member(c, ca, BCH_DEV_WRITE_REF_journal_do_discards) {
 		struct journal_device *ja = &ca->journal;
@@ -309,15 +305,12 @@ void bch2_journal_do_discards(struct journal *j)
 						ja->buckets[ja->discard_idx]),
 					ca->mi.bucket_size, GFP_NOFS);
 
-			spin_lock(&j->lock);
-			ja->discard_idx = (ja->discard_idx + 1) % ja->nr;
-
-			bch2_journal_space_available(j);
-			spin_unlock(&j->lock);
+			scoped_guard(spinlock, &j->lock) {
+				ja->discard_idx = (ja->discard_idx + 1) % ja->nr;
+				bch2_journal_space_available(j);
+			}
 		}
 	}
-
-	mutex_unlock(&j->discard_lock);
 }
 
 /*
@@ -358,9 +351,8 @@ bool __bch2_journal_pin_put(struct journal *j, u64 seq)
 void bch2_journal_pin_put(struct journal *j, u64 seq)
 {
 	if (__bch2_journal_pin_put(j, seq)) {
-		spin_lock(&j->lock);
+		guard(spinlock)(&j->lock);
 		bch2_journal_reclaim_fast(j);
-		spin_unlock(&j->lock);
 	}
 }
 
@@ -393,10 +385,9 @@ static inline bool __journal_pin_drop(struct journal *j,
 void bch2_journal_pin_drop(struct journal *j,
 			   struct journal_entry_pin *pin)
 {
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 	if (__journal_pin_drop(j, pin))
 		bch2_journal_reclaim_fast(j);
-	spin_unlock(&j->lock);
 }
 
 static enum journal_pin_type journal_pin_type(struct journal_entry_pin *pin,
@@ -443,7 +434,7 @@ void bch2_journal_pin_copy(struct journal *j,
 			   struct journal_entry_pin *src,
 			   journal_pin_flush_fn flush_fn)
 {
-	spin_lock(&j->lock);
+	guard(spinlock)(&j->lock);
 
 	u64 seq = READ_ONCE(src->seq);
 
@@ -454,7 +445,6 @@ void bch2_journal_pin_copy(struct journal *j,
 		 * longer to exist, but that means there's no longer anything to
 		 * copy and we can bail out here:
 		 */
-		spin_unlock(&j->lock);
 		return;
 	}
 
@@ -471,31 +461,32 @@ void bch2_journal_pin_copy(struct journal *j,
 	 */
 	if (seq == journal_last_seq(j))
 		journal_wake(j);
-	spin_unlock(&j->lock);
 }
 
 void bch2_journal_pin_set(struct journal *j, u64 seq,
 			  struct journal_entry_pin *pin,
 			  journal_pin_flush_fn flush_fn)
 {
-	spin_lock(&j->lock);
+	bool wake;
 
-	BUG_ON(seq < journal_last_seq(j));
+	scoped_guard(spinlock, &j->lock) {
+		BUG_ON(seq < journal_last_seq(j));
 
-	bool reclaim = __journal_pin_drop(j, pin);
+		bool reclaim = __journal_pin_drop(j, pin);
 
-	bch2_journal_pin_set_locked(j, seq, pin, flush_fn, journal_pin_type(pin, flush_fn));
+		bch2_journal_pin_set_locked(j, seq, pin, flush_fn, journal_pin_type(pin, flush_fn));
 
-	if (reclaim)
-		bch2_journal_reclaim_fast(j);
-	/*
-	 * If the journal is currently full,  we might want to call flush_fn
-	 * immediately:
-	 */
-	if (seq == journal_last_seq(j))
-		journal_wake(j);
+		if (reclaim)
+			bch2_journal_reclaim_fast(j);
+		/*
+		 * If the journal is currently full,  we might want to call flush_fn
+		 * immediately:
+		 */
+		wake = seq == journal_last_seq(j);
+	}
 
-	spin_unlock(&j->lock);
+	if (wake)
+		journal_wake(j);
 }
 
 /**
@@ -580,17 +571,17 @@ static size_t journal_flush_pins(struct journal *j,
 
 		j->last_flushed = jiffies;
 
-		spin_lock(&j->lock);
-		pin = journal_get_next_pin(j, seq_to_flush,
-					   allowed_below,
-					   allowed_above, &seq);
-		if (pin) {
-			BUG_ON(j->flush_in_progress);
-			j->flush_in_progress = pin;
-			j->flush_in_progress_dropped = false;
-			flush_fn = pin->flush;
+		scoped_guard(spinlock, &j->lock) {
+			pin = journal_get_next_pin(j, seq_to_flush,
+						   allowed_below,
+						   allowed_above, &seq);
+			if (pin) {
+				BUG_ON(j->flush_in_progress);
+				j->flush_in_progress = pin;
+				j->flush_in_progress_dropped = false;
+				flush_fn = pin->flush;
+			}
 		}
-		spin_unlock(&j->lock);
 
 		if (!pin)
 			break;
@@ -603,13 +594,13 @@ static size_t journal_flush_pins(struct journal *j,
 
 		err = flush_fn(j, pin, seq);
 
-		spin_lock(&j->lock);
-		/* Pin might have been dropped or rearmed: */
-		if (likely(!err && !j->flush_in_progress_dropped))
-			list_move(&pin->list, &journal_seq_pin(j, seq)->flushed[journal_pin_type(pin, flush_fn)]);
-		j->flush_in_progress = NULL;
-		j->flush_in_progress_dropped = false;
-		spin_unlock(&j->lock);
+		scoped_guard(spinlock, &j->lock) {
+			/* Pin might have been dropped or rearmed: */
+			if (likely(!err && !j->flush_in_progress_dropped))
+				list_move(&pin->list, &journal_seq_pin(j, seq)->flushed[journal_pin_type(pin, flush_fn)]);
+			j->flush_in_progress = NULL;
+			j->flush_in_progress_dropped = false;
+		}
 
 		wake_up(&j->pin_flush_wait);
 
@@ -770,9 +761,8 @@ static int bch2_journal_reclaim_thread(void *arg)
 
 		j->reclaim_kicked = false;
 
-		mutex_lock(&j->reclaim_lock);
-		ret = __bch2_journal_reclaim(j, false, kicked);
-		mutex_unlock(&j->reclaim_lock);
+		scoped_guard(mutex, &j->reclaim_lock)
+			ret = __bch2_journal_reclaim(j, false, kicked);
 
 		now = jiffies;
 		delay = msecs_to_jiffies(c->opts.journal_reclaim_delay);
@@ -788,9 +778,8 @@ static int bch2_journal_reclaim_thread(void *arg)
 			if (j->reclaim_kicked)
 				break;
 
-			spin_lock(&j->lock);
-			journal_empty = fifo_empty(&j->pin);
-			spin_unlock(&j->lock);
+			scoped_guard(spinlock, &j->lock)
+				journal_empty = fifo_empty(&j->pin);
 
 			long timeout = j->next_reclaim - jiffies;
 
@@ -844,10 +833,10 @@ int bch2_journal_reclaim_start(struct journal *j)
 static bool journal_pins_still_flushing(struct journal *j, u64 seq_to_flush,
 					unsigned types)
 {
+	guard(spinlock)(&j->lock);
+
 	struct journal_entry_pin_list *pin_list;
 	u64 seq;
-
-	spin_lock(&j->lock);
 	fifo_for_each_entry_ptr(pin_list, &j->pin, seq) {
 		if (seq > seq_to_flush)
 			break;
@@ -855,12 +844,9 @@ static bool journal_pins_still_flushing(struct journal *j, u64 seq_to_flush,
 		for (unsigned i = 0; i < JOURNAL_PIN_TYPE_NR; i++)
 			if ((BIT(i) & types) &&
 			    (!list_empty(&pin_list->unflushed[i]) ||
-			     !list_empty(&pin_list->flushed[i]))) {
-				spin_unlock(&j->lock);
+			     !list_empty(&pin_list->flushed[i])))
 				return true;
-			}
 	}
-	spin_unlock(&j->lock);
 
 	return false;
 }
@@ -881,32 +867,27 @@ static int journal_flush_done(struct journal *j, u64 seq_to_flush,
 	if (ret)
 		return ret;
 
-	mutex_lock(&j->reclaim_lock);
+	guard(mutex)(&j->reclaim_lock);
 
 	for (int type = JOURNAL_PIN_TYPE_NR - 1;
 	     type >= 0;
 	     --type)
 		if (journal_flush_pins_or_still_flushing(j, seq_to_flush, BIT(type))) {
 			*did_work = true;
-			goto unlock;
+			return ret;
 		}
 
 	if (seq_to_flush > journal_cur_seq(j))
 		bch2_journal_entry_close(j);
 
-	spin_lock(&j->lock);
 	/*
 	 * If journal replay hasn't completed, the unreplayed journal entries
 	 * hold refs on their corresponding sequence numbers
 	 */
+	guard(spinlock)(&j->lock);
 	ret = !test_bit(JOURNAL_replay_done, &j->flags) ||
 		journal_last_seq(j) > seq_to_flush ||
 		!fifo_used(&j->pin);
-
-	spin_unlock(&j->lock);
-unlock:
-	mutex_unlock(&j->reclaim_lock);
-
 	return ret;
 }
 
@@ -931,13 +912,12 @@ int bch2_journal_flush_device_pins(struct journal *j, int dev_idx)
 	u64 iter, seq = 0;
 	int ret = 0;
 
-	spin_lock(&j->lock);
-	fifo_for_each_entry_ptr(p, &j->pin, iter)
-		if (dev_idx >= 0
-		    ? bch2_dev_list_has_dev(p->devs, dev_idx)
-		    : p->devs.nr < c->opts.metadata_replicas)
-			seq = iter;
-	spin_unlock(&j->lock);
+	scoped_guard(spinlock, &j->lock)
+		fifo_for_each_entry_ptr(p, &j->pin, iter)
+			if (dev_idx >= 0
+			    ? bch2_dev_list_has_dev(p->devs, dev_idx)
+			    : p->devs.nr < c->opts.metadata_replicas)
+				seq = iter;
 
 	bch2_journal_flush_pins(j, seq);
 
@@ -945,7 +925,7 @@ int bch2_journal_flush_device_pins(struct journal *j, int dev_idx)
 	if (ret)
 		return ret;
 
-	mutex_lock(&c->replicas_gc_lock);
+	guard(mutex)(&c->replicas_gc_lock);
 	bch2_replicas_gc_start(c, 1 << BCH_DATA_journal);
 
 	/*
@@ -960,29 +940,25 @@ int bch2_journal_flush_device_pins(struct journal *j, int dev_idx)
 		goto err;
 
 	seq = 0;
-	spin_lock(&j->lock);
-	while (!ret) {
-		union bch_replicas_padded replicas;
+	scoped_guard(spinlock, &j->lock)
+		while (!ret) {
+			union bch_replicas_padded replicas;
 
-		seq = max(seq, journal_last_seq(j));
-		if (seq >= j->pin.back)
-			break;
-		bch2_devlist_to_replicas(&replicas.e, BCH_DATA_journal,
-					 journal_seq_pin(j, seq)->devs);
-		seq++;
+			seq = max(seq, journal_last_seq(j));
+			if (seq >= j->pin.back)
+				break;
+			bch2_devlist_to_replicas(&replicas.e, BCH_DATA_journal,
+						 journal_seq_pin(j, seq)->devs);
+			seq++;
 
-		if (replicas.e.nr_devs) {
-			spin_unlock(&j->lock);
-			ret = bch2_mark_replicas(c, &replicas.e);
-			spin_lock(&j->lock);
+			if (replicas.e.nr_devs) {
+				spin_unlock(&j->lock);
+				ret = bch2_mark_replicas(c, &replicas.e);
+				spin_lock(&j->lock);
+			}
 		}
-	}
-	spin_unlock(&j->lock);
 err:
-	ret = bch2_replicas_gc_end(c, ret);
-	mutex_unlock(&c->replicas_gc_lock);
-
-	return ret;
+	return bch2_replicas_gc_end(c, ret);
 }
 
 bool bch2_journal_seq_pins_to_text(struct printbuf *out, struct journal *j, u64 *seq)
@@ -990,20 +966,16 @@ bool bch2_journal_seq_pins_to_text(struct printbuf *out, struct journal *j, u64
 	struct journal_entry_pin_list *pin_list;
 	struct journal_entry_pin *pin;
 
-	spin_lock(&j->lock);
-	if (!test_bit(JOURNAL_running, &j->flags)) {
-		spin_unlock(&j->lock);
+	guard(spinlock)(&j->lock);
+	guard(printbuf_atomic)(out);
+
+	if (!test_bit(JOURNAL_running, &j->flags))
 		return true;
-	}
 
 	*seq = max(*seq, j->pin.front);
 
-	if (*seq >= j->pin.back) {
-		spin_unlock(&j->lock);
+	if (*seq >= j->pin.back)
 		return true;
-	}
-
-	out->atomic++;
 
 	pin_list = journal_seq_pin(j, *seq);
 
@@ -1022,9 +994,6 @@ bool bch2_journal_seq_pins_to_text(struct printbuf *out, struct journal *j, u64
 
 	printbuf_indent_sub(out, 2);
 
-	--out->atomic;
-	spin_unlock(&j->lock);
-
 	return false;
 }
 
-- 
2.51.0


From 966ee6ea920194bd49a6c378d447342a1b1e7cbe Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:42:35 -0400
Subject: [PATCH 151/309] bcachefs: convert journal_seq_blacklist.c to
 CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_seq_blacklist.c | 10 +++-------
 1 file changed, 3 insertions(+), 7 deletions(-)

diff --git a/fs/bcachefs/journal_seq_blacklist.c b/fs/bcachefs/journal_seq_blacklist.c
index 6361809b5e2e..399db5b77d9f 100644
--- a/fs/bcachefs/journal_seq_blacklist.c
+++ b/fs/bcachefs/journal_seq_blacklist.c
@@ -49,7 +49,7 @@ int bch2_journal_seq_blacklist_add(struct bch_fs *c, u64 start, u64 end)
 	unsigned i = 0, nr;
 	int ret = 0;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	bl = bch2_sb_field_get(c->disk_sb.sb, journal_seq_blacklist);
 	nr = blacklist_nr_entries(bl);
 
@@ -77,10 +77,8 @@ int bch2_journal_seq_blacklist_add(struct bch_fs *c, u64 start, u64 end)
 
 	bl = bch2_sb_field_resize(&c->disk_sb, journal_seq_blacklist,
 				  sb_blacklist_u64s(nr + 1));
-	if (!bl) {
-		ret = bch_err_throw(c, ENOSPC_sb_journal_seq_blacklist);
-		goto out;
-	}
+	if (!bl)
+		return bch_err_throw(c, ENOSPC_sb_journal_seq_blacklist);
 
 	array_insert_item(bl->start, nr, i, ((struct journal_seq_blacklist_entry) {
 		.start	= cpu_to_le64(start),
@@ -89,8 +87,6 @@ int bch2_journal_seq_blacklist_add(struct bch_fs *c, u64 start, u64 end)
 	c->disk_sb.sb->features[0] |= cpu_to_le64(1ULL << BCH_FEATURE_journal_seq_blacklist_v3);
 
 	ret = bch2_write_super(c);
-out:
-	mutex_unlock(&c->sb_lock);
 
 	return ret ?: bch2_blacklist_table_initialize(c);
 }
-- 
2.51.0


From ff98331019992302f21e68595f7e32086b7b9f52 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 11:35:53 -0400
Subject: [PATCH 152/309] bcachefs: convert btree_cache.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_cache.c | 33 ++++++++++-----------------------
 1 file changed, 10 insertions(+), 23 deletions(-)

diff --git a/fs/bcachefs/btree_cache.c b/fs/bcachefs/btree_cache.c
index 021580a5e7cc..e0679980508c 100644
--- a/fs/bcachefs/btree_cache.c
+++ b/fs/bcachefs/btree_cache.c
@@ -77,9 +77,8 @@ void bch2_btree_node_to_freelist(struct bch_fs *c, struct btree *b)
 {
 	struct btree_cache *bc = &c->btree_cache;
 
-	mutex_lock(&bc->lock);
-	__bch2_btree_node_to_freelist(bc, b);
-	mutex_unlock(&bc->lock);
+	scoped_guard(mutex, &bc->lock)
+		__bch2_btree_node_to_freelist(bc, b);
 
 	six_unlock_write(&b->c.lock);
 	six_unlock_intent(&b->c.lock);
@@ -214,14 +213,13 @@ void bch2_node_pin(struct bch_fs *c, struct btree *b)
 {
 	struct btree_cache *bc = &c->btree_cache;
 
-	mutex_lock(&bc->lock);
+	guard(mutex)(&bc->lock);
 	if (b != btree_node_root(c, b) && !btree_node_pinned(b)) {
 		set_btree_node_pinned(b);
 		list_move(&b->list, &bc->live[1].list);
 		bc->live[0].nr--;
 		bc->live[1].nr++;
 	}
-	mutex_unlock(&bc->lock);
 }
 
 void bch2_btree_cache_unpin(struct bch_fs *c)
@@ -229,7 +227,7 @@ void bch2_btree_cache_unpin(struct bch_fs *c)
 	struct btree_cache *bc = &c->btree_cache;
 	struct btree *b, *n;
 
-	mutex_lock(&bc->lock);
+	guard(mutex)(&bc->lock);
 	c->btree_cache.pinned_nodes_mask[0] = 0;
 	c->btree_cache.pinned_nodes_mask[1] = 0;
 
@@ -239,8 +237,6 @@ void bch2_btree_cache_unpin(struct bch_fs *c)
 		bc->live[0].nr++;
 		bc->live[1].nr--;
 	}
-
-	mutex_unlock(&bc->lock);
 }
 
 /* Btree in memory cache - hash table */
@@ -295,11 +291,8 @@ int bch2_btree_node_hash_insert(struct btree_cache *bc, struct btree *b,
 	b->c.level	= level;
 	b->c.btree_id	= id;
 
-	mutex_lock(&bc->lock);
-	int ret = __bch2_btree_node_hash_insert(bc, b);
-	mutex_unlock(&bc->lock);
-
-	return ret;
+	guard(mutex)(&bc->lock);
+	return __bch2_btree_node_hash_insert(bc, b);
 }
 
 void bch2_btree_node_update_key_early(struct btree_trans *trans,
@@ -316,7 +309,7 @@ void bch2_btree_node_update_key_early(struct btree_trans *trans,
 
 	b = bch2_btree_node_get_noiter(trans, tmp.k, btree, level, true);
 	if (!IS_ERR_OR_NULL(b)) {
-		mutex_lock(&c->btree_cache.lock);
+		guard(mutex)(&c->btree_cache.lock);
 
 		__bch2_btree_node_hash_remove(&c->btree_cache, b);
 
@@ -324,7 +317,6 @@ void bch2_btree_node_update_key_early(struct btree_trans *trans,
 		ret = __bch2_btree_node_hash_insert(&c->btree_cache, b);
 		BUG_ON(ret);
 
-		mutex_unlock(&c->btree_cache.lock);
 		six_unlock_read(&b->c.lock);
 	}
 
@@ -914,20 +906,18 @@ static noinline struct btree *bch2_btree_node_fill(struct btree_trans *trans,
 	}
 
 	if (unlikely(!bkey_is_btree_ptr(&k->k))) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(k));
 
 		int ret = bch2_fs_topology_error(c, "attempting to get btree node with non-btree key %s", buf.buf);
-		printbuf_exit(&buf);
 		return ERR_PTR(ret);
 	}
 
 	if (unlikely(k->k.u64s > BKEY_BTREE_PTR_U64s_MAX)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(k));
 
 		int ret = bch2_fs_topology_error(c, "attempting to get btree node with too big key %s", buf.buf);
-		printbuf_exit(&buf);
 		return ERR_PTR(ret);
 	}
 
@@ -1002,11 +992,10 @@ static noinline struct btree *bch2_btree_node_fill(struct btree_trans *trans,
 
 static noinline void btree_bad_header(struct bch_fs *c, struct btree *b)
 {
-	struct printbuf buf = PRINTBUF;
-
 	if (c->recovery.pass_done < BCH_RECOVERY_PASS_check_allocations)
 		return;
 
+	CLASS(printbuf, buf)();
 	prt_printf(&buf,
 		   "btree node header doesn't match ptr: ");
 	bch2_btree_id_level_to_text(&buf, b->c.btree_id, b->c.level);
@@ -1022,8 +1011,6 @@ static noinline void btree_bad_header(struct bch_fs *c, struct btree *b)
 	bch2_bpos_to_text(&buf, b->data->max_key);
 
 	bch2_fs_topology_error(c, "%s", buf.buf);
-
-	printbuf_exit(&buf);
 }
 
 static inline void btree_check_header(struct bch_fs *c, struct btree *b)
-- 
2.51.0


From 40cb7183ef449e99664d1d70c07032cf37e64b2d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:40:33 -0400
Subject: [PATCH 153/309] bcachefs: convert btree_gc.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_gc.c | 88 ++++++++++++++++--------------------------
 1 file changed, 33 insertions(+), 55 deletions(-)

diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index 7269490a5d9a..0804329601c1 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -95,11 +95,10 @@ static struct bkey_s unsafe_bkey_s_c_to_s(struct bkey_s_c k)
 
 static inline void __gc_pos_set(struct bch_fs *c, struct gc_pos new_pos)
 {
-	preempt_disable();
+	guard(preempt)();
 	write_seqcount_begin(&c->gc_pos_lock);
 	c->gc_pos = new_pos;
 	write_seqcount_end(&c->gc_pos_lock);
-	preempt_enable();
 }
 
 static inline void gc_pos_set(struct bch_fs *c, struct gc_pos new_pos)
@@ -138,14 +137,13 @@ static int set_node_min(struct bch_fs *c, struct btree *b, struct bpos new_min)
 	int ret;
 
 	if (c->opts.verbose) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&b->key));
 		prt_str(&buf, " -> ");
 		bch2_bpos_to_text(&buf, new_min);
 
 		bch_info(c, "%s(): %s", __func__, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	new = kmalloc_array(BKEY_BTREE_PTR_U64s_MAX, sizeof(u64), GFP_KERNEL);
@@ -174,14 +172,13 @@ static int set_node_max(struct bch_fs *c, struct btree *b, struct bpos new_max)
 	int ret;
 
 	if (c->opts.verbose) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&b->key));
 		prt_str(&buf, " -> ");
 		bch2_bpos_to_text(&buf, new_max);
 
 		bch_info(c, "%s(): %s", __func__, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	ret = bch2_journal_key_delete(c, b->c.btree_id, b->c.level + 1, b->key.k.p);
@@ -205,13 +202,12 @@ static int set_node_max(struct bch_fs *c, struct btree *b, struct bpos new_max)
 
 	bch2_btree_node_drop_keys_outside_node(b);
 
-	mutex_lock(&c->btree_cache.lock);
+	guard(mutex)(&c->btree_cache.lock);
 	__bch2_btree_node_hash_remove(&c->btree_cache, b);
 
 	bkey_copy(&b->key, &new->k_i);
 	ret = __bch2_btree_node_hash_insert(&c->btree_cache, b);
 	BUG_ON(ret);
-	mutex_unlock(&c->btree_cache.lock);
 	return 0;
 }
 
@@ -223,7 +219,7 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 	struct bpos expected_start = !prev
 		? b->data->min_key
 		: bpos_successor(prev->key.k.p);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	BUG_ON(b->key.k.type == KEY_TYPE_btree_ptr_v2 &&
@@ -253,7 +249,7 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 						     expected_start,
 						     bpos_predecessor(cur->data->min_key));
 			if (ret)
-				goto err;
+				return ret;
 
 			*pulled_from_scan = cur->data->min_key;
 			ret = DID_FILL_FROM_SCAN;
@@ -286,9 +282,7 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 			}
 		}
 	}
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -296,7 +290,7 @@ static int btree_repair_node_end(struct btree_trans *trans, struct btree *b,
 				 struct btree *child, struct bpos *pulled_from_scan)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	if (bpos_eq(child->key.k.p, b->key.k.p))
@@ -317,7 +311,7 @@ static int btree_repair_node_end(struct btree_trans *trans, struct btree *b,
 			ret = bch2_get_scanned_nodes(c, b->c.btree_id, 0,
 						bpos_successor(child->key.k.p), b->key.k.p);
 			if (ret)
-				goto err;
+				return ret;
 
 			*pulled_from_scan = b->key.k.p;
 			ret = DID_FILL_FROM_SCAN;
@@ -325,9 +319,7 @@ static int btree_repair_node_end(struct btree_trans *trans, struct btree *b,
 			ret = set_node_max(c, child, b->key.k.p);
 		}
 	}
-err:
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -340,7 +332,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 	struct bkey_buf prev_k, cur_k;
 	struct btree *prev = NULL, *cur = NULL;
 	bool have_child, new_pass = false;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	if (!b->c.level)
@@ -529,7 +521,6 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 
 	bch2_bkey_buf_exit(&prev_k, c);
 	bch2_bkey_buf_exit(&cur_k, c);
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -539,7 +530,7 @@ static int bch2_check_root(struct btree_trans *trans, enum btree_id btree,
 {
 	struct bch_fs *c = trans->c;
 	struct btree_root *r = bch2_btree_id_root(c, btree);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	bch2_btree_id_to_text(&buf, btree);
@@ -568,21 +559,20 @@ static int bch2_check_root(struct btree_trans *trans, enum btree_id btree,
 			bch2_shoot_down_journal_keys(c, btree, 1, BTREE_MAX_DEPTH, POS_MIN, SPOS_MAX);
 			ret = bch2_get_scanned_nodes(c, btree, 0, POS_MIN, SPOS_MAX);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		*reconstructed_root = true;
 	}
 err:
 fsck_err:
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
 
 int bch2_check_topology(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	struct bpos pulled_from_scan = POS_MIN;
 	int ret = 0;
 
@@ -603,9 +593,8 @@ int bch2_check_topology(struct bch_fs *c)
 		six_unlock_read(&b->c.lock);
 
 		if (ret == DROP_THIS_NODE) {
-			mutex_lock(&c->btree_cache.lock);
-			bch2_btree_node_hash_remove(&c->btree_cache, b);
-			mutex_unlock(&c->btree_cache.lock);
+			scoped_guard(mutex, &c->btree_cache.lock)
+				bch2_btree_node_hash_remove(&c->btree_cache, b);
 
 			r->b = NULL;
 
@@ -614,17 +603,15 @@ int bch2_check_topology(struct bch_fs *c)
 				goto recover;
 			}
 
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 			bch2_btree_id_to_text(&buf, i);
 			bch_err(c, "empty btree root %s", buf.buf);
-			printbuf_exit(&buf);
 			bch2_btree_root_alloc_fake_trans(trans, i, 0);
 			r->alive = false;
 			ret = 0;
 		}
 	}
 
-	bch2_trans_put(trans);
 	return ret;
 }
 
@@ -651,7 +638,7 @@ static int bch2_gc_mark_key(struct btree_trans *trans, enum btree_id btree_id,
 
 	struct bkey deleted = KEY(0, 0, 0);
 	struct bkey_s_c old = (struct bkey_s_c) { &deleted, NULL };
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	deleted.p = k.k->p;
@@ -675,10 +662,9 @@ static int bch2_gc_mark_key(struct btree_trans *trans, enum btree_id btree_id,
 				(printbuf_reset(&buf),
 				 bch2_bkey_val_to_text(&buf, c, k),
 				 buf.buf))) {
-		mutex_lock(&c->sb_lock);
+		guard(mutex)(&c->sb_lock);
 		bch2_dev_btree_bitmap_mark(c, k);
 		bch2_write_super(c);
-		mutex_unlock(&c->sb_lock);
 	}
 
 	/*
@@ -703,7 +689,6 @@ static int bch2_gc_mark_key(struct btree_trans *trans, enum btree_id btree_id,
 			       BTREE_TRIGGER_gc|BTREE_TRIGGER_insert|flags);
 out:
 fsck_err:
-	printbuf_exit(&buf);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -771,8 +756,8 @@ static inline int btree_id_gc_phase_cmp(enum btree_id l, enum btree_id r)
 
 static int bch2_gc_btrees(struct bch_fs *c)
 {
-	struct btree_trans *trans = bch2_trans_get(c);
-	struct printbuf buf = PRINTBUF;
+	CLASS(btree_trans, trans)(c);
+	CLASS(printbuf, buf)();
 	int ret = 0;
 
 	struct progress_indicator_state progress;
@@ -792,8 +777,6 @@ static int bch2_gc_btrees(struct bch_fs *c)
 		ret = bch2_gc_btree(trans, &progress, btree, true);
 	}
 
-	printbuf_exit(&buf);
-	bch2_trans_put(trans);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -945,16 +928,16 @@ static int bch2_alloc_write_key(struct btree_trans *trans,
 
 static int bch2_gc_alloc_done(struct bch_fs *c)
 {
+	CLASS(btree_trans, trans)(c);
 	int ret = 0;
 
 	for_each_member_device(c, ca) {
-		ret = bch2_trans_run(c,
-			for_each_btree_key_max_commit(trans, iter, BTREE_ID_alloc,
+		ret = for_each_btree_key_max_commit(trans, iter, BTREE_ID_alloc,
 					POS(ca->dev_idx, ca->mi.first_bucket),
 					POS(ca->dev_idx, ca->mi.nbuckets - 1),
 					BTREE_ITER_slots|BTREE_ITER_prefetch, k,
 					NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-				bch2_alloc_write_key(trans, &iter, ca, k)));
+				bch2_alloc_write_key(trans, &iter, ca, k));
 		if (ret) {
 			bch2_dev_put(ca);
 			break;
@@ -987,7 +970,7 @@ static int bch2_gc_write_stripes_key(struct btree_trans *trans,
 				     struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	const struct bch_stripe *s;
 	struct gc_stripe *m;
 	bool bad = false;
@@ -1032,18 +1015,17 @@ static int bch2_gc_write_stripes_key(struct btree_trans *trans,
 		ret = bch2_trans_update(trans, iter, &new->k_i, 0);
 	}
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
 static int bch2_gc_stripes_done(struct bch_fs *c)
 {
-	return bch2_trans_run(c,
-		for_each_btree_key_commit(trans, iter,
+	CLASS(btree_trans, trans)(c);
+	return for_each_btree_key_commit(trans, iter,
 				BTREE_ID_stripes, POS_MIN,
 				BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_gc_write_stripes_key(trans, &iter, k)));
+			bch2_gc_write_stripes_key(trans, &iter, k));
 }
 
 /**
@@ -1072,8 +1054,8 @@ int bch2_check_allocations(struct bch_fs *c)
 {
 	int ret;
 
-	down_read(&c->state_lock);
-	down_write(&c->gc_lock);
+	guard(rwsem_read)(&c->state_lock);
+	guard(rwsem_write)(&c->gc_lock);
 
 	bch2_btree_interior_updates_flush(c);
 
@@ -1102,15 +1084,11 @@ int bch2_check_allocations(struct bch_fs *c)
 		bch2_gc_stripes_done(c) ?:
 		bch2_gc_reflink_done(c);
 out:
-	percpu_down_write(&c->mark_lock);
-	/* Indicates that gc is no longer in progress: */
-	__gc_pos_set(c, gc_phase(GC_PHASE_not_running));
-
-	bch2_gc_free(c);
-	percpu_up_write(&c->mark_lock);
-
-	up_write(&c->gc_lock);
-	up_read(&c->state_lock);
+	scoped_guard(percpu_write, &c->mark_lock) {
+		/* Indicates that gc is no longer in progress: */
+		__gc_pos_set(c, gc_phase(GC_PHASE_not_running));
+		bch2_gc_free(c);
+	}
 
 	/*
 	 * At startup, allocations can happen directly instead of via the
-- 
2.51.0


From 00ed836b44c2ce08691bd5efb88f88474d66b956 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:43:01 -0400
Subject: [PATCH 154/309] bcachefs: convert btree_write_buffer.c to
 CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_write_buffer.c | 40 ++++++++++++++------------------
 1 file changed, 18 insertions(+), 22 deletions(-)

diff --git a/fs/bcachefs/btree_write_buffer.c b/fs/bcachefs/btree_write_buffer.c
index c897167820e4..9cfc3edce39a 100644
--- a/fs/bcachefs/btree_write_buffer.c
+++ b/fs/bcachefs/btree_write_buffer.c
@@ -259,9 +259,8 @@ static void move_keys_from_inc_to_flushing(struct btree_write_buffer *wb)
 					bch2_btree_write_buffer_journal_flush);
 
 	if (j->watermark) {
-		spin_lock(&j->lock);
+		guard(spinlock)(&j->lock);
 		bch2_journal_set_watermark(j);
-		spin_unlock(&j->lock);
 	}
 
 	BUG_ON(wb->sorted.size < wb->flushing.keys.nr);
@@ -270,7 +269,7 @@ static void move_keys_from_inc_to_flushing(struct btree_write_buffer *wb)
 int bch2_btree_write_buffer_insert_err(struct bch_fs *c,
 				       enum btree_id btree, struct bkey_i *k)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_printf(&buf, "attempting to do write buffer update on non wb btree=");
 	bch2_btree_id_to_text(&buf, btree);
@@ -278,7 +277,6 @@ int bch2_btree_write_buffer_insert_err(struct bch_fs *c,
 	bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(k));
 
 	bch2_fs_inconsistent(c, "%s", buf.buf);
-	printbuf_exit(&buf);
 	return -EROFS;
 }
 
@@ -300,9 +298,8 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 	bch2_trans_unlock(trans);
 	bch2_trans_begin(trans);
 
-	mutex_lock(&wb->inc.lock);
-	move_keys_from_inc_to_flushing(wb);
-	mutex_unlock(&wb->inc.lock);
+	scoped_guard(mutex, &wb->inc.lock)
+		move_keys_from_inc_to_flushing(wb);
 
 	for (size_t i = 0; i < wb->flushing.keys.nr; i++) {
 		wb->sorted.data[i].idx = i;
@@ -533,9 +530,8 @@ static int fetch_wb_keys_from_journal(struct bch_fs *c, u64 max_seq)
 		ret = bch2_journal_keys_to_write_buffer(c, buf);
 
 		if (!blocked && !ret) {
-			spin_lock(&j->lock);
+			guard(spinlock)(&j->lock);
 			buf->need_flush_to_write_buffer = false;
-			spin_unlock(&j->lock);
 		}
 
 		mutex_unlock(&j->buf_lock);
@@ -567,9 +563,8 @@ static int btree_write_buffer_flush_seq(struct btree_trans *trans, u64 max_seq,
 		 * On memory allocation failure, bch2_btree_write_buffer_flush_locked()
 		 * is not guaranteed to empty wb->inc:
 		 */
-		mutex_lock(&wb->flushing.lock);
-		ret = bch2_btree_write_buffer_flush_locked(trans);
-		mutex_unlock(&wb->flushing.lock);
+		scoped_guard(mutex, &wb->flushing.lock)
+			ret = bch2_btree_write_buffer_flush_locked(trans);
 	} while (!ret &&
 		 (fetch_from_journal_err ||
 		  (wb->inc.pin.seq && wb->inc.pin.seq <= max_seq) ||
@@ -582,9 +577,10 @@ static int bch2_btree_write_buffer_journal_flush(struct journal *j,
 				struct journal_entry_pin *_pin, u64 seq)
 {
 	struct bch_fs *c = container_of(j, struct bch_fs, journal);
+	CLASS(btree_trans, trans)(c);
 	bool did_work = false;
 
-	return bch2_trans_run(c, btree_write_buffer_flush_seq(trans, seq, &did_work));
+	return btree_write_buffer_flush_seq(trans, seq, &did_work);
 }
 
 int bch2_btree_write_buffer_flush_sync(struct btree_trans *trans)
@@ -606,9 +602,9 @@ bool bch2_btree_write_buffer_flush_going_ro(struct bch_fs *c)
 	if (bch2_journal_error(&c->journal))
 		return false;
 
+	CLASS(btree_trans, trans)(c);
 	bool did_work = false;
-	bch2_trans_run(c, btree_write_buffer_flush_seq(trans,
-				journal_cur_seq(&c->journal), &did_work));
+	btree_write_buffer_flush_seq(trans, journal_cur_seq(&c->journal), &did_work);
 	return did_work;
 }
 
@@ -655,11 +651,10 @@ int bch2_btree_write_buffer_maybe_flush(struct btree_trans *trans,
 
 	if (!bkey_and_val_eq(referring_k, bkey_i_to_s_c(last_flushed->k))) {
 		if (trace_write_buffer_maybe_flush_enabled()) {
-			struct printbuf buf = PRINTBUF;
+			CLASS(printbuf, buf)();
 
 			bch2_bkey_val_to_text(&buf, c, referring_k);
 			trace_write_buffer_maybe_flush(trans, _RET_IP_, buf.buf);
-			printbuf_exit(&buf);
 		}
 
 		bch2_bkey_buf_reassemble(&tmp, c, referring_k);
@@ -690,11 +685,12 @@ static void bch2_btree_write_buffer_flush_work(struct work_struct *work)
 	struct btree_write_buffer *wb = &c->btree_write_buffer;
 	int ret;
 
-	mutex_lock(&wb->flushing.lock);
-	do {
-		ret = bch2_trans_run(c, bch2_btree_write_buffer_flush_locked(trans));
-	} while (!ret && bch2_btree_write_buffer_should_flush(c));
-	mutex_unlock(&wb->flushing.lock);
+	scoped_guard(mutex, &wb->flushing.lock) {
+		CLASS(btree_trans, trans)(c);
+		do {
+			ret = bch2_btree_write_buffer_flush_locked(trans);
+		} while (!ret && bch2_btree_write_buffer_should_flush(c));
+	}
 
 	enumerated_ref_put(&c->writes, BCH_WRITE_REF_btree_write_buffer);
 }
-- 
2.51.0


From 0a72bc37ccc2e7b37be6eb066cfb6443c07263d4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:43:17 -0400
Subject: [PATCH 155/309] bcachefs: convert btree_update.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update.c | 26 +++++++++++++-------------
 fs/bcachefs/btree_update.h |  1 +
 2 files changed, 14 insertions(+), 13 deletions(-)

diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 7983c4940b3b..f514a8ad7a89 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -671,8 +671,9 @@ int bch2_btree_insert(struct bch_fs *c, enum btree_id id, struct bkey_i *k,
 		      enum bch_trans_commit_flags commit_flags,
 		      enum btree_iter_update_trigger_flags iter_flags)
 {
-	return bch2_trans_commit_do(c, disk_res, NULL, commit_flags,
-			     bch2_btree_insert_trans(trans, id, k, iter_flags));
+	CLASS(btree_trans, trans)(c);
+	return commit_do(trans, disk_res, NULL, commit_flags,
+			 bch2_btree_insert_trans(trans, id, k, iter_flags));
 }
 
 int bch2_btree_delete_at(struct btree_trans *trans, struct btree_iter *iter,
@@ -781,9 +782,8 @@ int bch2_btree_delete_range(struct bch_fs *c, enum btree_id id,
 			    enum btree_iter_update_trigger_flags flags,
 			    u64 *journal_seq)
 {
-	int ret = bch2_trans_run(c,
-			bch2_btree_delete_range_trans(trans, id, start, end,
-						      flags, journal_seq));
+	CLASS(btree_trans, trans)(c);
+	int ret = bch2_btree_delete_range_trans(trans, id, start, end, flags, journal_seq);
 	if (ret == -BCH_ERR_transaction_restart_nested)
 		ret = 0;
 	return ret;
@@ -877,31 +877,31 @@ static int
 __bch2_fs_log_msg(struct bch_fs *c, unsigned commit_flags, const char *fmt,
 		  va_list args)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	prt_vprintf(&buf, fmt, args);
 
 	unsigned u64s = DIV_ROUND_UP(buf.pos, sizeof(u64));
 
 	int ret = buf.allocation_failure ? -BCH_ERR_ENOMEM_trans_log_msg : 0;
 	if (ret)
-		goto err;
+		return ret;
 
 	if (!test_bit(JOURNAL_running, &c->journal.flags)) {
 		ret = darray_make_room(&c->journal.early_journal_entries, jset_u64s(u64s));
 		if (ret)
-			goto err;
+			return ret;
 
 		struct jset_entry_log *l = (void *) &darray_top(c->journal.early_journal_entries);
 		journal_entry_init(&l->entry, BCH_JSET_ENTRY_log, 0, 1, u64s);
 		memcpy_and_pad(l->d, u64s * sizeof(u64), buf.buf, buf.pos, 0);
 		c->journal.early_journal_entries.nr += jset_u64s(u64s);
 	} else {
-		ret = bch2_trans_commit_do(c, NULL, NULL, commit_flags,
-			bch2_trans_log_msg(trans, &buf));
+		CLASS(btree_trans, trans)(c);
+		ret = commit_do(trans, NULL, NULL, commit_flags,
+				bch2_trans_log_msg(trans, &buf));
 	}
-err:
-	printbuf_exit(&buf);
-	return ret;
+
+	return 0;
 }
 
 __printf(2, 3)
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 8e91b9f143d8..633de3b3ac28 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -278,6 +278,7 @@ static inline int bch2_trans_commit(struct btree_trans *trans,
 	nested_lockrestart_do(_trans, _do ?: bch2_trans_commit(_trans, (_disk_res),\
 					(_journal_seq), (_flags)))
 
+/* deprecated, prefer CLASS(btree_trans) */
 #define bch2_trans_commit_do(_c, _disk_res, _journal_seq, _flags, _do)		\
 	bch2_trans_run(_c, commit_do(trans, _disk_res, _journal_seq, _flags, _do))
 
-- 
2.51.0


From 3022d66e6269aee8fe0e4b2cc367e17738287cb4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:43:23 -0400
Subject: [PATCH 156/309] bcachefs: convert btree_update_interior.c to
 CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update_interior.c | 225 ++++++++++++----------------
 1 file changed, 96 insertions(+), 129 deletions(-)

diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index ebdb4d2f1be9..312ef203b27b 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -53,7 +53,7 @@ int bch2_btree_node_check_topology(struct btree_trans *trans, struct btree *b)
 		: b->data->min_key;
 	struct btree_and_journal_iter iter;
 	struct bkey_s_c k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	struct bkey_buf prev;
 	int ret = 0;
 
@@ -133,7 +133,6 @@ int bch2_btree_node_check_topology(struct btree_trans *trans, struct btree *b)
 out:
 	bch2_btree_and_journal_iter_exit(&iter);
 	bch2_bkey_buf_exit(&prev, c);
-	printbuf_exit(&buf);
 	return ret;
 err:
 	bch2_btree_id_level_to_text(&buf, b->c.btree_id, b->c.level);
@@ -240,9 +239,8 @@ static void bch2_btree_node_free_inmem(struct btree_trans *trans,
 
 	__btree_node_free(trans, b);
 
-	mutex_lock(&c->btree_cache.lock);
-	bch2_btree_node_hash_remove(&c->btree_cache, b);
-	mutex_unlock(&c->btree_cache.lock);
+	scoped_guard(mutex, &c->btree_cache.lock)
+		bch2_btree_node_hash_remove(&c->btree_cache, b);
 
 	six_unlock_write(&b->c.lock);
 	mark_btree_node_locked_noreset(path, b->c.level, BTREE_NODE_INTENT_LOCKED);
@@ -268,9 +266,8 @@ static void bch2_btree_node_free_never_used(struct btree_update *as,
 	clear_btree_node_dirty_acct(c, b);
 	clear_btree_node_need_write(b);
 
-	mutex_lock(&c->btree_cache.lock);
-	__bch2_btree_node_hash_remove(&c->btree_cache, b);
-	mutex_unlock(&c->btree_cache.lock);
+	scoped_guard(mutex, &c->btree_cache.lock)
+		__bch2_btree_node_hash_remove(&c->btree_cache, b);
 
 	BUG_ON(p->nr >= ARRAY_SIZE(p->b));
 	p->b[p->nr++] = b;
@@ -560,7 +557,8 @@ static void bch2_btree_update_free(struct btree_update *as, struct btree_trans *
 	bch2_time_stats_update(&c->times[BCH_TIME_btree_interior_update_total],
 			       as->start_time);
 
-	mutex_lock(&c->btree_interior_update_lock);
+	guard(mutex)(&c->btree_interior_update_lock);
+
 	list_del(&as->unwritten_list);
 	list_del(&as->list);
 
@@ -572,8 +570,6 @@ static void bch2_btree_update_free(struct btree_update *as, struct btree_trans *
 	 * since being on btree_interior_update_list is our ref on @c:
 	 */
 	closure_wake_up(&c->btree_interior_update_wait);
-
-	mutex_unlock(&c->btree_interior_update_lock);
 }
 
 static void btree_update_add_key(struct btree_update *as,
@@ -602,12 +598,11 @@ static void btree_update_new_nodes_mark_sb(struct btree_update *as)
 {
 	struct bch_fs *c = as->c;
 
-	mutex_lock(&c->sb_lock);
+	guard(mutex)(&c->sb_lock);
 	for_each_keylist_key(&as->new_keys, k)
 		bch2_dev_btree_bitmap_mark(c, bkey_i_to_s_c(k));
 
 	bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
 }
 
 /*
@@ -659,7 +654,7 @@ static void btree_update_nodes_written(struct btree_update *as)
 {
 	struct bch_fs *c = as->c;
 	struct btree *b;
-	struct btree_trans *trans = bch2_trans_get(c);
+	CLASS(btree_trans, trans)(c);
 	u64 journal_seq = 0;
 	unsigned i;
 	int ret;
@@ -818,15 +813,15 @@ static void btree_update_nodes_written(struct btree_update *as)
 
 	bch2_journal_pin_drop(&c->journal, &as->journal);
 
-	mutex_lock(&c->btree_interior_update_lock);
-	for (i = 0; i < as->nr_new_nodes; i++) {
-		b = as->new_nodes[i];
+	scoped_guard(mutex, &c->btree_interior_update_lock) {
+		for (i = 0; i < as->nr_new_nodes; i++) {
+			b = as->new_nodes[i];
 
-		BUG_ON(b->will_make_reachable != (unsigned long) as);
-		b->will_make_reachable = 0;
-		clear_btree_node_will_make_reachable(b);
+			BUG_ON(b->will_make_reachable != (unsigned long) as);
+			b->will_make_reachable = 0;
+			clear_btree_node_will_make_reachable(b);
+		}
 	}
-	mutex_unlock(&c->btree_interior_update_lock);
 
 	for (i = 0; i < as->nr_new_nodes; i++) {
 		b = as->new_nodes[i];
@@ -840,7 +835,6 @@ static void btree_update_nodes_written(struct btree_update *as)
 		bch2_open_bucket_put(c, c->open_buckets + as->open_buckets[i]);
 
 	bch2_btree_update_free(as, trans);
-	bch2_trans_put(trans);
 }
 
 static void btree_interior_update_work(struct work_struct *work)
@@ -850,12 +844,12 @@ static void btree_interior_update_work(struct work_struct *work)
 	struct btree_update *as;
 
 	while (1) {
-		mutex_lock(&c->btree_interior_update_lock);
-		as = list_first_entry_or_null(&c->btree_interior_updates_unwritten,
-					      struct btree_update, unwritten_list);
-		if (as && !as->nodes_written)
-			as = NULL;
-		mutex_unlock(&c->btree_interior_update_lock);
+		scoped_guard(mutex, &c->btree_interior_update_lock) {
+			as = list_first_entry_or_null(&c->btree_interior_updates_unwritten,
+						      struct btree_update, unwritten_list);
+			if (as && !as->nodes_written)
+				as = NULL;
+		}
 
 		if (!as)
 			break;
@@ -869,9 +863,8 @@ static CLOSURE_CALLBACK(btree_update_set_nodes_written)
 	closure_type(as, struct btree_update, cl);
 	struct bch_fs *c = as->c;
 
-	mutex_lock(&c->btree_interior_update_lock);
-	as->nodes_written = true;
-	mutex_unlock(&c->btree_interior_update_lock);
+	scoped_guard(mutex, &c->btree_interior_update_lock)
+		as->nodes_written = true;
 
 	queue_work(c->btree_interior_update_worker, &c->btree_interior_update_work);
 }
@@ -889,7 +882,7 @@ static void btree_update_updated_node(struct btree_update *as, struct btree *b)
 	BUG_ON(!btree_node_dirty(b));
 	BUG_ON(!b->c.level);
 
-	mutex_lock(&c->btree_interior_update_lock);
+	guard(mutex)(&c->btree_interior_update_lock);
 	list_add_tail(&as->unwritten_list, &c->btree_interior_updates_unwritten);
 
 	as->mode	= BTREE_UPDATE_node;
@@ -898,8 +891,6 @@ static void btree_update_updated_node(struct btree_update *as, struct btree *b)
 
 	set_btree_node_write_blocked(b);
 	list_add(&as->write_blocked_list, &b->write_blocked);
-
-	mutex_unlock(&c->btree_interior_update_lock);
 }
 
 static int bch2_update_reparent_journal_pin_flush(struct journal *j,
@@ -938,11 +929,11 @@ static void btree_update_updated_root(struct btree_update *as, struct btree *b)
 				  b->c.btree_id, b->c.level,
 				  insert, insert->k.u64s);
 
-	mutex_lock(&c->btree_interior_update_lock);
-	list_add_tail(&as->unwritten_list, &c->btree_interior_updates_unwritten);
+	scoped_guard(mutex, &c->btree_interior_update_lock) {
+		list_add_tail(&as->unwritten_list, &c->btree_interior_updates_unwritten);
 
-	as->mode	= BTREE_UPDATE_root;
-	mutex_unlock(&c->btree_interior_update_lock);
+		as->mode	= BTREE_UPDATE_root;
+	}
 }
 
 /*
@@ -963,7 +954,8 @@ static void bch2_btree_update_add_new_node(struct btree_update *as, struct btree
 
 	closure_get(&as->cl);
 
-	mutex_lock(&c->btree_interior_update_lock);
+	guard(mutex)(&c->btree_interior_update_lock);
+
 	BUG_ON(as->nr_new_nodes >= ARRAY_SIZE(as->new_nodes));
 	BUG_ON(b->will_make_reachable);
 
@@ -971,8 +963,6 @@ static void bch2_btree_update_add_new_node(struct btree_update *as, struct btree
 	b->will_make_reachable = 1UL|(unsigned long) as;
 	set_btree_node_will_make_reachable(b);
 
-	mutex_unlock(&c->btree_interior_update_lock);
-
 	btree_update_add_key(as, &as->new_keys, b);
 
 	if (b->key.k.type == KEY_TYPE_btree_ptr_v2) {
@@ -991,31 +981,29 @@ static void btree_update_drop_new_node(struct bch_fs *c, struct btree *b)
 {
 	struct btree_update *as;
 	unsigned long v;
-	unsigned i;
 
-	mutex_lock(&c->btree_interior_update_lock);
-	/*
-	 * When b->will_make_reachable != 0, it owns a ref on as->cl that's
-	 * dropped when it gets written by bch2_btree_complete_write - the
-	 * xchg() is for synchronization with bch2_btree_complete_write:
-	 */
-	v = xchg(&b->will_make_reachable, 0);
-	clear_btree_node_will_make_reachable(b);
-	as = (struct btree_update *) (v & ~1UL);
+	scoped_guard(mutex, &c->btree_interior_update_lock) {
+		/*
+		 * When b->will_make_reachable != 0, it owns a ref on as->cl that's
+		 * dropped when it gets written by bch2_btree_complete_write - the
+		 * xchg() is for synchronization with bch2_btree_complete_write:
+		 */
+		v = xchg(&b->will_make_reachable, 0);
+		clear_btree_node_will_make_reachable(b);
+		as = (struct btree_update *) (v & ~1UL);
 
-	if (!as) {
-		mutex_unlock(&c->btree_interior_update_lock);
-		return;
-	}
+		if (!as)
+			return;
 
-	for (i = 0; i < as->nr_new_nodes; i++)
-		if (as->new_nodes[i] == b)
-			goto found;
+		unsigned i;
+		for (i = 0; i < as->nr_new_nodes; i++)
+			if (as->new_nodes[i] == b)
+				goto found;
 
-	BUG();
-found:
-	array_remove_item(as->new_nodes, as->nr_new_nodes, i);
-	mutex_unlock(&c->btree_interior_update_lock);
+		BUG();
+	found:
+		array_remove_item(as->new_nodes, as->nr_new_nodes, i);
+	}
 
 	if (v & 1)
 		closure_put(&as->cl);
@@ -1232,9 +1220,8 @@ bch2_btree_update_start(struct btree_trans *trans, struct btree_path *path,
 	bch2_keylist_init(&as->new_keys, as->_new_keys);
 	bch2_keylist_init(&as->parent_keys, as->inline_keys);
 
-	mutex_lock(&c->btree_interior_update_lock);
-	list_add_tail(&as->list, &c->btree_interior_update_list);
-	mutex_unlock(&c->btree_interior_update_lock);
+	scoped_guard(mutex, &c->btree_interior_update_lock)
+		list_add_tail(&as->list, &c->btree_interior_update_list);
 
 	struct btree *b = btree_path_node(path, path->level);
 	as->node_start	= b->data->min_key;
@@ -1318,13 +1305,11 @@ bch2_btree_update_start(struct btree_trans *trans, struct btree_path *path,
 static void bch2_btree_set_root_inmem(struct bch_fs *c, struct btree *b)
 {
 	/* Root nodes cannot be reaped */
-	mutex_lock(&c->btree_cache.lock);
-	list_del_init(&b->list);
-	mutex_unlock(&c->btree_cache.lock);
+	scoped_guard(mutex, &c->btree_cache.lock)
+		list_del_init(&b->list);
 
-	mutex_lock(&c->btree_root_lock);
-	bch2_btree_id_root(c, b->c.btree_id)->b = b;
-	mutex_unlock(&c->btree_root_lock);
+	scoped_guard(mutex, &c->btree_root_lock)
+		bch2_btree_id_root(c, b->c.btree_id)->b = b;
 
 	bch2_recalc_btree_reserve(c);
 }
@@ -1379,7 +1364,7 @@ static void bch2_insert_fixup_btree_ptr(struct btree_update *as,
 {
 	struct bch_fs *c = as->c;
 	struct bkey_packed *k;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	unsigned long old, new;
 
 	BUG_ON(insert->k.type == KEY_TYPE_btree_ptr_v2 &&
@@ -1424,8 +1409,6 @@ static void bch2_insert_fixup_btree_ptr(struct btree_update *as,
 		new |= BTREE_WRITE_interior;
 		new |= 1 << BTREE_NODE_need_write;
 	} while (!try_cmpxchg(&b->flags, &old, new));
-
-	printbuf_exit(&buf);
 }
 
 static int
@@ -1452,7 +1435,7 @@ bch2_btree_insert_keys_interior(struct btree_update *as,
 
 	int ret = bch2_btree_node_check_topology(trans, b);
 	if (ret) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		for (struct bkey_i *k = keys->keys;
 		     k != insert;
@@ -1839,7 +1822,7 @@ static int bch2_btree_insert_node(struct btree_update *as, struct btree_trans *t
 	bch2_verify_keylist_sorted(keys);
 
 	if (!btree_node_intent_locked(path, b->c.level)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 		prt_printf(&buf, "%s(): node not locked at level %u\n",
 			   __func__, b->c.level);
@@ -1848,7 +1831,6 @@ static int bch2_btree_insert_node(struct btree_update *as, struct btree_trans *t
 		bch2_fs_emergency_read_only2(c, &buf);
 
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 		return -EIO;
 	}
 
@@ -1971,9 +1953,8 @@ static void __btree_increase_depth(struct btree_update *as, struct btree_trans *
 	bch2_trans_node_add(trans, path, n);
 	six_unlock_intent(&n->c.lock);
 
-	mutex_lock(&c->btree_cache.lock);
-	list_add_tail(&b->list, &c->btree_cache.live[btree_node_pinned(b)].list);
-	mutex_unlock(&c->btree_cache.lock);
+	scoped_guard(mutex, &c->btree_cache.lock)
+		list_add_tail(&b->list, &c->btree_cache.live[btree_node_pinned(b)].list);
 
 	bch2_trans_verify_locks(trans);
 }
@@ -2073,7 +2054,7 @@ int __bch2_foreground_maybe_merge(struct btree_trans *trans,
 	}
 
 	if (!bpos_eq(bpos_successor(prev->data->max_key), next->data->min_key)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		printbuf_indent_add_nextline(&buf, 2);
 		prt_printf(&buf, "%s(): ", __func__);
@@ -2088,7 +2069,6 @@ int __bch2_foreground_maybe_merge(struct btree_trans *trans,
 		bch2_bpos_to_text(&buf, next->data->min_key);
 
 		bch_err(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 		goto err;
 	}
 
@@ -2371,9 +2351,8 @@ static void async_btree_node_rewrite_work(struct work_struct *work)
 	    !bch2_err_matches(ret, EROFS))
 		bch_err_fn_ratelimited(c, ret);
 
-	spin_lock(&c->btree_node_rewrites_lock);
-	list_del(&a->list);
-	spin_unlock(&c->btree_node_rewrites_lock);
+	scoped_guard(spinlock, &c->btree_node_rewrites_lock)
+		list_del(&a->list);
 
 	closure_wake_up(&c->btree_node_rewrites_wait);
 
@@ -2398,16 +2377,16 @@ void bch2_btree_node_rewrite_async(struct bch_fs *c, struct btree *b)
 
 	bool now = false, pending = false;
 
-	spin_lock(&c->btree_node_rewrites_lock);
-	if (c->recovery.passes_complete & BIT_ULL(BCH_RECOVERY_PASS_journal_replay) &&
-	    enumerated_ref_tryget(&c->writes, BCH_WRITE_REF_node_rewrite)) {
-		list_add(&a->list, &c->btree_node_rewrites);
-		now = true;
-	} else if (!test_bit(BCH_FS_may_go_rw, &c->flags)) {
-		list_add(&a->list, &c->btree_node_rewrites_pending);
-		pending = true;
+	scoped_guard(spinlock, &c->btree_node_rewrites_lock) {
+		if (c->recovery.passes_complete & BIT_ULL(BCH_RECOVERY_PASS_journal_replay) &&
+		    enumerated_ref_tryget(&c->writes, BCH_WRITE_REF_node_rewrite)) {
+			list_add(&a->list, &c->btree_node_rewrites);
+			now = true;
+		} else if (!test_bit(BCH_FS_may_go_rw, &c->flags)) {
+			list_add(&a->list, &c->btree_node_rewrites_pending);
+			pending = true;
+		}
 	}
-	spin_unlock(&c->btree_node_rewrites_lock);
 
 	if (now) {
 		queue_work(c->btree_node_rewrite_worker, &a->work);
@@ -2428,13 +2407,14 @@ void bch2_async_btree_node_rewrites_flush(struct bch_fs *c)
 void bch2_do_pending_node_rewrites(struct bch_fs *c)
 {
 	while (1) {
-		spin_lock(&c->btree_node_rewrites_lock);
-		struct async_btree_rewrite *a =
-			list_pop_entry(&c->btree_node_rewrites_pending,
-				       struct async_btree_rewrite, list);
-		if (a)
-			list_add(&a->list, &c->btree_node_rewrites);
-		spin_unlock(&c->btree_node_rewrites_lock);
+		struct async_btree_rewrite *a;
+
+		scoped_guard(spinlock, &c->btree_node_rewrites_lock) {
+			a = list_pop_entry(&c->btree_node_rewrites_pending,
+					   struct async_btree_rewrite, list);
+			if (a)
+				list_add(&a->list, &c->btree_node_rewrites);
+		}
 
 		if (!a)
 			break;
@@ -2447,11 +2427,11 @@ void bch2_do_pending_node_rewrites(struct bch_fs *c)
 void bch2_free_pending_node_rewrites(struct bch_fs *c)
 {
 	while (1) {
-		spin_lock(&c->btree_node_rewrites_lock);
-		struct async_btree_rewrite *a =
-			list_pop_entry(&c->btree_node_rewrites_pending,
-				       struct async_btree_rewrite, list);
-		spin_unlock(&c->btree_node_rewrites_lock);
+		struct async_btree_rewrite *a;
+
+		scoped_guard(spinlock, &c->btree_node_rewrites_lock)
+			a = list_pop_entry(&c->btree_node_rewrites_pending,
+					   struct async_btree_rewrite, list);
 
 		if (!a)
 			break;
@@ -2533,7 +2513,7 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 	bch2_btree_node_lock_write_nofail(trans, btree_iter_path(trans, iter), &b->c);
 
 	if (new_hash) {
-		mutex_lock(&c->btree_cache.lock);
+		guard(mutex)(&c->btree_cache.lock);
 		bch2_btree_node_hash_remove(&c->btree_cache, new_hash);
 
 		__bch2_btree_node_hash_remove(&c->btree_cache, b);
@@ -2541,7 +2521,6 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 		bkey_copy(&b->key, new_key);
 		ret = __bch2_btree_node_hash_insert(&c->btree_cache, b);
 		BUG_ON(ret);
-		mutex_unlock(&c->btree_cache.lock);
 	} else {
 		bkey_copy(&b->key, new_key);
 	}
@@ -2552,9 +2531,8 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 	return ret;
 err:
 	if (new_hash) {
-		mutex_lock(&c->btree_cache.lock);
+		guard(mutex)(&c->btree_cache.lock);
 		bch2_btree_node_hash_remove(&c->btree_cache, b);
-		mutex_unlock(&c->btree_cache.lock);
 	}
 	goto out;
 }
@@ -2689,7 +2667,8 @@ int bch2_btree_root_alloc_fake_trans(struct btree_trans *trans, enum btree_id id
 
 void bch2_btree_root_alloc_fake(struct bch_fs *c, enum btree_id id, unsigned level)
 {
-	bch2_trans_run(c, lockrestart_do(trans, bch2_btree_root_alloc_fake_trans(trans, id, level)));
+	CLASS(btree_trans, trans)(c);
+	lockrestart_do(trans, bch2_btree_root_alloc_fake_trans(trans, id, level));
 }
 
 static void bch2_btree_update_to_text(struct printbuf *out, struct btree_update *as)
@@ -2722,21 +2701,15 @@ void bch2_btree_updates_to_text(struct printbuf *out, struct bch_fs *c)
 {
 	struct btree_update *as;
 
-	mutex_lock(&c->btree_interior_update_lock);
+	guard(mutex)(&c->btree_interior_update_lock);
 	list_for_each_entry(as, &c->btree_interior_update_list, list)
 		bch2_btree_update_to_text(out, as);
-	mutex_unlock(&c->btree_interior_update_lock);
 }
 
 static bool bch2_btree_interior_updates_pending(struct bch_fs *c)
 {
-	bool ret;
-
-	mutex_lock(&c->btree_interior_update_lock);
-	ret = !list_empty(&c->btree_interior_update_list);
-	mutex_unlock(&c->btree_interior_update_lock);
-
-	return ret;
+	guard(mutex)(&c->btree_interior_update_lock);
+	return !list_empty(&c->btree_interior_update_list);
 }
 
 bool bch2_btree_interior_updates_flush(struct bch_fs *c)
@@ -2753,13 +2726,11 @@ void bch2_journal_entry_to_btree_root(struct bch_fs *c, struct jset_entry *entry
 {
 	struct btree_root *r = bch2_btree_id_root(c, entry->btree_id);
 
-	mutex_lock(&c->btree_root_lock);
+	guard(mutex)(&c->btree_interior_update_lock);
 
 	r->level = entry->level;
 	r->alive = true;
 	bkey_copy(&r->key, (struct bkey_i *) entry->start);
-
-	mutex_unlock(&c->btree_root_lock);
 }
 
 struct jset_entry *
@@ -2767,11 +2738,9 @@ bch2_btree_roots_to_journal_entries(struct bch_fs *c,
 				    struct jset_entry *end,
 				    unsigned long skip)
 {
-	unsigned i;
-
-	mutex_lock(&c->btree_root_lock);
+	guard(mutex)(&c->btree_interior_update_lock);
 
-	for (i = 0; i < btree_id_nr_alive(c); i++) {
+	for (unsigned i = 0; i < btree_id_nr_alive(c); i++) {
 		struct btree_root *r = bch2_btree_id_root(c, i);
 
 		if (r->alive && !test_bit(i, &skip)) {
@@ -2781,8 +2750,6 @@ bch2_btree_roots_to_journal_entries(struct bch_fs *c,
 		}
 	}
 
-	mutex_unlock(&c->btree_root_lock);
-
 	return end;
 }
 
-- 
2.51.0


From f118624f4e3d1aa7947589bc9f93df4f2372fa30 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:43:35 -0400
Subject: [PATCH 157/309] bcachefs: convert btree_trans_commit.c to
 CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_trans_commit.c | 35 ++++++++++++++------------------
 1 file changed, 15 insertions(+), 20 deletions(-)

diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index 0f2812bb7963..c13da619f354 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -235,10 +235,10 @@ static int __btree_node_flush(struct journal *j, struct journal_entry_pin *pin,
 	struct bch_fs *c = container_of(j, struct bch_fs, journal);
 	struct btree_write *w = container_of(pin, struct btree_write, journal);
 	struct btree *b = container_of(w, struct btree, writes[i]);
-	struct btree_trans *trans = bch2_trans_get(c);
 	unsigned long old, new;
 	unsigned idx = w - b->writes;
 
+	CLASS(btree_trans, trans)(c);
 	btree_node_lock_nopath_nofail(trans, &b->c, SIX_LOCK_read);
 
 	old = READ_ONCE(b->flags);
@@ -257,8 +257,6 @@ static int __btree_node_flush(struct journal *j, struct journal_entry_pin *pin,
 
 	btree_node_write_if_need(trans, b, SIX_LOCK_read);
 	six_unlock_read(&b->c.lock);
-
-	bch2_trans_put(trans);
 	return 0;
 }
 
@@ -674,16 +672,20 @@ bch2_trans_commit_write_locked(struct btree_trans *trans,
 
 	struct bkey_i *accounting;
 
-	percpu_down_read(&c->mark_lock);
-	for (accounting = btree_trans_subbuf_base(trans, &trans->accounting);
-	     accounting != btree_trans_subbuf_top(trans, &trans->accounting);
-	     accounting = bkey_next(accounting)) {
-		ret = bch2_accounting_trans_commit_hook(trans,
-					bkey_i_to_accounting(accounting), flags);
-		if (ret)
-			goto revert_fs_usage;
-	}
-	percpu_up_read(&c->mark_lock);
+	scoped_guard(percpu_read, &c->mark_lock)
+		for (accounting = btree_trans_subbuf_base(trans, &trans->accounting);
+		     accounting != btree_trans_subbuf_top(trans, &trans->accounting);
+		     accounting = bkey_next(accounting)) {
+			ret = bch2_accounting_trans_commit_hook(trans,
+						bkey_i_to_accounting(accounting), flags);
+			if (unlikely(ret)) {
+				for (struct bkey_i *i = btree_trans_subbuf_base(trans, &trans->accounting);
+				     i != accounting;
+				     i = bkey_next(i))
+					bch2_accounting_trans_commit_revert(trans, bkey_i_to_accounting(i), flags);
+				return ret;
+			}
+		}
 
 	/* XXX: we only want to run this if deltas are nonzero */
 	bch2_trans_account_disk_usage_change(trans);
@@ -795,13 +797,6 @@ bch2_trans_commit_write_locked(struct btree_trans *trans,
 	return 0;
 fatal_err:
 	bch2_fs_fatal_error(c, "fatal error in transaction commit: %s", bch2_err_str(ret));
-	percpu_down_read(&c->mark_lock);
-revert_fs_usage:
-	for (struct bkey_i *i = btree_trans_subbuf_base(trans, &trans->accounting);
-	     i != accounting;
-	     i = bkey_next(i))
-		bch2_accounting_trans_commit_revert(trans, bkey_i_to_accounting(i), flags);
-	percpu_up_read(&c->mark_lock);
 	return ret;
 }
 
-- 
2.51.0


From 816ffd9d79450ad25a2dceb72daf743a9601f244 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:43:55 -0400
Subject: [PATCH 158/309] bcachefs: convert btree_key_cache.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_key_cache.c | 7 ++-----
 1 file changed, 2 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index f68265f9969c..61edf555c422 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -300,13 +300,12 @@ static noinline_for_stack void do_trace_key_cache_fill(struct btree_trans *trans
 						       struct btree_path *ck_path,
 						       struct bkey_s_c k)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	bch2_bpos_to_text(&buf, ck_path->pos);
 	prt_char(&buf, ' ');
 	bch2_bkey_val_to_text(&buf, trans->c, k);
 	trace_key_cache_fill(trans, buf.buf);
-	printbuf_exit(&buf);
 }
 
 static noinline int btree_key_cache_fill(struct btree_trans *trans,
@@ -539,10 +538,10 @@ int bch2_btree_key_cache_journal_flush(struct journal *j,
 	struct bkey_cached *ck =
 		container_of(pin, struct bkey_cached, journal);
 	struct bkey_cached_key key;
-	struct btree_trans *trans = bch2_trans_get(c);
 	int srcu_idx = srcu_read_lock(&c->btree_trans_barrier);
 	int ret = 0;
 
+	CLASS(btree_trans, trans)(c);
 	btree_node_lock_nopath_nofail(trans, &ck->c, SIX_LOCK_read);
 	key = ck->key;
 
@@ -565,8 +564,6 @@ int bch2_btree_key_cache_journal_flush(struct journal *j,
 				BCH_TRANS_COMMIT_journal_reclaim, false));
 unlock:
 	srcu_read_unlock(&c->btree_trans_barrier, srcu_idx);
-
-	bch2_trans_put(trans);
 	return ret;
 }
 
-- 
2.51.0


From 6cab1cadba7fb6734902b3eb06041b19ee36f141 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:44:08 -0400
Subject: [PATCH 159/309] bcachefs: convert btree_io.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 62 ++++++++++++++++--------------------------
 1 file changed, 24 insertions(+), 38 deletions(-)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index 064627a29883..c0fba9016d6a 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -592,7 +592,7 @@ static int __btree_err(int ret,
 		!(test_bit(BCH_FS_in_fsck, &c->flags) &&
 		  c->opts.fix_errors == FSCK_FIX_ask);
 
-	struct printbuf out = PRINTBUF;
+	CLASS(printbuf, out)();
 	bch2_log_msg_start(c, &out);
 
 	if (!print_deferred)
@@ -619,13 +619,13 @@ static int __btree_err(int ret,
 
 			if (!have_retry)
 				ret = bch_err_throw(c, fsck_fix);
-			goto out;
+			return ret;
 		case -BCH_ERR_btree_node_read_err_bad_node:
 			prt_str(&out, ", ");
 			break;
 		}
 
-		goto out;
+		return ret;
 	}
 
 	if (rw == WRITE) {
@@ -647,16 +647,14 @@ static int __btree_err(int ret,
 
 		if (!have_retry)
 			ret = bch_err_throw(c, fsck_fix);
-		goto out;
+		return ret;
 	case -BCH_ERR_btree_node_read_err_bad_node:
 		prt_str(&out, ", ");
 		break;
 	}
 print:
 	bch2_print_str(c, KERN_ERR, out.buf);
-out:
 fsck_err:
-	printbuf_exit(&out);
 	return ret;
 }
 
@@ -735,8 +733,8 @@ static int validate_bset(struct bch_fs *c, struct bch_dev *ca,
 			 struct printbuf *err_msg)
 {
 	unsigned version = le16_to_cpu(i->version);
-	struct printbuf buf1 = PRINTBUF;
-	struct printbuf buf2 = PRINTBUF;
+	CLASS(printbuf, buf1)();
+	CLASS(printbuf, buf2)();
 	int ret = 0;
 
 	btree_err_on(!bch2_version_compatible(version),
@@ -755,10 +753,9 @@ static int validate_bset(struct bch_fs *c, struct bch_dev *ca,
 			 "bset version %u older than superblock version_min %u",
 			 version, c->sb.version_min)) {
 		if (bch2_version_compatible(version)) {
-			mutex_lock(&c->sb_lock);
+			guard(mutex)(&c->sb_lock);
 			c->disk_sb.sb->version_min = cpu_to_le16(version);
 			bch2_write_super(c);
-			mutex_unlock(&c->sb_lock);
 		} else {
 			/* We have no idea what's going on: */
 			i->version = cpu_to_le16(c->sb.version);
@@ -772,10 +769,9 @@ static int validate_bset(struct bch_fs *c, struct bch_dev *ca,
 			 btree_node_bset_newer_than_sb,
 			 "bset version %u newer than superblock version %u",
 			 version, c->sb.version)) {
-		mutex_lock(&c->sb_lock);
+		guard(mutex)(&c->sb_lock);
 		c->disk_sb.sb->version = cpu_to_le16(version);
 		bch2_write_super(c);
-		mutex_unlock(&c->sb_lock);
 	}
 
 	btree_err_on(BSET_SEPARATE_WHITEOUTS(i),
@@ -875,8 +871,6 @@ static int validate_bset(struct bch_fs *c, struct bch_dev *ca,
 			       &bn->format);
 	}
 fsck_err:
-	printbuf_exit(&buf2);
-	printbuf_exit(&buf1);
 	return ret;
 }
 
@@ -946,7 +940,7 @@ static int validate_bset_keys(struct bch_fs *c, struct btree *b,
 {
 	unsigned version = le16_to_cpu(i->version);
 	struct bkey_packed *k, *prev = NULL;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool updated_range = b->key.k.type == KEY_TYPE_btree_ptr_v2 &&
 		BTREE_PTR_RANGE_UPDATED(&bkey_i_to_btree_ptr_v2(&b->key)->v);
 	int ret = 0;
@@ -1051,7 +1045,6 @@ static int validate_bset_keys(struct bch_fs *c, struct btree *b,
 		set_btree_node_need_rewrite_error(b);
 	}
 fsck_err:
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -1070,7 +1063,7 @@ int bch2_btree_node_read_done(struct bch_fs *c, struct bch_dev *ca,
 		BTREE_PTR_RANGE_UPDATED(&bkey_i_to_btree_ptr_v2(&b->key)->v);
 	unsigned ptr_written = btree_ptr_sectors_written(bkey_i_to_s_c(&b->key));
 	u64 max_journal_seq = 0;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	int ret = 0, write = READ;
 	u64 start_time = local_clock();
 
@@ -1385,7 +1378,6 @@ int bch2_btree_node_read_done(struct bch_fs *c, struct bch_dev *ca,
 	}
 fsck_err:
 	mempool_free(iter, &c->fill_iter);
-	printbuf_exit(&buf);
 	bch2_time_stats_update(&c->times[BCH_TIME_btree_node_read_done], start_time);
 	return ret;
 }
@@ -1401,7 +1393,7 @@ static void btree_node_read_work(struct work_struct *work)
 	struct bch_io_failures failed = { .nr = 0 };
 	int ret = 0;
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	prt_printf(&buf, "btree node read error at btree ");
@@ -1493,7 +1485,6 @@ static void btree_node_read_work(struct work_struct *work)
 	bch2_time_stats_update(&c->times[BCH_TIME_btree_node_read],
 			       rb->start_time);
 	bio_put(&rb->bio);
-	printbuf_exit(&buf);
 	clear_btree_node_read_in_flight(b);
 	smp_mb__after_atomic();
 	wake_up_bit(&b->flags, BTREE_NODE_read_in_flight);
@@ -1575,7 +1566,7 @@ static CLOSURE_CALLBACK(btree_node_read_all_replicas_done)
 	closure_type(ra, struct btree_node_read_all, cl);
 	struct bch_fs *c = ra->c;
 	struct btree *b = ra->b;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bool dump_bset_maps = false;
 	int ret = 0, best = -1, write = READ;
 	unsigned i, written = 0, written2 = 0;
@@ -1684,11 +1675,10 @@ static CLOSURE_CALLBACK(btree_node_read_all_replicas_done)
 	if (ret) {
 		set_btree_node_read_error(b);
 
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_btree_lost_data(c, &buf, b->c.btree_id);
 		if (buf.pos)
 			bch_err(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 	} else if (*saw_error)
 		bch2_btree_node_rewrite_async(c, b);
 
@@ -1699,7 +1689,6 @@ static CLOSURE_CALLBACK(btree_node_read_all_replicas_done)
 
 	closure_debug_destroy(&ra->cl);
 	kfree(ra);
-	printbuf_exit(&buf);
 
 	clear_btree_node_read_in_flight(b);
 	smp_mb__after_atomic();
@@ -1819,7 +1808,7 @@ void bch2_btree_node_read(struct btree_trans *trans, struct btree *b,
 
 	if (ret <= 0) {
 		bool ratelimit = true;
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 
 		prt_str(&buf, "btree node read error: no device to read from\n at ");
@@ -1836,7 +1825,6 @@ void bch2_btree_node_read(struct btree_trans *trans, struct btree *b,
 					      DEFAULT_RATELIMIT_BURST);
 		if (!ratelimit || __ratelimit(&rs))
 			bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 
 		set_btree_node_read_error(b);
 		clear_btree_node_read_in_flight(b);
@@ -1918,9 +1906,8 @@ static int __bch2_btree_root_read(struct btree_trans *trans, enum btree_id id,
 	bch2_btree_node_read(trans, b, true);
 
 	if (btree_node_read_error(b)) {
-		mutex_lock(&c->btree_cache.lock);
-		bch2_btree_node_hash_remove(&c->btree_cache, b);
-		mutex_unlock(&c->btree_cache.lock);
+		scoped_guard(mutex, &c->btree_cache.lock)
+			bch2_btree_node_hash_remove(&c->btree_cache, b);
 
 		ret = bch_err_throw(c, btree_node_read_error);
 		goto err;
@@ -1937,7 +1924,8 @@ static int __bch2_btree_root_read(struct btree_trans *trans, enum btree_id id,
 int bch2_btree_root_read(struct bch_fs *c, enum btree_id id,
 			const struct bkey_i *k, unsigned level)
 {
-	return bch2_trans_run(c, __bch2_btree_root_read(trans, id, k, level));
+	CLASS(btree_trans, trans)(c);
+	return __bch2_btree_root_read(trans, id, k, level);
 }
 
 struct btree_node_scrub {
@@ -2016,7 +2004,7 @@ static void btree_node_scrub_work(struct work_struct *work)
 {
 	struct btree_node_scrub *scrub = container_of(work, struct btree_node_scrub, work);
 	struct bch_fs *c = scrub->c;
-	struct printbuf err = PRINTBUF;
+	CLASS(printbuf, err)();
 
 	__bch2_btree_pos_to_text(&err, c, scrub->btree, scrub->level,
 				 bkey_i_to_s_c(scrub->key.k));
@@ -2031,7 +2019,6 @@ static void btree_node_scrub_work(struct work_struct *work)
 			bch_err_fn_ratelimited(c, ret);
 	}
 
-	printbuf_exit(&err);
 	bch2_bkey_buf_exit(&scrub->key, c);;
 	btree_bounce_free(c, c->opts.btree_node_size, scrub->used_mempool, scrub->buf);
 	enumerated_ref_put(&scrub->ca->io_ref[READ], BCH_DEV_READ_REF_btree_node_scrub);
@@ -2212,7 +2199,8 @@ static void btree_node_write_work(struct work_struct *work)
 
 		}
 	} else {
-		ret = bch2_trans_do(c,
+		CLASS(btree_trans, trans)(c);
+		ret = lockrestart_do(trans,
 			bch2_btree_node_update_key_get_iter(trans, b, &wbio->key,
 					BCH_WATERMARK_interior_updates|
 					BCH_TRANS_COMMIT_journal_reclaim|
@@ -2231,11 +2219,10 @@ static void btree_node_write_work(struct work_struct *work)
 	set_btree_node_noevict(b);
 
 	if (!bch2_err_matches(ret, EROFS)) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		prt_printf(&buf, "writing btree node: %s\n  ", bch2_err_str(ret));
 		bch2_btree_pos_to_text(&buf, c, b);
 		bch2_fs_fatal_error(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 	goto out;
 }
@@ -2254,13 +2241,12 @@ static void btree_node_write_endio(struct bio *bio)
 				   wbio->submit_time, !bio->bi_status);
 
 	if (ca && bio->bi_status) {
-		struct printbuf buf = PRINTBUF;
-		buf.atomic++;
+		CLASS(printbuf, buf)();
+		guard(printbuf_atomic)(&buf);
 		prt_printf(&buf, "btree write error: %s\n  ",
 			   bch2_blk_status_to_str(bio->bi_status));
 		bch2_btree_pos_to_text(&buf, c, b);
 		bch_err_dev_ratelimited(ca, "%s", buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	if (bio->bi_status) {
-- 
2.51.0


From 83ac9a5d7e4b5a22d9658cc7ce290260d601a861 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:44:15 -0400
Subject: [PATCH 160/309] bcachefs: convert btree_iter.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 36 +++++++++++++-----------------------
 1 file changed, 13 insertions(+), 23 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 7463946898c0..cc771affa511 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -903,7 +903,7 @@ static noinline int btree_node_iter_and_journal_peek(struct btree_trans *trans,
 
 	k = bch2_btree_and_journal_iter_peek(&jiter);
 	if (!k.k) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_str(&buf, "node not found at pos ");
 		bch2_bpos_to_text(&buf, path->pos);
@@ -911,7 +911,6 @@ static noinline int btree_node_iter_and_journal_peek(struct btree_trans *trans,
 		bch2_btree_pos_to_text(&buf, c, l->b);
 
 		ret = bch2_fs_topology_error(c, "%s", buf.buf);
-		printbuf_exit(&buf);
 		goto err;
 	}
 
@@ -930,7 +929,7 @@ static noinline_for_stack int btree_node_missing_err(struct btree_trans *trans,
 						     struct btree_path *path)
 {
 	struct bch_fs *c = trans->c;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	prt_str(&buf, "node not found at pos ");
 	bch2_bpos_to_text(&buf, path->pos);
@@ -1451,7 +1450,7 @@ void __noreturn bch2_trans_restart_error(struct btree_trans *trans, u32 restart_
 static void __noreturn bch2_trans_in_restart_error(struct btree_trans *trans)
 {
 #ifdef CONFIG_BCACHEFS_DEBUG
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	bch2_prt_backtrace(&buf, &trans->last_restarted_trace);
 	panic("in transaction restart: %s, last restarted by\n%s",
 	      bch2_err_str(trans->restarted),
@@ -1601,13 +1600,13 @@ void bch2_trans_paths_to_text(struct printbuf *out, struct btree_trans *trans)
 static noinline __cold
 void __bch2_dump_trans_paths_updates(struct btree_trans *trans, bool nosort)
 {
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
+	bch2_log_msg_start(trans->c, &buf);
 
 	__bch2_trans_paths_to_text(&buf, trans, nosort);
 	bch2_trans_updates_to_text(&buf, trans);
 
 	bch2_print_str(trans->c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 }
 
 noinline __cold
@@ -1620,22 +1619,19 @@ noinline __cold
 static void bch2_trans_update_max_paths(struct btree_trans *trans)
 {
 	struct btree_transaction_stats *s = btree_trans_stats(trans);
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	size_t nr = bitmap_weight(trans->paths_allocated, trans->nr_paths);
 
 	bch2_trans_paths_to_text(&buf, trans);
 
 	if (!buf.allocation_failure) {
-		mutex_lock(&s->lock);
+		guard(mutex)(&s->lock);
 		if (nr > s->nr_max_paths) {
 			s->nr_max_paths = nr;
 			swap(s->max_paths_text, buf.buf);
 		}
-		mutex_unlock(&s->lock);
 	}
 
-	printbuf_exit(&buf);
-
 	trans->nr_paths_max = nr;
 }
 
@@ -1643,11 +1639,10 @@ noinline __cold
 int __bch2_btree_trans_too_many_iters(struct btree_trans *trans)
 {
 	if (trace_trans_restart_too_many_iters_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_trans_paths_to_text(&buf, trans);
 		trace_trans_restart_too_many_iters(trans, _THIS_IP_, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	count_event(trans->c, trans_restart_too_many_iters);
@@ -3196,14 +3191,13 @@ void *__bch2_trans_kmalloc(struct btree_trans *trans, size_t size, unsigned long
 
 	if (WARN_ON_ONCE(new_bytes > BTREE_TRANS_MEM_MAX)) {
 #ifdef CONFIG_BCACHEFS_TRANS_KMALLOC_TRACE
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 		prt_printf(&buf, "bump allocator exceeded BTREE_TRANS_MEM_MAX (%u)\n",
 			   BTREE_TRANS_MEM_MAX);
 
 		bch2_trans_kmalloc_trace_to_text(&buf, &trans->trans_kmalloc_trace);
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 #endif
 	}
 
@@ -3213,7 +3207,7 @@ void *__bch2_trans_kmalloc(struct btree_trans *trans, size_t size, unsigned long
 
 	struct btree_transaction_stats *s = btree_trans_stats(trans);
 	if (new_bytes > s->max_mem) {
-		mutex_lock(&s->lock);
+		guard(mutex)(&s->lock);
 #ifdef CONFIG_BCACHEFS_TRANS_KMALLOC_TRACE
 		darray_resize(&s->trans_kmalloc_trace, trans->trans_kmalloc_trace.nr);
 		s->trans_kmalloc_trace.nr = min(s->trans_kmalloc_trace.size,
@@ -3225,7 +3219,6 @@ void *__bch2_trans_kmalloc(struct btree_trans *trans, size_t size, unsigned long
 		       s->trans_kmalloc_trace.nr);
 #endif
 		s->max_mem = new_bytes;
-		mutex_unlock(&s->lock);
 	}
 
 	if (trans->used_mempool || new_bytes > BTREE_TRANS_MEM_MAX) {
@@ -3535,7 +3528,7 @@ static void check_btree_paths_leaked(struct btree_trans *trans)
 		struct btree_path *path;
 		unsigned i;
 
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		bch2_log_msg_start(c, &buf);
 
 		prt_printf(&buf, "btree paths leaked from %s!\n", trans->fn);
@@ -3547,7 +3540,6 @@ static void check_btree_paths_leaked(struct btree_trans *trans)
 
 		bch2_fs_emergency_read_only2(c, &buf);
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
 }
 #else
@@ -3672,11 +3664,11 @@ void bch2_btree_trans_to_text(struct printbuf *out, struct btree_trans *trans)
 
 	/* trans->paths is rcu protected vs. freeing */
 	guard(rcu)();
-	out->atomic++;
+	guard(printbuf_atomic)(out);
 
 	struct btree_path *paths = rcu_dereference(trans->paths);
 	if (!paths)
-		goto out;
+		return;
 
 	unsigned long *paths_allocated = trans_paths_allocated(paths);
 
@@ -3712,8 +3704,6 @@ void bch2_btree_trans_to_text(struct printbuf *out, struct btree_trans *trans)
 		bch2_btree_bkey_cached_common_to_text(out, b);
 		prt_newline(out);
 	}
-out:
-	--out->atomic;
 }
 
 void bch2_fs_btree_iter_exit(struct bch_fs *c)
-- 
2.51.0


From 5899301d07d3545f7b9bc2bca273aad264a0dd60 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:44:23 -0400
Subject: [PATCH 161/309] bcachefs: convert btree_locking.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_locking.c | 17 ++++++-----------
 1 file changed, 6 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/btree_locking.c b/fs/bcachefs/btree_locking.c
index bed2b4b6ffb9..38c5643e8a78 100644
--- a/fs/bcachefs/btree_locking.c
+++ b/fs/bcachefs/btree_locking.c
@@ -159,13 +159,11 @@ static void trace_would_deadlock(struct lock_graph *g, struct btree_trans *trans
 	count_event(c, trans_restart_would_deadlock);
 
 	if (trace_trans_restart_would_deadlock_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
+		guard(printbuf_atomic)(&buf);
 
-		buf.atomic++;
 		print_cycle(&buf, g);
-
 		trace_trans_restart_would_deadlock(trans, buf.buf);
-		printbuf_exit(&buf);
 	}
 }
 
@@ -196,8 +194,8 @@ static int btree_trans_abort_preference(struct btree_trans *trans)
 
 static noinline __noreturn void break_cycle_fail(struct lock_graph *g)
 {
-	struct printbuf buf = PRINTBUF;
-	buf.atomic++;
+	CLASS(printbuf, buf)();
+	guard(printbuf_atomic)(&buf);
 
 	prt_printf(&buf, bch2_fmt(g->g->trans->c, "cycle of nofail locks"));
 
@@ -214,7 +212,6 @@ static noinline __noreturn void break_cycle_fail(struct lock_graph *g)
 	}
 
 	bch2_print_str(g->g->trans->c, KERN_ERR, buf.buf);
-	printbuf_exit(&buf);
 	BUG();
 }
 
@@ -692,7 +689,7 @@ int __bch2_btree_path_upgrade(struct btree_trans *trans,
 
 	count_event(trans->c, trans_restart_upgrade);
 	if (trace_trans_restart_upgrade_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		prt_printf(&buf, "%s %pS\n", trans->fn, (void *) _RET_IP_);
 		prt_printf(&buf, "btree %s pos\n", bch2_btree_id_str(path->btree_id));
@@ -708,7 +705,6 @@ int __bch2_btree_path_upgrade(struct btree_trans *trans,
 			   path->l[f.l].lock_seq);
 
 		trace_trans_restart_upgrade(trans->c, buf.buf);
-		printbuf_exit(&buf);
 	}
 out:
 	bch2_trans_verify_locks(trans);
@@ -777,7 +773,7 @@ static noinline __cold void bch2_trans_relock_fail(struct btree_trans *trans, st
 		goto out;
 
 	if (trace_trans_restart_relock_enabled()) {
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 
 		bch2_bpos_to_text(&buf, path->pos);
 		prt_printf(&buf, " %s l=%u seq=%u node seq=",
@@ -797,7 +793,6 @@ static noinline __cold void bch2_trans_relock_fail(struct btree_trans *trans, st
 		}
 
 		trace_trans_restart_relock(trans, ip, buf.buf);
-		printbuf_exit(&buf);
 	}
 
 	count_event(trans->c, trans_restart_relock);
-- 
2.51.0


From ad08cdd14a3bedb220539543dff055c6293491b1 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 12:44:32 -0400
Subject: [PATCH 162/309] bcachefs: convert btree_journal_iter.c to
 CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_journal_iter.c | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index 39ecd95ce2ff..24f2fbe84ad7 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -462,9 +462,8 @@ void bch2_journal_key_overwritten(struct bch_fs *c, enum btree_id btree,
 	    keys->data[idx].level	== level &&
 	    bpos_eq(keys->data[idx].k->k.p, pos) &&
 	    !keys->data[idx].overwritten) {
-		mutex_lock(&keys->overwrite_lock);
+		guard(mutex)(&keys->overwrite_lock);
 		__bch2_journal_key_overwritten(keys, idx);
-		mutex_unlock(&keys->overwrite_lock);
 	}
 }
 
@@ -815,7 +814,7 @@ void bch2_shoot_down_journal_keys(struct bch_fs *c, enum btree_id btree,
 void bch2_journal_keys_dump(struct bch_fs *c)
 {
 	struct journal_keys *keys = &c->journal_keys;
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 
 	pr_info("%zu keys:", keys->nr);
 
@@ -829,7 +828,6 @@ void bch2_journal_keys_dump(struct bch_fs *c)
 		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(i->k));
 		pr_err("%s", buf.buf);
 	}
-	printbuf_exit(&buf);
 }
 
 void bch2_fs_journal_keys_init(struct bch_fs *c)
-- 
2.51.0


From 283120fc5169e3a69fc6cbcf34f6d69f2feb093b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 22:05:34 -0400
Subject: [PATCH 163/309] bcachefs: bch2_run_recovery_pass() now prints errors

With this the individual recovery passes no longer have to prin errors,
and we can eliminate some gotos.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 13 ++++---------
 fs/bcachefs/backpointers.c     |  5 -----
 fs/bcachefs/btree_gc.c         |  1 -
 fs/bcachefs/disk_accounting.c  | 10 ++++------
 fs/bcachefs/fsck.c             | 34 +++++++---------------------------
 fs/bcachefs/inode.c            | 17 ++++-------------
 fs/bcachefs/logged_ops.c       |  4 +---
 fs/bcachefs/lru.c              |  1 -
 fs/bcachefs/recovery_passes.c  |  4 +++-
 fs/bcachefs/snapshot.c         | 11 ++---------
 fs/bcachefs/subvolume.c        | 17 ++++-------------
 11 files changed, 29 insertions(+), 88 deletions(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index 58706dfcdfe0..4c1604fd80f9 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -609,7 +609,6 @@ int bch2_bucket_gens_init(struct bch_fs *c)
 				BCH_TRANS_COMMIT_no_enospc,
 			bch2_btree_insert_trans(trans, BTREE_ID_bucket_gens, &g.k_i, 0));
 
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -678,7 +677,6 @@ int bch2_alloc_read(struct bch_fs *c)
 	}
 
 	bch2_dev_put(ca);
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -1619,14 +1617,14 @@ int bch2_check_alloc_info(struct bch_fs *c)
 	ca = NULL;
 
 	if (ret < 0)
-		goto err;
+		return ret;
 
 	ret = for_each_btree_key(trans, iter,
 			BTREE_ID_need_discard, POS_MIN,
 			BTREE_ITER_prefetch, k,
 		bch2_check_discard_freespace_key(trans, &iter));
 	if (ret)
-		goto err;
+		return ret;
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_freespace, POS_MIN,
 			     BTREE_ITER_prefetch);
@@ -1653,15 +1651,14 @@ int bch2_check_alloc_info(struct bch_fs *c)
 	}
 	bch2_trans_iter_exit(trans, &iter);
 	if (ret)
-		goto err;
+		return ret;
 
 	ret = for_each_btree_key_commit(trans, iter,
 			BTREE_ID_bucket_gens, POS_MIN,
 			BTREE_ITER_prefetch, k,
 			NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 		bch2_check_bucket_gens_key(trans, &iter, k));
-err:
-	bch_err_fn(c, ret);
+
 	return ret;
 }
 
@@ -1743,7 +1740,6 @@ int bch2_check_alloc_to_lru_refs(struct bch_fs *c)
 		bch2_check_stripe_to_lru_refs(trans);
 
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -2353,7 +2349,6 @@ int bch2_fs_freespace_init(struct bch_fs *c)
 	if (c->sb.features & BIT_ULL(BCH_FEATURE_small_image))
 		return 0;
 
-
 	/*
 	 * We can crash during the device add path, so we need to check this on
 	 * every mount:
diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 7bb9d0cab289..bd26ab3e6812 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -438,7 +438,6 @@ int bch2_check_btree_backpointers(struct bch_fs *c)
 		  bch2_check_backpointer_has_valid_bucket(trans, k, &last_flushed));
 
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -1163,8 +1162,6 @@ int bch2_check_extents_to_backpointers(struct bch_fs *c)
 err:
 	bch2_bkey_buf_exit(&s.last_flushed, c);
 	bch2_btree_cache_unpin(c);
-
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -1327,8 +1324,6 @@ int bch2_check_backpointers_to_extents(struct bch_fs *c)
 	}
 
 	bch2_btree_cache_unpin(c);
-
-	bch_err_fn(c, ret);
 	return ret;
 }
 
diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index 0804329601c1..34cb8a4324dc 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -1099,7 +1099,6 @@ int bch2_check_allocations(struct bch_fs *c)
 	if (!ret && !test_bit(BCH_FS_errors_not_fixed, &c->flags))
 		bch2_sb_members_clean_deleted(c);
 
-	bch_err_fn(c, ret);
 	return ret;
 }
 
diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 2f74e68da699..219e37738aee 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -785,7 +785,7 @@ int bch2_accounting_read(struct bch_fs *c)
 			accounting_read_key(trans, k);
 		}));
 	if (ret)
-		goto err;
+		return ret;
 
 	struct journal_keys *keys = &c->journal_keys;
 	struct journal_key *dst = keys->data;
@@ -824,7 +824,7 @@ int bch2_accounting_read(struct bch_fs *c)
 
 			ret = accounting_read_key(trans, k);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		*dst++ = *i;
@@ -863,7 +863,7 @@ int bch2_accounting_read(struct bch_fs *c)
 		}
 
 		if (ret)
-			goto fsck_err;
+			return ret;
 	}
 
 	eytzinger0_sort(acc->k.data, acc->k.nr, sizeof(acc->k.data[0]),
@@ -904,9 +904,7 @@ int bch2_accounting_read(struct bch_fs *c)
 			}
 		}
 	}
-fsck_err:
-err:
-	bch_err_fn(c, ret);
+
 	return ret;
 }
 
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 2526a7121dee..668b491dfd29 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1331,14 +1331,11 @@ int bch2_check_inodes(struct bch_fs *c)
 	CLASS(btree_trans, trans)(c);
 	CLASS(snapshots_seen, s)();
 
-	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
+	return for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_inode(trans, &iter, k, &snapshot_root, &s));
-
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static int find_oldest_inode_needs_reattach(struct btree_trans *trans,
@@ -1426,13 +1423,11 @@ static int check_unreachable_inode(struct btree_trans *trans,
 int bch2_check_unreachable_inodes(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
+	return for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_unreachable_inode(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static inline bool btree_matches_i_mode(enum btree_id btree, unsigned mode)
@@ -2033,8 +2028,6 @@ int bch2_check_extents(struct bch_fs *c)
 		check_i_sectors_notnested(trans, &w);
 
 	bch2_disk_reservation_put(c, &res);
-
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -2053,7 +2046,6 @@ int bch2_check_indirect_extents(struct bch_fs *c)
 		}));
 
 	bch2_disk_reservation_put(c, &res);
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -2479,7 +2471,6 @@ int bch2_check_dirents(struct bch_fs *c)
 		ret = -EINVAL;
 	}
 
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -2533,7 +2524,6 @@ int bch2_check_xattrs(struct bch_fs *c)
 			NULL, NULL,
 			BCH_TRANS_COMMIT_no_enospc,
 		check_xattr(trans, &iter, k, &hash_info, &inode));
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -2599,10 +2589,8 @@ static int check_root_trans(struct btree_trans *trans)
 int bch2_check_root(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			    check_root_trans(trans));
-	bch_err_fn(c, ret);
-	return ret;
+	return commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
+			 check_root_trans(trans));
 }
 
 static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter, struct bkey_s_c k)
@@ -2677,12 +2665,10 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 int bch2_check_subvolume_structure(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_commit(trans, iter,
+	return for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolumes, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_subvol_path(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static int bch2_bi_depth_renumber_one(struct btree_trans *trans,
@@ -2851,7 +2837,7 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 int bch2_check_directory_structure(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_reverse_commit(trans, iter, BTREE_ID_inodes, POS_MIN,
+	return for_each_btree_key_reverse_commit(trans, iter, BTREE_ID_inodes, POS_MIN,
 					  BTREE_ITER_intent|
 					  BTREE_ITER_prefetch|
 					  BTREE_ITER_all_snapshots, k,
@@ -2864,9 +2850,6 @@ int bch2_check_directory_structure(struct bch_fs *c)
 
 			check_path_loop(trans, k);
 		}));
-
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 struct nlink_table {
@@ -3116,7 +3099,6 @@ int bch2_check_nlinks(struct bch_fs *c)
 	} while (next_iter_range_start != U64_MAX);
 
 	kvfree(links.d);
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -3152,14 +3134,12 @@ int bch2_fix_reflink_p(struct bch_fs *c)
 		return 0;
 
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_commit(trans, iter,
+	return for_each_btree_key_commit(trans, iter,
 				BTREE_ID_extents, POS_MIN,
 				BTREE_ITER_intent|BTREE_ITER_prefetch|
 				BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			fix_reflink_p_key(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 #ifndef NO_BCACHEFS_CHARDEV
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index fd4a20ce06ff..4a9725f30c4f 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1522,28 +1522,22 @@ static int may_delete_deleted_inum(struct btree_trans *trans, subvol_inum inum,
 int bch2_delete_dead_inodes(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret;
-
 	/*
 	 * if we ran check_inodes() unlinked inodes will have already been
 	 * cleaned up but the write buffer will be out of sync; therefore we
 	 * alway need a write buffer flush
-	 */
-	ret = bch2_btree_write_buffer_flush_sync(trans);
-	if (ret)
-		goto err;
-
-	/*
+	 *
 	 * Weird transaction restart handling here because on successful delete,
 	 * bch2_inode_rm_snapshot() will return a nested transaction restart,
 	 * but we can't retry because the btree write buffer won't have been
 	 * flushed and we'd spin:
 	 */
-	ret = for_each_btree_key_commit(trans, iter, BTREE_ID_deleted_inodes, POS_MIN,
+	return  bch2_btree_write_buffer_flush_sync(trans) ?:
+		for_each_btree_key_commit(trans, iter, BTREE_ID_deleted_inodes, POS_MIN,
 					BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 					NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
 		struct bch_inode_unpacked inode;
-		ret = may_delete_deleted_inode(trans, k.k->p, &inode, true);
+		int ret = may_delete_deleted_inode(trans, k.k->p, &inode, true);
 		if (ret > 0) {
 			bch_verbose_ratelimited(c, "deleting unlinked inode %llu:%u",
 						k.k->p.offset, k.k->p.snapshot);
@@ -1564,7 +1558,4 @@ int bch2_delete_dead_inodes(struct bch_fs *c)
 
 		ret;
 	}));
-err:
-	bch_err_fn(c, ret);
-	return ret;
 }
diff --git a/fs/bcachefs/logged_ops.c b/fs/bcachefs/logged_ops.c
index 3964f92a26b0..0367ea37e857 100644
--- a/fs/bcachefs/logged_ops.c
+++ b/fs/bcachefs/logged_ops.c
@@ -62,14 +62,12 @@ static int resume_logged_op(struct btree_trans *trans, struct btree_iter *iter,
 int bch2_resume_logged_ops(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_max(trans, iter,
+	return for_each_btree_key_max(trans, iter,
 				   BTREE_ID_logged_ops,
 				   POS(LOGGED_OPS_INUM_logged_ops, 0),
 				   POS(LOGGED_OPS_INUM_logged_ops, U64_MAX),
 				   BTREE_ITER_prefetch, k,
 			resume_logged_op(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static int __bch2_logged_op_start(struct btree_trans *trans, struct bkey_i *k)
diff --git a/fs/bcachefs/lru.c b/fs/bcachefs/lru.c
index c2c593356f41..ee14656c3fdd 100644
--- a/fs/bcachefs/lru.c
+++ b/fs/bcachefs/lru.c
@@ -214,7 +214,6 @@ int bch2_check_lrus(struct bch_fs *c)
 			bch2_check_lru_key(trans, &iter, k, &last_flushed));
 
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch_err_fn(c, ret);
 	return ret;
 
 }
diff --git a/fs/bcachefs/recovery_passes.c b/fs/bcachefs/recovery_passes.c
index a89508a87def..f9d1c4921392 100644
--- a/fs/bcachefs/recovery_passes.c
+++ b/fs/bcachefs/recovery_passes.c
@@ -246,11 +246,12 @@ static int bch2_lookup_root_inode(struct bch_fs *c)
 
 struct recovery_pass_fn {
 	int		(*fn)(struct bch_fs *);
+	const char	*name;
 	unsigned	when;
 };
 
 static struct recovery_pass_fn recovery_pass_fns[] = {
-#define x(_fn, _id, _when)	{ .fn = bch2_##_fn, .when = _when },
+#define x(_fn, _id, _when)	{ .fn = bch2_##_fn, .name = #_fn, .when = _when },
 	BCH_RECOVERY_PASSES()
 #undef x
 };
@@ -480,6 +481,7 @@ static int bch2_run_recovery_pass(struct bch_fs *c, enum bch_recovery_pass pass)
 	r->passes_to_run &= ~BIT_ULL(pass);
 
 	if (ret) {
+		bch_err(c, "%s(): error %s", p->name, bch2_err_str(ret));
 		r->passes_failing |= BIT_ULL(pass);
 		return ret;
 	}
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 398a1a8bceab..7a801513b134 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -574,13 +574,11 @@ static int check_snapshot_tree(struct btree_trans *trans,
 int bch2_check_snapshot_trees(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_commit(trans, iter,
+	return for_each_btree_key_commit(trans, iter,
 			BTREE_ID_snapshot_trees, POS_MIN,
 			BTREE_ITER_prefetch, k,
 			NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 		check_snapshot_tree(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 /*
@@ -842,13 +840,11 @@ int bch2_check_snapshots(struct bch_fs *c)
 	 * the parent's depth already be correct:
 	 */
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_reverse_commit(trans, iter,
+	return for_each_btree_key_reverse_commit(trans, iter,
 				BTREE_ID_snapshots, POS_MAX,
 				BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_snapshot(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static int check_snapshot_exists(struct btree_trans *trans, u32 id)
@@ -1016,7 +1012,6 @@ int bch2_reconstruct_snapshots(struct bch_fs *c)
 fsck_err:
 err:
 	snapshot_tree_reconstruct_exit(&r);
-	bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -1894,8 +1889,6 @@ int __bch2_delete_dead_snapshots(struct bch_fs *c)
 	bch2_recovery_pass_set_no_ratelimit(c, BCH_RECOVERY_PASS_check_snapshots);
 
 	mutex_unlock(&d->lock);
-	if (!bch2_err_matches(ret, EROFS))
-		bch_err_fn(c, ret);
 	return ret;
 }
 
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index dbd6bbfd972f..2d2d6b22df88 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -183,12 +183,10 @@ static int check_subvol(struct btree_trans *trans,
 int bch2_check_subvols(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_commit(trans, iter,
+	return for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolumes, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_subvol(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static int check_subvol_child(struct btree_trans *trans,
@@ -218,12 +216,10 @@ static int check_subvol_child(struct btree_trans *trans,
 int bch2_check_subvol_children(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = for_each_btree_key_commit(trans, iter,
+	return for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolume_children, POS_MIN, BTREE_ITER_prefetch, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			check_subvol_child(trans, &iter, k));
-	bch_err_fn(c, ret);
-	return 0;
 }
 
 /* Subvolumes: */
@@ -679,7 +675,6 @@ int bch2_initialize_subvolumes(struct bch_fs *c)
 	struct bkey_i_snapshot_tree	root_tree;
 	struct bkey_i_snapshot		root_snapshot;
 	struct bkey_i_subvolume		root_volume;
-	int ret;
 
 	bkey_snapshot_tree_init(&root_tree.k_i);
 	root_tree.k.p.offset		= 1;
@@ -700,11 +695,9 @@ int bch2_initialize_subvolumes(struct bch_fs *c)
 	root_volume.v.snapshot	= cpu_to_le32(U32_MAX);
 	root_volume.v.inode	= cpu_to_le64(BCACHEFS_ROOT_INO);
 
-	ret =   bch2_btree_insert(c, BTREE_ID_snapshot_trees,	&root_tree.k_i, NULL, 0, 0) ?:
+	return  bch2_btree_insert(c, BTREE_ID_snapshot_trees,	&root_tree.k_i, NULL, 0, 0) ?:
 		bch2_btree_insert(c, BTREE_ID_snapshots,	&root_snapshot.k_i, NULL, 0, 0) ?:
 		bch2_btree_insert(c, BTREE_ID_subvolumes,	&root_volume.k_i, NULL, 0, 0);
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 static int __bch2_fs_upgrade_for_subvolumes(struct btree_trans *trans)
@@ -742,10 +735,8 @@ static int __bch2_fs_upgrade_for_subvolumes(struct btree_trans *trans)
 int bch2_fs_upgrade_for_subvolumes(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	int ret = commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
+	return commit_do(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
 			    __bch2_fs_upgrade_for_subvolumes(trans));
-	bch_err_fn(c, ret);
-	return ret;
 }
 
 void bch2_fs_subvolumes_init_early(struct bch_fs *c)
-- 
2.51.0


From baf4090406537a98a39959d7ac47d5169ac7202b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 14 Jul 2025 10:56:23 -0400
Subject: [PATCH 164/309] bcachefs: convert error.c to CLASS/guards

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/error.c | 47 +++++++++++++++++----------------------------
 1 file changed, 18 insertions(+), 29 deletions(-)

diff --git a/fs/bcachefs/error.c b/fs/bcachefs/error.c
index c7ee81b7d45c..32a286b3a74e 100644
--- a/fs/bcachefs/error.c
+++ b/fs/bcachefs/error.c
@@ -42,15 +42,14 @@ bool __bch2_inconsistent_error(struct bch_fs *c, struct printbuf *out)
 
 bool bch2_inconsistent_error(struct bch_fs *c)
 {
-	struct printbuf buf = PRINTBUF;
-	buf.atomic++;
+	CLASS(printbuf, buf)();
+	guard(printbuf_atomic)(&buf);
 
 	printbuf_indent_add_nextline(&buf, 2);
 
 	bool ret = __bch2_inconsistent_error(c, &buf);
 	if (ret)
 		bch_err(c, "%s", buf.buf);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -58,8 +57,8 @@ __printf(3, 0)
 static bool bch2_fs_trans_inconsistent(struct bch_fs *c, struct btree_trans *trans,
 				       const char *fmt, va_list args)
 {
-	struct printbuf buf = PRINTBUF;
-	buf.atomic++;
+	CLASS(printbuf, buf)();
+	guard(printbuf_atomic)(&buf);
 
 	bch2_log_msg_start(c, &buf);
 
@@ -70,8 +69,6 @@ static bool bch2_fs_trans_inconsistent(struct bch_fs *c, struct btree_trans *tra
 		bch2_trans_updates_to_text(&buf, trans);
 	bool ret = __bch2_inconsistent_error(c, &buf);
 	bch2_print_str(c, KERN_ERR, buf.buf);
-
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -109,8 +106,7 @@ int __bch2_topology_error(struct bch_fs *c, struct printbuf *out)
 
 int bch2_fs_topology_error(struct bch_fs *c, const char *fmt, ...)
 {
-	struct printbuf buf = PRINTBUF;
-
+	CLASS(printbuf, buf)();
 	bch2_log_msg_start(c, &buf);
 
 	va_list args;
@@ -120,8 +116,6 @@ int bch2_fs_topology_error(struct bch_fs *c, const char *fmt, ...)
 
 	int ret = __bch2_topology_error(c, &buf);
 	bch2_print_str(c, KERN_ERR, buf.buf);
-
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -138,18 +132,18 @@ void bch2_io_error_work(struct work_struct *work)
 
 	/* XXX: if it's reads or checksums that are failing, set it to failed */
 
-	down_write(&c->state_lock);
+	guard(rwsem_write)(&c->state_lock);
 	unsigned long write_errors_start = READ_ONCE(ca->write_errors_start);
 
 	if (write_errors_start &&
 	    time_after(jiffies,
 		       write_errors_start + c->opts.write_error_timeout * HZ)) {
 		if (ca->mi.state >= BCH_MEMBER_STATE_ro)
-			goto out;
+			return;
 
 		bool dev = !__bch2_dev_set_state(c, ca, BCH_MEMBER_STATE_ro,
 						 BCH_FORCE_IF_DEGRADED);
-		struct printbuf buf = PRINTBUF;
+		CLASS(printbuf, buf)();
 		__bch2_log_msg_start(ca->name, &buf);
 
 		prt_printf(&buf, "writes erroring for %u seconds, setting %s ro",
@@ -159,10 +153,7 @@ void bch2_io_error_work(struct work_struct *work)
 			bch2_fs_emergency_read_only2(c, &buf);
 
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		printbuf_exit(&buf);
 	}
-out:
-	up_write(&c->state_lock);
 }
 
 void bch2_io_error(struct bch_dev *ca, enum bch_member_error_type type)
@@ -382,11 +373,10 @@ bool __bch2_count_fsck_err(struct bch_fs *c,
 {
 	bch2_sb_error_count(c, id);
 
-	mutex_lock(&c->fsck_error_msgs_lock);
 	bool print = true, repeat = false, suppress = false;
 
-	count_fsck_err_locked(c, id, msg->buf, &repeat, &print, &suppress);
-	mutex_unlock(&c->fsck_error_msgs_lock);
+	scoped_guard(mutex, &c->fsck_error_msgs_lock)
+		count_fsck_err_locked(c, id, msg->buf, &repeat, &print, &suppress);
 
 	if (suppress)
 		prt_printf(msg, "Ratelimiting new instances of previous error\n");
@@ -444,7 +434,8 @@ int __bch2_fsck_err(struct bch_fs *c,
 		  const char *fmt, ...)
 {
 	va_list args;
-	struct printbuf buf = PRINTBUF, *out = &buf;
+	CLASS(printbuf, buf)();
+	struct printbuf *out = &buf;
 	int ret = 0;
 	const char *action_orig = "fix?", *action = action_orig;
 
@@ -648,7 +639,6 @@ int __bch2_fsck_err(struct bch_fs *c,
 
 	if (action != action_orig)
 		kfree(action);
-	printbuf_exit(&buf);
 
 	BUG_ON(!ret);
 	return ret;
@@ -680,7 +670,7 @@ int __bch2_bkey_fsck_err(struct bch_fs *c,
 	if (!WARN_ON(err >= ARRAY_SIZE(fsck_flags_extra)))
 		fsck_flags |= fsck_flags_extra[err];
 
-	struct printbuf buf = PRINTBUF;
+	CLASS(printbuf, buf)();
 	prt_printf(&buf, "invalid bkey in %s",
 		   bch2_bkey_validate_contexts[from.from]);
 
@@ -701,7 +691,6 @@ int __bch2_bkey_fsck_err(struct bch_fs *c,
 	va_end(args);
 
 	int ret = __bch2_fsck_err(c, NULL, fsck_flags, err, "%s, delete?", buf.buf);
-	printbuf_exit(&buf);
 	return ret;
 }
 
@@ -709,7 +698,7 @@ static void __bch2_flush_fsck_errs(struct bch_fs *c, bool print)
 {
 	struct fsck_err_state *s, *n;
 
-	mutex_lock(&c->fsck_error_msgs_lock);
+	guard(mutex)(&c->fsck_error_msgs_lock);
 
 	list_for_each_entry_safe(s, n, &c->fsck_error_msgs, list) {
 		if (print && s->ratelimited && s->last_msg)
@@ -719,8 +708,6 @@ static void __bch2_flush_fsck_errs(struct bch_fs *c, bool print)
 		kfree(s->last_msg);
 		kfree(s);
 	}
-
-	mutex_unlock(&c->fsck_error_msgs_lock);
 }
 
 void bch2_flush_fsck_errs(struct bch_fs *c)
@@ -754,7 +741,8 @@ int bch2_inum_offset_err_msg_trans(struct btree_trans *trans, struct printbuf *o
 void bch2_inum_offset_err_msg(struct bch_fs *c, struct printbuf *out,
 			      subvol_inum inum, u64 offset)
 {
-	bch2_trans_do(c, bch2_inum_offset_err_msg_trans(trans, out, inum, offset));
+	CLASS(btree_trans, trans)(c);
+	lockrestart_do(trans, bch2_inum_offset_err_msg_trans(trans, out, inum, offset));
 }
 
 int bch2_inum_snap_offset_err_msg_trans(struct btree_trans *trans, struct printbuf *out,
@@ -771,5 +759,6 @@ int bch2_inum_snap_offset_err_msg_trans(struct btree_trans *trans, struct printb
 void bch2_inum_snap_offset_err_msg(struct bch_fs *c, struct printbuf *out,
 				  struct bpos pos)
 {
-	bch2_trans_do(c, bch2_inum_snap_offset_err_msg_trans(trans, out, pos));
+	CLASS(btree_trans, trans)(c);
+	lockrestart_do(trans, bch2_inum_snap_offset_err_msg_trans(trans, out, pos));
 }
-- 
2.51.0


From cfdb00dc1fb0f9c52ea0836f7ba70e6379cffda7 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 14:21:17 -0400
Subject: [PATCH 165/309] bcachefs: Fix padding zeroout when creating
 casefolded dirents

Reported-by: syzbot+894877f2c4dd5fdea634@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/dirent.c | 11 +++++------
 1 file changed, 5 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index e27cf62d3a5e..dd60c47528da 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -262,6 +262,7 @@ int bch2_dirent_init_name(struct bch_fs *c,
 		memcpy(&dirent->v.d_cf_name_block.d_names[0], name->name, name->len);
 
 		char *cf_out = &dirent->v.d_cf_name_block.d_names[name->len];
+		void *val_end = bkey_val_end(bkey_i_to_s(&dirent->k_i));
 
 		if (cf_name) {
 			cf_len = cf_name->len;
@@ -269,16 +270,14 @@ int bch2_dirent_init_name(struct bch_fs *c,
 			memcpy(cf_out, cf_name->name, cf_name->len);
 		} else {
 			cf_len = utf8_casefold(hash_info->cf_encoding, name,
-					       cf_out,
-					       bkey_val_end(bkey_i_to_s(&dirent->k_i)) - (void *) cf_out);
+					       cf_out, val_end - (void *) cf_out);
 			if (cf_len <= 0)
 				return cf_len;
 		}
 
-		memset(&dirent->v.d_cf_name_block.d_names[name->len + cf_len], 0,
-		       bkey_val_bytes(&dirent->k) -
-		       offsetof(struct bch_dirent, d_cf_name_block.d_names) -
-		       name->len + cf_len);
+		void *name_end = &dirent->v.d_cf_name_block.d_names[name->len + cf_len];
+		BUG_ON(name_end > val_end);
+		memset(name_end, 0, val_end - name_end);
 
 		dirent->v.d_cf_name_block.d_name_len = cpu_to_le16(name->len);
 		dirent->v.d_cf_name_block.d_cf_name_len = cpu_to_le16(cf_len);
-- 
2.51.0


From 0ee173ef1a7507e6db68b3e47f1a4b44fce3106f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 17:47:45 -0400
Subject: [PATCH 166/309] bcachefs: Don't call
 bch2_recovery_pass_want_ratelimit without sb_lock

Fix a locking bug - we need to look up the recovery_passes section of
the superblock to check whether a recovery pass should be ratelimited.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery_passes.c | 16 ++++++++++------
 1 file changed, 10 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/recovery_passes.c b/fs/bcachefs/recovery_passes.c
index f9d1c4921392..226b7dce736c 100644
--- a/fs/bcachefs/recovery_passes.c
+++ b/fs/bcachefs/recovery_passes.c
@@ -408,13 +408,17 @@ int bch2_run_explicit_recovery_pass(struct bch_fs *c,
 				    enum bch_recovery_pass pass,
 				    enum bch_run_recovery_pass_flags flags)
 {
-	int ret = 0;
+	/*
+	 * With RUN_RECOVERY_PASS_ratelimit, recovery_pass_needs_set needs
+	 * sb_lock
+	 */
+	if (!(flags & RUN_RECOVERY_PASS_ratelimit) &&
+	    !recovery_pass_needs_set(c, pass, &flags))
+		return 0;
 
-	if (recovery_pass_needs_set(c, pass, &flags)) {
-		guard(mutex)(&c->sb_lock);
-		ret = __bch2_run_explicit_recovery_pass(c, out, pass, flags);
-		bch2_write_super(c);
-	}
+	guard(mutex)(&c->sb_lock);
+	int ret = __bch2_run_explicit_recovery_pass(c, out, pass, flags);
+	bch2_write_super(c);
 
 	return ret;
 }
-- 
2.51.0


From 9b1c72ed5019ca7393149bf89d90dab6c2f5ca6c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 15 Jul 2025 14:48:52 -0400
Subject: [PATCH 167/309] bcachefs: Tell wbt throttling not to throttle
 metadata writes

blk-wbt.c skips throttling for REQ_SYNC|REQ_IDLE, but not REQ_META - !?

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c   | 7 ++++++-
 fs/bcachefs/journal_io.c | 6 +++++-
 fs/bcachefs/super-io.c   | 7 ++++++-
 3 files changed, 17 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index c0fba9016d6a..bd86dd7151a1 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -2540,9 +2540,14 @@ void __bch2_btree_node_write(struct bch_fs *c, struct btree *b, unsigned flags)
 	}
 	count_event(c, btree_node_write);
 
+	/*
+	 * blk-wbt.c throttles all writes except those that have both REQ_SYNC
+	 * and REQ_IDLE set...
+	 */
+
 	wbio = container_of(bio_alloc_bioset(NULL,
 				buf_pages(data, sectors_to_write << 9),
-				REQ_OP_WRITE|REQ_META,
+				REQ_OP_WRITE|REQ_META|REQ_SYNC|REQ_IDLE,
 				GFP_NOFS,
 				&c->btree_bio),
 			    struct btree_write_bio, wbio.bio);
diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 7d0cd2bb8f94..47224666d07e 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -1869,7 +1869,11 @@ static CLOSURE_CALLBACK(journal_write_submit)
 
 		jbio->submit_time	= local_clock();
 
-		bio_reset(bio, ca->disk_sb.bdev, REQ_OP_WRITE|REQ_SYNC|REQ_META);
+		/*
+		 * blk-wbt.c throttles all writes except those that have both
+		 * REQ_SYNC and REQ_IDLE set...
+		 */
+		bio_reset(bio, ca->disk_sb.bdev, REQ_OP_WRITE|REQ_SYNC|REQ_IDLE|REQ_META);
 		bio->bi_iter.bi_sector	= ptr->offset;
 		bio->bi_end_io		= journal_write_endio;
 		bio->bi_private		= ca;
diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index 820cb0f4fe57..40fa87ce1d09 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -991,7 +991,12 @@ static void write_one_super(struct bch_fs *c, struct bch_dev *ca, unsigned idx)
 	sb->csum = csum_vstruct(c, BCH_SB_CSUM_TYPE(sb),
 				null_nonce(), sb);
 
-	bio_reset(bio, ca->disk_sb.bdev, REQ_OP_WRITE|REQ_SYNC|REQ_META);
+	/*
+	 * blk-wbt.c throttles all writes except those that have both REQ_SYNC
+	 * and REQ_IDLE set...
+	 */
+
+	bio_reset(bio, ca->disk_sb.bdev, REQ_OP_WRITE|REQ_SYNC|REQ_IDLE|REQ_META);
 	bio->bi_iter.bi_sector	= le64_to_cpu(sb->offset);
 	bio->bi_end_io		= write_super_endio;
 	bio->bi_private		= ca;
-- 
2.51.0


From e16ce9e7b1d23b044cc7673c63559224344d94c3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 16 Jul 2025 17:53:05 -0400
Subject: [PATCH 168/309] bcachefs: Kill redundant write_super() when running
 recovery passes

write_super() is an expensive operation, and when we're doing extensive
repair we may call btree_lost_data() or run_explicit_recovery_pass()
quite frequently.

Add a new helper, __test_and_set_bit_le64(), for tracking whether we did
an update.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c        | 59 ++++++++++++++++++-----------------
 fs/bcachefs/recovery_passes.c | 28 ++++++++++-------
 fs/bcachefs/recovery_passes.h |  3 +-
 fs/bcachefs/util.h            |  7 +++++
 4 files changed, 55 insertions(+), 42 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index a8eea4787a3e..58c159e5f10d 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -37,78 +37,79 @@ int bch2_btree_lost_data(struct bch_fs *c,
 			 struct printbuf *msg,
 			 enum btree_id btree)
 {
-	u64 b = BIT_ULL(btree);
 	int ret = 0;
 
 	guard(mutex)(&c->sb_lock);
+	bool write_sb = false;
 	struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
 
-	if (!(c->sb.btrees_lost_data & b)) {
+	if (!(c->sb.btrees_lost_data & BIT_ULL(btree))) {
 		prt_printf(msg, "flagging btree ");
 		bch2_btree_id_to_text(msg, btree);
 		prt_printf(msg, " lost data\n");
 
-		ext->btrees_lost_data |= cpu_to_le64(b);
+		write_sb |= !__test_and_set_bit_le64(btree, &ext->btrees_lost_data);
 	}
 
 	/* Once we have runtime self healing for topology errors we won't need this: */
-	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_topology, 0) ?: ret;
+	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_topology, 0, &write_sb) ?: ret;
 
 	/* Btree node accounting will be off: */
-	__set_bit_le64(BCH_FSCK_ERR_accounting_mismatch, ext->errors_silent);
-	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_allocations, 0) ?: ret;
+	write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_accounting_mismatch, ext->errors_silent);
+	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_allocations, 0, &write_sb) ?: ret;
 
 #ifdef CONFIG_BCACHEFS_DEBUG
 	/*
 	 * These are much more minor, and don't need to be corrected right away,
 	 * but in debug mode we want the next fsck run to be clean:
 	 */
-	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_lrus, 0) ?: ret;
-	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_backpointers_to_extents, 0) ?: ret;
+	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_lrus, 0, &write_sb) ?: ret;
+	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_backpointers_to_extents, 0, &write_sb) ?: ret;
 #endif
 
 	switch (btree) {
 	case BTREE_ID_alloc:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0) ?: ret;
-
-		__set_bit_le64(BCH_FSCK_ERR_alloc_key_data_type_wrong, ext->errors_silent);
-		__set_bit_le64(BCH_FSCK_ERR_alloc_key_gen_wrong, ext->errors_silent);
-		__set_bit_le64(BCH_FSCK_ERR_alloc_key_dirty_sectors_wrong, ext->errors_silent);
-		__set_bit_le64(BCH_FSCK_ERR_alloc_key_cached_sectors_wrong, ext->errors_silent);
-		__set_bit_le64(BCH_FSCK_ERR_alloc_key_stripe_wrong, ext->errors_silent);
-		__set_bit_le64(BCH_FSCK_ERR_alloc_key_stripe_redundancy_wrong, ext->errors_silent);
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0, &write_sb) ?: ret;
+
+		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_data_type_wrong, ext->errors_silent);
+		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_gen_wrong, ext->errors_silent);
+		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_dirty_sectors_wrong, ext->errors_silent);
+		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_cached_sectors_wrong, ext->errors_silent);
+		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_stripe_wrong, ext->errors_silent);
+		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_stripe_redundancy_wrong, ext->errors_silent);
 		goto out;
 	case BTREE_ID_backpointers:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_btree_backpointers, 0) ?: ret;
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_extents_to_backpointers, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_btree_backpointers, 0, &write_sb) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_extents_to_backpointers, 0, &write_sb) ?: ret;
 		goto out;
 	case BTREE_ID_need_discard:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0, &write_sb) ?: ret;
 		goto out;
 	case BTREE_ID_freespace:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0, &write_sb) ?: ret;
 		goto out;
 	case BTREE_ID_bucket_gens:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0, &write_sb) ?: ret;
 		goto out;
 	case BTREE_ID_lru:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0, &write_sb) ?: ret;
 		goto out;
 	case BTREE_ID_accounting:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_allocations, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_allocations, 0, &write_sb) ?: ret;
 		goto out;
 	case BTREE_ID_snapshots:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_reconstruct_snapshots, 0) ?: ret;
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_topology, 0) ?: ret;
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_scan_for_btree_nodes, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_reconstruct_snapshots, 0, &write_sb) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_topology, 0, &write_sb) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_scan_for_btree_nodes, 0, &write_sb) ?: ret;
 		goto out;
 	default:
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_topology, 0) ?: ret;
-		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_scan_for_btree_nodes, 0) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_topology, 0, &write_sb) ?: ret;
+		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_scan_for_btree_nodes, 0, &write_sb) ?: ret;
 		goto out;
 	}
 out:
-	bch2_write_super(c);
+	if (write_sb)
+		bch2_write_super(c);
 	return ret;
 }
 
diff --git a/fs/bcachefs/recovery_passes.c b/fs/bcachefs/recovery_passes.c
index 226b7dce736c..b2cdd111fd0e 100644
--- a/fs/bcachefs/recovery_passes.c
+++ b/fs/bcachefs/recovery_passes.c
@@ -340,7 +340,8 @@ static bool recovery_pass_needs_set(struct bch_fs *c,
 int __bch2_run_explicit_recovery_pass(struct bch_fs *c,
 				      struct printbuf *out,
 				      enum bch_recovery_pass pass,
-				      enum bch_run_recovery_pass_flags flags)
+				      enum bch_run_recovery_pass_flags flags,
+				      bool *write_sb)
 {
 	struct bch_fs_recovery *r = &c->recovery;
 	int ret = 0;
@@ -362,7 +363,8 @@ int __bch2_run_explicit_recovery_pass(struct bch_fs *c,
 
 	if (!(flags & RUN_RECOVERY_PASS_nopersistent)) {
 		struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
-		__set_bit_le64(bch2_recovery_pass_to_stable(pass), ext->recovery_passes_required);
+		*write_sb |= !__test_and_set_bit_le64(bch2_recovery_pass_to_stable(pass),
+						     ext->recovery_passes_required);
 	}
 
 	if (pass < BCH_RECOVERY_PASS_set_may_go_rw &&
@@ -417,9 +419,10 @@ int bch2_run_explicit_recovery_pass(struct bch_fs *c,
 		return 0;
 
 	guard(mutex)(&c->sb_lock);
-	int ret = __bch2_run_explicit_recovery_pass(c, out, pass, flags);
-	bch2_write_super(c);
-
+	bool write_sb = false;
+	int ret = __bch2_run_explicit_recovery_pass(c, out, pass, flags, &write_sb);
+	if (write_sb)
+		bch2_write_super(c);
 	return ret;
 }
 
@@ -442,14 +445,13 @@ int bch2_require_recovery_pass(struct bch_fs *c,
 		return 0;
 
 	enum bch_run_recovery_pass_flags flags = 0;
-	int ret = 0;
 
-	if (recovery_pass_needs_set(c, pass, &flags)) {
-		ret = __bch2_run_explicit_recovery_pass(c, out, pass, flags);
+	bool write_sb = false;
+	int ret = __bch2_run_explicit_recovery_pass(c, out, pass, flags, &write_sb) ?:
+		bch_err_throw(c, recovery_pass_will_run);
+	if (write_sb)
 		bch2_write_super(c);
-	}
-
-	return ret ?: bch_err_throw(c, recovery_pass_will_run);
+	return ret;
 }
 
 int bch2_run_print_explicit_recovery_pass(struct bch_fs *c, enum bch_recovery_pass pass)
@@ -463,8 +465,10 @@ int bch2_run_print_explicit_recovery_pass(struct bch_fs *c, enum bch_recovery_pa
 	bch2_log_msg_start(c, &buf);
 
 	guard(mutex)(&c->sb_lock);
+	bool write_sb = false;
 	int ret = __bch2_run_explicit_recovery_pass(c, &buf, pass,
-						RUN_RECOVERY_PASS_nopersistent);
+						RUN_RECOVERY_PASS_nopersistent,
+						&write_sb);
 
 	bch2_print_str(c, KERN_NOTICE, buf.buf);
 	return ret;
diff --git a/fs/bcachefs/recovery_passes.h b/fs/bcachefs/recovery_passes.h
index 2117f0ce1922..4f2c2f811d5e 100644
--- a/fs/bcachefs/recovery_passes.h
+++ b/fs/bcachefs/recovery_passes.h
@@ -30,7 +30,8 @@ int bch2_run_print_explicit_recovery_pass(struct bch_fs *, enum bch_recovery_pas
 
 int __bch2_run_explicit_recovery_pass(struct bch_fs *, struct printbuf *,
 				      enum bch_recovery_pass,
-				      enum bch_run_recovery_pass_flags);
+				      enum bch_run_recovery_pass_flags,
+				      bool *);
 int bch2_run_explicit_recovery_pass(struct bch_fs *, struct printbuf *,
 				    enum bch_recovery_pass,
 				    enum bch_run_recovery_pass_flags);
diff --git a/fs/bcachefs/util.h b/fs/bcachefs/util.h
index 768528c2bae7..52ac8230be9f 100644
--- a/fs/bcachefs/util.h
+++ b/fs/bcachefs/util.h
@@ -733,6 +733,13 @@ static inline bool test_bit_le64(size_t bit, __le64 *addr)
 	return (addr[bit / 64] & cpu_to_le64(BIT_ULL(bit % 64))) != 0;
 }
 
+static inline bool __test_and_set_bit_le64(size_t bit, __le64 *addr)
+{
+	bool ret = test_bit_le64(bit, addr);
+	__set_bit_le64(bit, addr);
+	return ret;
+}
+
 static inline void memcpy_swab(void *_dst, void *_src, size_t len)
 {
 	u8 *dst = _dst + len;
-- 
2.51.0


From e882d9e05f35a17ba7a7d7548b900621b4307da6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 11:26:20 -0400
Subject: [PATCH 169/309] bcachefs: Add comment to journal_flush_done()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_reclaim.c | 29 ++++++++++++++++++++++++++++-
 1 file changed, 28 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/journal_reclaim.c b/fs/bcachefs/journal_reclaim.c
index be50455c7f13..f23e5ee9ad75 100644
--- a/fs/bcachefs/journal_reclaim.c
+++ b/fs/bcachefs/journal_reclaim.c
@@ -874,7 +874,34 @@ static int journal_flush_done(struct journal *j, u64 seq_to_flush,
 	     --type)
 		if (journal_flush_pins_or_still_flushing(j, seq_to_flush, BIT(type))) {
 			*did_work = true;
-			return ret;
+
+			/*
+			 * Question from Dan Carpenter, on the early return:
+			 *
+			 * If journal_flush_pins_or_still_flushing() returns
+			 * true, then the flush hasn't complete and we must
+			 * return 0; we want the outer closure_wait_event() in
+			 * journal_flush_pins() to continue.
+			 *
+			 * The early return is there because we don't want to
+			 * call journal_entry_close() until we've finished
+			 * flushing all outstanding journal pins - otherwise
+			 * seq_to_flush can be U64_MAX, and we'll close a bunch
+			 * of journal entries and write tiny ones completely
+			 * unnecessarily.
+			 *
+			 * Having the early return be in the loop where we loop
+			 * over types is important, because flushing one journal
+			 * pin can cause new journal pins to be added (even of
+			 * the same type, btree node writes may generate more
+			 * btree node writes, when updating the parent pointer
+			 * has a full node and has to trigger a split/compact).
+			 *
+			 * This is part of our shutdown sequence, where order of
+			 * flushing is important in order to make sure that it
+			 * terminates...
+			 */
+			return 0;
 		}
 
 	if (seq_to_flush > journal_cur_seq(j))
-- 
2.51.0


From 096611f806a45cf46b6cc4c2e8b90e3d6f020d94 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 13:17:29 -0400
Subject: [PATCH 170/309] bcachefs: Don't emit empty journal entry for
 accounting

Eliminate a bit of wasted space in the journal.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_trans_commit.c | 19 ++++++++++++-------
 1 file changed, 12 insertions(+), 7 deletions(-)

diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index c13da619f354..8b94a8156fbf 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -772,12 +772,13 @@ bch2_trans_commit_write_locked(struct btree_trans *trans,
 		trans->journal_res.offset	+= trans->journal_entries.u64s;
 		trans->journal_res.u64s		-= trans->journal_entries.u64s;
 
-		memcpy_u64s_small(bch2_journal_add_entry(j, &trans->journal_res,
-						BCH_JSET_ENTRY_write_buffer_keys,
-						BTREE_ID_accounting, 0,
-						trans->accounting.u64s)->_data,
-				  btree_trans_subbuf_base(trans, &trans->accounting),
-				  trans->accounting.u64s);
+		if (trans->accounting.u64s)
+			memcpy_u64s_small(bch2_journal_add_entry(j, &trans->journal_res,
+							BCH_JSET_ENTRY_write_buffer_keys,
+							BTREE_ID_accounting, 0,
+							trans->accounting.u64s)->_data,
+					  btree_trans_subbuf_base(trans, &trans->accounting),
+					  trans->accounting.u64s);
 
 		if (trans->journal_seq)
 			*trans->journal_seq = trans->journal_res.seq;
@@ -1069,11 +1070,15 @@ int __bch2_trans_commit(struct btree_trans *trans, enum bch_trans_commit_flags f
 
 	EBUG_ON(test_bit(BCH_FS_clean_shutdown, &c->flags));
 
-	journal_u64s = jset_u64s(trans->accounting.u64s);
+	journal_u64s = 0;
+
 	trans->journal_transaction_names = READ_ONCE(c->opts.journal_transaction_names);
 	if (trans->journal_transaction_names)
 		journal_u64s += jset_u64s(JSET_ENTRY_LOG_U64s);
 
+	if (trans->accounting.u64s)
+		journal_u64s += jset_u64s(trans->accounting.u64s);
+
 	trans_for_each_update(trans, i) {
 		struct btree_path *path = trans->paths + i->path;
 
-- 
2.51.0


From 1518d0e47befb4e6f439702360529dab19b808d8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 13:36:56 -0400
Subject: [PATCH 171/309] bcachefs: sysfs trigger_btree_write_buffer_flush

Add a knob for torture testing write buffer flushing.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sysfs.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/fs/bcachefs/sysfs.c b/fs/bcachefs/sysfs.c
index a3a9a29e1db5..cf97c9ab2a5c 100644
--- a/fs/bcachefs/sysfs.c
+++ b/fs/bcachefs/sysfs.c
@@ -18,6 +18,7 @@
 #include "btree_key_cache.h"
 #include "btree_update.h"
 #include "btree_update_interior.h"
+#include "btree_write_buffer.h"
 #include "btree_gc.h"
 #include "buckets.h"
 #include "clock.h"
@@ -149,6 +150,7 @@ write_attribute(trigger_journal_flush);
 write_attribute(trigger_journal_writes);
 write_attribute(trigger_btree_cache_shrink);
 write_attribute(trigger_btree_key_cache_shrink);
+write_attribute(trigger_btree_write_buffer_flush);
 write_attribute(trigger_btree_updates);
 write_attribute(trigger_freelist_wakeup);
 write_attribute(trigger_recalc_capacity);
@@ -427,6 +429,11 @@ STORE(bch2_fs)
 		c->btree_key_cache.shrink->scan_objects(c->btree_key_cache.shrink, &sc);
 	}
 
+	if (attr == &sysfs_trigger_btree_write_buffer_flush)
+		bch2_trans_do(c,
+			      (bch2_btree_write_buffer_flush_sync(trans),
+			       bch2_trans_begin(trans)));
+
 	if (attr == &sysfs_trigger_gc)
 		bch2_gc_gens(c);
 
@@ -597,6 +604,7 @@ struct attribute *bch2_fs_internal_files[] = {
 	&sysfs_trigger_journal_writes,
 	&sysfs_trigger_btree_cache_shrink,
 	&sysfs_trigger_btree_key_cache_shrink,
+	&sysfs_trigger_btree_write_buffer_flush,
 	&sysfs_trigger_btree_updates,
 	&sysfs_trigger_freelist_wakeup,
 	&sysfs_trigger_recalc_capacity,
-- 
2.51.0


From bc754833a0c9aae7442c4985e354e8922ea26244 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 16:16:48 -0400
Subject: [PATCH 172/309] closures: Improve warnings on bad put

Print out cl->fn - this narrows down the codepaths to look at.

See https://syzkaller.appspot.com/bug?extid=0ea2c41a649240197795

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 lib/closure.c | 12 +++++++-----
 1 file changed, 7 insertions(+), 5 deletions(-)

diff --git a/lib/closure.c b/lib/closure.c
index 2bfe7d2a0048..4fb78d18ee1b 100644
--- a/lib/closure.c
+++ b/lib/closure.c
@@ -13,23 +13,25 @@
 #include <linux/seq_file.h>
 #include <linux/sched/debug.h>
 
-static inline void closure_put_after_sub_checks(int flags)
+static inline void closure_put_after_sub_checks(struct closure *cl, int flags)
 {
 	int r = flags & CLOSURE_REMAINING_MASK;
 
 	if (WARN(flags & CLOSURE_GUARD_MASK,
-		 "closure has guard bits set: %x (%u)",
+		 "closure %ps has guard bits set: %x (%u)",
+		 cl->fn,
 		 flags & CLOSURE_GUARD_MASK, (unsigned) __fls(r)))
 		r &= ~CLOSURE_GUARD_MASK;
 
 	WARN(!r && (flags & ~CLOSURE_DESTRUCTOR),
-	     "closure ref hit 0 with incorrect flags set: %x (%u)",
+	     "closure %ps ref hit 0 with incorrect flags set: %x (%u)",
+	     cl->fn,
 	     flags & ~CLOSURE_DESTRUCTOR, (unsigned) __fls(flags));
 }
 
 static inline void closure_put_after_sub(struct closure *cl, int flags)
 {
-	closure_put_after_sub_checks(flags);
+	closure_put_after_sub_checks(cl, flags);
 
 	if (!(flags & CLOSURE_REMAINING_MASK)) {
 		smp_acquire__after_ctrl_dep();
@@ -167,7 +169,7 @@ void __sched closure_return_sync(struct closure *cl)
 	unsigned flags = atomic_sub_return_release(1 + CLOSURE_RUNNING - CLOSURE_DESTRUCTOR,
 						   &cl->remaining);
 
-	closure_put_after_sub_checks(flags);
+	closure_put_after_sub_checks(cl, flags);
 
 	if (unlikely(flags & CLOSURE_REMAINING_MASK)) {
 		while (1) {
-- 
2.51.0


From 982f60b71ae4bfe40cd5367283c95e434d145c29 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 18:06:40 -0400
Subject: [PATCH 173/309] bcachefs: Fix unhandled key type in
 fiemap_fill_extent

KEY_TYPE_error was unhandled; also add a warning for other unhandled key
types.

Reported-by: syzbot+397f6fe952a0defb9424@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs.c | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index 2789b30add10..56b7126bc31d 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -1295,8 +1295,14 @@ static int bch2_fill_extent(struct bch_fs *c,
 					       flags|
 					       FIEMAP_EXTENT_DELALLOC|
 					       FIEMAP_EXTENT_UNWRITTEN);
+	} else if (k.k->type == KEY_TYPE_error) {
+		return 0;
 	} else {
-		BUG();
+		WARN_ONCE(1, "unhandled key type %s",
+			  k.k->type < KEY_TYPE_MAX
+			  ? bch2_bkey_types[k.k->type]
+			  : "(unknown)");
+		return 0;
 	}
 }
 
-- 
2.51.0


From f874f89b4aaa335755d73afed903f6c6568a7227 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 16:28:28 -0400
Subject: [PATCH 174/309] bcachefs: Ensure we don't return with closure on
 waitlist

things will break wildly if we leave a stack allocated closure on a
waitlist

Reported-by: syzbot+0ea2c41a649240197795@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/ec.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index 62dda821247e..bea14f02114f 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -2060,6 +2060,9 @@ struct ec_stripe_head *bch2_ec_stripe_head_get(struct btree_trans *trans,
 	BUG_ON(trans->restarted);
 	return h;
 err:
+	if (waiting &&
+	    !bch2_err_matches(ret, BCH_ERR_operation_blocked))
+		closure_wake_up(&c->freelist_wait);
 	bch2_ec_stripe_head_put(c, h);
 	return ERR_PTR(ret);
 }
-- 
2.51.0


From ffed41e3c3dffc31923fb1aac7c9d3ec348dca5a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 18:59:48 -0400
Subject: [PATCH 175/309] bcachefs: bch2_move_data() now walks btree nodes

bch2_move_data_btree() can already walk btree nodes, and it properly
handles btree roots.

This is a code cleanup - and it fixes the rereplicate2 test, we can now
reliably rerereplicate in one psas.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/move.c | 95 ++++++++++++++++++----------------------------
 fs/bcachefs/move.h | 12 ------
 2 files changed, 36 insertions(+), 71 deletions(-)

diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 3f44bb54f91a..3419e406f0c7 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -795,50 +795,50 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 	return ret;
 }
 
-int __bch2_move_data(struct moving_context *ctxt,
-		     struct bbpos start,
-		     struct bbpos end,
-		     move_pred_fn pred, void *arg)
+static int bch2_move_data(struct bch_fs *c,
+			  struct bbpos start,
+			  struct bbpos end,
+			  unsigned min_depth,
+			  struct bch_ratelimit *rate,
+			  struct bch_move_stats *stats,
+			  struct write_point_specifier wp,
+			  bool wait_on_copygc,
+			  move_pred_fn pred, void *arg)
 {
-	struct bch_fs *c = ctxt->trans->c;
-	enum btree_id id;
 	int ret = 0;
 
-	for (id = start.btree;
+	struct moving_context ctxt;
+	bch2_moving_ctxt_init(&ctxt, c, rate, stats, wp, wait_on_copygc);
+
+	for (enum btree_id id = start.btree;
 	     id <= min_t(unsigned, end.btree, btree_id_nr_alive(c) - 1);
 	     id++) {
-		ctxt->stats->pos = BBPOS(id, POS_MIN);
+		ctxt.stats->pos = BBPOS(id, POS_MIN);
 
-		if (!btree_type_has_ptrs(id) ||
-		    !bch2_btree_id_root(c, id)->b)
+		if (!bch2_btree_id_root(c, id)->b)
 			continue;
 
-		ret = bch2_move_data_btree(ctxt,
-				       id == start.btree ? start.pos : POS_MIN,
-				       id == end.btree   ? end.pos   : POS_MAX,
-				       pred, arg, id, 0);
+		unsigned min_depth_this_btree = min_depth;
+
+		if (!btree_type_has_ptrs(id))
+			min_depth_this_btree = max(min_depth_this_btree, 1);
+
+		for (unsigned level = min_depth_this_btree;
+		     level < BTREE_MAX_DEPTH;
+		     level++) {
+			ret = bch2_move_data_btree(&ctxt,
+						   id == start.btree ? start.pos : POS_MIN,
+						   id == end.btree   ? end.pos   : POS_MAX,
+						   pred, arg, id, level);
+			if (ret)
+				break;
+		}
+
 		if (ret)
 			break;
 	}
 
-	return ret;
-}
-
-int bch2_move_data(struct bch_fs *c,
-		   struct bbpos start,
-		   struct bbpos end,
-		   struct bch_ratelimit *rate,
-		   struct bch_move_stats *stats,
-		   struct write_point_specifier wp,
-		   bool wait_on_copygc,
-		   move_pred_fn pred, void *arg)
-{
-	struct moving_context ctxt;
-
-	bch2_moving_ctxt_init(&ctxt, c, rate, stats, wp, wait_on_copygc);
-	int ret = __bch2_move_data(&ctxt, start, end, pred, arg);
 	bch2_moving_ctxt_exit(&ctxt);
-
 	return ret;
 }
 
@@ -1206,14 +1206,6 @@ static bool migrate_pred(struct bch_fs *c, void *arg,
 	return data_opts->rewrite_ptrs != 0;
 }
 
-static bool rereplicate_btree_pred(struct bch_fs *c, void *arg,
-				   struct btree *b,
-				   struct bch_io_opts *io_opts,
-				   struct data_update_opts *data_opts)
-{
-	return rereplicate_pred(c, arg, b->c.btree_id, bkey_i_to_s_c(&b->key), io_opts, data_opts);
-}
-
 /*
  * Ancient versions of bcachefs produced packed formats which could represent
  * keys that the in memory format cannot represent; this checks for those
@@ -1293,15 +1285,6 @@ static bool drop_extra_replicas_pred(struct bch_fs *c, void *arg,
 	return data_opts->kill_ptrs != 0;
 }
 
-static bool drop_extra_replicas_btree_pred(struct bch_fs *c, void *arg,
-				   struct btree *b,
-				   struct bch_io_opts *io_opts,
-				   struct data_update_opts *data_opts)
-{
-	return drop_extra_replicas_pred(c, arg, b->c.btree_id, bkey_i_to_s_c(&b->key),
-					io_opts, data_opts);
-}
-
 static bool scrub_pred(struct bch_fs *c, void *_arg,
 		       enum btree_id btree, struct bkey_s_c k,
 		       struct bch_io_opts *io_opts,
@@ -1359,11 +1342,7 @@ int bch2_data_job(struct bch_fs *c,
 	case BCH_DATA_OP_rereplicate:
 		stats->data_type = BCH_DATA_journal;
 		ret = bch2_journal_flush_device_pins(&c->journal, -1);
-		ret = bch2_move_btree(c, start, end,
-				      rereplicate_btree_pred, c, stats) ?: ret;
-		ret = bch2_move_data(c, start, end,
-				     NULL,
-				     stats,
+		ret = bch2_move_data(c, start, end, 0, NULL, stats,
 				     writepoint_hashed((unsigned long) current),
 				     true,
 				     rereplicate_pred, c) ?: ret;
@@ -1389,12 +1368,10 @@ int bch2_data_job(struct bch_fs *c,
 		ret = bch2_scan_old_btree_nodes(c, stats);
 		break;
 	case BCH_DATA_OP_drop_extra_replicas:
-		ret = bch2_move_btree(c, start, end,
-				drop_extra_replicas_btree_pred, c, stats) ?: ret;
-		ret = bch2_move_data(c, start, end, NULL, stats,
-				writepoint_hashed((unsigned long) current),
-				true,
-				drop_extra_replicas_pred, c) ?: ret;
+		ret = bch2_move_data(c, start, end, 0, NULL, stats,
+				     writepoint_hashed((unsigned long) current),
+				     true,
+				     drop_extra_replicas_pred, c) ?: ret;
 		ret = bch2_replicas_gc2(c) ?: ret;
 		break;
 	default:
diff --git a/fs/bcachefs/move.h b/fs/bcachefs/move.h
index fe92ca6d418d..481026ff99ab 100644
--- a/fs/bcachefs/move.h
+++ b/fs/bcachefs/move.h
@@ -128,18 +128,6 @@ struct bch_io_opts *bch2_move_get_io_opts(struct btree_trans *,
 
 int bch2_move_data_btree(struct moving_context *, struct bpos, struct bpos,
 			 move_pred_fn, void *, enum btree_id, unsigned);
-int __bch2_move_data(struct moving_context *,
-		     struct bbpos,
-		     struct bbpos,
-		     move_pred_fn, void *);
-int bch2_move_data(struct bch_fs *,
-		   struct bbpos start,
-		   struct bbpos end,
-		   struct bch_ratelimit *,
-		   struct bch_move_stats *,
-		   struct write_point_specifier,
-		   bool,
-		   move_pred_fn, void *);
 
 int bch2_move_data_phys(struct bch_fs *, unsigned, u64, u64, unsigned,
 			struct bch_ratelimit *, struct bch_move_stats *,
-- 
2.51.0


From 6e6cb8f719a152cff5b1c646d14a8aff84627dab Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 22:30:25 -0400
Subject: [PATCH 176/309] bcachefs: rereplicate flushes interior updates

We need to flush interior updates before gcing replicas entries,
otherwise we might still see replicas entries from in flight btree
updates.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/move.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 3419e406f0c7..54dd6fec81db 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -1346,6 +1346,7 @@ int bch2_data_job(struct bch_fs *c,
 				     writepoint_hashed((unsigned long) current),
 				     true,
 				     rereplicate_pred, c) ?: ret;
+		bch2_btree_interior_updates_flush(c);
 		ret = bch2_replicas_gc2(c) ?: ret;
 		break;
 	case BCH_DATA_OP_migrate:
-- 
2.51.0


From 15afe80388783fe11017d1a8c82e1236698f1a73 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 17 Jul 2025 22:31:22 -0400
Subject: [PATCH 177/309] bcachefs: can_use_btree_node()

Make sure btree_node_alloc() respects allocation policy when allocating
from the btree node reserve.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update_interior.c | 41 ++++++++++++++++++++++++++---
 fs/bcachefs/extents.c               | 14 ++++++++++
 fs/bcachefs/extents.h               |  2 ++
 3 files changed, 54 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 312ef203b27b..e4aa4fa749bc 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -14,6 +14,7 @@
 #include "btree_locking.h"
 #include "buckets.h"
 #include "clock.h"
+#include "disk_groups.h"
 #include "enumerated_ref.h"
 #include "error.h"
 #include "extents.h"
@@ -277,6 +278,36 @@ static void bch2_btree_node_free_never_used(struct btree_update *as,
 	bch2_trans_node_drop(trans, b);
 }
 
+static bool can_use_btree_node(struct bch_fs *c,
+			       struct disk_reservation *res,
+			       unsigned target,
+			       struct bkey_s_c k)
+{
+	if (!bch2_bkey_devs_rw(c, k))
+		return false;
+
+	if (target && !bch2_bkey_in_target(c, k, target))
+		return false;
+
+	unsigned durability = bch2_bkey_durability(c, k);
+
+	if (durability >= res->nr_replicas)
+		return true;
+
+	struct bch_devs_mask devs = target_rw_devs(c, BCH_DATA_btree, target);
+
+	guard(rcu)();
+
+	unsigned durability_available = 0, i;
+	for_each_set_bit(i, devs.d, BCH_SB_MEMBERS_MAX) {
+		struct bch_dev *ca = bch2_dev_rcu_noerror(c, i);
+		if (ca)
+			durability_available += ca->mi.durability;
+	}
+
+	return durability >= durability_available;
+}
+
 static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 					     struct disk_reservation *res,
 					     struct closure *cl,
@@ -303,10 +334,14 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 	mutex_lock(&c->btree_reserve_cache_lock);
 	if (c->btree_reserve_cache_nr > nr_reserve) {
 		for (struct btree_alloc *a = c->btree_reserve_cache;
-		     a < c->btree_reserve_cache + c->btree_reserve_cache_nr;
-		     a++) {
-			if (target && !bch2_bkey_in_target(c, bkey_i_to_s_c(&a->k), target))
+		     a < c->btree_reserve_cache + c->btree_reserve_cache_nr;) {
+			/* check if it has sufficient durability */
+
+			if (!can_use_btree_node(c, res, target, bkey_i_to_s_c(&a->k))) {
+				bch2_open_buckets_put(c, &a->ob);
+				*a = c->btree_reserve_cache[--c->btree_reserve_cache_nr];
 				continue;
+			}
 
 			bkey_copy(&b->key, &a->k);
 			b->ob = a->ob;
diff --git a/fs/bcachefs/extents.c b/fs/bcachefs/extents.c
index b36ecfc0ab9d..8152ef1cbbcd 100644
--- a/fs/bcachefs/extents.c
+++ b/fs/bcachefs/extents.c
@@ -1006,6 +1006,20 @@ const struct bch_extent_ptr *bch2_bkey_has_device_c(struct bkey_s_c k, unsigned
 	return NULL;
 }
 
+bool bch2_bkey_devs_rw(struct bch_fs *c, struct bkey_s_c k)
+{
+	struct bkey_ptrs_c ptrs = bch2_bkey_ptrs_c(k);
+
+	guard(rcu)();
+	bkey_for_each_ptr(ptrs, ptr) {
+		CLASS(bch2_dev_tryget, ca)(c, ptr->dev);
+		if (!ca || ca->mi.state != BCH_MEMBER_STATE_rw)
+			return false;
+	}
+
+	return true;
+}
+
 bool bch2_bkey_has_target(struct bch_fs *c, struct bkey_s_c k, unsigned target)
 {
 	struct bkey_ptrs_c ptrs = bch2_bkey_ptrs_c(k);
diff --git a/fs/bcachefs/extents.h b/fs/bcachefs/extents.h
index f212f91c278d..35ee03cd5065 100644
--- a/fs/bcachefs/extents.h
+++ b/fs/bcachefs/extents.h
@@ -614,6 +614,8 @@ static inline struct bch_extent_ptr *bch2_bkey_has_device(struct bkey_s k, unsig
 	return (void *) bch2_bkey_has_device_c(k.s_c, dev);
 }
 
+bool bch2_bkey_devs_rw(struct bch_fs *, struct bkey_s_c);
+
 bool bch2_bkey_has_target(struct bch_fs *, struct bkey_s_c, unsigned);
 bool bch2_bkey_in_target(struct bch_fs *, struct bkey_s_c, unsigned);
 
-- 
2.51.0


From a4b20a2dd2979cdf3361086beae6549880bb3ab6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 04:59:56 -0400
Subject: [PATCH 178/309] bcachefs: Fix error handling in btree_iter_peek_slot

Fixes: 2a33d540b22c ("bcachefs: Don't peek key cache unless we have a real key")
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index cc771affa511..a282c3886168 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2860,8 +2860,9 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 		    !bkey_deleted(k.k) &&
 		    (k2 = btree_trans_peek_key_cache(trans, iter, iter->pos)).k) {
 			k = k2;
-			if (!bkey_err(k))
-				iter->k = *k.k;
+			if (bkey_err(k))
+				goto out;
+			iter->k = *k.k;
 		}
 
 		if (unlikely(k.k->type == KEY_TYPE_whiteout &&
-- 
2.51.0


From 7821d812825fe5f1c7db232ecf3d9f5b21ebcda4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 12:21:33 -0400
Subject: [PATCH 179/309] bcachefs: fix assert in
 bch2_btree_path_traverse_cached()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_key_cache.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index 61edf555c422..8ceffea705f4 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -406,7 +406,7 @@ int bch2_btree_path_traverse_cached(struct btree_trans *trans,
 			btree_node_unlock(trans, path, 0);
 			path->l[0].b = ERR_PTR(ret);
 		}
-	} else {
+	} else if (!(flags & BTREE_ITER_cached_nofill)) {
 		BUG_ON(path->uptodate);
 		BUG_ON(!path->nodes_locked);
 	}
-- 
2.51.0


From cf61035d27295787426c82c5087ef1c871378a45 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 12:13:59 -0400
Subject: [PATCH 180/309] bcachefs: Fix allocate_dropping_locks() usage

Simplify callers a bit, and make sure we're not squashing a transaction
restart error.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/acl.c             |  4 ++--
 fs/bcachefs/btree_key_cache.c |  6 ++++--
 fs/bcachefs/errcode.h         |  2 ++
 fs/bcachefs/move.c            | 16 +++++++---------
 4 files changed, 15 insertions(+), 13 deletions(-)

diff --git a/fs/bcachefs/acl.c b/fs/bcachefs/acl.c
index 307824d6eccb..8f970dc19dea 100644
--- a/fs/bcachefs/acl.c
+++ b/fs/bcachefs/acl.c
@@ -138,8 +138,8 @@ static struct posix_acl *bch2_acl_from_disk(struct btree_trans *trans,
 
 	acl = allocate_dropping_locks(trans, ret,
 			posix_acl_alloc(count, _gfp));
-	if (!acl)
-		return ERR_PTR(-ENOMEM);
+	if (!acl && !ret)
+		ret = bch_err_throw(trans->c, ENOMEM_acl);
 	if (ret) {
 		kfree(acl);
 		return ERR_PTR(ret);
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index 8ceffea705f4..172875b5be8e 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -253,11 +253,13 @@ static int btree_key_cache_create(struct btree_trans *trans,
 
 		struct bkey_i *new_k = allocate_dropping_locks(trans, ret,
 				kmalloc(key_u64s * sizeof(u64), _gfp));
-		if (unlikely(!new_k)) {
+		if (unlikely(!new_k && !ret)) {
 			bch_err(trans->c, "error allocating memory for key cache key, btree %s u64s %u",
 				bch2_btree_id_str(ck->key.btree_id), key_u64s);
 			ret = bch_err_throw(c, ENOMEM_btree_key_cache_fill);
-		} else if (ret) {
+		}
+
+		if (unlikely(ret)) {
 			kfree(new_k);
 			goto err;
 		}
diff --git a/fs/bcachefs/errcode.h b/fs/bcachefs/errcode.h
index 2de0dc91a69e..5db48c01f8e6 100644
--- a/fs/bcachefs/errcode.h
+++ b/fs/bcachefs/errcode.h
@@ -90,6 +90,8 @@
 	x(ENOMEM,			ENOMEM_disk_accounting)			\
 	x(ENOMEM,			ENOMEM_stripe_head_alloc)		\
 	x(ENOMEM,                       ENOMEM_journal_read_bucket)             \
+	x(ENOMEM,                       ENOMEM_acl)				\
+	x(ENOMEM,                       ENOMEM_move_extent)			\
 	x(ENOSPC,			ENOSPC_disk_reservation)		\
 	x(ENOSPC,			ENOSPC_bucket_alloc)			\
 	x(ENOSPC,			ENOSPC_disk_label_add)			\
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 54dd6fec81db..84a228c42f06 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -330,7 +330,7 @@ int bch2_move_extent(struct moving_context *ctxt,
 {
 	struct btree_trans *trans = ctxt->trans;
 	struct bch_fs *c = trans->c;
-	int ret = -ENOMEM;
+	int ret = 0;
 
 	if (trace_io_move_enabled())
 		trace_io_move2(c, k, &io_opts, &data_opts);
@@ -351,11 +351,10 @@ int bch2_move_extent(struct moving_context *ctxt,
 
 	struct moving_io *io = allocate_dropping_locks(trans, ret,
 				kzalloc(sizeof(struct moving_io), _gfp));
-	if (!io)
-		goto err;
-
+	if (!io && !ret)
+		ret = bch_err_throw(c, ENOMEM_move_extent);
 	if (ret)
-		goto err_free;
+		goto err;
 
 	INIT_LIST_HEAD(&io->io_list);
 	io->write.ctxt		= ctxt;
@@ -366,7 +365,7 @@ int bch2_move_extent(struct moving_context *ctxt,
 		ret = bch2_data_update_init(trans, iter, ctxt, &io->write, ctxt->wp,
 					    &io_opts, data_opts, iter->btree_id, k);
 		if (ret)
-			goto err_free;
+			goto err;
 
 		io->write.op.end_io	= move_write_done;
 	} else {
@@ -380,7 +379,7 @@ int bch2_move_extent(struct moving_context *ctxt,
 
 		ret = bch2_data_update_bios_init(&io->write, c, &io_opts);
 		if (ret)
-			goto err_free;
+			goto err;
 	}
 
 	io->write.rbio.bio.bi_end_io = move_read_endio;
@@ -423,9 +422,8 @@ int bch2_move_extent(struct moving_context *ctxt,
 			   BCH_READ_last_fragment,
 			   data_opts.scrub ?  data_opts.read_dev : -1);
 	return 0;
-err_free:
-	kfree(io);
 err:
+	kfree(io);
 	if (bch2_err_matches(ret, EROFS) ||
 	    bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		return ret;
-- 
2.51.0


From 6e25c5a9693084ddeb34ac4fd19684903d8948d1 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 13:44:52 -0400
Subject: [PATCH 181/309] bcachefs: log devices we're scanning in btree node
 scan

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_node_scan.c | 7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/fs/bcachefs/btree_node_scan.c b/fs/bcachefs/btree_node_scan.c
index 6c0accafa44e..4b7b5ca74ba1 100644
--- a/fs/bcachefs/btree_node_scan.c
+++ b/fs/bcachefs/btree_node_scan.c
@@ -270,6 +270,9 @@ static int read_btree_nodes(struct find_btree_nodes *f)
 	int ret = 0;
 
 	closure_init_stack(&cl);
+	CLASS(printbuf, buf)();
+
+	prt_printf(&buf, "scanning for btree nodes on");
 
 	for_each_online_member(c, ca, BCH_DEV_READ_REF_btree_node_scan) {
 		if (!(ca->mi.data_allowed & BIT(BCH_DATA_btree)))
@@ -295,10 +298,14 @@ static int read_btree_nodes(struct find_btree_nodes *f)
 			break;
 		}
 
+		prt_printf(&buf, " %s", ca->name);
+
 		closure_get(&cl);
 		enumerated_ref_get(&ca->io_ref[READ], BCH_DEV_READ_REF_btree_node_scan);
 		wake_up_process(t);
 	}
+
+	bch_notice(c, "%s", buf.buf);
 err:
 	while (closure_sync_timeout(&cl, sysctl_hung_task_timeout_secs * HZ / 2))
 		;
-- 
2.51.0


From c2e1bc77cade39a8223576763b136f12dd82d63b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 13:53:46 -0400
Subject: [PATCH 182/309] bcachefs: Fix refs to undefined fields in
 __bch2_alloc_v4_to_text()

Recent stack usage reductions have avoided unpacking alloc keys onto the
stack in a few places, but when we do so we must be careful not to
reference fields that don't exist - key values can be extended with new
fields over time.

Reported-by: syzbot+8eb51728519f6659ef7b@syzkaller.appspotmail.com
Fixes: eabef52ff881 ("bcachefs: bch2_alloc_v4_to_text()")
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 16 ++++++++++------
 1 file changed, 10 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index 4c1604fd80f9..f1d35b7f3fc5 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -337,9 +337,10 @@ void bch2_alloc_v4_swab(struct bkey_s k)
 }
 
 static inline void __bch2_alloc_v4_to_text(struct printbuf *out, struct bch_fs *c,
-					   unsigned dev, const struct bch_alloc_v4 *a)
+					   struct bkey_s_c k,
+					   const struct bch_alloc_v4 *a)
 {
-	struct bch_dev *ca = c ? bch2_dev_tryget_noerror(c, dev) : NULL;
+	struct bch_dev *ca = c ? bch2_dev_tryget_noerror(c, k.k->p.inode) : NULL;
 
 	prt_newline(out);
 	printbuf_indent_add(out, 2);
@@ -348,11 +349,14 @@ static inline void __bch2_alloc_v4_to_text(struct printbuf *out, struct bch_fs *
 	bch2_prt_data_type(out, a->data_type);
 	prt_newline(out);
 	prt_printf(out, "journal_seq_nonempty %llu\n",	a->journal_seq_nonempty);
-	prt_printf(out, "journal_seq_empty    %llu\n",	a->journal_seq_empty);
+	if (bkey_val_bytes(k.k) > offsetof(struct bch_alloc_v4, journal_seq_empty))
+		prt_printf(out, "journal_seq_empty    %llu\n",	a->journal_seq_empty);
+
 	prt_printf(out, "need_discard         %llu\n",	BCH_ALLOC_V4_NEED_DISCARD(a));
 	prt_printf(out, "need_inc_gen         %llu\n",	BCH_ALLOC_V4_NEED_INC_GEN(a));
 	prt_printf(out, "dirty_sectors        %u\n",	a->dirty_sectors);
-	prt_printf(out, "stripe_sectors       %u\n",	a->stripe_sectors);
+	if (bkey_val_bytes(k.k) > offsetof(struct bch_alloc_v4, stripe_sectors))
+		prt_printf(out, "stripe_sectors       %u\n",	a->stripe_sectors);
 	prt_printf(out, "cached_sectors       %u\n",	a->cached_sectors);
 	prt_printf(out, "stripe               %u\n",	a->stripe);
 	prt_printf(out, "stripe_redundancy    %u\n",	a->stripe_redundancy);
@@ -372,12 +376,12 @@ void bch2_alloc_to_text(struct printbuf *out, struct bch_fs *c, struct bkey_s_c
 	struct bch_alloc_v4 _a;
 	const struct bch_alloc_v4 *a = bch2_alloc_to_v4(k, &_a);
 
-	__bch2_alloc_v4_to_text(out, c, k.k->p.inode, a);
+	__bch2_alloc_v4_to_text(out, c, k, a);
 }
 
 void bch2_alloc_v4_to_text(struct printbuf *out, struct bch_fs *c, struct bkey_s_c k)
 {
-	__bch2_alloc_v4_to_text(out, c, k.k->p.inode, bkey_s_c_to_alloc_v4(k).v);
+	__bch2_alloc_v4_to_text(out, c, k, bkey_s_c_to_alloc_v4(k).v);
 }
 
 void __bch2_alloc_to_v4(struct bkey_s_c k, struct bch_alloc_v4 *out)
-- 
2.51.0


From d0673b36190a50129b1b8812d9cd0178b160aca3 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Sat, 19 Jul 2025 02:16:35 +0800
Subject: [PATCH 183/309] bcachefs: Use user_backed_iter instead of
 iter_is_iovec

ITER_UBUF is also one of the user backed iter, which is equivalent
of single-segment iovec. DIO handling should use user_backed_iter.

Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-direct.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/fs-io-direct.c b/fs/bcachefs/fs-io-direct.c
index 73d44875faf2..e53fee0513fd 100644
--- a/fs/bcachefs/fs-io-direct.c
+++ b/fs/bcachefs/fs-io-direct.c
@@ -127,7 +127,7 @@ static int bch2_direct_IO_read(struct kiocb *req, struct iov_iter *iter)
 	 * the dirtying of requests that are internal from the kernel (i.e. from
 	 * loopback), because we'll deadlock on page_lock.
 	 */
-	dio->should_dirty = iter_is_iovec(iter);
+	dio->should_dirty = user_backed_iter(iter);
 
 	blk_start_plug(&plug);
 
-- 
2.51.0


From d07885db344de84c2e3fd806923892a174b31dd0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 14:35:09 -0400
Subject: [PATCH 184/309] bcachefs: fix check_extent_overbig() call

We can't access btree key values after a transaction commit.

Reported-by: syzbot+fbc1f6040dd365cce0d8@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c | 7 +++++--
 1 file changed, 5 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 668b491dfd29..61249bf75c93 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1976,6 +1976,10 @@ static int check_extent(struct btree_trans *trans, struct btree_iter *iter,
 		}
 	}
 
+	ret = check_extent_overbig(trans, iter, k);
+	if (ret)
+		goto err;
+
 	ret = bch2_trans_commit(trans, res, NULL, BCH_TRANS_COMMIT_no_enospc);
 	if (ret)
 		goto err;
@@ -2022,8 +2026,7 @@ int bch2_check_extents(struct bch_fs *c)
 				POS(BCACHEFS_ROOT_INO, 0),
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k, ({
 			bch2_disk_reservation_put(c, &res);
-			check_extent(trans, &iter, k, &w, &s, &extent_ends, &res) ?:
-			check_extent_overbig(trans, &iter, k);
+			check_extent(trans, &iter, k, &w, &s, &extent_ends, &res);
 		})) ?:
 		check_i_sectors_notnested(trans, &w);
 
-- 
2.51.0


From db716308dba7d1f468c0a5aa25abbef5f3e11880 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 18 Jul 2025 13:27:16 -0400
Subject: [PATCH 185/309] bcachefs: Convert topology repair errs to standard
 error codes

When we log an error, this makes sure they're printed correctly.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_gc.c | 31 ++++++++++++++-----------------
 fs/bcachefs/errcode.h  |  6 +++++-
 2 files changed, 19 insertions(+), 18 deletions(-)

diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index 34cb8a4324dc..e95bb6849aef 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -44,10 +44,6 @@
 #include <linux/rcupdate.h>
 #include <linux/sched/task.h>
 
-#define DROP_THIS_NODE		10
-#define DROP_PREV_NODE		11
-#define DID_FILL_FROM_SCAN	12
-
 /*
  * Returns true if it's a btree we can easily reconstruct, or otherwise won't
  * cause data loss if it's missing:
@@ -252,7 +248,7 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 				return ret;
 
 			*pulled_from_scan = cur->data->min_key;
-			ret = DID_FILL_FROM_SCAN;
+			ret = bch_err_throw(c, topology_repair_did_fill_from_scan);
 		} else {
 			if (mustfix_fsck_err(trans, btree_node_topology_bad_min_key,
 					     "btree node with incorrect min_key%s", buf.buf))
@@ -263,7 +259,7 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 			if (bpos_ge(prev->data->min_key, cur->data->min_key)) {		/* fully? */
 				if (mustfix_fsck_err(trans, btree_node_topology_overwritten_by_next_node,
 						     "btree node overwritten by next node%s", buf.buf))
-					ret = DROP_PREV_NODE;
+					ret = bch_err_throw(c, topology_repair_drop_prev_node);
 			} else {
 				if (mustfix_fsck_err(trans, btree_node_topology_bad_max_key,
 						     "btree node with incorrect max_key%s", buf.buf))
@@ -274,7 +270,7 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 			if (bpos_ge(expected_start, cur->data->max_key)) {		/* fully? */
 				if (mustfix_fsck_err(trans, btree_node_topology_overwritten_by_prev_node,
 						     "btree node overwritten by prev node%s", buf.buf))
-					ret = DROP_THIS_NODE;
+					ret = bch_err_throw(c, topology_repair_drop_this_node);
 			} else {
 				if (mustfix_fsck_err(trans, btree_node_topology_bad_min_key,
 						     "btree node with incorrect min_key%s", buf.buf))
@@ -314,7 +310,7 @@ static int btree_repair_node_end(struct btree_trans *trans, struct btree *b,
 				return ret;
 
 			*pulled_from_scan = b->key.k.p;
-			ret = DID_FILL_FROM_SCAN;
+			ret = bch_err_throw(c, topology_repair_did_fill_from_scan);
 		} else {
 			ret = set_node_max(c, child, b->key.k.p);
 		}
@@ -391,15 +387,15 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 
 		ret = lockrestart_do(trans,
 			btree_check_node_boundaries(trans, b, prev, cur, pulled_from_scan));
-		if (ret < 0)
+		if (ret && !bch2_err_matches(ret, BCH_ERR_topology_repair))
 			goto err;
 
-		if (ret == DID_FILL_FROM_SCAN) {
+		if (bch2_err_matches(ret, BCH_ERR_topology_repair_did_fill_from_scan)) {
 			new_pass = true;
 			ret = 0;
 		}
 
-		if (ret == DROP_THIS_NODE) {
+		if (bch2_err_matches(ret, BCH_ERR_topology_repair_drop_this_node)) {
 			six_unlock_read(&cur->c.lock);
 			bch2_btree_node_evict(trans, cur_k.k);
 			ret = bch2_journal_key_delete(c, b->c.btree_id,
@@ -414,7 +410,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 			six_unlock_read(&prev->c.lock);
 		prev = NULL;
 
-		if (ret == DROP_PREV_NODE) {
+		if (bch2_err_matches(ret, BCH_ERR_topology_repair_drop_prev_node)) {
 			bch_info(c, "dropped prev node");
 			bch2_btree_node_evict(trans, prev_k.k);
 			ret = bch2_journal_key_delete(c, b->c.btree_id,
@@ -436,7 +432,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 		BUG_ON(cur);
 		ret = lockrestart_do(trans,
 			btree_repair_node_end(trans, b, prev, pulled_from_scan));
-		if (ret == DID_FILL_FROM_SCAN) {
+		if (bch2_err_matches(ret, BCH_ERR_topology_repair_did_fill_from_scan)) {
 			new_pass = true;
 			ret = 0;
 		}
@@ -477,7 +473,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 		six_unlock_read(&cur->c.lock);
 		cur = NULL;
 
-		if (ret == DROP_THIS_NODE) {
+		if (bch2_err_matches(ret, BCH_ERR_topology_repair_drop_this_node)) {
 			bch2_btree_node_evict(trans, cur_k.k);
 			ret = bch2_journal_key_delete(c, b->c.btree_id,
 						      b->c.level, cur_k.k->k.p);
@@ -504,7 +500,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 	if (mustfix_fsck_err_on(!have_child,
 			c, btree_node_topology_interior_node_empty,
 			"empty interior btree node at %s", buf.buf))
-		ret = DROP_THIS_NODE;
+		ret = bch_err_throw(c, topology_repair_drop_this_node);
 err:
 fsck_err:
 	if (!IS_ERR_OR_NULL(prev))
@@ -521,7 +517,8 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 
 	bch2_bkey_buf_exit(&prev_k, c);
 	bch2_bkey_buf_exit(&cur_k, c);
-	bch_err_fn(c, ret);
+	if (!bch2_err_matches(ret, BCH_ERR_topology_repair))
+		bch_err_fn(c, ret);
 	return ret;
 }
 
@@ -592,7 +589,7 @@ int bch2_check_topology(struct bch_fs *c)
 		ret = bch2_btree_repair_topology_recurse(trans, b, &pulled_from_scan);
 		six_unlock_read(&b->c.lock);
 
-		if (ret == DROP_THIS_NODE) {
+		if (bch2_err_matches(ret, BCH_ERR_topology_repair_drop_this_node)) {
 			scoped_guard(mutex, &c->btree_cache.lock)
 				bch2_btree_node_hash_remove(&c->btree_cache, b);
 
diff --git a/fs/bcachefs/errcode.h b/fs/bcachefs/errcode.h
index 5db48c01f8e6..cec8b0f47d3d 100644
--- a/fs/bcachefs/errcode.h
+++ b/fs/bcachefs/errcode.h
@@ -218,9 +218,13 @@
 	x(EINVAL,			varint_decode_error)			\
 	x(EINVAL,			erasure_coding_found_btree_node)	\
 	x(EINVAL,			option_negative)			\
+	x(EINVAL,			topology_repair)			\
+	x(BCH_ERR_topology_repair,	topology_repair_drop_this_node)		\
+	x(BCH_ERR_topology_repair,	topology_repair_drop_prev_node)		\
+	x(BCH_ERR_topology_repair,	topology_repair_did_fill_from_scan)	\
 	x(EOPNOTSUPP,			may_not_use_incompat_feature)		\
 	x(EOPNOTSUPP,			no_casefolding_without_utf8)		\
-	x(EOPNOTSUPP,			casefolding_disabled)		\
+	x(EOPNOTSUPP,			casefolding_disabled)			\
 	x(EOPNOTSUPP,			casefold_opt_is_dir_only)		\
 	x(EOPNOTSUPP,			unsupported_fsx_flag)			\
 	x(EOPNOTSUPP,			unsupported_fa_flag)			\
-- 
2.51.0


From 66f8203b7b384e5990da083b2816d44b555b71fe Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 19 Jul 2025 14:48:25 -0400
Subject: [PATCH 186/309] bcachefs: Fix __bch2_alloc_to_v4 copy

bch_alloc_v4 is a key type that's been extended over time, so we can't
do a dump struct copy - we need to check the value size.

Reported-by: syzbot+487dd8c670b175dd59ed@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index f1d35b7f3fc5..d5cb07c7f4d6 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -389,7 +389,7 @@ void __bch2_alloc_to_v4(struct bkey_s_c k, struct bch_alloc_v4 *out)
 	if (k.k->type == KEY_TYPE_alloc_v4) {
 		void *src, *dst;
 
-		*out = *bkey_s_c_to_alloc_v4(k).v;
+		bkey_val_copy(out, bkey_s_c_to_alloc_v4(k));
 
 		src = alloc_v4_backpointers(out);
 		SET_BCH_ALLOC_V4_BACKPOINTERS_START(out, BCH_ALLOC_V4_U64s);
-- 
2.51.0


From cfd0319aa132b3f317e8645c2fec77a293d09ac3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 19 Jul 2025 15:09:20 -0400
Subject: [PATCH 187/309] bcachefs: Flush btree_interior_update_work before
 freeing fs

Avoid a UAF for the list of pending interior updates, or when the last
btree_update_nodes_written() frees its btree_trans.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 0fc0b2221036..b3b2d8353a36 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -729,6 +729,8 @@ void __bch2_fs_stop(struct bch_fs *c)
 		cancel_work_sync(&ca->io_error_work);
 
 	cancel_work_sync(&c->read_only_work);
+
+	flush_work(&c->btree_interior_update_work);
 }
 
 void bch2_fs_free(struct bch_fs *c)
-- 
2.51.0


From 4d20931be1ac4c98a40788310be7ab77dcbbe93e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 19 Jul 2025 13:22:13 -0400
Subject: [PATCH 188/309] bcachefs: Only track read latency for congestion
 tracking

Writes are subject to queing delays from page cache writeback; we don't
necessarily want these considered when tracking if a device is congested
for the purpose of cache promotion.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_write.c | 7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index d7620138e038..44b02d4b6502 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -89,7 +89,12 @@ void bch2_latency_acct(struct bch_dev *ca, u64 submit_time, int rw)
 		new = ewma_add(old, io_latency, 5);
 	} while (!atomic64_try_cmpxchg(latency, &old, new));
 
-	bch2_congested_acct(ca, io_latency, now, rw);
+	/*
+	 * Only track read latency for congestion accounting: writes are subject
+	 * to heavy queuing delays from page cache writeback:
+	 */
+	if (rw == READ)
+		bch2_congested_acct(ca, io_latency, now, rw);
 
 	__bch2_time_stats_update(&ca->io_latency[rw].stats, submit_time, now);
 }
-- 
2.51.0


From c0e2b1fcbc346ab19c5e192d220cbd26ad70e420 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 19 Jul 2025 19:33:30 -0400
Subject: [PATCH 189/309] bcachefs: Clean up btree_node_read_work() error
 handling

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 24 ++++++++----------------
 1 file changed, 8 insertions(+), 16 deletions(-)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index bd86dd7151a1..83c836080ea2 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -1405,10 +1405,8 @@ static void btree_node_read_work(struct work_struct *work)
 		ret = bch2_bkey_pick_read_device(c,
 					bkey_i_to_s_c(&b->key),
 					&failed, &rb->pick, -1);
-		if (ret <= 0) {
-			set_btree_node_read_error(b);
+		if (ret <= 0)
 			break;
-		}
 
 		ca = bch2_dev_get_ioref(c, rb->pick.ptr.dev, READ, BCH_DEV_READ_REF_btree_node_read);
 		rb->have_ioref		= ca != NULL;
@@ -1442,27 +1440,21 @@ static void btree_node_read_work(struct work_struct *work)
 		bch2_maybe_corrupt_bio(bio, bch2_btree_read_corrupt_ratio);
 
 		ret = bch2_btree_node_read_done(c, ca, b, &failed, &buf);
-		if (ret == -BCH_ERR_btree_node_read_err_want_retry ||
-		    ret == -BCH_ERR_btree_node_read_err_must_retry)
-			continue;
-
-		if (ret)
-			set_btree_node_read_error(b);
-
-		break;
+		if (ret != -BCH_ERR_btree_node_read_err_want_retry &&
+		    ret != -BCH_ERR_btree_node_read_err_must_retry)
+			break;
 	}
 
 	bch2_io_failures_to_text(&buf, c, &failed);
 
-	if (btree_node_read_error(b))
-		bch2_btree_lost_data(c, &buf, b->c.btree_id);
-
 	/*
 	 * only print retry success if we read from a replica with no errors
 	 */
-	if (btree_node_read_error(b))
+	if (ret) {
+		set_btree_node_read_error(b);
+		bch2_btree_lost_data(c, &buf, b->c.btree_id);
 		prt_printf(&buf, "ret %s", bch2_err_str(ret));
-	else if (failed.nr) {
+	} else if (failed.nr) {
 		if (!bch2_dev_io_failures(&failed, rb->pick.ptr.dev))
 			prt_printf(&buf, "retry success");
 		else
-- 
2.51.0


From bb0c5d3bda70f5b00dd05c00840f99fe3400dc1d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 19 Jul 2025 19:34:27 -0400
Subject: [PATCH 190/309] bcachefs: Ensure pick_read_device() returns error for
 btree pointers

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/extents.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/extents.c b/fs/bcachefs/extents.c
index 8152ef1cbbcd..b879a586b7f6 100644
--- a/fs/bcachefs/extents.c
+++ b/fs/bcachefs/extents.c
@@ -282,9 +282,9 @@ int bch2_bkey_pick_read_device(struct bch_fs *c, struct bkey_s_c k,
 
 	if (have_pick)
 		return 1;
-	if (!have_dirty_ptrs)
+	if (!have_dirty_ptrs && !bkey_is_btree_ptr(k.k))
 		return 0;
-	if (have_missing_devs)
+	if (have_missing_devs || !have_dirty_ptrs)
 		return bch_err_throw(c, no_device_to_read_from);
 	if (have_csum_errors)
 		return bch_err_throw(c, data_read_csum_err);
-- 
2.51.0


From 7162c2b0f89b493a0ead691ef9724a9f0ad71b9e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 19 Jul 2025 19:39:53 -0400
Subject: [PATCH 191/309] bcachefs: btree_lost_data: mark a few more errors for
 silent fixing

Keep the log clean for harmless, expected errors.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c | 7 +++++--
 1 file changed, 5 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 58c159e5f10d..304473dac268 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -67,13 +67,16 @@ int bch2_btree_lost_data(struct bch_fs *c,
 	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_backpointers_to_extents, 0, &write_sb) ?: ret;
 #endif
 
+	write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_lru_entry_bad, ext->errors_silent);
+	write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_backpointer_to_missing_ptr, ext->errors_silent);
+	write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_data_type_wrong, ext->errors_silent);
+	write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_dirty_sectors_wrong, ext->errors_silent);
+
 	switch (btree) {
 	case BTREE_ID_alloc:
 		ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_alloc_info, 0, &write_sb) ?: ret;
 
-		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_data_type_wrong, ext->errors_silent);
 		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_gen_wrong, ext->errors_silent);
-		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_dirty_sectors_wrong, ext->errors_silent);
 		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_cached_sectors_wrong, ext->errors_silent);
 		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_stripe_wrong, ext->errors_silent);
 		write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_alloc_key_stripe_redundancy_wrong, ext->errors_silent);
-- 
2.51.0


From 468a14e221c651fcd5c72fa68772067cdf77cdd8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 20 Jul 2025 10:51:48 -0400
Subject: [PATCH 192/309] bcachefs: Don't allow mounting with crazy numbers of
 dirty journal entries

We might have to initialize the journal pin fifo with a size greater
than the normal max, but we can disallow crazy numbers.

Reported-by: syzbot+527519da96e15b411c73@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index c0c594c783c0..a4f43c550ad7 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -1471,6 +1471,10 @@ int bch2_fs_journal_start(struct journal *j, u64 last_seq, u64 cur_seq)
 		last_seq = cur_seq;
 
 	u64 nr = cur_seq - last_seq;
+	if (nr * sizeof(struct journal_entry_pin_list) > 1U << 30) {
+		bch_err(c, "too many ntjournal fifo (%llu open entries)", nr);
+		return bch_err_throw(c, ENOMEM_journal_pin_fifo);
+	}
 
 	/*
 	 * Extra fudge factor, in case we crashed when the journal pin fifo was
@@ -1483,7 +1487,7 @@ int bch2_fs_journal_start(struct journal *j, u64 last_seq, u64 cur_seq)
 	nr = max(nr, JOURNAL_PIN);
 	init_fifo(&j->pin, roundup_pow_of_two(nr), GFP_KERNEL);
 	if (!j->pin.data) {
-		bch_err(c, "error reallocating journal fifo (%llu open entries)", nr);
+		bch_err(c, "error allocating journal fifo (%llu open entries)", nr);
 		return bch_err_throw(c, ENOMEM_journal_pin_fifo);
 	}
 
-- 
2.51.0


From 4e30ad7d360252f2c64339421bd7c90f85c77498 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 20 Jul 2025 21:37:05 -0400
Subject: [PATCH 193/309] bcachefs: Add pass_done to
 recovery_pass_status_to_text()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery_passes.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/fs/bcachefs/recovery_passes.c b/fs/bcachefs/recovery_passes.c
index b2cdd111fd0e..bd442652d0f5 100644
--- a/fs/bcachefs/recovery_passes.c
+++ b/fs/bcachefs/recovery_passes.c
@@ -639,6 +639,8 @@ void bch2_recovery_pass_status_to_text(struct printbuf *out, struct bch_fs *c)
 		prt_printf(out, "Current pass:\t%s\n", bch2_recovery_passes[r->curr_pass]);
 		prt_passes(out, "Current passes", r->passes_to_run);
 	}
+
+	prt_printf(out, "Pass done:\t%s\n", bch2_recovery_passes[r->pass_done]);
 }
 
 void bch2_fs_recovery_passes_init(struct bch_fs *c)
-- 
2.51.0


From aee94970fb69ca330ecd0d4eb8a5e5d63f6ee649 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 20 Jul 2025 19:49:08 -0400
Subject: [PATCH 194/309] bcachefs: Increase BCH_MIN_NR_NBUCKETS

We can't run with only 64 buckets anymore, due to various reserves. 512
should be a more reasonable minimum.

Reported-by: syzbot+c6fd966ebbdea1e8ff08@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-members_format.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/sb-members_format.h b/fs/bcachefs/sb-members_format.h
index fb72ad730518..b2b892687cdd 100644
--- a/fs/bcachefs/sb-members_format.h
+++ b/fs/bcachefs/sb-members_format.h
@@ -17,7 +17,7 @@
 	UUID_INIT(0xffffffff, 0xffff, 0xffff,				\
 		  0xd9, 0x6a, 0x60, 0xcf, 0x80, 0x3d, 0xf7, 0xef)
 
-#define BCH_MIN_NR_NBUCKETS	(1 << 6)
+#define BCH_MIN_NR_NBUCKETS	(1 << 9)
 
 #define BCH_IOPS_MEASUREMENTS()			\
 	x(seqread,	0)			\
-- 
2.51.0


From c0e459be859c1783058fe42206e46b8628885862 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 20 Jul 2025 21:24:58 -0400
Subject: [PATCH 195/309] bcachefs: Hook up progress indicators for most
 recovery passes

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 16 ++++++++--
 fs/bcachefs/bcachefs.h         |  7 +++++
 fs/bcachefs/btree_types.h      | 12 ++++----
 fs/bcachefs/fsck.c             | 55 +++++++++++++++++++++++++++-------
 fs/bcachefs/lru.c              | 10 +++++--
 fs/bcachefs/progress.c         |  3 +-
 fs/bcachefs/progress.h         |  3 ++
 fs/bcachefs/rebalance.c        |  6 ++++
 fs/bcachefs/snapshot.c         |  5 ++++
 9 files changed, 95 insertions(+), 22 deletions(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index d5cb07c7f4d6..55c21e9b4c52 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -20,6 +20,7 @@
 #include "enumerated_ref.h"
 #include "error.h"
 #include "lru.h"
+#include "progress.h"
 #include "recovery.h"
 #include "varint.h"
 
@@ -1553,6 +1554,9 @@ int bch2_check_alloc_info(struct bch_fs *c)
 	struct bkey_s_c k;
 	int ret = 0;
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_alloc));
+
 	CLASS(btree_trans, trans)(c);
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_alloc, POS_MIN,
 			     BTREE_ITER_prefetch);
@@ -1576,6 +1580,8 @@ int bch2_check_alloc_info(struct bch_fs *c)
 		if (!k.k)
 			break;
 
+		progress_update_iter(trans, &progress, &iter);
+
 		if (k.k->type) {
 			next = bpos_nosnap_successor(k.k->p);
 
@@ -1736,12 +1742,16 @@ int bch2_check_alloc_to_lru_refs(struct bch_fs *c)
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_alloc));
+
 	CLASS(btree_trans, trans)(c);
 	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_alloc,
 				POS_MIN, BTREE_ITER_prefetch, k,
-				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_check_alloc_to_lru_ref(trans, &iter, &last_flushed)) ?:
-		bch2_check_stripe_to_lru_refs(trans);
+				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
+			progress_update_iter(trans, &progress, &iter);
+			bch2_check_alloc_to_lru_ref(trans, &iter, &last_flushed);
+	}))?: bch2_check_stripe_to_lru_refs(trans);
 
 	bch2_bkey_buf_exit(&last_flushed, c);
 	return ret;
diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index 8a6f886b5bf2..45c15bdaa6f4 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -1277,4 +1277,11 @@ static inline int bch2_fs_casefold_enabled(struct bch_fs *c)
 	return 0;
 }
 
+static inline const char *strip_bch2(const char *msg)
+{
+	if (!strncmp("bch2_", msg, 5))
+		return msg + 5;
+	return msg;
+}
+
 #endif /* _BCACHEFS_H */
diff --git a/fs/bcachefs/btree_types.h b/fs/bcachefs/btree_types.h
index 76adf75617aa..e6177b747216 100644
--- a/fs/bcachefs/btree_types.h
+++ b/fs/bcachefs/btree_types.h
@@ -854,15 +854,15 @@ static inline bool btree_node_type_is_extents(enum btree_node_type type)
 	return type != BKEY_TYPE_btree && btree_id_is_extents(type - 1);
 }
 
-static inline bool btree_type_has_snapshots(enum btree_id btree)
-{
-	const u64 mask = 0
+static const u64 btree_has_snapshots_mask = 0
 #define x(name, nr, flags, ...)	|((!!((flags) & BTREE_IS_snapshots)) << nr)
-	BCH_BTREE_IDS()
+BCH_BTREE_IDS()
 #undef x
-	;
+;
 
-	return BIT_ULL(btree) & mask;
+static inline bool btree_type_has_snapshots(enum btree_id btree)
+{
+	return BIT_ULL(btree) & btree_has_snapshots_mask;
 }
 
 static inline bool btree_type_has_snapshot_field(enum btree_id btree)
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 61249bf75c93..f5a9da40c647 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -15,6 +15,7 @@
 #include "io_misc.h"
 #include "keylist.h"
 #include "namei.h"
+#include "progress.h"
 #include "recovery_passes.h"
 #include "snapshot.h"
 #include "super.h"
@@ -1331,11 +1332,16 @@ int bch2_check_inodes(struct bch_fs *c)
 	CLASS(btree_trans, trans)(c);
 	CLASS(snapshots_seen, s)();
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_inodes));
+
 	return for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
-				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_inode(trans, &iter, k, &snapshot_root, &s));
+				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
+		progress_update_iter(trans, &progress, &iter);
+		check_inode(trans, &iter, k, &snapshot_root, &s);
+	}));
 }
 
 static int find_oldest_inode_needs_reattach(struct btree_trans *trans,
@@ -1422,12 +1428,17 @@ static int check_unreachable_inode(struct btree_trans *trans,
  */
 int bch2_check_unreachable_inodes(struct bch_fs *c)
 {
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_inodes));
+
 	CLASS(btree_trans, trans)(c);
 	return for_each_btree_key_commit(trans, iter, BTREE_ID_inodes,
 				POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
-				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_unreachable_inode(trans, &iter, k));
+				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
+		progress_update_iter(trans, &progress, &iter);
+		check_unreachable_inode(trans, &iter, k);
+	}));
 }
 
 static inline bool btree_matches_i_mode(enum btree_id btree, unsigned mode)
@@ -2022,9 +2033,13 @@ int bch2_check_extents(struct bch_fs *c)
 	CLASS(inode_walker, w)();
 	CLASS(extent_ends, extent_ends)();
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_extents));
+
 	int ret = for_each_btree_key(trans, iter, BTREE_ID_extents,
 				POS(BCACHEFS_ROOT_INO, 0),
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k, ({
+			progress_update_iter(trans, &progress, &iter);
 			bch2_disk_reservation_put(c, &res);
 			check_extent(trans, &iter, k, &w, &s, &extent_ends, &res);
 		})) ?:
@@ -2039,11 +2054,15 @@ int bch2_check_indirect_extents(struct bch_fs *c)
 	CLASS(btree_trans, trans)(c);
 	struct disk_reservation res = { 0 };
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_reflink));
+
 	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_reflink,
 				POS_MIN,
 				BTREE_ITER_prefetch, k,
 				&res, NULL,
 				BCH_TRANS_COMMIT_no_enospc, ({
+			progress_update_iter(trans, &progress, &iter);
 			bch2_disk_reservation_put(c, &res);
 			check_extent_overbig(trans, &iter, k);
 		}));
@@ -2452,15 +2471,20 @@ int bch2_check_dirents(struct bch_fs *c)
 	CLASS(snapshots_seen, s)();
 	CLASS(inode_walker, dir)();
 	CLASS(inode_walker, target)();
+	struct progress_indicator_state progress;
 	bool need_second_pass = false, did_second_pass = false;
 	int ret;
 again:
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_dirents));
+
 	ret = for_each_btree_key_commit(trans, iter, BTREE_ID_dirents,
 				POS(BCACHEFS_ROOT_INO, 0),
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
-				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
+				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
+			progress_update_iter(trans, &progress, &iter);
 			check_dirent(trans, &iter, k, &hash_info, &dir, &target, &s,
-				     &need_second_pass)) ?:
+				     &need_second_pass);
+		})) ?:
 		check_subdir_count_notnested(trans, &dir);
 
 	if (!ret && need_second_pass && !did_second_pass) {
@@ -2520,13 +2544,18 @@ int bch2_check_xattrs(struct bch_fs *c)
 	CLASS(btree_trans, trans)(c);
 	CLASS(inode_walker, inode)();
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_xattrs));
+
 	int ret = for_each_btree_key_commit(trans, iter, BTREE_ID_xattrs,
 			POS(BCACHEFS_ROOT_INO, 0),
 			BTREE_ITER_prefetch|BTREE_ITER_all_snapshots,
 			k,
 			NULL, NULL,
-			BCH_TRANS_COMMIT_no_enospc,
-		check_xattr(trans, &iter, k, &hash_info, &inode));
+			BCH_TRANS_COMMIT_no_enospc, ({
+		progress_update_iter(trans, &progress, &iter);
+		check_xattr(trans, &iter, k, &hash_info, &inode);
+	}));
 	return ret;
 }
 
@@ -2668,10 +2697,16 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 int bch2_check_subvolume_structure(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
+
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_subvolumes));
+
 	return for_each_btree_key_commit(trans, iter,
 				BTREE_ID_subvolumes, POS_MIN, BTREE_ITER_prefetch, k,
-				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			check_subvol_path(trans, &iter, k));
+				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
+			progress_update_iter(trans, &progress, &iter);
+			check_subvol_path(trans, &iter, k);
+	}));
 }
 
 static int bch2_bi_depth_renumber_one(struct btree_trans *trans,
diff --git a/fs/bcachefs/lru.c b/fs/bcachefs/lru.c
index ee14656c3fdd..76109b37d681 100644
--- a/fs/bcachefs/lru.c
+++ b/fs/bcachefs/lru.c
@@ -9,6 +9,7 @@
 #include "ec.h"
 #include "error.h"
 #include "lru.h"
+#include "progress.h"
 #include "recovery.h"
 
 /* KEY_TYPE_lru is obsolete: */
@@ -207,11 +208,16 @@ int bch2_check_lrus(struct bch_fs *c)
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_lru));
+
 	CLASS(btree_trans, trans)(c);
 	int ret = for_each_btree_key_commit(trans, iter,
 				BTREE_ID_lru, POS_MIN, BTREE_ITER_prefetch, k,
-				NULL, NULL, BCH_TRANS_COMMIT_no_enospc,
-			bch2_check_lru_key(trans, &iter, k, &last_flushed));
+				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
+		progress_update_iter(trans, &progress, &iter);
+		bch2_check_lru_key(trans, &iter, k, &last_flushed);
+	}));
 
 	bch2_bkey_buf_exit(&last_flushed, c);
 	return ret;
diff --git a/fs/bcachefs/progress.c b/fs/bcachefs/progress.c
index 42353067ba28..792fc6fef270 100644
--- a/fs/bcachefs/progress.c
+++ b/fs/bcachefs/progress.c
@@ -52,7 +52,8 @@ void bch2_progress_update_iter(struct btree_trans *trans,
 			: 0;
 
 		prt_printf(&buf, "%s: %d%%, done %llu/%llu nodes, at ",
-			   msg, percent, s->nodes_seen, s->nodes_total);
+			   strip_bch2(msg),
+			   percent, s->nodes_seen, s->nodes_total);
 		bch2_bbpos_to_text(&buf, BBPOS(iter->btree_id, iter->pos));
 
 		bch_info(c, "%s", buf.buf);
diff --git a/fs/bcachefs/progress.h b/fs/bcachefs/progress.h
index 23fb1811f943..972a73087ffe 100644
--- a/fs/bcachefs/progress.h
+++ b/fs/bcachefs/progress.h
@@ -26,4 +26,7 @@ void bch2_progress_update_iter(struct btree_trans *,
 			       struct btree_iter *,
 			       const char *);
 
+#define progress_update_iter(trans, p, iter)			\
+	bch2_progress_update_iter(trans, p, iter, __func__)
+
 #endif /* _BCACHEFS_PROGRESS_H */
diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index 32fa7cf90b63..c7e7f508fd0b 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -15,6 +15,7 @@
 #include "inode.h"
 #include "io_write.h"
 #include "move.h"
+#include "progress.h"
 #include "rebalance.h"
 #include "subvolume.h"
 #include "super-io.h"
@@ -858,7 +859,12 @@ int bch2_check_rebalance_work(struct bch_fs *c)
 	bch2_bkey_buf_init(&last_flushed);
 	bkey_init(&last_flushed.k->k);
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_rebalance_work));
+
 	while (!ret) {
+		progress_update_iter(trans, &progress, &rebalance_iter);
+
 		bch2_trans_begin(trans);
 
 		ret = check_rebalance_work_one(trans, &extent_iter, &rebalance_iter, &last_flushed);
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 7a801513b134..3c3cdad79d30 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -11,6 +11,7 @@
 #include "errcode.h"
 #include "error.h"
 #include "fs.h"
+#include "progress.h"
 #include "recovery_passes.h"
 #include "snapshot.h"
 
@@ -973,12 +974,16 @@ int bch2_reconstruct_snapshots(struct bch_fs *c)
 	struct snapshot_tree_reconstruct r = {};
 	int ret = 0;
 
+	struct progress_indicator_state progress;
+	bch2_progress_init(&progress, c, btree_has_snapshots_mask);
+
 	for (unsigned btree = 0; btree < BTREE_ID_NR; btree++) {
 		if (btree_type_has_snapshots(btree)) {
 			r.btree = btree;
 
 			ret = for_each_btree_key(trans, iter, btree, POS_MIN,
 					BTREE_ITER_all_snapshots|BTREE_ITER_prefetch, k, ({
+				progress_update_iter(trans, &progress, &iter);
 				get_snapshot_trees(c, &r, k.k->p);
 			}));
 			if (ret)
-- 
2.51.0


From 3cf99aee74fa340efb39aafc076a6847e7b0d998 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 20 Jul 2025 22:22:52 -0400
Subject: [PATCH 196/309] bcachefs: recovery_pass_will_run()

Add a proper helper for "we're still in recovery and we're going to run
a pass", for bch2_snapshot_is_ancestor() - this fixes an incorrect check
that was causing it to run the slowpath unnecessarily.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery_passes.h | 6 ++++++
 fs/bcachefs/snapshot.c        | 2 +-
 2 files changed, 7 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/recovery_passes.h b/fs/bcachefs/recovery_passes.h
index 4f2c2f811d5e..95e3612bb96c 100644
--- a/fs/bcachefs/recovery_passes.h
+++ b/fs/bcachefs/recovery_passes.h
@@ -26,6 +26,12 @@ static inline bool go_rw_in_recovery(struct bch_fs *c)
 		(c->opts.fsck && !(c->sb.features & BIT_ULL(BCH_FEATURE_no_alloc_info))));
 }
 
+static inline bool recovery_pass_will_run(struct bch_fs *c, enum bch_recovery_pass pass)
+{
+	return unlikely(test_bit(BCH_FS_in_recovery, &c->flags) &&
+			c->recovery.passes_to_run & BIT_ULL(pass));
+}
+
 int bch2_run_print_explicit_recovery_pass(struct bch_fs *, enum bch_recovery_pass);
 
 int __bch2_run_explicit_recovery_pass(struct bch_fs *, struct printbuf *,
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 3c3cdad79d30..c1419afe4239 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -143,7 +143,7 @@ bool __bch2_snapshot_is_ancestor(struct bch_fs *c, u32 id, u32 ancestor)
 	guard(rcu)();
 	struct snapshot_table *t = rcu_dereference(c->snapshots);
 
-	if (unlikely(c->recovery.pass_done < BCH_RECOVERY_PASS_check_snapshots))
+	if (unlikely(recovery_pass_will_run(c, BCH_RECOVERY_PASS_check_snapshots)))
 		return __bch2_snapshot_is_ancestor_early(t, id, ancestor);
 
 	if (likely(ancestor >= IS_ANCESTOR_BITMAP))
-- 
2.51.0


From ac97c2f849a71fcc6b60126544c698edd731e1f8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 21 Jul 2025 13:30:19 -0400
Subject: [PATCH 197/309] bcachefs: journal_entry_btree_keys_to_text() is more
 careful

to_text() functions run on data structures that haven't passed
validation, so they need to be more careful with bounds checks.

Reported-by: syzbot+4e41a25632658c77b441@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_io.c | 15 +++++++++++----
 1 file changed, 11 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 47224666d07e..093e4acad085 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -428,15 +428,22 @@ static void journal_entry_btree_keys_to_text(struct printbuf *out, struct bch_fs
 	bool first = true;
 
 	jset_entry_for_each_key(entry, k) {
-		/* We may be called on entries that haven't been validated: */
-		if (!k->k.u64s)
-			break;
-
 		if (!first) {
 			prt_newline(out);
 			bch2_prt_jset_entry_type(out, entry->type);
 			prt_str(out, ": ");
 		}
+		/* We may be called on entries that haven't been validated: */
+		if (!k->k.u64s) {
+			prt_str(out, "(invalid, k->u64s 0)");
+			break;
+		}
+
+		if (bkey_next(k) > vstruct_last(entry)) {
+			prt_str(out, "(invalid, bkey overruns jset_entry)");
+			break;
+		}
+
 		bch2_btree_id_level_to_text(out, entry->btree_id, entry->level);
 		prt_char(out, ' ');
 		bch2_bkey_val_to_text(out, c, bkey_i_to_s_c(k));
-- 
2.51.0


From 90be4e83c2076bc91642d8bc1b70b4fa04aa9da1 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 21 Jul 2025 13:26:55 -0400
Subject: [PATCH 198/309] bcachefs: dirent_to_text() now uses prt_bytes()

Small optimization, calling into vsprintf() is heavy.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/dirent.c | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index dd60c47528da..1b891ac43053 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -214,11 +214,13 @@ void bch2_dirent_to_text(struct printbuf *out, struct bch_fs *c, struct bkey_s_c
 	struct bkey_s_c_dirent d = bkey_s_c_to_dirent(k);
 	struct qstr d_name = bch2_dirent_get_name(d);
 
-	prt_printf(out, "%.*s", d_name.len, d_name.name);
+	prt_bytes(out, d_name.name, d_name.len);
 
 	if (d.v->d_casefold) {
+		prt_str(out, " (casefold ");
 		struct qstr d_name = bch2_dirent_get_lookup_name(d);
-		prt_printf(out, " (casefold %.*s)", d_name.len, d_name.name);
+		prt_bytes(out, d_name.name, d_name.len);
+		prt_char(out, ')');
 	}
 
 	prt_str(out, " ->");
-- 
2.51.0


From 94fb407a99a6f94a9c97d8cdebeee679266cc690 Mon Sep 17 00:00:00 2001
From: Anindya Sundar Gayen <anindya19@gmail.com>
Date: Tue, 22 Jul 2025 23:53:10 +0530
Subject: [PATCH 199/309] bcachefs: remove extraneous ; after statements

There are a couple of statements with two following semicolons, replace
these with just one semicolon.

Signed-off-by: Anindya Sundar Gayen <anindya19@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_cache.c | 2 +-
 fs/bcachefs/btree_io.c    | 2 +-
 fs/bcachefs/btree_iter.c  | 2 +-
 fs/bcachefs/btree_types.h | 2 +-
 fs/bcachefs/fast_list.h   | 2 +-
 fs/bcachefs/journal.c     | 2 +-
 6 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/btree_cache.c b/fs/bcachefs/btree_cache.c
index e0679980508c..2f7c384a8c81 100644
--- a/fs/bcachefs/btree_cache.c
+++ b/fs/bcachefs/btree_cache.c
@@ -510,7 +510,7 @@ static unsigned long bch2_btree_cache_scan(struct shrinker *shrink,
 		if (btree_node_accessed(b)) {
 			clear_btree_node_accessed(b);
 			bc->not_freed[BCH_BTREE_CACHE_NOT_FREED_access_bit]++;
-			--touched;;
+			--touched;
 		} else if (!btree_node_reclaim(c, b)) {
 			__bch2_btree_node_hash_remove(bc, b);
 			__btree_node_data_free(b);
diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index 83c836080ea2..8a03cd75a64f 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -2011,7 +2011,7 @@ static void btree_node_scrub_work(struct work_struct *work)
 			bch_err_fn_ratelimited(c, ret);
 	}
 
-	bch2_bkey_buf_exit(&scrub->key, c);;
+	bch2_bkey_buf_exit(&scrub->key, c);
 	btree_bounce_free(c, c->opts.btree_node_size, scrub->used_mempool, scrub->buf);
 	enumerated_ref_put(&scrub->ca->io_ref[READ], BCH_DEV_READ_REF_btree_node_scrub);
 	kfree(scrub);
diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index a282c3886168..dd716b35a11d 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2744,7 +2744,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 	}
 
 	/* Extents can straddle iter->pos: */
-	iter->pos = bpos_min(iter->pos, k.k->p);;
+	iter->pos = bpos_min(iter->pos, k.k->p);
 
 	if (iter->flags & BTREE_ITER_filter_snapshots)
 		iter->pos.snapshot = iter->snapshot;
diff --git a/fs/bcachefs/btree_types.h b/fs/bcachefs/btree_types.h
index e6177b747216..e4870fbc11d0 100644
--- a/fs/bcachefs/btree_types.h
+++ b/fs/bcachefs/btree_types.h
@@ -485,7 +485,7 @@ typedef DARRAY(struct trans_kmalloc_trace) darray_trans_kmalloc_trace;
 struct btree_trans_subbuf {
 	u16			base;
 	u16			u64s;
-	u16			size;;
+	u16			size;
 };
 
 struct btree_trans {
diff --git a/fs/bcachefs/fast_list.h b/fs/bcachefs/fast_list.h
index 73c9bf591fd6..f67df3f72ee2 100644
--- a/fs/bcachefs/fast_list.h
+++ b/fs/bcachefs/fast_list.h
@@ -9,7 +9,7 @@ struct fast_list_pcpu;
 
 struct fast_list {
 	GENRADIX(void *)	items;
-	struct ida		slots_allocated;;
+	struct ida		slots_allocated;
 	struct fast_list_pcpu __percpu
 				*buffer;
 };
diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index a4f43c550ad7..07869436a964 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -1296,7 +1296,7 @@ int bch2_dev_journal_bucket_delete(struct bch_dev *ca, u64 b)
 		return -EINVAL;
 	}
 
-	u64 *new_buckets = kcalloc(ja->nr, sizeof(u64), GFP_KERNEL);;
+	u64 *new_buckets = kcalloc(ja->nr, sizeof(u64), GFP_KERNEL);
 	if (!new_buckets)
 		return bch_err_throw(c, ENOMEM_set_nr_journal_buckets);
 
-- 
2.51.0


From 0f3b086842c5be1dc94e68fb79aa76839f622acd Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 22 Jul 2025 18:41:14 -0400
Subject: [PATCH 200/309] bcachefs: Add missing ei_last_dirtied update

ei_last_dirtied tracks the process that last dirtied a file, it's used
for segregating writes from different processes into different
writepoints.

But bch2_page_mkwrite() was missing it, leading to a KMSAN splat.

Reported-by: syzbot+2caec1f3fc52004d4f3c@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-pagecache.c | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/fs/bcachefs/fs-io-pagecache.c b/fs/bcachefs/fs-io-pagecache.c
index 2a6705186c44..469492f6264a 100644
--- a/fs/bcachefs/fs-io-pagecache.c
+++ b/fs/bcachefs/fs-io-pagecache.c
@@ -635,6 +635,8 @@ vm_fault_t bch2_page_mkwrite(struct vm_fault *vmf)
 		goto out;
 	}
 
+	inode->ei_last_dirtied = (unsigned long) current;
+
 	bch2_set_folio_dirty(c, inode, folio, &res, offset, len);
 	bch2_folio_reservation_put(c, inode, &res);
 
-- 
2.51.0


From f9d8f265859de4ff331960ea4f6dd385ff8dfedb Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 22 Jul 2025 13:43:27 -0400
Subject: [PATCH 201/309] bcachefs: snapshots: pass snapshot_table where
 appropriate

Once we have rcu_lock() we shouldn't reload c->snapshots.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/snapshot.c | 34 +++++++++++++++++++---------------
 fs/bcachefs/snapshot.h | 30 +++++++++++++++++++-----------
 2 files changed, 38 insertions(+), 26 deletions(-)

diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index c1419afe4239..8c24e2a93041 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -365,31 +365,32 @@ int bch2_snapshot_lookup(struct btree_trans *trans, u32 id,
 
 /* fsck: */
 
-static u32 bch2_snapshot_child(struct bch_fs *c, u32 id, unsigned child)
+static u32 bch2_snapshot_child(struct snapshot_table *t,
+			       u32 id, unsigned child)
 {
-	return snapshot_t(c, id)->children[child];
+	return __snapshot_t(t, id)->children[child];
 }
 
-static u32 bch2_snapshot_left_child(struct bch_fs *c, u32 id)
+static u32 bch2_snapshot_left_child(struct snapshot_table *t, u32 id)
 {
-	return bch2_snapshot_child(c, id, 0);
+	return bch2_snapshot_child(t, id, 0);
 }
 
-static u32 bch2_snapshot_right_child(struct bch_fs *c, u32 id)
+static u32 bch2_snapshot_right_child(struct snapshot_table *t, u32 id)
 {
-	return bch2_snapshot_child(c, id, 1);
+	return bch2_snapshot_child(t, id, 1);
 }
 
-static u32 bch2_snapshot_tree_next(struct bch_fs *c, u32 id)
+static u32 bch2_snapshot_tree_next(struct snapshot_table *t, u32 id)
 {
 	u32 n, parent;
 
-	n = bch2_snapshot_left_child(c, id);
+	n = bch2_snapshot_left_child(t, id);
 	if (n)
 		return n;
 
-	while ((parent = bch2_snapshot_parent(c, id))) {
-		n = bch2_snapshot_right_child(c, parent);
+	while ((parent = __bch2_snapshot_parent(t, id))) {
+		n = bch2_snapshot_right_child(t, parent);
 		if (n && n != id)
 			return n;
 		id = parent;
@@ -402,17 +403,18 @@ u32 bch2_snapshot_oldest_subvol(struct bch_fs *c, u32 snapshot_root,
 				snapshot_id_list *skip)
 {
 	guard(rcu)();
+	struct snapshot_table *t = rcu_dereference(c->snapshots);
 	u32 id, subvol = 0, s;
 retry:
 	id = snapshot_root;
-	while (id && bch2_snapshot_exists(c, id)) {
+	while (id && __bch2_snapshot_exists(t, id)) {
 		if (!(skip && snapshot_list_has_id(skip, id))) {
-			s = snapshot_t(c, id)->subvol;
+			s = __snapshot_t(t, id)->subvol;
 
 			if (s && (!subvol || s < subvol))
 				subvol = s;
 		}
-		id = bch2_snapshot_tree_next(c, id);
+		id = bch2_snapshot_tree_next(t, id);
 		if (id == snapshot_root)
 			break;
 	}
@@ -1717,12 +1719,14 @@ static inline u32 bch2_snapshot_nth_parent_skip(struct bch_fs *c, u32 id, u32 n,
 						interior_delete_list *skip)
 {
 	guard(rcu)();
+	struct snapshot_table *t = rcu_dereference(c->snapshots);
+
 	while (interior_delete_has_id(skip, id))
-		id = __bch2_snapshot_parent(c, id);
+		id = __bch2_snapshot_parent(t, id);
 
 	while (n--) {
 		do {
-			id = __bch2_snapshot_parent(c, id);
+			id = __bch2_snapshot_parent(t, id);
 		} while (interior_delete_has_id(skip, id));
 	}
 
diff --git a/fs/bcachefs/snapshot.h b/fs/bcachefs/snapshot.h
index 6dcb118b0fbd..fef32a0118c4 100644
--- a/fs/bcachefs/snapshot.h
+++ b/fs/bcachefs/snapshot.h
@@ -63,19 +63,19 @@ static inline u32 bch2_snapshot_parent_early(struct bch_fs *c, u32 id)
 	return __bch2_snapshot_parent_early(c, id);
 }
 
-static inline u32 __bch2_snapshot_parent(struct bch_fs *c, u32 id)
+static inline u32 __bch2_snapshot_parent(struct snapshot_table *t, u32 id)
 {
-	const struct snapshot_t *s = snapshot_t(c, id);
+	const struct snapshot_t *s = __snapshot_t(t, id);
 	if (!s)
 		return 0;
 
 	u32 parent = s->parent;
 	if (IS_ENABLED(CONFIG_BCACHEFS_DEBUG) &&
 	    parent &&
-	    s->depth != snapshot_t(c, parent)->depth + 1)
+	    s->depth != __snapshot_t(t, parent)->depth + 1)
 		panic("id %u depth=%u parent %u depth=%u\n",
-		      id, snapshot_t(c, id)->depth,
-		      parent, snapshot_t(c, parent)->depth);
+		      id, __snapshot_t(t, id)->depth,
+		      parent, __snapshot_t(t, parent)->depth);
 
 	return parent;
 }
@@ -83,14 +83,16 @@ static inline u32 __bch2_snapshot_parent(struct bch_fs *c, u32 id)
 static inline u32 bch2_snapshot_parent(struct bch_fs *c, u32 id)
 {
 	guard(rcu)();
-	return __bch2_snapshot_parent(c, id);
+	return __bch2_snapshot_parent(rcu_dereference(c->snapshots), id);
 }
 
 static inline u32 bch2_snapshot_nth_parent(struct bch_fs *c, u32 id, u32 n)
 {
 	guard(rcu)();
+	struct snapshot_table *t = rcu_dereference(c->snapshots);
+
 	while (n--)
-		id = __bch2_snapshot_parent(c, id);
+		id = __bch2_snapshot_parent(t, id);
 	return id;
 }
 
@@ -100,23 +102,29 @@ u32 bch2_snapshot_skiplist_get(struct bch_fs *, u32);
 static inline u32 bch2_snapshot_root(struct bch_fs *c, u32 id)
 {
 	guard(rcu)();
+	struct snapshot_table *t = rcu_dereference(c->snapshots);
 
 	u32 parent;
-	while ((parent = __bch2_snapshot_parent(c, id)))
+	while ((parent = __bch2_snapshot_parent(t, id)))
 		id = parent;
 	return id;
 }
 
-static inline enum snapshot_id_state __bch2_snapshot_id_state(struct bch_fs *c, u32 id)
+static inline enum snapshot_id_state __bch2_snapshot_id_state(struct snapshot_table *t, u32 id)
 {
-	const struct snapshot_t *s = snapshot_t(c, id);
+	const struct snapshot_t *s = __snapshot_t(t, id);
 	return s ? s->state : SNAPSHOT_ID_empty;
 }
 
 static inline enum snapshot_id_state bch2_snapshot_id_state(struct bch_fs *c, u32 id)
 {
 	guard(rcu)();
-	return __bch2_snapshot_id_state(c, id);
+	return __bch2_snapshot_id_state(rcu_dereference(c->snapshots), id);
+}
+
+static inline bool __bch2_snapshot_exists(struct snapshot_table *t, u32 id)
+{
+	return __bch2_snapshot_id_state(t, id) == SNAPSHOT_ID_live;
 }
 
 static inline bool bch2_snapshot_exists(struct bch_fs *c, u32 id)
-- 
2.51.0


From 77058295d7c60e660f5253e743201b0e87add908 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 22 Jul 2025 18:57:26 -0400
Subject: [PATCH 202/309] bcachefs: live_child() no longer uses recursion

We already had helpers for doing a snapshot tree walk without recursion
- this fixes a stack overflow for a user with lots of snapshots.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/snapshot.c | 40 ++++++++++++----------------------------
 1 file changed, 12 insertions(+), 28 deletions(-)

diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 8c24e2a93041..5370ccb85d2d 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -1431,38 +1431,22 @@ static inline u32 interior_delete_has_id(interior_delete_list *l, u32 id)
 	return i ? i->live_child : 0;
 }
 
-static unsigned __live_child(struct snapshot_table *t, u32 id,
-			     snapshot_id_list *delete_leaves,
-			     interior_delete_list *delete_interior)
-{
-	struct snapshot_t *s = __snapshot_t(t, id);
-	if (!s)
-		return 0;
-
-	for (unsigned i = 0; i < ARRAY_SIZE(s->children); i++)
-		if (s->children[i] &&
-		    !snapshot_list_has_id(delete_leaves, s->children[i]) &&
-		    !interior_delete_has_id(delete_interior, s->children[i]))
-			return s->children[i];
-
-	for (unsigned i = 0; i < ARRAY_SIZE(s->children); i++) {
-		u32 live_child = s->children[i]
-			? __live_child(t, s->children[i], delete_leaves, delete_interior)
-			: 0;
-		if (live_child)
-			return live_child;
-	}
-
-	return 0;
-}
-
-static unsigned live_child(struct bch_fs *c, u32 id)
+static unsigned live_child(struct bch_fs *c, u32 start)
 {
 	struct snapshot_delete *d = &c->snapshot_delete;
 
 	guard(rcu)();
-	return __live_child(rcu_dereference(c->snapshots), id,
-			    &d->delete_leaves, &d->delete_interior);
+	struct snapshot_table *t = rcu_dereference(c->snapshots);
+
+	for (u32 id = bch2_snapshot_tree_next(t, start);
+	     id && id != start;
+	     id = bch2_snapshot_tree_next(t, id))
+		if (bch2_snapshot_is_leaf(c, id) &&
+		    !snapshot_list_has_id(&d->delete_leaves, id) &&
+		    !interior_delete_has_id(&d->delete_interior, id))
+			return id;
+
+	return 0;
 }
 
 static bool snapshot_id_dying(struct snapshot_delete *d, unsigned id)
-- 
2.51.0


From c0d938c16b674bfe9e710579344653b703b92a49 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 24 Jul 2025 13:52:03 -0400
Subject: [PATCH 203/309] bcachefs: Add missing error_throw to
 bch2_set_version_incompat()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super-io.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index 40fa87ce1d09..c88759964575 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -79,7 +79,7 @@ int bch2_set_version_incompat(struct bch_fs *c, enum bcachefs_metadata_version v
 	} else {
 		darray_for_each(c->incompat_versions_requested, i)
 			if (version == *i)
-				return -BCH_ERR_may_not_use_incompat_feature;
+				return bch_err_throw(c, may_not_use_incompat_feature);
 
 		darray_push(&c->incompat_versions_requested, version);
 		CLASS(printbuf, buf)();
@@ -90,7 +90,7 @@ int bch2_set_version_incompat(struct bch_fs *c, enum bcachefs_metadata_version v
 		prt_printf(&buf, "\n  set version_upgrade=incompat to enable");
 
 		bch_notice(c, "%s", buf.buf);
-		return -BCH_ERR_may_not_use_incompat_feature;
+		return bch_err_throw(c, may_not_use_incompat_feature);
 	}
 }
 
-- 
2.51.0


From 986cef178c949afda68367503d8cbce3da879aa3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 16:15:56 -0400
Subject: [PATCH 204/309] bcachefs: inum_to_path() now prints inum when
 disconnected

When we're using this in fsck, we need to make sure we don't lose
information vs. just printing the inum.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/namei.c | 44 +++++++++++++++++++++++++++++++-------------
 1 file changed, 31 insertions(+), 13 deletions(-)

diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index 8fa108880f58..70ec5a015479 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -591,6 +591,22 @@ int bch2_rename_trans(struct btree_trans *trans,
 
 /* inum_to_path */
 
+static inline void reverse_bytes(void *b, size_t n)
+{
+	char *e = b + n, *s = b;
+
+	while (s < e) {
+		--e;
+		swap(*s, *e);
+		s++;
+	}
+}
+
+static inline void printbuf_reverse_from(struct printbuf *out, unsigned pos)
+{
+	reverse_bytes(out->buf + pos, out->pos - pos);
+}
+
 static inline void prt_bytes_reversed(struct printbuf *out, const void *b, unsigned n)
 {
 	bch2_printbuf_make_room(out, n);
@@ -610,15 +626,17 @@ static inline void prt_str_reversed(struct printbuf *out, const char *s)
 	prt_bytes_reversed(out, s, strlen(s));
 }
 
-static inline void reverse_bytes(void *b, size_t n)
+__printf(2, 3)
+static inline void prt_printf_reversed(struct printbuf *out, const char *fmt, ...)
 {
-	char *e = b + n, *s = b;
+	unsigned orig_pos = out->pos;
 
-	while (s < e) {
-		--e;
-		swap(*s, *e);
-		s++;
-	}
+	va_list args;
+	va_start(args, fmt);
+	prt_vprintf(out, fmt, args);
+	va_end(args);
+
+	printbuf_reverse_from(out, orig_pos);
 }
 
 static int __bch2_inum_to_path(struct btree_trans *trans,
@@ -639,7 +657,7 @@ static int __bch2_inum_to_path(struct btree_trans *trans,
 		subvol_inum n = (subvol_inum) { subvol ?: snapshot, inum };
 
 		if (darray_find_p(inums, i, i->subvol == n.subvol && i->inum == n.inum)) {
-			prt_str_reversed(path, "(loop)");
+			prt_printf_reversed(path, "(loop at %llu:%u)", inum, snapshot);
 			break;
 		}
 
@@ -689,21 +707,21 @@ static int __bch2_inum_to_path(struct btree_trans *trans,
 	if (orig_pos == path->pos)
 		prt_char(path, '/');
 out:
+	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
+		goto err;
+
 	ret = path->allocation_failure ? -ENOMEM : 0;
 	if (ret)
 		goto err;
 
-	reverse_bytes(path->buf + orig_pos, path->pos - orig_pos);
+	printbuf_reverse_from(path, orig_pos);
 	darray_exit(&inums);
 	return 0;
 err:
 	darray_exit(&inums);
 	return ret;
 disconnected:
-	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
-		goto err;
-
-	prt_str_reversed(path, "(disconnected)");
+	prt_printf_reversed(path, "(disconnected at %llu.%u)", inum, snapshot);
 	goto out;
 }
 
-- 
2.51.0


From c58a116db87fce5fee9b4eaa66303f97496bf79e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 18:02:18 -0400
Subject: [PATCH 205/309] bcachefs: More enum conversion

Flags should not be passed as bare integers.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c            | 13 +++---
 fs/bcachefs/btree_iter.h            | 72 ++++++++++++++++-------------
 fs/bcachefs/btree_update_interior.c |  2 +-
 3 files changed, 48 insertions(+), 39 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index dd716b35a11d..4db7056b7aeb 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -891,7 +891,7 @@ static noinline void btree_node_mem_ptr_set(struct btree_trans *trans,
 
 static noinline int btree_node_iter_and_journal_peek(struct btree_trans *trans,
 						     struct btree_path *path,
-						     unsigned flags)
+						     enum btree_iter_update_trigger_flags flags)
 {
 	struct bch_fs *c = trans->c;
 	struct btree_path_level *l = path_l(path);
@@ -943,7 +943,7 @@ static noinline_for_stack int btree_node_missing_err(struct btree_trans *trans,
 
 static __always_inline int btree_path_down(struct btree_trans *trans,
 					   struct btree_path *path,
-					   unsigned flags,
+					   enum btree_iter_update_trigger_flags flags,
 					   unsigned long trace_ip)
 {
 	struct bch_fs *c = trans->c;
@@ -1151,7 +1151,7 @@ static inline unsigned btree_path_up_until_good_node(struct btree_trans *trans,
  */
 int bch2_btree_path_traverse_one(struct btree_trans *trans,
 				 btree_path_idx_t path_idx,
-				 unsigned flags,
+				 enum btree_iter_update_trigger_flags flags,
 				 unsigned long trace_ip)
 {
 	struct btree_path *path = &trans->paths[path_idx];
@@ -1732,7 +1732,8 @@ static inline btree_path_idx_t btree_path_alloc(struct btree_trans *trans,
 btree_path_idx_t bch2_path_get(struct btree_trans *trans,
 			     enum btree_id btree_id, struct bpos pos,
 			     unsigned locks_want, unsigned level,
-			     unsigned flags, unsigned long ip)
+			     enum btree_iter_update_trigger_flags flags,
+			     unsigned long ip)
 {
 	struct btree_path *path;
 	bool cached = flags & BTREE_ITER_cached;
@@ -3120,7 +3121,7 @@ void bch2_trans_iter_exit(struct btree_trans *trans, struct btree_iter *iter)
 void bch2_trans_iter_init_outlined(struct btree_trans *trans,
 			  struct btree_iter *iter,
 			  enum btree_id btree_id, struct bpos pos,
-			  unsigned flags)
+			  enum btree_iter_update_trigger_flags flags)
 {
 	bch2_trans_iter_init_common(trans, iter, btree_id, pos, 0, 0,
 			       bch2_btree_iter_flags(trans, btree_id, 0, flags),
@@ -3133,7 +3134,7 @@ void bch2_trans_node_iter_init(struct btree_trans *trans,
 			       struct bpos pos,
 			       unsigned locks_want,
 			       unsigned depth,
-			       unsigned flags)
+			       enum btree_iter_update_trigger_flags flags)
 {
 	flags |= BTREE_ITER_not_extents;
 	flags |= BTREE_ITER_snapshot_field;
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 53074ed62e09..9034fcfeed65 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -235,12 +235,14 @@ bch2_btree_path_set_pos(struct btree_trans *trans,
 
 int __must_check bch2_btree_path_traverse_one(struct btree_trans *,
 					      btree_path_idx_t,
-					      unsigned, unsigned long);
+					      enum btree_iter_update_trigger_flags,
+					      unsigned long);
 
 static inline void bch2_trans_verify_not_unlocked_or_in_restart(struct btree_trans *);
 
 static inline int __must_check bch2_btree_path_traverse(struct btree_trans *trans,
-					  btree_path_idx_t path, unsigned flags)
+					  btree_path_idx_t path,
+					  enum btree_iter_update_trigger_flags flags)
 {
 	bch2_trans_verify_not_unlocked_or_in_restart(trans);
 
@@ -251,7 +253,9 @@ static inline int __must_check bch2_btree_path_traverse(struct btree_trans *tran
 }
 
 btree_path_idx_t bch2_path_get(struct btree_trans *, enum btree_id, struct bpos,
-				 unsigned, unsigned, unsigned, unsigned long);
+			       unsigned, unsigned,
+			       enum btree_iter_update_trigger_flags,
+			       unsigned long);
 btree_path_idx_t bch2_path_get_unlocked_mut(struct btree_trans *, enum btree_id,
 					    unsigned, struct bpos);
 
@@ -477,10 +481,10 @@ static inline void bch2_btree_iter_set_snapshot(struct btree_trans *trans,
 
 void bch2_trans_iter_exit(struct btree_trans *, struct btree_iter *);
 
-static inline unsigned bch2_btree_iter_flags(struct btree_trans *trans,
-					     unsigned btree_id,
-					     unsigned level,
-					     unsigned flags)
+static inline enum btree_iter_update_trigger_flags
+bch2_btree_iter_flags(struct btree_trans *trans,
+		      unsigned btree_id, unsigned level,
+		      enum btree_iter_update_trigger_flags flags)
 {
 	if (level || !btree_id_cached(trans->c, btree_id)) {
 		flags &= ~BTREE_ITER_cached;
@@ -508,15 +512,15 @@ static inline unsigned bch2_btree_iter_flags(struct btree_trans *trans,
 
 static inline void bch2_trans_iter_init_common(struct btree_trans *trans,
 					  struct btree_iter *iter,
-					  unsigned btree_id, struct bpos pos,
+					  enum btree_id btree, struct bpos pos,
 					  unsigned locks_want,
 					  unsigned depth,
-					  unsigned flags,
+					  enum btree_iter_update_trigger_flags flags,
 					  unsigned long ip)
 {
 	iter->update_path	= 0;
 	iter->key_cache_path	= 0;
-	iter->btree_id		= btree_id;
+	iter->btree_id		= btree;
 	iter->min_depth		= 0;
 	iter->flags		= flags;
 	iter->snapshot		= pos.snapshot;
@@ -526,30 +530,32 @@ static inline void bch2_trans_iter_init_common(struct btree_trans *trans,
 #ifdef CONFIG_BCACHEFS_DEBUG
 	iter->ip_allocated = ip;
 #endif
-	iter->path = bch2_path_get(trans, btree_id, iter->pos,
-				   locks_want, depth, flags, ip);
+	iter->path = bch2_path_get(trans, btree, iter->pos, locks_want, depth, flags, ip);
 }
 
 void bch2_trans_iter_init_outlined(struct btree_trans *, struct btree_iter *,
-			  enum btree_id, struct bpos, unsigned);
+			  enum btree_id, struct bpos,
+			  enum btree_iter_update_trigger_flags);
 
 static inline void bch2_trans_iter_init(struct btree_trans *trans,
 			  struct btree_iter *iter,
-			  unsigned btree_id, struct bpos pos,
-			  unsigned flags)
+			  enum btree_id btree, struct bpos pos,
+			  enum btree_iter_update_trigger_flags flags)
 {
-	if (__builtin_constant_p(btree_id) &&
+	if (__builtin_constant_p(btree) &&
 	    __builtin_constant_p(flags))
-		bch2_trans_iter_init_common(trans, iter, btree_id, pos, 0, 0,
-				bch2_btree_iter_flags(trans, btree_id, 0, flags),
+		bch2_trans_iter_init_common(trans, iter, btree, pos, 0, 0,
+				bch2_btree_iter_flags(trans, btree, 0, flags),
 				_THIS_IP_);
 	else
-		bch2_trans_iter_init_outlined(trans, iter, btree_id, pos, flags);
+		bch2_trans_iter_init_outlined(trans, iter, btree, pos, flags);
 }
 
 void bch2_trans_node_iter_init(struct btree_trans *, struct btree_iter *,
 			       enum btree_id, struct bpos,
-			       unsigned, unsigned, unsigned);
+			       unsigned, unsigned,
+			       enum btree_iter_update_trigger_flags);
+
 void bch2_trans_copy_iter(struct btree_trans *, struct btree_iter *, struct btree_iter *);
 
 void bch2_set_btree_iter_dontneed(struct btree_trans *, struct btree_iter *);
@@ -623,12 +629,13 @@ static __always_inline void *bch2_trans_kmalloc_nomemzero(struct btree_trans *tr
 
 static inline struct bkey_s_c __bch2_bkey_get_iter(struct btree_trans *trans,
 				struct btree_iter *iter,
-				unsigned btree_id, struct bpos pos,
-				unsigned flags, unsigned type)
+				enum btree_id btree, struct bpos pos,
+				enum btree_iter_update_trigger_flags flags,
+				enum bch_bkey_type type)
 {
 	struct bkey_s_c k;
 
-	bch2_trans_iter_init(trans, iter, btree_id, pos, flags);
+	bch2_trans_iter_init(trans, iter, btree, pos, flags);
 	k = bch2_btree_iter_peek_slot(trans, iter);
 
 	if (!bkey_err(k) && type && k.k->type != type)
@@ -640,10 +647,10 @@ static inline struct bkey_s_c __bch2_bkey_get_iter(struct btree_trans *trans,
 
 static inline struct bkey_s_c bch2_bkey_get_iter(struct btree_trans *trans,
 				struct btree_iter *iter,
-				unsigned btree_id, struct bpos pos,
-				unsigned flags)
+				enum btree_id btree, struct bpos pos,
+				enum btree_iter_update_trigger_flags flags)
 {
-	return __bch2_bkey_get_iter(trans, iter, btree_id, pos, flags, 0);
+	return __bch2_bkey_get_iter(trans, iter, btree, pos, flags, 0);
 }
 
 #define bch2_bkey_get_iter_typed(_trans, _iter, _btree_id, _pos, _flags, _type)\
@@ -665,12 +672,13 @@ do {									\
 } while (0)
 
 static inline int __bch2_bkey_get_val_typed(struct btree_trans *trans,
-				unsigned btree_id, struct bpos pos,
-				unsigned flags, unsigned type,
+				enum btree_id btree, struct bpos pos,
+				enum btree_iter_update_trigger_flags flags,
+				enum bch_bkey_type type,
 				unsigned val_size, void *val)
 {
 	struct btree_iter iter;
-	struct bkey_s_c k = __bch2_bkey_get_iter(trans, &iter, btree_id, pos, flags, type);
+	struct bkey_s_c k = __bch2_bkey_get_iter(trans, &iter, btree, pos, flags, type);
 	int ret = bkey_err(k);
 	if (!ret) {
 		__bkey_val_copy(val, val_size, k);
@@ -720,7 +728,7 @@ u32 bch2_trans_begin(struct btree_trans *);
 
 static inline struct bkey_s_c bch2_btree_iter_peek_prev_type(struct btree_trans *trans,
 							     struct btree_iter *iter,
-							     unsigned flags)
+							     enum btree_iter_update_trigger_flags flags)
 {
 	return  flags & BTREE_ITER_slots      ? bch2_btree_iter_peek_slot(trans, iter) :
 						bch2_btree_iter_peek_prev(trans, iter);
@@ -728,7 +736,7 @@ static inline struct bkey_s_c bch2_btree_iter_peek_prev_type(struct btree_trans
 
 static inline struct bkey_s_c bch2_btree_iter_peek_type(struct btree_trans *trans,
 							struct btree_iter *iter,
-							unsigned flags)
+							enum btree_iter_update_trigger_flags flags)
 {
 	return  flags & BTREE_ITER_slots      ? bch2_btree_iter_peek_slot(trans, iter) :
 						bch2_btree_iter_peek(trans, iter);
@@ -737,7 +745,7 @@ static inline struct bkey_s_c bch2_btree_iter_peek_type(struct btree_trans *tran
 static inline struct bkey_s_c bch2_btree_iter_peek_max_type(struct btree_trans *trans,
 							    struct btree_iter *iter,
 							    struct bpos end,
-							    unsigned flags)
+							    enum btree_iter_update_trigger_flags flags)
 {
 	if (!(flags & BTREE_ITER_slots))
 		return bch2_btree_iter_peek_max(trans, iter, end);
diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index e4aa4fa749bc..6b0433ccf3df 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -2066,7 +2066,7 @@ int __bch2_foreground_maybe_merge(struct btree_trans *trans,
 
 	sib_path = bch2_path_get(trans, btree, sib_pos,
 				 U8_MAX, level, BTREE_ITER_intent, _THIS_IP_);
-	ret = bch2_btree_path_traverse(trans, sib_path, false);
+	ret = bch2_btree_path_traverse(trans, sib_path, 0);
 	if (ret)
 		goto err;
 
-- 
2.51.0


From 25201eae7abed78c4a043b260045c64bfb122659 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 18:22:22 -0400
Subject: [PATCH 206/309] bcachefs: Revert "Kill btree_iter.trans"

The stack usage reduction from this patch was minimal, and reverting it
lets us add CLASS() support.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/acl.c                   |   4 +-
 fs/bcachefs/alloc_background.c      |  78 ++++++------
 fs/bcachefs/alloc_foreground.c      |   8 +-
 fs/bcachefs/backpointers.c          |  10 +-
 fs/bcachefs/btree_gc.c              |   4 +-
 fs/bcachefs/btree_iter.c            | 191 ++++++++++++++--------------
 fs/bcachefs/btree_iter.h            | 118 +++++++++--------
 fs/bcachefs/btree_key_cache.c       |   8 +-
 fs/bcachefs/btree_types.h           |   1 +
 fs/bcachefs/btree_update.c          |  22 ++--
 fs/bcachefs/btree_update_interior.c |  12 +-
 fs/bcachefs/btree_write_buffer.c    |  10 +-
 fs/bcachefs/buckets.c               |   2 +-
 fs/bcachefs/data_update.c           |   8 +-
 fs/bcachefs/dirent.c                |  14 +-
 fs/bcachefs/disk_accounting.c       |   4 +-
 fs/bcachefs/ec.c                    |   4 +-
 fs/bcachefs/extent_update.c         |   6 +-
 fs/bcachefs/fs-io-buffered.c        |   6 +-
 fs/bcachefs/fs-io.c                 |  10 +-
 fs/bcachefs/fs.c                    |  12 +-
 fs/bcachefs/fsck.c                  |  22 ++--
 fs/bcachefs/inode.c                 |  16 +--
 fs/bcachefs/io_misc.c               |  18 +--
 fs/bcachefs/io_read.c               |   8 +-
 fs/bcachefs/io_write.c              |  12 +-
 fs/bcachefs/migrate.c               |   4 +-
 fs/bcachefs/move.c                  |  16 +--
 fs/bcachefs/namei.c                 |  36 +++---
 fs/bcachefs/quota.c                 |   2 +-
 fs/bcachefs/rebalance.c             |  20 +--
 fs/bcachefs/recovery.c              |   6 +-
 fs/bcachefs/reflink.c               |  21 ++-
 fs/bcachefs/snapshot.c              |  12 +-
 fs/bcachefs/str_hash.h              |   8 +-
 fs/bcachefs/subvolume.c             |   4 +-
 fs/bcachefs/subvolume.h             |  14 +-
 fs/bcachefs/tests.c                 |  30 ++---
 fs/bcachefs/xattr.c                 |   2 +-
 39 files changed, 391 insertions(+), 392 deletions(-)

diff --git a/fs/bcachefs/acl.c b/fs/bcachefs/acl.c
index 8f970dc19dea..0098cd1cc002 100644
--- a/fs/bcachefs/acl.c
+++ b/fs/bcachefs/acl.c
@@ -273,7 +273,7 @@ struct posix_acl *bch2_get_acl(struct inode *vinode, int type, bool rcu)
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
 	struct bch_hash_info hash = bch2_hash_info_init(c, &inode->ei_inode);
 	struct xattr_search_key search = X_SEARCH(acl_to_xattr_type(type), "", 0);
-	struct btree_iter iter = {};
+	struct btree_iter iter = { NULL };
 	struct posix_acl *acl = NULL;
 
 	if (rcu)
@@ -343,7 +343,7 @@ int bch2_set_acl(struct mnt_idmap *idmap,
 {
 	struct bch_inode_info *inode = to_bch_ei(dentry->d_inode);
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	struct btree_iter inode_iter = {};
+	struct btree_iter inode_iter = { NULL };
 	struct bch_inode_unpacked inode_u;
 	struct posix_acl *acl;
 	umode_t mode;
diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index 55c21e9b4c52..9bdc70d23f4c 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -640,7 +640,7 @@ int bch2_alloc_read(struct bch_fs *c)
 			 * bch2_check_alloc_key() which runs later:
 			 */
 			if (!ca) {
-				bch2_btree_iter_set_pos(trans, &iter, POS(k.k->p.inode + 1, 0));
+				bch2_btree_iter_set_pos(&iter, POS(k.k->p.inode + 1, 0));
 				continue;
 			}
 
@@ -661,17 +661,17 @@ int bch2_alloc_read(struct bch_fs *c)
 			 * bch2_check_alloc_key() which runs later:
 			 */
 			if (!ca) {
-				bch2_btree_iter_set_pos(trans, &iter, POS(k.k->p.inode + 1, 0));
+				bch2_btree_iter_set_pos(&iter, POS(k.k->p.inode + 1, 0));
 				continue;
 			}
 
 			if (k.k->p.offset < ca->mi.first_bucket) {
-				bch2_btree_iter_set_pos(trans, &iter, POS(k.k->p.inode, ca->mi.first_bucket));
+				bch2_btree_iter_set_pos(&iter, POS(k.k->p.inode, ca->mi.first_bucket));
 				continue;
 			}
 
 			if (k.k->p.offset >= ca->mi.nbuckets) {
-				bch2_btree_iter_set_pos(trans, &iter, POS(k.k->p.inode + 1, 0));
+				bch2_btree_iter_set_pos(&iter, POS(k.k->p.inode + 1, 0));
 				continue;
 			}
 
@@ -1044,10 +1044,9 @@ int bch2_trigger_alloc(struct btree_trans *trans,
  * This synthesizes deleted extents for holes, similar to BTREE_ITER_slots for
  * extents style btrees, but works on non-extents btrees:
  */
-static struct bkey_s_c bch2_get_key_or_hole(struct btree_trans *trans, struct btree_iter *iter,
-					    struct bpos end, struct bkey *hole)
+static struct bkey_s_c bch2_get_key_or_hole(struct btree_iter *iter, struct bpos end, struct bkey *hole)
 {
-	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 
 	if (bkey_err(k))
 		return k;
@@ -1058,9 +1057,9 @@ static struct bkey_s_c bch2_get_key_or_hole(struct btree_trans *trans, struct bt
 		struct btree_iter iter2;
 		struct bpos next;
 
-		bch2_trans_copy_iter(trans, &iter2, iter);
+		bch2_trans_copy_iter(&iter2, iter);
 
-		struct btree_path *path = btree_iter_path(trans, iter);
+		struct btree_path *path = btree_iter_path(iter->trans, iter);
 		if (!bpos_eq(path->l[0].b->key.k.p, SPOS_MAX))
 			end = bkey_min(end, bpos_nosnap_successor(path->l[0].b->key.k.p));
 
@@ -1070,9 +1069,9 @@ static struct bkey_s_c bch2_get_key_or_hole(struct btree_trans *trans, struct bt
 		 * btree node min/max is a closed interval, upto takes a half
 		 * open interval:
 		 */
-		k = bch2_btree_iter_peek_max(trans, &iter2, end);
+		k = bch2_btree_iter_peek_max(&iter2, end);
 		next = iter2.pos;
-		bch2_trans_iter_exit(trans, &iter2);
+		bch2_trans_iter_exit(iter->trans, &iter2);
 
 		BUG_ON(next.offset >= iter->pos.offset + U32_MAX);
 
@@ -1112,14 +1111,13 @@ static bool next_bucket(struct bch_fs *c, struct bch_dev **ca, struct bpos *buck
 	return *ca != NULL;
 }
 
-static struct bkey_s_c bch2_get_key_or_real_bucket_hole(struct btree_trans *trans,
-							struct btree_iter *iter,
-							struct bch_dev **ca, struct bkey *hole)
+static struct bkey_s_c bch2_get_key_or_real_bucket_hole(struct btree_iter *iter,
+					struct bch_dev **ca, struct bkey *hole)
 {
-	struct bch_fs *c = trans->c;
+	struct bch_fs *c = iter->trans->c;
 	struct bkey_s_c k;
 again:
-	k = bch2_get_key_or_hole(trans, iter, POS_MAX, hole);
+	k = bch2_get_key_or_hole(iter, POS_MAX, hole);
 	if (bkey_err(k))
 		return k;
 
@@ -1132,7 +1130,7 @@ static struct bkey_s_c bch2_get_key_or_real_bucket_hole(struct btree_trans *tran
 			if (!next_bucket(c, ca, &hole_start))
 				return bkey_s_c_null;
 
-			bch2_btree_iter_set_pos(trans, iter, hole_start);
+			bch2_btree_iter_set_pos(iter, hole_start);
 			goto again;
 		}
 
@@ -1173,8 +1171,8 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 
 	a = bch2_alloc_to_v4(alloc_k, &a_convert);
 
-	bch2_btree_iter_set_pos(trans, discard_iter, alloc_k.k->p);
-	k = bch2_btree_iter_peek_slot(trans, discard_iter);
+	bch2_btree_iter_set_pos(discard_iter, alloc_k.k->p);
+	k = bch2_btree_iter_peek_slot(discard_iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1187,8 +1185,8 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 			return ret;
 	}
 
-	bch2_btree_iter_set_pos(trans, freespace_iter, alloc_freespace_pos(alloc_k.k->p, *a));
-	k = bch2_btree_iter_peek_slot(trans, freespace_iter);
+	bch2_btree_iter_set_pos(freespace_iter, alloc_freespace_pos(alloc_k.k->p, *a));
+	k = bch2_btree_iter_peek_slot(freespace_iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1201,8 +1199,8 @@ int bch2_check_alloc_key(struct btree_trans *trans,
 			return ret;
 	}
 
-	bch2_btree_iter_set_pos(trans, bucket_gens_iter, alloc_gens_pos(alloc_k.k->p, &gens_offset));
-	k = bch2_btree_iter_peek_slot(trans, bucket_gens_iter);
+	bch2_btree_iter_set_pos(bucket_gens_iter, alloc_gens_pos(alloc_k.k->p, &gens_offset));
+	k = bch2_btree_iter_peek_slot(bucket_gens_iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1251,9 +1249,9 @@ int bch2_check_alloc_hole_freespace(struct btree_trans *trans,
 	if (!ca->mi.freespace_initialized)
 		return 0;
 
-	bch2_btree_iter_set_pos(trans, freespace_iter, start);
+	bch2_btree_iter_set_pos(freespace_iter, start);
 
-	k = bch2_btree_iter_peek_slot(trans, freespace_iter);
+	k = bch2_btree_iter_peek_slot(freespace_iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1299,9 +1297,9 @@ int bch2_check_alloc_hole_bucket_gens(struct btree_trans *trans,
 	unsigned i, gens_offset, gens_end_offset;
 	int ret;
 
-	bch2_btree_iter_set_pos(trans, bucket_gens_iter, alloc_gens_pos(start, &gens_offset));
+	bch2_btree_iter_set_pos(bucket_gens_iter, alloc_gens_pos(start, &gens_offset));
 
-	k = bch2_btree_iter_peek_slot(trans, bucket_gens_iter);
+	k = bch2_btree_iter_peek_slot(bucket_gens_iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1436,7 +1434,7 @@ int __bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_i
 	*gen = a->gen;
 out:
 fsck_err:
-	bch2_set_btree_iter_dontneed(trans, &alloc_iter);
+	bch2_set_btree_iter_dontneed(&alloc_iter);
 	bch2_trans_iter_exit(trans, &alloc_iter);
 	return ret;
 delete:
@@ -1572,7 +1570,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 
 		bch2_trans_begin(trans);
 
-		k = bch2_get_key_or_real_bucket_hole(trans, &iter, &ca, &hole);
+		k = bch2_get_key_or_real_bucket_hole(&iter, &ca, &hole);
 		ret = bkey_err(k);
 		if (ret)
 			goto bkey_err;
@@ -1612,7 +1610,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 		if (ret)
 			goto bkey_err;
 
-		bch2_btree_iter_set_pos(trans, &iter, next);
+		bch2_btree_iter_set_pos(&iter, next);
 bkey_err:
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			continue;
@@ -1640,7 +1638,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 			     BTREE_ITER_prefetch);
 	while (1) {
 		bch2_trans_begin(trans);
-		k = bch2_btree_iter_peek(trans, &iter);
+		k = bch2_btree_iter_peek(&iter);
 		if (!k.k)
 			break;
 
@@ -1657,7 +1655,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 			break;
 		}
 
-		bch2_btree_iter_set_pos(trans, &iter, bpos_nosnap_successor(iter.pos));
+		bch2_btree_iter_set_pos(&iter, bpos_nosnap_successor(iter.pos));
 	}
 	bch2_trans_iter_exit(trans, &iter);
 	if (ret)
@@ -1683,7 +1681,7 @@ static int bch2_check_alloc_to_lru_ref(struct btree_trans *trans,
 	CLASS(printbuf, buf)();
 	int ret;
 
-	alloc_k = bch2_btree_iter_peek(trans, alloc_iter);
+	alloc_k = bch2_btree_iter_peek(alloc_iter);
 	if (!alloc_k.k)
 		return 0;
 
@@ -1799,7 +1797,7 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct bpos pos = need_discard_iter->pos;
-	struct btree_iter iter = {};
+	struct btree_iter iter = { NULL };
 	struct bkey_s_c k;
 	struct bkey_i_alloc_v4 *a;
 	CLASS(printbuf, buf)();
@@ -2175,9 +2173,9 @@ static struct bkey_s_c next_lru_key(struct btree_trans *trans, struct btree_iter
 {
 	struct bkey_s_c k;
 again:
-	k = bch2_btree_iter_peek_max(trans, iter, lru_pos(ca->dev_idx, U64_MAX, LRU_TIME_MAX));
+	k = bch2_btree_iter_peek_max(iter, lru_pos(ca->dev_idx, U64_MAX, LRU_TIME_MAX));
 	if (!k.k && !*wrapped) {
-		bch2_btree_iter_set_pos(trans, iter, lru_pos(ca->dev_idx, 0, 0));
+		bch2_btree_iter_set_pos(iter, lru_pos(ca->dev_idx, 0, 0));
 		*wrapped = true;
 		goto again;
 	}
@@ -2227,7 +2225,7 @@ static void bch2_do_invalidates_work(struct work_struct *work)
 		if (ret)
 			break;
 
-		bch2_btree_iter_advance(trans, &iter);
+		bch2_btree_iter_advance(&iter);
 	}
 	bch2_trans_iter_exit(trans, &iter);
 err:
@@ -2295,7 +2293,7 @@ int bch2_dev_freespace_init(struct bch_fs *c, struct bch_dev *ca,
 			break;
 		}
 
-		k = bch2_get_key_or_hole(trans, &iter, end, &hole);
+		k = bch2_get_key_or_hole(&iter, end, &hole);
 		ret = bkey_err(k);
 		if (ret)
 			goto bkey_err;
@@ -2314,7 +2312,7 @@ int bch2_dev_freespace_init(struct bch_fs *c, struct bch_dev *ca,
 			if (ret)
 				goto bkey_err;
 
-			bch2_btree_iter_advance(trans, &iter);
+			bch2_btree_iter_advance(&iter);
 		} else {
 			struct bkey_i *freespace;
 
@@ -2334,7 +2332,7 @@ int bch2_dev_freespace_init(struct bch_fs *c, struct bch_dev *ca,
 			if (ret)
 				goto bkey_err;
 
-			bch2_btree_iter_set_pos(trans, &iter, k.k->p);
+			bch2_btree_iter_set_pos(&iter, k.k->p);
 		}
 bkey_err:
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
diff --git a/fs/bcachefs/alloc_foreground.c b/fs/bcachefs/alloc_foreground.c
index fd1415524e46..f2123d4c7584 100644
--- a/fs/bcachefs/alloc_foreground.c
+++ b/fs/bcachefs/alloc_foreground.c
@@ -321,7 +321,7 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 			bucket = sector_to_bucket(ca,
 					round_up(bucket_to_sector(ca, bucket) + 1,
 						 1ULL << ca->mi.btree_bitmap_shift));
-			bch2_btree_iter_set_pos(trans, &iter, POS(ca->dev_idx, bucket));
+			bch2_btree_iter_set_pos(&iter, POS(ca->dev_idx, bucket));
 			req->counters.buckets_seen++;
 			req->counters.skipped_mi_btree_bitmap++;
 			continue;
@@ -348,7 +348,7 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 			? __try_alloc_bucket(c, req, k.k->p.offset, a->gen, cl)
 			: NULL;
 next:
-		bch2_set_btree_iter_dontneed(trans, &citer);
+		bch2_set_btree_iter_dontneed(&citer);
 		bch2_trans_iter_exit(trans, &citer);
 		if (ob)
 			break;
@@ -409,7 +409,7 @@ static struct open_bucket *bch2_bucket_alloc_freelist(struct btree_trans *trans,
 							 1ULL << ca->mi.btree_bitmap_shift));
 				alloc_cursor = bucket|(iter.pos.offset & (~0ULL << 56));
 
-				bch2_btree_iter_set_pos(trans, &iter, POS(ca->dev_idx, alloc_cursor));
+				bch2_btree_iter_set_pos(&iter, POS(ca->dev_idx, alloc_cursor));
 				req->counters.skipped_mi_btree_bitmap++;
 				goto next;
 			}
@@ -418,7 +418,7 @@ static struct open_bucket *bch2_bucket_alloc_freelist(struct btree_trans *trans,
 			if (ob) {
 				if (!IS_ERR(ob))
 					*dev_alloc_cursor = iter.pos.offset;
-				bch2_set_btree_iter_dontneed(trans, &iter);
+				bch2_set_btree_iter_dontneed(&iter);
 				break;
 			}
 
diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index bd26ab3e6812..e1a8eb25f8be 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -282,7 +282,7 @@ static struct btree *__bch2_backpointer_get_node(struct btree_trans *trans,
 				  0,
 				  bp.v->level - 1,
 				  0);
-	struct btree *b = bch2_btree_iter_peek_node(trans, iter);
+	struct btree *b = bch2_btree_iter_peek_node(iter);
 	if (IS_ERR_OR_NULL(b))
 		goto err;
 
@@ -322,7 +322,7 @@ static struct bkey_s_c __bch2_backpointer_get_key(struct btree_trans *trans,
 				  0,
 				  bp.v->level,
 				  iter_flags);
-	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 	if (bkey_err(k)) {
 		bch2_trans_iter_exit(trans, iter);
 		return k;
@@ -384,7 +384,7 @@ static int bch2_check_backpointer_has_valid_bucket(struct btree_trans *trans, st
 		return 0;
 
 	struct bch_fs *c = trans->c;
-	struct btree_iter alloc_iter = {};
+	struct btree_iter alloc_iter = { NULL };
 	struct bkey_s_c alloc_k;
 	CLASS(printbuf, buf)();
 	int ret = 0;
@@ -720,7 +720,7 @@ static int check_btree_root_to_backpointers(struct btree_trans *trans,
 retry:
 	bch2_trans_node_iter_init(trans, &iter, btree_id, POS_MIN,
 				  0, bch2_btree_id_root(c, btree_id)->b->c.level, 0);
-	b = bch2_btree_iter_peek_node(trans, &iter);
+	b = bch2_btree_iter_peek_node(&iter);
 	ret = PTR_ERR_OR_ZERO(b);
 	if (ret)
 		goto err;
@@ -1016,7 +1016,7 @@ static int btree_node_get_and_pin(struct btree_trans *trans, struct bkey_i *k,
 {
 	struct btree_iter iter;
 	bch2_trans_node_iter_init(trans, &iter, btree, k->k.p, 0, level, 0);
-	struct btree *b = bch2_btree_iter_peek_node(trans, &iter);
+	struct btree *b = bch2_btree_iter_peek_node(&iter);
 	int ret = PTR_ERR_OR_ZERO(b);
 	if (ret)
 		goto err;
diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index e95bb6849aef..368d1edf6f5c 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -725,7 +725,7 @@ static int bch2_gc_btree(struct btree_trans *trans,
 		struct btree_iter iter;
 		bch2_trans_node_iter_init(trans, &iter, btree, POS_MIN,
 					  0, bch2_btree_id_root(c, btree)->b->c.level, 0);
-		struct btree *b = bch2_btree_iter_peek_node(trans, &iter);
+		struct btree *b = bch2_btree_iter_peek_node(&iter);
 		ret = PTR_ERR_OR_ZERO(b);
 		if (ret)
 			goto err_root;
@@ -1228,7 +1228,7 @@ int bch2_gc_gens(struct bch_fs *c)
 				BCH_TRANS_COMMIT_no_enospc, ({
 			ca = bch2_dev_iterate(c, ca, k.k->p.inode);
 			if (!ca) {
-				bch2_btree_iter_set_pos(trans, &iter, POS(k.k->p.inode + 1, 0));
+				bch2_btree_iter_set_pos(&iter, POS(k.k->p.inode + 1, 0));
 				continue;
 			}
 			bch2_alloc_write_oldest_gen(trans, ca, &iter, k);
diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 4db7056b7aeb..c7012c14be60 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -240,8 +240,10 @@ void __bch2_trans_verify_paths(struct btree_trans *trans)
 		__bch2_btree_path_verify(trans, path);
 }
 
-static void __bch2_btree_iter_verify(struct btree_trans *trans, struct btree_iter *iter)
+static void __bch2_btree_iter_verify(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
+
 	BUG_ON(!!(iter->flags & BTREE_ITER_cached) != btree_iter_path(trans, iter)->cached);
 
 	BUG_ON((iter->flags & BTREE_ITER_is_extents) &&
@@ -270,9 +272,9 @@ static void __bch2_btree_iter_verify_entry_exit(struct btree_iter *iter)
 		bkey_gt(iter->pos, iter->k.p)));
 }
 
-static int __bch2_btree_iter_verify_ret(struct btree_trans *trans,
-					struct btree_iter *iter, struct bkey_s_c k)
+static int __bch2_btree_iter_verify_ret(struct btree_iter *iter, struct bkey_s_c k)
 {
+	struct btree_trans *trans = iter->trans;
 	struct btree_iter copy;
 	struct bkey_s_c prev;
 	int ret = 0;
@@ -290,7 +292,7 @@ static int __bch2_btree_iter_verify_ret(struct btree_trans *trans,
 	bch2_trans_iter_init(trans, &copy, iter->btree_id, iter->pos,
 			     BTREE_ITER_nopreserve|
 			     BTREE_ITER_all_snapshots);
-	prev = bch2_btree_iter_prev(trans, &copy);
+	prev = bch2_btree_iter_prev(&copy);
 	if (!prev.k)
 		goto out;
 
@@ -364,11 +366,10 @@ static inline void bch2_btree_path_verify(struct btree_trans *trans,
 		__bch2_btree_path_verify(trans, path);
 }
 
-static inline void bch2_btree_iter_verify(struct btree_trans *trans,
-					  struct btree_iter *iter)
+static inline void bch2_btree_iter_verify(struct btree_iter *iter)
 {
 	if (static_branch_unlikely(&bch2_debug_check_iterators))
-		__bch2_btree_iter_verify(trans, iter);
+		__bch2_btree_iter_verify(iter);
 }
 
 static inline void bch2_btree_iter_verify_entry_exit(struct btree_iter *iter)
@@ -377,11 +378,11 @@ static inline void bch2_btree_iter_verify_entry_exit(struct btree_iter *iter)
 		__bch2_btree_iter_verify_entry_exit(iter);
 }
 
-static inline int bch2_btree_iter_verify_ret(struct btree_trans *trans, struct btree_iter *iter,
+static inline int bch2_btree_iter_verify_ret(struct btree_iter *iter,
 					     struct bkey_s_c k)
 {
 	return static_branch_unlikely(&bch2_debug_check_iterators)
-		? __bch2_btree_iter_verify_ret(trans, iter, k)
+		? __bch2_btree_iter_verify_ret(iter, k)
 		: 0;
 }
 
@@ -1864,8 +1865,10 @@ struct bkey_s_c bch2_btree_path_peek_slot(struct btree_path *path, struct bkey *
 	return (struct bkey_s_c) { u, NULL };
 }
 
-void bch2_set_btree_iter_dontneed(struct btree_trans *trans, struct btree_iter *iter)
+void bch2_set_btree_iter_dontneed(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
+
 	if (!iter->path || trans->restarted)
 		return;
 
@@ -1877,14 +1880,17 @@ void bch2_set_btree_iter_dontneed(struct btree_trans *trans, struct btree_iter *
 /* Btree iterators: */
 
 int __must_check
-__bch2_btree_iter_traverse(struct btree_trans *trans, struct btree_iter *iter)
+__bch2_btree_iter_traverse(struct btree_iter *iter)
 {
-	return bch2_btree_path_traverse(trans, iter->path, iter->flags);
+	return bch2_btree_path_traverse(iter->trans, iter->path, iter->flags);
 }
 
 int __must_check
-bch2_btree_iter_traverse(struct btree_trans *trans, struct btree_iter *iter)
+bch2_btree_iter_traverse(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
+	int ret;
+
 	bch2_trans_verify_not_unlocked_or_in_restart(trans);
 
 	iter->path = bch2_btree_path_set_pos(trans, iter->path,
@@ -1892,7 +1898,7 @@ bch2_btree_iter_traverse(struct btree_trans *trans, struct btree_iter *iter)
 					iter->flags & BTREE_ITER_intent,
 					btree_iter_ip_allocated(iter));
 
-	int ret = bch2_btree_path_traverse(trans, iter->path, iter->flags);
+	ret = bch2_btree_path_traverse(iter->trans, iter->path, iter->flags);
 	if (ret)
 		return ret;
 
@@ -1904,14 +1910,14 @@ bch2_btree_iter_traverse(struct btree_trans *trans, struct btree_iter *iter)
 
 /* Iterate across nodes (leaf and interior nodes) */
 
-struct btree *bch2_btree_iter_peek_node(struct btree_trans *trans,
-					struct btree_iter *iter)
+struct btree *bch2_btree_iter_peek_node(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
 	struct btree *b = NULL;
 	int ret;
 
 	EBUG_ON(trans->paths[iter->path].cached);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	ret = bch2_btree_path_traverse(trans, iter->path, iter->flags);
 	if (ret)
@@ -1933,7 +1939,7 @@ struct btree *bch2_btree_iter_peek_node(struct btree_trans *trans,
 	btree_path_set_should_be_locked(trans, btree_iter_path(trans, iter));
 out:
 	bch2_btree_iter_verify_entry_exit(iter);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	return b;
 err:
@@ -1942,26 +1948,26 @@ struct btree *bch2_btree_iter_peek_node(struct btree_trans *trans,
 }
 
 /* Only kept for -tools */
-struct btree *bch2_btree_iter_peek_node_and_restart(struct btree_trans *trans,
-						    struct btree_iter *iter)
+struct btree *bch2_btree_iter_peek_node_and_restart(struct btree_iter *iter)
 {
 	struct btree *b;
 
-	while (b = bch2_btree_iter_peek_node(trans, iter),
+	while (b = bch2_btree_iter_peek_node(iter),
 	       bch2_err_matches(PTR_ERR_OR_ZERO(b), BCH_ERR_transaction_restart))
-		bch2_trans_begin(trans);
+		bch2_trans_begin(iter->trans);
 
 	return b;
 }
 
-struct btree *bch2_btree_iter_next_node(struct btree_trans *trans, struct btree_iter *iter)
+struct btree *bch2_btree_iter_next_node(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
 	struct btree *b = NULL;
 	int ret;
 
 	EBUG_ON(trans->paths[iter->path].cached);
 	bch2_trans_verify_not_unlocked_or_in_restart(trans);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	ret = bch2_btree_path_traverse(trans, iter->path, iter->flags);
 	if (ret)
@@ -2035,7 +2041,7 @@ struct btree *bch2_btree_iter_next_node(struct btree_trans *trans, struct btree_
 	EBUG_ON(btree_iter_path(trans, iter)->uptodate);
 out:
 	bch2_btree_iter_verify_entry_exit(iter);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	return b;
 err:
@@ -2045,7 +2051,7 @@ struct btree *bch2_btree_iter_next_node(struct btree_trans *trans, struct btree_
 
 /* Iterate across keys (in leaf nodes only) */
 
-inline bool bch2_btree_iter_advance(struct btree_trans *trans, struct btree_iter *iter)
+inline bool bch2_btree_iter_advance(struct btree_iter *iter)
 {
 	struct bpos pos = iter->k.p;
 	bool ret = !(iter->flags & BTREE_ITER_all_snapshots
@@ -2054,11 +2060,11 @@ inline bool bch2_btree_iter_advance(struct btree_trans *trans, struct btree_iter
 
 	if (ret && !(iter->flags & BTREE_ITER_is_extents))
 		pos = bkey_successor(iter, pos);
-	bch2_btree_iter_set_pos(trans, iter, pos);
+	bch2_btree_iter_set_pos(iter, pos);
 	return ret;
 }
 
-inline bool bch2_btree_iter_rewind(struct btree_trans *trans, struct btree_iter *iter)
+inline bool bch2_btree_iter_rewind(struct btree_iter *iter)
 {
 	struct bpos pos = bkey_start_pos(&iter->k);
 	bool ret = !(iter->flags & BTREE_ITER_all_snapshots
@@ -2067,7 +2073,7 @@ inline bool bch2_btree_iter_rewind(struct btree_trans *trans, struct btree_iter
 
 	if (ret && !(iter->flags & BTREE_ITER_is_extents))
 		pos = bkey_predecessor(iter, pos);
-	bch2_btree_iter_set_pos(trans, iter, pos);
+	bch2_btree_iter_set_pos(iter, pos);
 	return ret;
 }
 
@@ -2199,9 +2205,9 @@ void btree_trans_peek_prev_journal(struct btree_trans *trans,
  * bkey_s_c_null:
  */
 static noinline
-struct bkey_s_c btree_trans_peek_key_cache(struct btree_trans *trans, struct btree_iter *iter,
-					   struct bpos pos)
+struct bkey_s_c btree_trans_peek_key_cache(struct btree_iter *iter, struct bpos pos)
 {
+	struct btree_trans *trans = iter->trans;
 	struct bch_fs *c = trans->c;
 	struct bkey u;
 	struct bkey_s_c k;
@@ -2247,14 +2253,14 @@ struct bkey_s_c btree_trans_peek_key_cache(struct btree_trans *trans, struct btr
 	return k;
 }
 
-static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct btree_iter *iter,
-					      struct bpos search_key)
+static struct bkey_s_c __bch2_btree_iter_peek(struct btree_iter *iter, struct bpos search_key)
 {
+	struct btree_trans *trans = iter->trans;
 	struct bkey_s_c k, k2;
 	int ret;
 
 	EBUG_ON(btree_iter_path(trans, iter)->cached);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	while (1) {
 		iter->path = bch2_btree_path_set_pos(trans, iter->path, search_key,
@@ -2264,7 +2270,7 @@ static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct
 		ret = bch2_btree_path_traverse(trans, iter->path, iter->flags);
 		if (unlikely(ret)) {
 			/* ensure that iter->k is consistent with iter->pos: */
-			bch2_btree_iter_set_pos(trans, iter, iter->pos);
+			bch2_btree_iter_set_pos(iter, iter->pos);
 			k = bkey_s_c_err(ret);
 			break;
 		}
@@ -2274,7 +2280,7 @@ static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct
 
 		if (unlikely(!l->b)) {
 			/* No btree nodes at requested level: */
-			bch2_btree_iter_set_pos(trans, iter, SPOS_MAX);
+			bch2_btree_iter_set_pos(iter, SPOS_MAX);
 			k = bkey_s_c_null;
 			break;
 		}
@@ -2286,10 +2292,10 @@ static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct
 		if (unlikely(iter->flags & BTREE_ITER_with_key_cache) &&
 		    k.k &&
 		    !bkey_deleted(k.k) &&
-		    (k2 = btree_trans_peek_key_cache(trans, iter, k.k->p)).k) {
+		    (k2 = btree_trans_peek_key_cache(iter, k.k->p)).k) {
 			k = k2;
 			if (bkey_err(k)) {
-				bch2_btree_iter_set_pos(trans, iter, iter->pos);
+				bch2_btree_iter_set_pos(iter, iter->pos);
 				break;
 			}
 		}
@@ -2322,13 +2328,13 @@ static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct
 			search_key = bpos_successor(l->b->key.k.p);
 		} else {
 			/* End of btree: */
-			bch2_btree_iter_set_pos(trans, iter, SPOS_MAX);
+			bch2_btree_iter_set_pos(iter, SPOS_MAX);
 			k = bkey_s_c_null;
 			break;
 		}
 	}
 
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	if (trace___btree_iter_peek_enabled()) {
 		CLASS(printbuf, buf)();
@@ -2349,15 +2355,14 @@ static struct bkey_s_c __bch2_btree_iter_peek(struct btree_trans *trans, struct
 /**
  * bch2_btree_iter_peek_max() - returns first key greater than or equal to
  * iterator's current position
- * @trans:	btree transaction object
  * @iter:	iterator to peek from
  * @end:	search limit: returns keys less than or equal to @end
  *
  * Returns:	key if found, or an error extractable with bkey_err().
  */
-struct bkey_s_c bch2_btree_iter_peek_max(struct btree_trans *trans, struct btree_iter *iter,
-					 struct bpos end)
+struct bkey_s_c bch2_btree_iter_peek_max(struct btree_iter *iter, struct bpos end)
 {
+	struct btree_trans *trans = iter->trans;
 	struct bpos search_key = btree_iter_search_key(iter);
 	struct bkey_s_c k;
 	struct bpos iter_pos = iter->pos;
@@ -2379,7 +2384,7 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_trans *trans, struct btree
 	}
 
 	while (1) {
-		k = __bch2_btree_iter_peek(trans, iter, search_key);
+		k = __bch2_btree_iter_peek(iter, search_key);
 		if (unlikely(!k.k))
 			goto end;
 		if (unlikely(bkey_err(k)))
@@ -2493,9 +2498,9 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_trans *trans, struct btree
 	if (!(iter->flags & BTREE_ITER_all_snapshots))
 		iter->pos.snapshot = iter->snapshot;
 
-	ret = bch2_btree_iter_verify_ret(trans, iter, k);
+	ret = bch2_btree_iter_verify_ret(iter, k);
 	if (unlikely(ret)) {
-		bch2_btree_iter_set_pos(trans, iter, iter->pos);
+		bch2_btree_iter_set_pos(iter, iter->pos);
 		k = bkey_s_c_err(ret);
 	}
 
@@ -2516,7 +2521,7 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_trans *trans, struct btree
 
 	return k;
 end:
-	bch2_btree_iter_set_pos(trans, iter, end);
+	bch2_btree_iter_set_pos(iter, end);
 	k = bkey_s_c_null;
 	goto out_no_locked;
 }
@@ -2524,25 +2529,24 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_trans *trans, struct btree
 /**
  * bch2_btree_iter_next() - returns first key greater than iterator's current
  * position
- * @trans:	btree transaction object
  * @iter:	iterator to peek from
  *
  * Returns:	key if found, or an error extractable with bkey_err().
  */
-struct bkey_s_c bch2_btree_iter_next(struct btree_trans *trans, struct btree_iter *iter)
+struct bkey_s_c bch2_btree_iter_next(struct btree_iter *iter)
 {
-	if (!bch2_btree_iter_advance(trans, iter))
+	if (!bch2_btree_iter_advance(iter))
 		return bkey_s_c_null;
 
-	return bch2_btree_iter_peek(trans, iter);
+	return bch2_btree_iter_peek(iter);
 }
 
-static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_trans *trans, struct btree_iter *iter,
-						   struct bpos search_key)
+static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_iter *iter, struct bpos search_key)
 {
+	struct btree_trans *trans = iter->trans;
 	struct bkey_s_c k, k2;
 
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	while (1) {
 		iter->path = bch2_btree_path_set_pos(trans, iter->path, search_key,
@@ -2552,7 +2556,7 @@ static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_trans *trans, st
 		int ret = bch2_btree_path_traverse(trans, iter->path, iter->flags);
 		if (unlikely(ret)) {
 			/* ensure that iter->k is consistent with iter->pos: */
-			bch2_btree_iter_set_pos(trans, iter, iter->pos);
+			bch2_btree_iter_set_pos(iter, iter->pos);
 			k = bkey_s_c_err(ret);
 			break;
 		}
@@ -2562,7 +2566,7 @@ static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_trans *trans, st
 
 		if (unlikely(!l->b)) {
 			/* No btree nodes at requested level: */
-			bch2_btree_iter_set_pos(trans, iter, SPOS_MAX);
+			bch2_btree_iter_set_pos(iter, SPOS_MAX);
 			k = bkey_s_c_null;
 			break;
 		}
@@ -2579,10 +2583,10 @@ static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_trans *trans, st
 		if (unlikely(iter->flags & BTREE_ITER_with_key_cache) &&
 		    k.k &&
 		    !bkey_deleted(k.k) &&
-		    (k2 = btree_trans_peek_key_cache(trans, iter, k.k->p)).k) {
+		    (k2 = btree_trans_peek_key_cache(iter, k.k->p)).k) {
 			k = k2;
 			if (bkey_err(k2)) {
-				bch2_btree_iter_set_pos(trans, iter, iter->pos);
+				bch2_btree_iter_set_pos(iter, iter->pos);
 				break;
 			}
 		}
@@ -2603,27 +2607,25 @@ static struct bkey_s_c __bch2_btree_iter_peek_prev(struct btree_trans *trans, st
 			search_key = bpos_predecessor(path->l[0].b->data->min_key);
 		} else {
 			/* Start of btree: */
-			bch2_btree_iter_set_pos(trans, iter, POS_MIN);
+			bch2_btree_iter_set_pos(iter, POS_MIN);
 			k = bkey_s_c_null;
 			break;
 		}
 	}
 
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 	return k;
 }
 
 /**
  * bch2_btree_iter_peek_prev_min() - returns first key less than or equal to
  * iterator's current position
- * @trans:	btree transaction object
  * @iter:	iterator to peek from
  * @end:	search limit: returns keys greater than or equal to @end
  *
  * Returns:	key if found, or an error extractable with bkey_err().
  */
-struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct btree_iter *iter,
-					      struct bpos end)
+struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_iter *iter, struct bpos end)
 {
 	if ((iter->flags & (BTREE_ITER_is_extents|BTREE_ITER_filter_snapshots)) &&
 	   !bkey_eq(iter->pos, POS_MAX) &&
@@ -2638,7 +2640,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 		 * real visible extents - easiest to just use peek_slot() (which
 		 * internally uses peek() for extents)
 		 */
-		struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, iter);
+		struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 		if (bkey_err(k))
 			return k;
 
@@ -2648,6 +2650,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 			return k;
 	}
 
+	struct btree_trans *trans = iter->trans;
 	struct bpos search_key = iter->pos;
 	struct bkey_s_c k;
 	btree_path_idx_t saved_path = 0;
@@ -2663,7 +2666,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 	}
 
 	while (1) {
-		k = __bch2_btree_iter_peek_prev(trans, iter, search_key);
+		k = __bch2_btree_iter_peek_prev(iter, search_key);
 		if (unlikely(!k.k))
 			goto end;
 		if (unlikely(bkey_err(k)))
@@ -2754,7 +2757,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 		bch2_path_put(trans, saved_path, iter->flags & BTREE_ITER_intent);
 
 	bch2_btree_iter_verify_entry_exit(iter);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 
 	if (trace_btree_iter_peek_prev_min_enabled()) {
 		CLASS(printbuf, buf)();
@@ -2770,7 +2773,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 	}
 	return k;
 end:
-	bch2_btree_iter_set_pos(trans, iter, end);
+	bch2_btree_iter_set_pos(iter, end);
 	k = bkey_s_c_null;
 	goto out_no_locked;
 }
@@ -2778,27 +2781,27 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *trans, struct
 /**
  * bch2_btree_iter_prev() - returns first key less than iterator's current
  * position
- * @trans:	btree transaction object
  * @iter:	iterator to peek from
  *
  * Returns:	key if found, or an error extractable with bkey_err().
  */
-struct bkey_s_c bch2_btree_iter_prev(struct btree_trans *trans, struct btree_iter *iter)
+struct bkey_s_c bch2_btree_iter_prev(struct btree_iter *iter)
 {
-	if (!bch2_btree_iter_rewind(trans, iter))
+	if (!bch2_btree_iter_rewind(iter))
 		return bkey_s_c_null;
 
-	return bch2_btree_iter_peek_prev(trans, iter);
+	return bch2_btree_iter_peek_prev(iter);
 }
 
-struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btree_iter *iter)
+struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
 	struct bpos search_key;
 	struct bkey_s_c k, k2;
 	int ret;
 
 	bch2_trans_verify_not_unlocked_or_in_restart(trans);
-	bch2_btree_iter_verify(trans, iter);
+	bch2_btree_iter_verify(iter);
 	bch2_btree_iter_verify_entry_exit(iter);
 	EBUG_ON(btree_iter_path(trans, iter)->level && (iter->flags & BTREE_ITER_with_key_cache));
 
@@ -2816,7 +2819,7 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 			goto out2;
 		}
 
-		bch2_btree_iter_set_pos(trans, iter, bpos_nosnap_successor(iter->pos));
+		bch2_btree_iter_set_pos(iter, bpos_nosnap_successor(iter->pos));
 	}
 
 	search_key = btree_iter_search_key(iter);
@@ -2859,7 +2862,7 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 
 		if (unlikely(iter->flags & BTREE_ITER_with_key_cache) &&
 		    !bkey_deleted(k.k) &&
-		    (k2 = btree_trans_peek_key_cache(trans, iter, iter->pos)).k) {
+		    (k2 = btree_trans_peek_key_cache(iter, iter->pos)).k) {
 			k = k2;
 			if (bkey_err(k))
 				goto out;
@@ -2882,8 +2885,8 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 		if (iter->flags & BTREE_ITER_intent) {
 			struct btree_iter iter2;
 
-			bch2_trans_copy_iter(trans, &iter2, iter);
-			k = bch2_btree_iter_peek_max(trans, &iter2, end);
+			bch2_trans_copy_iter(&iter2, iter);
+			k = bch2_btree_iter_peek_max(&iter2, end);
 
 			if (k.k && !bkey_err(k)) {
 				swap(iter->key_cache_path, iter2.key_cache_path);
@@ -2894,9 +2897,9 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 		} else {
 			struct bpos pos = iter->pos;
 
-			k = bch2_btree_iter_peek_max(trans, iter, end);
+			k = bch2_btree_iter_peek_max(iter, end);
 			if (unlikely(bkey_err(k)))
-				bch2_btree_iter_set_pos(trans, iter, pos);
+				bch2_btree_iter_set_pos(iter, pos);
 			else
 				iter->pos = pos;
 		}
@@ -2925,8 +2928,8 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 	}
 out:
 	bch2_btree_iter_verify_entry_exit(iter);
-	bch2_btree_iter_verify(trans, iter);
-	ret = bch2_btree_iter_verify_ret(trans, iter, k);
+	bch2_btree_iter_verify(iter);
+	ret = bch2_btree_iter_verify_ret(iter, k);
 	if (unlikely(ret))
 		k = bkey_s_c_err(ret);
 out2:
@@ -2946,31 +2949,31 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *trans, struct btre
 	return k;
 }
 
-struct bkey_s_c bch2_btree_iter_next_slot(struct btree_trans *trans, struct btree_iter *iter)
+struct bkey_s_c bch2_btree_iter_next_slot(struct btree_iter *iter)
 {
-	if (!bch2_btree_iter_advance(trans, iter))
+	if (!bch2_btree_iter_advance(iter))
 		return bkey_s_c_null;
 
-	return bch2_btree_iter_peek_slot(trans, iter);
+	return bch2_btree_iter_peek_slot(iter);
 }
 
-struct bkey_s_c bch2_btree_iter_prev_slot(struct btree_trans *trans, struct btree_iter *iter)
+struct bkey_s_c bch2_btree_iter_prev_slot(struct btree_iter *iter)
 {
-	if (!bch2_btree_iter_rewind(trans, iter))
+	if (!bch2_btree_iter_rewind(iter))
 		return bkey_s_c_null;
 
-	return bch2_btree_iter_peek_slot(trans, iter);
+	return bch2_btree_iter_peek_slot(iter);
 }
 
 /* Obsolete, but still used by rust wrapper in -tools */
-struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_trans *trans, struct btree_iter *iter)
+struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_iter *iter)
 {
 	struct bkey_s_c k;
 
-	while (btree_trans_too_many_iters(trans) ||
-	       (k = bch2_btree_iter_peek_type(trans, iter, iter->flags),
+	while (btree_trans_too_many_iters(iter->trans) ||
+	       (k = bch2_btree_iter_peek_type(iter, iter->flags),
 		bch2_err_matches(bkey_err(k), BCH_ERR_transaction_restart)))
-		bch2_trans_begin(trans);
+		bch2_trans_begin(iter->trans);
 
 	return k;
 }
@@ -3116,6 +3119,7 @@ void bch2_trans_iter_exit(struct btree_trans *trans, struct btree_iter *iter)
 	iter->path		= 0;
 	iter->update_path	= 0;
 	iter->key_cache_path	= 0;
+	iter->trans		= NULL;
 }
 
 void bch2_trans_iter_init_outlined(struct btree_trans *trans,
@@ -3155,9 +3159,10 @@ void bch2_trans_node_iter_init(struct btree_trans *trans,
 	BUG_ON(iter->min_depth	!= depth);
 }
 
-void bch2_trans_copy_iter(struct btree_trans *trans,
-			  struct btree_iter *dst, struct btree_iter *src)
+void bch2_trans_copy_iter(struct btree_iter *dst, struct btree_iter *src)
 {
+	struct btree_trans *trans = src->trans;
+
 	*dst = *src;
 #ifdef TRACK_PATH_ALLOCATED
 	dst->ip_allocated = _RET_IP_;
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 9034fcfeed65..1be35e642ab0 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -408,37 +408,36 @@ void bch2_trans_node_add(struct btree_trans *trans, struct btree_path *, struct
 void bch2_trans_node_drop(struct btree_trans *trans, struct btree *);
 void bch2_trans_node_reinit_iter(struct btree_trans *, struct btree *);
 
-int __must_check __bch2_btree_iter_traverse(struct btree_trans *, struct btree_iter *);
-int __must_check bch2_btree_iter_traverse(struct btree_trans *, struct btree_iter *);
+int __must_check __bch2_btree_iter_traverse(struct btree_iter *iter);
+int __must_check bch2_btree_iter_traverse(struct btree_iter *);
 
-struct btree *bch2_btree_iter_peek_node(struct btree_trans *, struct btree_iter *);
-struct btree *bch2_btree_iter_peek_node_and_restart(struct btree_trans *, struct btree_iter *);
-struct btree *bch2_btree_iter_next_node(struct btree_trans *, struct btree_iter *);
+struct btree *bch2_btree_iter_peek_node(struct btree_iter *);
+struct btree *bch2_btree_iter_peek_node_and_restart(struct btree_iter *);
+struct btree *bch2_btree_iter_next_node(struct btree_iter *);
 
-struct bkey_s_c bch2_btree_iter_peek_max(struct btree_trans *, struct btree_iter *, struct bpos);
-struct bkey_s_c bch2_btree_iter_next(struct btree_trans *, struct btree_iter *);
+struct bkey_s_c bch2_btree_iter_peek_max(struct btree_iter *, struct bpos);
+struct bkey_s_c bch2_btree_iter_next(struct btree_iter *);
 
-static inline struct bkey_s_c bch2_btree_iter_peek(struct btree_trans *trans,
-						   struct btree_iter *iter)
+static inline struct bkey_s_c bch2_btree_iter_peek(struct btree_iter *iter)
 {
-	return bch2_btree_iter_peek_max(trans, iter, SPOS_MAX);
+	return bch2_btree_iter_peek_max(iter, SPOS_MAX);
 }
 
-struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_trans *, struct btree_iter *, struct bpos);
+struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_iter *, struct bpos);
 
-static inline struct bkey_s_c bch2_btree_iter_peek_prev(struct btree_trans *trans, struct btree_iter *iter)
+static inline struct bkey_s_c bch2_btree_iter_peek_prev(struct btree_iter *iter)
 {
-	return bch2_btree_iter_peek_prev_min(trans, iter, POS_MIN);
+	return bch2_btree_iter_peek_prev_min(iter, POS_MIN);
 }
 
-struct bkey_s_c bch2_btree_iter_prev(struct btree_trans *, struct btree_iter *);
+struct bkey_s_c bch2_btree_iter_prev(struct btree_iter *);
 
-struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_trans *, struct btree_iter *);
-struct bkey_s_c bch2_btree_iter_next_slot(struct btree_trans *, struct btree_iter *);
-struct bkey_s_c bch2_btree_iter_prev_slot(struct btree_trans *, struct btree_iter *);
+struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_iter *);
+struct bkey_s_c bch2_btree_iter_next_slot(struct btree_iter *);
+struct bkey_s_c bch2_btree_iter_prev_slot(struct btree_iter *);
 
-bool bch2_btree_iter_advance(struct btree_trans *, struct btree_iter *);
-bool bch2_btree_iter_rewind(struct btree_trans *, struct btree_iter *);
+bool bch2_btree_iter_advance(struct btree_iter *);
+bool bch2_btree_iter_rewind(struct btree_iter *);
 
 static inline void __bch2_btree_iter_set_pos(struct btree_iter *iter, struct bpos new_pos)
 {
@@ -449,9 +448,10 @@ static inline void __bch2_btree_iter_set_pos(struct btree_iter *iter, struct bpo
 	iter->k.size = 0;
 }
 
-static inline void bch2_btree_iter_set_pos(struct btree_trans *trans,
-					   struct btree_iter *iter, struct bpos new_pos)
+static inline void bch2_btree_iter_set_pos(struct btree_iter *iter, struct bpos new_pos)
 {
+	struct btree_trans *trans = iter->trans;
+
 	if (unlikely(iter->update_path))
 		bch2_path_put(trans, iter->update_path,
 			      iter->flags & BTREE_ITER_intent);
@@ -469,14 +469,13 @@ static inline void bch2_btree_iter_set_pos_to_extent_start(struct btree_iter *it
 	iter->pos = bkey_start_pos(&iter->k);
 }
 
-static inline void bch2_btree_iter_set_snapshot(struct btree_trans *trans,
-						struct btree_iter *iter, u32 snapshot)
+static inline void bch2_btree_iter_set_snapshot(struct btree_iter *iter, u32 snapshot)
 {
 	struct bpos pos = iter->pos;
 
 	iter->snapshot = snapshot;
 	pos.snapshot = snapshot;
-	bch2_btree_iter_set_pos(trans, iter, pos);
+	bch2_btree_iter_set_pos(iter, pos);
 }
 
 void bch2_trans_iter_exit(struct btree_trans *, struct btree_iter *);
@@ -518,6 +517,7 @@ static inline void bch2_trans_iter_init_common(struct btree_trans *trans,
 					  enum btree_iter_update_trigger_flags flags,
 					  unsigned long ip)
 {
+	iter->trans		= trans;
 	iter->update_path	= 0;
 	iter->key_cache_path	= 0;
 	iter->btree_id		= btree;
@@ -556,9 +556,9 @@ void bch2_trans_node_iter_init(struct btree_trans *, struct btree_iter *,
 			       unsigned, unsigned,
 			       enum btree_iter_update_trigger_flags);
 
-void bch2_trans_copy_iter(struct btree_trans *, struct btree_iter *, struct btree_iter *);
+void bch2_trans_copy_iter(struct btree_iter *, struct btree_iter *);
 
-void bch2_set_btree_iter_dontneed(struct btree_trans *, struct btree_iter *);
+void bch2_set_btree_iter_dontneed(struct btree_iter *);
 
 #ifdef CONFIG_BCACHEFS_TRANS_KMALLOC_TRACE
 void bch2_trans_kmalloc_trace_to_text(struct printbuf *,
@@ -636,7 +636,7 @@ static inline struct bkey_s_c __bch2_bkey_get_iter(struct btree_trans *trans,
 	struct bkey_s_c k;
 
 	bch2_trans_iter_init(trans, iter, btree, pos, flags);
-	k = bch2_btree_iter_peek_slot(trans, iter);
+	k = bch2_btree_iter_peek_slot(iter);
 
 	if (!bkey_err(k) && type && k.k->type != type)
 		k = bkey_s_c_err(-BCH_ERR_ENOENT_bkey_type_mismatch);
@@ -707,14 +707,14 @@ u32 bch2_trans_begin(struct btree_trans *);
 	int _ret3 = 0;								\
 	do {									\
 		_ret3 = lockrestart_do((_trans), ({				\
-			struct btree *_b = bch2_btree_iter_peek_node(_trans, &_iter);\
+			struct btree *_b = bch2_btree_iter_peek_node(&_iter);	\
 			if (!_b)						\
 				break;						\
 										\
 			PTR_ERR_OR_ZERO(_b) ?: (_do);				\
 		})) ?:								\
 		lockrestart_do((_trans),					\
-			PTR_ERR_OR_ZERO(bch2_btree_iter_next_node(_trans, &_iter)));\
+			PTR_ERR_OR_ZERO(bch2_btree_iter_next_node(&_iter)));	\
 	} while (!_ret3);							\
 										\
 	bch2_trans_iter_exit((_trans), &(_iter));				\
@@ -726,34 +726,31 @@ u32 bch2_trans_begin(struct btree_trans *);
 	__for_each_btree_node(_trans, _iter, _btree_id, _start,	\
 			      0, 0, _flags, _b, _do)
 
-static inline struct bkey_s_c bch2_btree_iter_peek_prev_type(struct btree_trans *trans,
-							     struct btree_iter *iter,
+static inline struct bkey_s_c bch2_btree_iter_peek_prev_type(struct btree_iter *iter,
 							     enum btree_iter_update_trigger_flags flags)
 {
-	return  flags & BTREE_ITER_slots      ? bch2_btree_iter_peek_slot(trans, iter) :
-						bch2_btree_iter_peek_prev(trans, iter);
+	return  flags & BTREE_ITER_slots      ? bch2_btree_iter_peek_slot(iter) :
+						bch2_btree_iter_peek_prev(iter);
 }
 
-static inline struct bkey_s_c bch2_btree_iter_peek_type(struct btree_trans *trans,
-							struct btree_iter *iter,
+static inline struct bkey_s_c bch2_btree_iter_peek_type(struct btree_iter *iter,
 							enum btree_iter_update_trigger_flags flags)
 {
-	return  flags & BTREE_ITER_slots      ? bch2_btree_iter_peek_slot(trans, iter) :
-						bch2_btree_iter_peek(trans, iter);
+	return  flags & BTREE_ITER_slots      ? bch2_btree_iter_peek_slot(iter) :
+						bch2_btree_iter_peek(iter);
 }
 
-static inline struct bkey_s_c bch2_btree_iter_peek_max_type(struct btree_trans *trans,
-							    struct btree_iter *iter,
+static inline struct bkey_s_c bch2_btree_iter_peek_max_type(struct btree_iter *iter,
 							    struct bpos end,
 							    enum btree_iter_update_trigger_flags flags)
 {
 	if (!(flags & BTREE_ITER_slots))
-		return bch2_btree_iter_peek_max(trans, iter, end);
+		return bch2_btree_iter_peek_max(iter, end);
 
 	if (bkey_gt(iter->pos, end))
 		return bkey_s_c_null;
 
-	return bch2_btree_iter_peek_slot(trans, iter);
+	return bch2_btree_iter_peek_slot(iter);
 }
 
 int __bch2_btree_trans_too_many_iters(struct btree_trans *);
@@ -820,14 +817,14 @@ transaction_restart:							\
 									\
 	do {								\
 		_ret3 = lockrestart_do(_trans, ({			\
-			(_k) = bch2_btree_iter_peek_max_type(_trans, &(_iter),	\
+			(_k) = bch2_btree_iter_peek_max_type(&(_iter),	\
 						_end, (_flags));	\
 			if (!(_k).k)					\
 				break;					\
 									\
 			bkey_err(_k) ?: (_do);				\
 		}));							\
-	} while (!_ret3 && bch2_btree_iter_advance(_trans, &(_iter)));	\
+	} while (!_ret3 && bch2_btree_iter_advance(&(_iter)));		\
 									\
 	bch2_trans_iter_exit((_trans), &(_iter));			\
 	_ret3;								\
@@ -865,14 +862,14 @@ transaction_restart:							\
 									\
 	do {								\
 		_ret3 = lockrestart_do(_trans, ({			\
-			(_k) = bch2_btree_iter_peek_prev_type(_trans, &(_iter),	\
+			(_k) = bch2_btree_iter_peek_prev_type(&(_iter),	\
 							(_flags));	\
 			if (!(_k).k)					\
 				break;					\
 									\
 			bkey_err(_k) ?: (_do);				\
 		}));							\
-	} while (!_ret3 && bch2_btree_iter_rewind(_trans, &(_iter)));	\
+	} while (!_ret3 && bch2_btree_iter_rewind(&(_iter)));		\
 									\
 	bch2_trans_iter_exit((_trans), &(_iter));			\
 	_ret3;								\
@@ -902,38 +899,37 @@ transaction_restart:							\
 			    (_do) ?: bch2_trans_commit(_trans, (_disk_res),\
 					(_journal_seq), (_commit_flags)))
 
-struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_trans *,
-							  struct btree_iter *);
+struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_iter *);
 
 #define for_each_btree_key_max_norestart(_trans, _iter, _btree_id,	\
 			   _start, _end, _flags, _k, _ret)		\
 	for (bch2_trans_iter_init((_trans), &(_iter), (_btree_id),	\
 				  (_start), (_flags));			\
-	     (_k) = bch2_btree_iter_peek_max_type(_trans, &(_iter), _end, _flags),\
+	     (_k) = bch2_btree_iter_peek_max_type(&(_iter), _end, _flags),\
 	     !((_ret) = bkey_err(_k)) && (_k).k;			\
-	     bch2_btree_iter_advance(_trans, &(_iter)))
+	     bch2_btree_iter_advance(&(_iter)))
 
-#define for_each_btree_key_max_continue_norestart(_trans, _iter, _end, _flags, _k, _ret)\
+#define for_each_btree_key_max_continue_norestart(_iter, _end, _flags, _k, _ret)\
 	for (;									\
-	     (_k) = bch2_btree_iter_peek_max_type(_trans, &(_iter), _end, _flags),	\
+	     (_k) = bch2_btree_iter_peek_max_type(&(_iter), _end, _flags),	\
 	     !((_ret) = bkey_err(_k)) && (_k).k;				\
-	     bch2_btree_iter_advance(_trans, &(_iter)))
+	     bch2_btree_iter_advance(&(_iter)))
 
 #define for_each_btree_key_norestart(_trans, _iter, _btree_id,		\
 			   _start, _flags, _k, _ret)			\
 	for_each_btree_key_max_norestart(_trans, _iter, _btree_id, _start,\
 					  SPOS_MAX, _flags, _k, _ret)
 
-#define for_each_btree_key_reverse_norestart(_trans, _iter, _btree_id,		\
-					     _start, _flags, _k, _ret)		\
-	for (bch2_trans_iter_init((_trans), &(_iter), (_btree_id),		\
-				  (_start), (_flags));				\
-	     (_k) = bch2_btree_iter_peek_prev_type(_trans, &(_iter), _flags),	\
-	     !((_ret) = bkey_err(_k)) && (_k).k;				\
-	     bch2_btree_iter_rewind(_trans, &(_iter)))
+#define for_each_btree_key_reverse_norestart(_trans, _iter, _btree_id,	\
+					     _start, _flags, _k, _ret)	\
+	for (bch2_trans_iter_init((_trans), &(_iter), (_btree_id),	\
+				  (_start), (_flags));			\
+	     (_k) = bch2_btree_iter_peek_prev_type(&(_iter), _flags),	\
+	     !((_ret) = bkey_err(_k)) && (_k).k;			\
+	     bch2_btree_iter_rewind(&(_iter)))
 
-#define for_each_btree_key_continue_norestart(_trans, _iter, _flags, _k, _ret)	\
-	for_each_btree_key_max_continue_norestart(_trans, _iter, SPOS_MAX, _flags, _k, _ret)
+#define for_each_btree_key_continue_norestart(_iter, _flags, _k, _ret)	\
+	for_each_btree_key_max_continue_norestart(_iter, SPOS_MAX, _flags, _k, _ret)
 
 /*
  * This should not be used in a fastpath, without first trying _do in
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index 172875b5be8e..797aa6e5b100 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -331,7 +331,7 @@ static noinline int btree_key_cache_fill(struct btree_trans *trans,
 			     BTREE_ITER_key_cache_fill|
 			     BTREE_ITER_cached_nofill);
 	iter.flags &= ~BTREE_ITER_with_journal;
-	k = bch2_btree_iter_peek_slot(trans, &iter);
+	k = bch2_btree_iter_peek_slot(&iter);
 	ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -350,7 +350,7 @@ static noinline int btree_key_cache_fill(struct btree_trans *trans,
 		do_trace_key_cache_fill(trans, ck_path, k);
 out:
 	/* We're not likely to need this iterator again: */
-	bch2_set_btree_iter_dontneed(trans, &iter);
+	bch2_set_btree_iter_dontneed(&iter);
 err:
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
@@ -437,7 +437,7 @@ static int btree_key_cache_flush_pos(struct btree_trans *trans,
 			     BTREE_ITER_intent);
 	b_iter.flags &= ~BTREE_ITER_with_key_cache;
 
-	ret = bch2_btree_iter_traverse(trans, &c_iter);
+	ret = bch2_btree_iter_traverse(&c_iter);
 	if (ret)
 		goto out;
 
@@ -469,7 +469,7 @@ static int btree_key_cache_flush_pos(struct btree_trans *trans,
 	    !test_bit(JOURNAL_space_low, &c->journal.flags))
 		commit_flags |= BCH_TRANS_COMMIT_no_journal_res;
 
-	struct bkey_s_c btree_k = bch2_btree_iter_peek_slot(trans, &b_iter);
+	struct bkey_s_c btree_k = bch2_btree_iter_peek_slot(&b_iter);
 	ret = bkey_err(btree_k);
 	if (ret)
 		goto err;
diff --git a/fs/bcachefs/btree_types.h b/fs/bcachefs/btree_types.h
index e4870fbc11d0..ffa250008d91 100644
--- a/fs/bcachefs/btree_types.h
+++ b/fs/bcachefs/btree_types.h
@@ -364,6 +364,7 @@ static inline unsigned long btree_path_ip_allocated(struct btree_path *path)
  * @nodes_intent_locked	- bitmask indicating which locks are intent locks
  */
 struct btree_iter {
+	struct btree_trans	*trans;
 	btree_path_idx_t	path;
 	btree_path_idx_t	update_path;
 	btree_path_idx_t	key_cache_path;
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index f514a8ad7a89..36c957127eba 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -277,7 +277,7 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 			     BTREE_ITER_intent|
 			     BTREE_ITER_with_updates|
 			     BTREE_ITER_not_extents);
-	k = bch2_btree_iter_peek_max(trans, &iter, POS(insert->k.p.inode, U64_MAX));
+	k = bch2_btree_iter_peek_max(&iter, POS(insert->k.p.inode, U64_MAX));
 	if ((ret = bkey_err(k)))
 		goto err;
 	if (!k.k)
@@ -303,8 +303,8 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 		if (done)
 			goto out;
 next:
-		bch2_btree_iter_advance(trans, &iter);
-		k = bch2_btree_iter_peek_max(trans, &iter, POS(insert->k.p.inode, U64_MAX));
+		bch2_btree_iter_advance(&iter);
+		k = bch2_btree_iter_peek_max(&iter, POS(insert->k.p.inode, U64_MAX));
 		if ((ret = bkey_err(k)))
 			goto err;
 		if (!k.k)
@@ -594,13 +594,13 @@ int bch2_bkey_get_empty_slot(struct btree_trans *trans, struct btree_iter *iter,
 			     enum btree_id btree, struct bpos end)
 {
 	bch2_trans_iter_init(trans, iter, btree, end, BTREE_ITER_intent);
-	struct bkey_s_c k = bch2_btree_iter_peek_prev(trans, iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_prev(iter);
 	int ret = bkey_err(k);
 	if (ret)
 		goto err;
 
-	bch2_btree_iter_advance(trans, iter);
-	k = bch2_btree_iter_peek_slot(trans, iter);
+	bch2_btree_iter_advance(iter);
+	k = bch2_btree_iter_peek_slot(iter);
 	ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -636,7 +636,7 @@ int bch2_btree_insert_nonextent(struct btree_trans *trans,
 			     BTREE_ITER_cached|
 			     BTREE_ITER_not_extents|
 			     BTREE_ITER_intent);
-	ret   = bch2_btree_iter_traverse(trans, &iter) ?:
+	ret   = bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, k, flags);
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
@@ -648,7 +648,7 @@ int bch2_btree_insert_trans(struct btree_trans *trans, enum btree_id id,
 	struct btree_iter iter;
 	bch2_trans_iter_init(trans, &iter, id, bkey_start_pos(&k->k),
 			     BTREE_ITER_intent|flags);
-	int ret = bch2_btree_iter_traverse(trans, &iter) ?:
+	int ret = bch2_btree_iter_traverse(&iter) ?:
 		  bch2_trans_update(trans, &iter, k, flags);
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
@@ -699,7 +699,7 @@ int bch2_btree_delete(struct btree_trans *trans,
 	bch2_trans_iter_init(trans, &iter, btree, pos,
 			     BTREE_ITER_cached|
 			     BTREE_ITER_intent);
-	ret   = bch2_btree_iter_traverse(trans, &iter) ?:
+	ret   = bch2_btree_iter_traverse(&iter) ?:
 		bch2_btree_delete_at(trans, &iter, flags);
 	bch2_trans_iter_exit(trans, &iter);
 
@@ -717,7 +717,7 @@ int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
 	int ret = 0;
 
 	bch2_trans_iter_init(trans, &iter, id, start, BTREE_ITER_intent|flags);
-	while ((k = bch2_btree_iter_peek_max(trans, &iter, end)).k) {
+	while ((k = bch2_btree_iter_peek_max(&iter, end)).k) {
 		struct disk_reservation disk_res =
 			bch2_disk_reservation_init(trans->c, 0);
 		struct bkey_i delete;
@@ -811,7 +811,7 @@ int bch2_btree_bit_mod(struct btree_trans *trans, enum btree_id btree,
 	struct btree_iter iter;
 	bch2_trans_iter_init(trans, &iter, btree, pos, BTREE_ITER_intent);
 
-	int ret = bch2_btree_iter_traverse(trans, &iter) ?:
+	int ret = bch2_btree_iter_traverse(&iter) ?:
 		  bch2_btree_bit_mod_iter(trans, &iter, set);
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 6b0433ccf3df..7016e81f74e2 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -2220,7 +2220,7 @@ static int get_iter_to_node(struct btree_trans *trans, struct btree_iter *iter,
 	bch2_trans_node_iter_init(trans, iter, b->c.btree_id, b->key.k.p,
 				  BTREE_MAX_DEPTH, b->c.level,
 				  BTREE_ITER_intent);
-	int ret = bch2_btree_iter_traverse(trans, iter);
+	int ret = bch2_btree_iter_traverse(iter);
 	if (ret)
 		goto err;
 
@@ -2315,7 +2315,7 @@ int bch2_btree_node_rewrite_key(struct btree_trans *trans,
 	bch2_trans_node_iter_init(trans, &iter,
 				  btree, k->k.p,
 				  BTREE_MAX_DEPTH, level, 0);
-	struct btree *b = bch2_btree_iter_peek_node(trans, &iter);
+	struct btree *b = bch2_btree_iter_peek_node(&iter);
 	int ret = PTR_ERR_OR_ZERO(b);
 	if (ret)
 		goto out;
@@ -2340,7 +2340,7 @@ int bch2_btree_node_rewrite_pos(struct btree_trans *trans,
 	/* Traverse one depth lower to get a pointer to the node itself: */
 	struct btree_iter iter;
 	bch2_trans_node_iter_init(trans, &iter, btree, pos, 0, level - 1, 0);
-	struct btree *b = bch2_btree_iter_peek_node(trans, &iter);
+	struct btree *b = bch2_btree_iter_peek_node(&iter);
 	int ret = PTR_ERR_OR_ZERO(b);
 	if (ret)
 		goto err;
@@ -2484,7 +2484,7 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 					bool skip_triggers)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter2 = {};
+	struct btree_iter iter2 = { NULL };
 	struct btree *parent;
 	int ret;
 
@@ -2508,7 +2508,7 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 
 	parent = btree_node_parent(btree_iter_path(trans, iter), b);
 	if (parent) {
-		bch2_trans_copy_iter(trans, &iter2, iter);
+		bch2_trans_copy_iter(&iter2, iter);
 
 		iter2.path = bch2_btree_path_make_mut(trans, iter2.path,
 				iter2.flags & BTREE_ITER_intent,
@@ -2522,7 +2522,7 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 
 		trans->paths_sorted = false;
 
-		ret   = bch2_btree_iter_traverse(trans, &iter2) ?:
+		ret   = bch2_btree_iter_traverse(&iter2) ?:
 			bch2_trans_update(trans, &iter2, new_key, BTREE_TRIGGER_norun);
 		if (ret)
 			goto err;
diff --git a/fs/bcachefs/btree_write_buffer.c b/fs/bcachefs/btree_write_buffer.c
index 9cfc3edce39a..cbadf989ec6a 100644
--- a/fs/bcachefs/btree_write_buffer.c
+++ b/fs/bcachefs/btree_write_buffer.c
@@ -145,7 +145,7 @@ static inline int wb_flush_one(struct btree_trans *trans, struct btree_iter *ite
 	EBUG_ON(!trans->c->btree_write_buffer.flushing.pin.seq);
 	EBUG_ON(trans->c->btree_write_buffer.flushing.pin.seq > wb->journal_seq);
 
-	ret = bch2_btree_iter_traverse(trans, iter);
+	ret = bch2_btree_iter_traverse(iter);
 	if (ret)
 		return ret;
 
@@ -211,7 +211,7 @@ btree_write_buffered_insert(struct btree_trans *trans,
 
 	trans->journal_res.seq = wb->journal_seq;
 
-	ret   = bch2_btree_iter_traverse(trans, &iter) ?:
+	ret   = bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &wb->k,
 				  BTREE_UPDATE_internal_snapshot_node);
 	bch2_trans_iter_exit(trans, &iter);
@@ -285,7 +285,7 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 	struct bch_fs *c = trans->c;
 	struct journal *j = &c->journal;
 	struct btree_write_buffer *wb = &c->btree_write_buffer;
-	struct btree_iter iter = {};
+	struct btree_iter iter = { NULL };
 	size_t overwritten = 0, fast = 0, slowpath = 0, could_not_insert = 0;
 	bool write_locked = false;
 	bool accounting_replay_done = test_bit(BCH_FS_accounting_replay_done, &c->flags);
@@ -366,7 +366,7 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 				write_locked = false;
 
 				ret = lockrestart_do(trans,
-					bch2_btree_iter_traverse(trans, &iter) ?:
+					bch2_btree_iter_traverse(&iter) ?:
 					bch2_foreground_maybe_merge(trans, iter.path, 0,
 							BCH_WATERMARK_reclaim|
 							BCH_TRANS_COMMIT_journal_reclaim|
@@ -383,7 +383,7 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 					     BTREE_ITER_intent|BTREE_ITER_all_snapshots);
 		}
 
-		bch2_btree_iter_set_pos(trans, &iter, k->k.k.p);
+		bch2_btree_iter_set_pos(&iter, k->k.k.p);
 		btree_iter_path(trans, &iter)->preserve = false;
 
 		bool accounting_accumulated = false;
diff --git a/fs/bcachefs/buckets.c b/fs/bcachefs/buckets.c
index 5aab527e3e7c..423e0732e6f8 100644
--- a/fs/bcachefs/buckets.c
+++ b/fs/bcachefs/buckets.c
@@ -372,7 +372,7 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 			struct btree_iter iter;
 			bch2_trans_node_iter_init(trans, &iter, btree, new->k.p, 0, level,
 						  BTREE_ITER_intent|BTREE_ITER_all_snapshots);
-			ret =   bch2_btree_iter_traverse(trans, &iter) ?:
+			ret =   bch2_btree_iter_traverse(&iter) ?:
 				bch2_trans_update(trans, &iter, new,
 						  BTREE_UPDATE_internal_snapshot_node|
 						  BTREE_TRIGGER_norun);
diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index ccedc93fe0ef..23070bb6b60c 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -283,7 +283,7 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 
 		bch2_trans_begin(trans);
 
-		k = bch2_btree_iter_peek_slot(trans, &iter);
+		k = bch2_btree_iter_peek_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
@@ -456,7 +456,7 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 		if (ret)
 			goto err;
 
-		bch2_btree_iter_set_pos(trans, &iter, next_pos);
+		bch2_btree_iter_set_pos(&iter, next_pos);
 
 		this_cpu_add(c->counters[BCH_COUNTER_io_move_finish], new->k.size);
 		if (trace_io_move_finish_enabled())
@@ -483,7 +483,7 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 
 		count_event(c, io_move_fail);
 
-		bch2_btree_iter_advance(trans, &iter);
+		bch2_btree_iter_advance(&iter);
 		goto next;
 	}
 out:
@@ -553,7 +553,7 @@ int bch2_update_unwritten_extent(struct btree_trans *trans,
 		bch2_trans_iter_init(trans, &iter, update->btree_id, update->op.pos,
 				     BTREE_ITER_slots);
 		ret = lockrestart_do(trans, ({
-			k = bch2_btree_iter_peek_slot(trans, &iter);
+			k = bch2_btree_iter_peek_slot(&iter);
 			bkey_err(k);
 		}));
 		bch2_trans_iter_exit(trans, &iter);
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index 1b891ac43053..5dc909eaeefd 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -406,8 +406,8 @@ int bch2_dirent_rename(struct btree_trans *trans,
 		enum bch_rename_mode mode)
 {
 	struct qstr src_name_lookup, dst_name_lookup;
-	struct btree_iter src_iter = {};
-	struct btree_iter dst_iter = {};
+	struct btree_iter src_iter = { NULL };
+	struct btree_iter dst_iter = { NULL };
 	struct bkey_s_c old_src, old_dst = bkey_s_c_null;
 	struct bkey_i_dirent *new_src = NULL, *new_dst = NULL;
 	struct bpos dst_pos =
@@ -567,16 +567,16 @@ int bch2_dirent_rename(struct btree_trans *trans,
 	}
 
 	if (delete_src) {
-		bch2_btree_iter_set_snapshot(trans, &src_iter, old_src.k->p.snapshot);
-		ret =   bch2_btree_iter_traverse(trans, &src_iter) ?:
+		bch2_btree_iter_set_snapshot(&src_iter, old_src.k->p.snapshot);
+		ret =   bch2_btree_iter_traverse(&src_iter) ?:
 			bch2_btree_delete_at(trans, &src_iter, BTREE_UPDATE_internal_snapshot_node);
 		if (ret)
 			goto out;
 	}
 
 	if (delete_dst) {
-		bch2_btree_iter_set_snapshot(trans, &dst_iter, old_dst.k->p.snapshot);
-		ret =   bch2_btree_iter_traverse(trans, &dst_iter) ?:
+		bch2_btree_iter_set_snapshot(&dst_iter, old_dst.k->p.snapshot);
+		ret =   bch2_btree_iter_traverse(&dst_iter) ?:
 			bch2_btree_delete_at(trans, &dst_iter, BTREE_UPDATE_internal_snapshot_node);
 		if (ret)
 			goto out;
@@ -757,7 +757,7 @@ int bch2_fsck_remove_dirent(struct btree_trans *trans, struct bpos pos)
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_dirents, pos, BTREE_ITER_intent);
 
-	ret =   bch2_btree_iter_traverse(trans, &iter) ?:
+	ret =   bch2_btree_iter_traverse(&iter) ?:
 		bch2_hash_delete_at(trans, bch2_dirent_hash_desc,
 				    &dir_hash_info, &iter,
 				    BTREE_UPDATE_internal_snapshot_node);
diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 219e37738aee..484261da6d25 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -778,7 +778,7 @@ int bch2_accounting_read(struct bch_fs *c)
 				struct disk_accounting_pos next;
 				memset(&next, 0, sizeof(next));
 				next.type = acc_k.type + 1;
-				bch2_btree_iter_set_pos(trans, &iter, disk_accounting_pos_to_bpos(&next));
+				bch2_btree_iter_set_pos(&iter, disk_accounting_pos_to_bpos(&next));
 				continue;
 			}
 
@@ -965,7 +965,7 @@ void bch2_verify_accounting_clean(struct bch_fs *c)
 			struct disk_accounting_pos next;
 			memset(&next, 0, sizeof(next));
 			next.type = acc_k.type + 1;
-			bch2_btree_iter_set_pos(trans, &iter, disk_accounting_pos_to_bpos(&next));
+			bch2_btree_iter_set_pos(&iter, disk_accounting_pos_to_bpos(&next));
 			continue;
 		}
 
diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index bea14f02114f..d154f85c5cd9 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -1809,7 +1809,7 @@ static int __get_existing_stripe(struct btree_trans *trans,
 		ret = 1;
 	}
 out:
-	bch2_set_btree_iter_dontneed(trans, &iter);
+	bch2_set_btree_iter_dontneed(&iter);
 err:
 	bch2_trans_iter_exit(trans, &iter);
 	return ret;
@@ -1922,7 +1922,7 @@ static int __bch2_ec_stripe_head_reserve(struct btree_trans *trans, struct ec_st
 		if (bkey_gt(k.k->p, POS(0, U32_MAX))) {
 			if (start_pos.offset) {
 				start_pos = min_pos;
-				bch2_btree_iter_set_pos(trans, &iter, start_pos);
+				bch2_btree_iter_set_pos(&iter, start_pos);
 				continue;
 			}
 
diff --git a/fs/bcachefs/extent_update.c b/fs/bcachefs/extent_update.c
index e76e58a568bf..cedd68f3f9f2 100644
--- a/fs/bcachefs/extent_update.c
+++ b/fs/bcachefs/extent_update.c
@@ -108,14 +108,14 @@ int bch2_extent_atomic_end(struct btree_trans *trans,
 	unsigned nr_iters = 0;
 
 	struct btree_iter copy;
-	bch2_trans_copy_iter(trans, &copy, iter);
+	bch2_trans_copy_iter(&copy, iter);
 
-	int ret = bch2_btree_iter_traverse(trans, &copy);
+	int ret = bch2_btree_iter_traverse(&copy);
 	if (ret)
 		goto err;
 
 	struct bkey_s_c k;
-	for_each_btree_key_max_continue_norestart(trans, copy, *end, 0, k, ret) {
+	for_each_btree_key_max_continue_norestart(copy, *end, 0, k, ret) {
 		unsigned offset = 0;
 
 		if (bkey_gt(iter->pos, bkey_start_pos(k.k)))
diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index f2389054693a..8001ec467121 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -183,12 +183,12 @@ static void bchfs_read(struct btree_trans *trans,
 		if (ret)
 			goto err;
 
-		bch2_btree_iter_set_snapshot(trans, &iter, snapshot);
+		bch2_btree_iter_set_snapshot(&iter, snapshot);
 
-		bch2_btree_iter_set_pos(trans, &iter,
+		bch2_btree_iter_set_pos(&iter,
 				POS(inum.inum, rbio->bio.bi_iter.bi_sector));
 
-		k = bch2_btree_iter_peek_slot(trans, &iter);
+		k = bch2_btree_iter_peek_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
diff --git a/fs/bcachefs/fs-io.c b/fs/bcachefs/fs-io.c
index 93ad33f0953a..4a4f97f0d4b9 100644
--- a/fs/bcachefs/fs-io.c
+++ b/fs/bcachefs/fs-io.c
@@ -657,9 +657,9 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 		if (ret)
 			goto bkey_err;
 
-		bch2_btree_iter_set_snapshot(trans, &iter, snapshot);
+		bch2_btree_iter_set_snapshot(&iter, snapshot);
 
-		k = bch2_btree_iter_peek_slot(trans, &iter);
+		k = bch2_btree_iter_peek_slot(&iter);
 		if ((ret = bkey_err(k)))
 			goto bkey_err;
 
@@ -670,13 +670,13 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 		/* already reserved */
 		if (bkey_extent_is_reservation(k) &&
 		    bch2_bkey_nr_ptrs_fully_allocated(k) >= opts.data_replicas) {
-			bch2_btree_iter_advance(trans, &iter);
+			bch2_btree_iter_advance(&iter);
 			continue;
 		}
 
 		if (bkey_extent_is_data(k.k) &&
 		    !(mode & FALLOC_FL_ZERO_RANGE)) {
-			bch2_btree_iter_advance(trans, &iter);
+			bch2_btree_iter_advance(&iter);
 			continue;
 		}
 
@@ -697,7 +697,7 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 				if (ret)
 					goto bkey_err;
 			}
-			bch2_btree_iter_set_pos(trans, &iter, POS(iter.pos.inode, hole_start));
+			bch2_btree_iter_set_pos(&iter, POS(iter.pos.inode, hole_start));
 
 			if (ret)
 				goto bkey_err;
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index 56b7126bc31d..b17ac884f8c6 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -1402,7 +1402,7 @@ static int bch2_next_fiemap_extent(struct btree_trans *trans,
 			     SPOS(inode->ei_inum.inum, start, snapshot), 0);
 
 	struct bkey_s_c k =
-		bch2_btree_iter_peek_max(trans, &iter, POS(inode->ei_inum.inum, end));
+		bch2_btree_iter_peek_max(&iter, POS(inode->ei_inum.inum, end));
 	ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -1974,17 +1974,17 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 	if (ret)
 		goto err;
 
-	bch2_btree_iter_set_snapshot(trans, &iter1, snapshot);
-	bch2_btree_iter_set_snapshot(trans, &iter2, snapshot);
+	bch2_btree_iter_set_snapshot(&iter1, snapshot);
+	bch2_btree_iter_set_snapshot(&iter2, snapshot);
 
 	ret = bch2_inode_find_by_inum_trans(trans, inode_inum(inode), &inode_u);
 	if (ret)
 		goto err;
 
 	if (inode_u.bi_dir == dir->ei_inode.bi_inum) {
-		bch2_btree_iter_set_pos(trans, &iter1, POS(inode_u.bi_dir, inode_u.bi_dir_offset));
+		bch2_btree_iter_set_pos(&iter1, POS(inode_u.bi_dir, inode_u.bi_dir_offset));
 
-		k = bch2_btree_iter_peek_slot(trans, &iter1);
+		k = bch2_btree_iter_peek_slot(&iter1);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
@@ -2008,7 +2008,7 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 		 * File with multiple hardlinks and our backref is to the wrong
 		 * directory - linear search:
 		 */
-		for_each_btree_key_continue_norestart(trans, iter2, 0, k, ret) {
+		for_each_btree_key_continue_norestart(iter2, 0, k, ret) {
 			if (k.k->p.inode > dir->ei_inode.bi_inum)
 				break;
 
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index f5a9da40c647..d716cbe20976 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -167,7 +167,7 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 {
 	struct bch_fs *c = trans->c;
 	struct qstr lostfound_str = QSTR("lost+found");
-	struct btree_iter lostfound_iter = {};
+	struct btree_iter lostfound_iter = { NULL };
 	u64 inum = 0;
 	unsigned d_type = 0;
 	int ret;
@@ -275,8 +275,8 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 	if (ret)
 		goto err;
 
-	bch2_btree_iter_set_snapshot(trans, &lostfound_iter, snapshot);
-	ret = bch2_btree_iter_traverse(trans, &lostfound_iter);
+	bch2_btree_iter_set_snapshot(&lostfound_iter, snapshot);
+	ret = bch2_btree_iter_traverse(&lostfound_iter);
 	if (ret)
 		goto err;
 
@@ -583,7 +583,7 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 		new_inode.bi_subvol = subvolid;
 
 		int ret = bch2_inode_create(trans, &inode_iter, &new_inode, snapshotid, cpu) ?:
-			  bch2_btree_iter_traverse(trans, &inode_iter) ?:
+			  bch2_btree_iter_traverse(&inode_iter) ?:
 			  bch2_inode_write(trans, &inode_iter, &new_inode);
 		bch2_trans_iter_exit(trans, &inode_iter);
 		if (ret)
@@ -648,7 +648,7 @@ static int reconstruct_inode(struct btree_trans *trans, enum btree_id btree, u32
 		struct btree_iter iter = {};
 
 		bch2_trans_iter_init(trans, &iter, BTREE_ID_extents, SPOS(inum, U64_MAX, snapshot), 0);
-		struct bkey_s_c k = bch2_btree_iter_peek_prev_min(trans, &iter, POS(inum, 0));
+		struct bkey_s_c k = bch2_btree_iter_peek_prev_min(&iter, POS(inum, 0));
 		bch2_trans_iter_exit(trans, &iter);
 		int ret = bkey_err(k);
 		if (ret)
@@ -1749,7 +1749,7 @@ static int overlapping_extents_found(struct btree_trans *trans,
 	bch2_trans_iter_init(trans, &iter1, btree, pos1,
 			     BTREE_ITER_all_snapshots|
 			     BTREE_ITER_not_extents);
-	k1 = bch2_btree_iter_peek_max(trans, &iter1, POS(pos1.inode, U64_MAX));
+	k1 = bch2_btree_iter_peek_max(&iter1, POS(pos1.inode, U64_MAX));
 	ret = bkey_err(k1);
 	if (ret)
 		goto err;
@@ -1769,12 +1769,12 @@ static int overlapping_extents_found(struct btree_trans *trans,
 		goto err;
 	}
 
-	bch2_trans_copy_iter(trans, &iter2, &iter1);
+	bch2_trans_copy_iter(&iter2, &iter1);
 
 	while (1) {
-		bch2_btree_iter_advance(trans, &iter2);
+		bch2_btree_iter_advance(&iter2);
 
-		k2 = bch2_btree_iter_peek_max(trans, &iter2, POS(pos1.inode, U64_MAX));
+		k2 = bch2_btree_iter_peek_max(&iter2, POS(pos1.inode, U64_MAX));
 		ret = bkey_err(k2);
 		if (ret)
 			goto err;
@@ -2429,7 +2429,7 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 						     BTREE_ID_dirents,
 						     SPOS(k.k->p.inode, k.k->p.offset, *i),
 						     BTREE_ITER_intent);
-				ret =   bch2_btree_iter_traverse(trans, &delete_iter) ?:
+				ret =   bch2_btree_iter_traverse(&delete_iter) ?:
 					bch2_hash_delete_at(trans, bch2_dirent_hash_desc,
 							  hash_info,
 							  &delete_iter,
@@ -2673,7 +2673,7 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 		bch2_trans_iter_exit(trans, &parent_iter);
 		bch2_trans_iter_init(trans, &parent_iter,
 				     BTREE_ID_subvolumes, POS(0, parent), 0);
-		k = bch2_btree_iter_peek_slot(trans, &parent_iter);
+		k = bch2_btree_iter_peek_slot(&parent_iter);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 4a9725f30c4f..c033c8f9b11e 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1026,7 +1026,7 @@ int bch2_inode_create(struct btree_trans *trans,
 			     BTREE_ITER_intent);
 	struct bkey_s_c k;
 again:
-	while ((k = bch2_btree_iter_peek(trans, iter)).k &&
+	while ((k = bch2_btree_iter_peek(iter)).k &&
 	       !(ret = bkey_err(k)) &&
 	       bkey_lt(k.k->p, POS(0, max))) {
 		if (pos < iter->pos.offset)
@@ -1043,7 +1043,7 @@ int bch2_inode_create(struct btree_trans *trans,
 		 * we've found just one:
 		 */
 		pos = iter->pos.offset + 1;
-		bch2_btree_iter_set_pos(trans, iter, POS(0, pos));
+		bch2_btree_iter_set_pos(iter, POS(0, pos));
 	}
 
 	if (!ret && pos < max)
@@ -1059,12 +1059,12 @@ int bch2_inode_create(struct btree_trans *trans,
 
 	/* Retry from start */
 	pos = start = min;
-	bch2_btree_iter_set_pos(trans, iter, POS(0, pos));
+	bch2_btree_iter_set_pos(iter, POS(0, pos));
 	le32_add_cpu(&cursor->v.gen, 1);
 	goto again;
 found_slot:
-	bch2_btree_iter_set_pos(trans, iter, SPOS(0, pos, snapshot));
-	k = bch2_btree_iter_peek_slot(trans, iter);
+	bch2_btree_iter_set_pos(iter, SPOS(0, pos, snapshot));
+	k = bch2_btree_iter_peek_slot(iter);
 	ret = bkey_err(k);
 	if (ret) {
 		bch2_trans_iter_exit(trans, iter);
@@ -1101,9 +1101,9 @@ static int bch2_inode_delete_keys(struct btree_trans *trans,
 		if (ret)
 			goto err;
 
-		bch2_btree_iter_set_snapshot(trans, &iter, snapshot);
+		bch2_btree_iter_set_snapshot(&iter, snapshot);
 
-		k = bch2_btree_iter_peek_max(trans, &iter, end);
+		k = bch2_btree_iter_peek_max(&iter, end);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
@@ -1305,7 +1305,7 @@ int bch2_inode_set_casefold(struct btree_trans *trans, subvol_inum inum,
 static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum, u32 snapshot)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter = {};
+	struct btree_iter iter = { NULL };
 	struct bkey_i_inode_generation delete;
 	struct bch_inode_unpacked inode_u;
 	struct bkey_s_c k;
diff --git a/fs/bcachefs/io_misc.c b/fs/bcachefs/io_misc.c
index 5d6681c070ba..538f04fb3157 100644
--- a/fs/bcachefs/io_misc.c
+++ b/fs/bcachefs/io_misc.c
@@ -43,7 +43,7 @@ int bch2_extent_fallocate(struct btree_trans *trans,
 	bch2_bkey_buf_init(&new);
 	closure_init_stack(&cl);
 
-	k = bch2_btree_iter_peek_slot(trans, iter);
+	k = bch2_btree_iter_peek_slot(iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -190,12 +190,12 @@ int bch2_fpunch_at(struct btree_trans *trans, struct btree_iter *iter,
 		if (ret)
 			continue;
 
-		bch2_btree_iter_set_snapshot(trans, iter, snapshot);
+		bch2_btree_iter_set_snapshot(iter, snapshot);
 
 		/*
 		 * peek_max() doesn't have ideal semantics for extents:
 		 */
-		k = bch2_btree_iter_peek_max(trans, iter, end_pos);
+		k = bch2_btree_iter_peek_max(iter, end_pos);
 		if (!k.k)
 			break;
 
@@ -251,7 +251,7 @@ static int truncate_set_isize(struct btree_trans *trans,
 			      u64 new_i_size,
 			      bool warn)
 {
-	struct btree_iter iter = {};
+	struct btree_iter iter = { NULL };
 	struct bch_inode_unpacked inode_u;
 	int ret;
 
@@ -416,7 +416,7 @@ case LOGGED_OP_FINSERT_start:
 		if (ret)
 			goto err;
 	} else {
-		bch2_btree_iter_set_pos(trans, &iter, POS(inum.inum, src_offset));
+		bch2_btree_iter_set_pos(&iter, POS(inum.inum, src_offset));
 
 		ret = bch2_fpunch_at(trans, &iter, inum, src_offset + len, i_sectors_delta);
 		if (ret && !bch2_err_matches(ret, BCH_ERR_transaction_restart))
@@ -442,12 +442,12 @@ case LOGGED_OP_FINSERT_shift_extents:
 		if (ret)
 			goto btree_err;
 
-		bch2_btree_iter_set_snapshot(trans, &iter, snapshot);
-		bch2_btree_iter_set_pos(trans, &iter, SPOS(inum.inum, pos, snapshot));
+		bch2_btree_iter_set_snapshot(&iter, snapshot);
+		bch2_btree_iter_set_pos(&iter, SPOS(inum.inum, pos, snapshot));
 
 		k = insert
-			? bch2_btree_iter_peek_prev_min(trans, &iter, POS(inum.inum, 0))
-			: bch2_btree_iter_peek_max(trans, &iter, POS(inum.inum, U64_MAX));
+			? bch2_btree_iter_peek_prev_min(&iter, POS(inum.inum, 0))
+			: bch2_btree_iter_peek_max(&iter, POS(inum.inum, U64_MAX));
 		if ((ret = bkey_err(k)))
 			goto btree_err;
 
diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index 386b2480b026..870e8785ca1b 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -1048,7 +1048,7 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 
 		prt_printf(&buf, "memory gen: %u", gen);
 
-		ret = lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_slot(trans, &iter)));
+		ret = lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_slot(&iter)));
 		if (!ret) {
 			prt_newline(&buf);
 			bch2_bkey_val_to_text(&buf, c, k);
@@ -1434,12 +1434,12 @@ int __bch2_read(struct btree_trans *trans, struct bch_read_bio *rbio,
 		if (ret)
 			goto err;
 
-		bch2_btree_iter_set_snapshot(trans, &iter, snapshot);
+		bch2_btree_iter_set_snapshot(&iter, snapshot);
 
-		bch2_btree_iter_set_pos(trans, &iter,
+		bch2_btree_iter_set_pos(&iter,
 				POS(inum.inum, bvec_iter.bi_sector));
 
-		k = bch2_btree_iter_peek_slot(trans, &iter);
+		k = bch2_btree_iter_peek_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index 44b02d4b6502..b2f7e992b435 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -171,9 +171,9 @@ int bch2_sum_sector_overwrites(struct btree_trans *trans,
 	*i_sectors_delta	= 0;
 	*disk_sectors_delta	= 0;
 
-	bch2_trans_copy_iter(trans, &iter, extent_iter);
+	bch2_trans_copy_iter(&iter, extent_iter);
 
-	for_each_btree_key_max_continue_norestart(trans, iter,
+	for_each_btree_key_max_continue_norestart(iter,
 				new->k.p, BTREE_ITER_slots, old, ret) {
 		s64 sectors = min(new->k.p.offset, old.k->p.offset) -
 			max(bkey_start_offset(&new->k),
@@ -319,7 +319,7 @@ int bch2_extent_update(struct btree_trans *trans,
 	 * path already traversed at iter->pos because
 	 * bch2_trans_extent_update() will use it to attempt extent merging
 	 */
-	ret = __bch2_btree_iter_traverse(trans, iter);
+	ret = __bch2_btree_iter_traverse(iter);
 	if (ret)
 		return ret;
 
@@ -364,7 +364,7 @@ int bch2_extent_update(struct btree_trans *trans,
 
 	if (i_sectors_delta_total)
 		*i_sectors_delta_total += i_sectors_delta;
-	bch2_btree_iter_set_pos(trans, iter, next_pos);
+	bch2_btree_iter_set_pos(iter, next_pos);
 	return 0;
 }
 
@@ -1345,7 +1345,7 @@ static void bch2_nocow_write(struct bch_write_op *op)
 		if (ret)
 			break;
 
-		k = bch2_btree_iter_peek_slot(trans, &iter);
+		k = bch2_btree_iter_peek_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
 			break;
@@ -1430,7 +1430,7 @@ static void bch2_nocow_write(struct bch_write_op *op)
 		bch2_keylist_push(&op->insert_keys);
 		if (op->flags & BCH_WRITE_submitted)
 			break;
-		bch2_btree_iter_advance(trans, &iter);
+		bch2_btree_iter_advance(&iter);
 	}
 out:
 	bch2_trans_iter_exit(trans, &iter);
diff --git a/fs/bcachefs/migrate.c b/fs/bcachefs/migrate.c
index bd1e54e0efd5..60acef7f6bfb 100644
--- a/fs/bcachefs/migrate.c
+++ b/fs/bcachefs/migrate.c
@@ -163,7 +163,7 @@ static int bch2_dev_metadata_drop(struct bch_fs *c,
 retry:
 		ret = 0;
 		while (bch2_trans_begin(trans),
-		       (b = bch2_btree_iter_peek_node(trans, &iter)) &&
+		       (b = bch2_btree_iter_peek_node(&iter)) &&
 		       !(ret = PTR_ERR_OR_ZERO(b))) {
 			bch2_progress_update_iter(trans, progress, &iter, "dropping metadata");
 
@@ -179,7 +179,7 @@ static int bch2_dev_metadata_drop(struct bch_fs *c,
 			if (ret)
 				break;
 next:
-			bch2_btree_iter_next_node(trans, &iter);
+			bch2_btree_iter_next_node(&iter);
 		}
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			goto retry;
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 84a228c42f06..d08fdb81188a 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -594,7 +594,7 @@ static struct bkey_s_c bch2_lookup_indirect_extent_for_move(struct btree_trans *
 			     BTREE_ID_reflink, reflink_pos,
 			     BTREE_ITER_not_extents);
 
-	struct bkey_s_c k = bch2_btree_iter_peek(trans, iter);
+	struct bkey_s_c k = bch2_btree_iter_peek(iter);
 	if (!k.k || bkey_err(k)) {
 		bch2_trans_iter_exit(trans, iter);
 		return k;
@@ -646,7 +646,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 					  BTREE_ITER_prefetch|
 					  BTREE_ITER_not_extents|
 					  BTREE_ITER_all_snapshots);
-		struct btree *b = bch2_btree_iter_peek_node(trans, &iter);
+		struct btree *b = bch2_btree_iter_peek_node(&iter);
 		ret = PTR_ERR_OR_ZERO(b);
 		if (ret)
 			goto root_err;
@@ -696,7 +696,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 
 		bch2_trans_begin(trans);
 
-		k = bch2_btree_iter_peek(trans, &iter);
+		k = bch2_btree_iter_peek(&iter);
 		if (!k.k)
 			break;
 
@@ -781,7 +781,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 		if (ctxt->stats)
 			atomic64_add(k.k->size, &ctxt->stats->sectors_seen);
 next_nondata:
-		if (!bch2_btree_iter_advance(trans, &iter))
+		if (!bch2_btree_iter_advance(&iter))
 			break;
 	}
 out:
@@ -892,7 +892,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 
 		bch2_trans_begin(trans);
 
-		k = bch2_btree_iter_peek(trans, &bp_iter);
+		k = bch2_btree_iter_peek(&bp_iter);
 		ret = bkey_err(k);
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			continue;
@@ -989,7 +989,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 		if (ctxt->stats)
 			atomic64_add(sectors, &ctxt->stats->sectors_seen);
 next:
-		bch2_btree_iter_advance(trans, &bp_iter);
+		bch2_btree_iter_advance(&bp_iter);
 	}
 
 	while (check_mismatch_done < bucket_end)
@@ -1112,7 +1112,7 @@ static int bch2_move_btree(struct bch_fs *c,
 retry:
 		ret = 0;
 		while (bch2_trans_begin(trans),
-		       (b = bch2_btree_iter_peek_node(trans, &iter)) &&
+		       (b = bch2_btree_iter_peek_node(&iter)) &&
 		       !(ret = PTR_ERR_OR_ZERO(b))) {
 			if (kthread && kthread_should_stop())
 				break;
@@ -1132,7 +1132,7 @@ static int bch2_move_btree(struct bch_fs *c,
 			if (ret)
 				break;
 next:
-			bch2_btree_iter_next_node(trans, &iter);
+			bch2_btree_iter_next_node(&iter);
 		}
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			goto retry;
diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index 70ec5a015479..aeb675298b72 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -36,8 +36,8 @@ int bch2_create_trans(struct btree_trans *trans,
 		      unsigned flags)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter dir_iter = {};
-	struct btree_iter inode_iter = {};
+	struct btree_iter dir_iter = { NULL };
+	struct btree_iter inode_iter = { NULL };
 	subvol_inum new_inum = dir;
 	u64 now = bch2_current_time(c);
 	u64 cpu = raw_smp_processor_id();
@@ -133,8 +133,8 @@ int bch2_create_trans(struct btree_trans *trans,
 		if (ret)
 			goto err;
 
-		bch2_btree_iter_set_snapshot(trans, &dir_iter, dir_snapshot);
-		ret = bch2_btree_iter_traverse(trans, &dir_iter);
+		bch2_btree_iter_set_snapshot(&dir_iter, dir_snapshot);
+		ret = bch2_btree_iter_traverse(&dir_iter);
 		if (ret)
 			goto err;
 	}
@@ -192,9 +192,9 @@ int bch2_create_trans(struct btree_trans *trans,
 		new_inode->bi_depth = dir_u->bi_depth + 1;
 
 	inode_iter.flags &= ~BTREE_ITER_all_snapshots;
-	bch2_btree_iter_set_snapshot(trans, &inode_iter, snapshot);
+	bch2_btree_iter_set_snapshot(&inode_iter, snapshot);
 
-	ret   = bch2_btree_iter_traverse(trans, &inode_iter) ?:
+	ret   = bch2_btree_iter_traverse(&inode_iter) ?:
 		bch2_inode_write(trans, &inode_iter, new_inode);
 err:
 	bch2_trans_iter_exit(trans, &inode_iter);
@@ -208,8 +208,8 @@ int bch2_link_trans(struct btree_trans *trans,
 		    const struct qstr *name)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter dir_iter = {};
-	struct btree_iter inode_iter = {};
+	struct btree_iter dir_iter = { NULL };
+	struct btree_iter inode_iter = { NULL };
 	struct bch_hash_info dir_hash;
 	u64 now = bch2_current_time(c);
 	u64 dir_offset = 0;
@@ -267,9 +267,9 @@ int bch2_unlink_trans(struct btree_trans *trans,
 		      bool deleting_subvol)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter dir_iter = {};
-	struct btree_iter dirent_iter = {};
-	struct btree_iter inode_iter = {};
+	struct btree_iter dir_iter = { NULL };
+	struct btree_iter dirent_iter = { NULL };
+	struct btree_iter inode_iter = { NULL };
 	struct bch_hash_info dir_hash;
 	subvol_inum inum;
 	u64 now = bch2_current_time(c);
@@ -315,7 +315,7 @@ int bch2_unlink_trans(struct btree_trans *trans,
 		if (ret)
 			goto err;
 
-		k = bch2_btree_iter_peek_slot(trans, &dirent_iter);
+		k = bch2_btree_iter_peek_slot(&dirent_iter);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
@@ -324,8 +324,8 @@ int bch2_unlink_trans(struct btree_trans *trans,
 		 * If we're deleting a subvolume, we need to really delete the
 		 * dirent, not just emit a whiteout in the current snapshot:
 		 */
-		bch2_btree_iter_set_snapshot(trans, &dirent_iter, k.k->p.snapshot);
-		ret = bch2_btree_iter_traverse(trans, &dirent_iter);
+		bch2_btree_iter_set_snapshot(&dirent_iter, k.k->p.snapshot);
+		ret = bch2_btree_iter_traverse(&dirent_iter);
 		if (ret)
 			goto err;
 	} else {
@@ -407,10 +407,10 @@ int bch2_rename_trans(struct btree_trans *trans,
 		      enum bch_rename_mode mode)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter src_dir_iter = {};
-	struct btree_iter dst_dir_iter = {};
-	struct btree_iter src_inode_iter = {};
-	struct btree_iter dst_inode_iter = {};
+	struct btree_iter src_dir_iter = { NULL };
+	struct btree_iter dst_dir_iter = { NULL };
+	struct btree_iter src_inode_iter = { NULL };
+	struct btree_iter dst_inode_iter = { NULL };
 	struct bch_hash_info src_hash, dst_hash;
 	subvol_inum src_inum, dst_inum;
 	u64 src_offset, dst_offset;
diff --git a/fs/bcachefs/quota.c b/fs/bcachefs/quota.c
index 5f1eff591b29..ae4dc4e1b3be 100644
--- a/fs/bcachefs/quota.c
+++ b/fs/bcachefs/quota.c
@@ -512,7 +512,7 @@ static int bch2_fs_quota_read_inode(struct btree_trans *trans,
 	bch2_quota_acct(c, bch_qid(&u), Q_INO, 1,
 			KEY_TYPE_QUOTA_NOCHECK);
 advance:
-	bch2_btree_iter_set_pos(trans, iter, bpos_nosnap_successor(iter->pos));
+	bch2_btree_iter_set_pos(iter, bpos_nosnap_successor(iter->pos));
 	return 0;
 }
 
diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index c7e7f508fd0b..d4500c051146 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -239,7 +239,7 @@ int bch2_set_rebalance_needs_scan_trans(struct btree_trans *trans, u64 inum)
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_rebalance_work,
 			     SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
 			     BTREE_ITER_intent);
-	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, &iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -283,7 +283,7 @@ static int bch2_clear_rebalance_needs_scan(struct btree_trans *trans, u64 inum,
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_rebalance_work,
 			     SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
 			     BTREE_ITER_intent);
-	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, &iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -303,7 +303,7 @@ static struct bkey_s_c next_rebalance_entry(struct btree_trans *trans,
 					    struct btree_iter *work_iter)
 {
 	return !kthread_should_stop()
-		? bch2_btree_iter_peek(trans, work_iter)
+		? bch2_btree_iter_peek(work_iter)
 		: bkey_s_c_null;
 }
 
@@ -337,7 +337,7 @@ static struct bkey_s_c next_rebalance_extent(struct btree_trans *trans,
 			     work_pos.inode ? BTREE_ID_extents : BTREE_ID_reflink,
 			     work_pos,
 			     BTREE_ITER_all_snapshots);
-	struct bkey_s_c k = bch2_btree_iter_peek_slot(trans, extent_iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(extent_iter);
 	if (bkey_err(k))
 		return k;
 
@@ -531,7 +531,7 @@ static int do_rebalance(struct moving_context *ctxt)
 	struct btree_trans *trans = ctxt->trans;
 	struct bch_fs *c = trans->c;
 	struct bch_fs_rebalance *r = &c->rebalance;
-	struct btree_iter rebalance_work_iter, extent_iter = {};
+	struct btree_iter rebalance_work_iter, extent_iter = { NULL };
 	struct bkey_s_c k;
 	u32 kick = r->kick;
 	int ret = 0;
@@ -573,7 +573,7 @@ static int do_rebalance(struct moving_context *ctxt)
 		if (ret)
 			break;
 
-		bch2_btree_iter_advance(trans, &rebalance_work_iter);
+		bch2_btree_iter_advance(&rebalance_work_iter);
 	}
 
 	bch2_trans_iter_exit(trans, &extent_iter);
@@ -770,8 +770,8 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 	struct bkey_s_c extent_k, rebalance_k;
 	CLASS(printbuf, buf)();
 
-	int ret = bkey_err(extent_k	= bch2_btree_iter_peek(trans, extent_iter)) ?:
-		  bkey_err(rebalance_k	= bch2_btree_iter_peek(trans, rebalance_iter));
+	int ret = bkey_err(extent_k	= bch2_btree_iter_peek(extent_iter)) ?:
+		  bkey_err(rebalance_k	= bch2_btree_iter_peek(rebalance_iter));
 	if (ret)
 		return ret;
 
@@ -835,9 +835,9 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 	}
 
 	if (cmp <= 0)
-		bch2_btree_iter_advance(trans, extent_iter);
+		bch2_btree_iter_advance(extent_iter);
 	if (cmp >= 0)
-		bch2_btree_iter_advance(trans, rebalance_iter);
+		bch2_btree_iter_advance(rebalance_iter);
 fsck_err:
 	return ret;
 }
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 304473dac268..b7a7adbed608 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -206,7 +206,7 @@ static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 	bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
 				  BTREE_MAX_DEPTH, k->level,
 				  BTREE_ITER_intent);
-	int ret = bch2_btree_iter_traverse(trans, &iter);
+	int ret = bch2_btree_iter_traverse(&iter);
 	if (ret)
 		goto out;
 
@@ -269,7 +269,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 	bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
 				  BTREE_MAX_DEPTH, k->level,
 				  iter_flags);
-	ret = bch2_btree_iter_traverse(trans, &iter);
+	ret = bch2_btree_iter_traverse(&iter);
 	if (ret)
 		goto out;
 
@@ -300,7 +300,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 		bch2_trans_iter_exit(trans, &iter);
 		bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
 					  BTREE_MAX_DEPTH, 0, iter_flags);
-		ret =   bch2_btree_iter_traverse(trans, &iter) ?:
+		ret =   bch2_btree_iter_traverse(&iter) ?:
 			bch2_btree_increase_depth(trans, iter.path, 0) ?:
 			-BCH_ERR_transaction_restart_nested;
 		goto out;
diff --git a/fs/bcachefs/reflink.c b/fs/bcachefs/reflink.c
index 60abd89d7c9f..6bce82f5d72b 100644
--- a/fs/bcachefs/reflink.c
+++ b/fs/bcachefs/reflink.c
@@ -500,7 +500,7 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	struct btree_iter reflink_iter;
 	bch2_trans_iter_init(trans, &reflink_iter, BTREE_ID_reflink, POS_MAX,
 			     BTREE_ITER_intent);
-	struct bkey_s_c k = bch2_btree_iter_peek_prev(trans, &reflink_iter);
+	struct bkey_s_c k = bch2_btree_iter_peek_prev(&reflink_iter);
 	int ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -563,13 +563,12 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	return ret;
 }
 
-static struct bkey_s_c get_next_src(struct btree_trans *trans,
-				    struct btree_iter *iter, struct bpos end)
+static struct bkey_s_c get_next_src(struct btree_iter *iter, struct bpos end)
 {
 	struct bkey_s_c k;
 	int ret;
 
-	for_each_btree_key_max_continue_norestart(trans, *iter, end, 0, k, ret) {
+	for_each_btree_key_max_continue_norestart(*iter, end, 0, k, ret) {
 		if (bkey_extent_is_unwritten(k))
 			continue;
 
@@ -578,7 +577,7 @@ static struct bkey_s_c get_next_src(struct btree_trans *trans,
 	}
 
 	if (bkey_ge(iter->pos, end))
-		bch2_btree_iter_set_pos(trans, iter, end);
+		bch2_btree_iter_set_pos(iter, end);
 	return ret ? bkey_s_c_err(ret) : bkey_s_c_null;
 }
 
@@ -641,27 +640,27 @@ s64 bch2_remap_range(struct bch_fs *c,
 		if (ret)
 			continue;
 
-		bch2_btree_iter_set_snapshot(trans, &src_iter, src_snapshot);
+		bch2_btree_iter_set_snapshot(&src_iter, src_snapshot);
 
 		ret = bch2_subvolume_get_snapshot(trans, dst_inum.subvol,
 						  &dst_snapshot);
 		if (ret)
 			continue;
 
-		bch2_btree_iter_set_snapshot(trans, &dst_iter, dst_snapshot);
+		bch2_btree_iter_set_snapshot(&dst_iter, dst_snapshot);
 
 		if (dst_inum.inum < src_inum.inum) {
 			/* Avoid some lock cycle transaction restarts */
-			ret = bch2_btree_iter_traverse(trans, &dst_iter);
+			ret = bch2_btree_iter_traverse(&dst_iter);
 			if (ret)
 				continue;
 		}
 
 		dst_done = dst_iter.pos.offset - dst_start.offset;
 		src_want = POS(src_start.inode, src_start.offset + dst_done);
-		bch2_btree_iter_set_pos(trans, &src_iter, src_want);
+		bch2_btree_iter_set_pos(&src_iter, src_want);
 
-		src_k = get_next_src(trans, &src_iter, src_end);
+		src_k = get_next_src(&src_iter, src_end);
 		ret = bkey_err(src_k);
 		if (ret)
 			continue;
@@ -733,7 +732,7 @@ s64 bch2_remap_range(struct bch_fs *c,
 
 	do {
 		struct bch_inode_unpacked inode_u;
-		struct btree_iter inode_iter = {};
+		struct btree_iter inode_iter = { NULL };
 
 		bch2_trans_begin(trans);
 
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 5370ccb85d2d..ca3208942e2a 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -1279,13 +1279,13 @@ static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_snapshots,
 			     POS_MIN, BTREE_ITER_intent);
-	k = bch2_btree_iter_peek(trans, &iter);
+	k = bch2_btree_iter_peek(&iter);
 	ret = bkey_err(k);
 	if (ret)
 		goto err;
 
 	for (i = 0; i < nr_snapids; i++) {
-		k = bch2_btree_iter_prev_slot(trans, &iter);
+		k = bch2_btree_iter_prev_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
 			goto err;
@@ -1517,7 +1517,7 @@ static bool skip_unrelated_snapshot_tree(struct btree_trans *trans, struct btree
 		pos.snapshot = 0;
 		if (iter->btree_id != BTREE_ID_inodes)
 			pos.offset = U64_MAX;
-		bch2_btree_iter_set_pos(trans, iter, bpos_nosnap_successor(pos));
+		bch2_btree_iter_set_pos(iter, bpos_nosnap_successor(pos));
 	}
 
 	return ret;
@@ -1595,7 +1595,7 @@ static int delete_dead_snapshot_keys_v2(struct btree_trans *trans)
 	while (1) {
 		struct bkey_s_c k;
 		ret = lockrestart_do(trans,
-				bkey_err(k = bch2_btree_iter_peek(trans, &iter)));
+				bkey_err(k = bch2_btree_iter_peek(&iter)));
 		if (ret)
 			break;
 
@@ -1618,9 +1618,9 @@ static int delete_dead_snapshot_keys_v2(struct btree_trans *trans)
 			if (ret)
 				break;
 
-			bch2_btree_iter_set_pos(trans, &iter, POS(0, k.k->p.offset + 1));
+			bch2_btree_iter_set_pos(&iter, POS(0, k.k->p.offset + 1));
 		} else {
-			bch2_btree_iter_advance(trans, &iter);
+			bch2_btree_iter_advance(&iter);
 		}
 	}
 	bch2_trans_iter_exit(trans, &iter);
diff --git a/fs/bcachefs/str_hash.h b/fs/bcachefs/str_hash.h
index 353a927857f1..f4031e37ef96 100644
--- a/fs/bcachefs/str_hash.h
+++ b/fs/bcachefs/str_hash.h
@@ -230,11 +230,11 @@ int bch2_hash_needs_whiteout(struct btree_trans *trans,
 	struct bkey_s_c k;
 	int ret;
 
-	bch2_trans_copy_iter(trans, &iter, start);
+	bch2_trans_copy_iter(&iter, start);
 
-	bch2_btree_iter_advance(trans, &iter);
+	bch2_btree_iter_advance(&iter);
 
-	for_each_btree_key_continue_norestart(trans, iter, BTREE_ITER_slots, k, ret) {
+	for_each_btree_key_continue_norestart(iter, BTREE_ITER_slots, k, ret) {
 		if (k.k->type != desc.key_type &&
 		    k.k->type != KEY_TYPE_hash_whiteout)
 			break;
@@ -280,7 +280,7 @@ struct bkey_s_c bch2_hash_set_or_get_in_snapshot(struct btree_trans *trans,
 		}
 
 		if (!slot.path && !(flags & STR_HASH_must_replace))
-			bch2_trans_copy_iter(trans, &slot, iter);
+			bch2_trans_copy_iter(&slot, iter);
 
 		if (k.k->type != KEY_TYPE_hash_whiteout)
 			goto not_found;
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index 2d2d6b22df88..ae3b06d70130 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -300,7 +300,7 @@ int bch2_subvol_has_children(struct btree_trans *trans, u32 subvol)
 	struct btree_iter iter;
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_subvolume_children, POS(subvol, 0), 0);
-	struct bkey_s_c k = bch2_btree_iter_peek(trans, &iter);
+	struct bkey_s_c k = bch2_btree_iter_peek(&iter);
 	bch2_trans_iter_exit(trans, &iter);
 
 	return bkey_err(k) ?: k.k && k.k->p.inode == subvol
@@ -602,7 +602,7 @@ int bch2_subvolume_create(struct btree_trans *trans, u64 inode,
 			  bool ro)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter dst_iter, src_iter = {};
+	struct btree_iter dst_iter, src_iter = (struct btree_iter) { NULL };
 	struct bkey_i_subvolume *new_subvol = NULL;
 	struct bkey_i_subvolume *src_subvol = NULL;
 	u32 parent = 0, new_nodes[2], snapshot_subvols[2];
diff --git a/fs/bcachefs/subvolume.h b/fs/bcachefs/subvolume.h
index 075f55e25c70..3ee80821732c 100644
--- a/fs/bcachefs/subvolume.h
+++ b/fs/bcachefs/subvolume.h
@@ -33,16 +33,16 @@ int bch2_subvol_is_ro_trans(struct btree_trans *, u32);
 int bch2_subvol_is_ro(struct bch_fs *, u32);
 
 static inline struct bkey_s_c
-bch2_btree_iter_peek_in_subvolume_max_type(struct btree_trans *trans, struct btree_iter *iter,
-					   struct bpos end, u32 subvolid, unsigned flags)
+bch2_btree_iter_peek_in_subvolume_max_type(struct btree_iter *iter, struct bpos end,
+					    u32 subvolid, unsigned flags)
 {
 	u32 snapshot;
-	int ret = bch2_subvolume_get_snapshot(trans, subvolid, &snapshot);
+	int ret = bch2_subvolume_get_snapshot(iter->trans, subvolid, &snapshot);
 	if (ret)
 		return bkey_s_c_err(ret);
 
-	bch2_btree_iter_set_snapshot(trans, iter, snapshot);
-	return bch2_btree_iter_peek_max_type(trans, iter, end, flags);
+	bch2_btree_iter_set_snapshot(iter, snapshot);
+	return bch2_btree_iter_peek_max_type(iter, end, flags);
 }
 
 #define for_each_btree_key_in_subvolume_max_continue(_trans, _iter,		\
@@ -53,14 +53,14 @@ bch2_btree_iter_peek_in_subvolume_max_type(struct btree_trans *trans, struct btr
 										\
 	do {									\
 		_ret3 = lockrestart_do(_trans, ({				\
-			(_k) = bch2_btree_iter_peek_in_subvolume_max_type(trans, &(_iter),\
+			(_k) = bch2_btree_iter_peek_in_subvolume_max_type(&(_iter),	\
 						_end, _subvolid, (_flags));	\
 			if (!(_k).k)						\
 				break;						\
 										\
 			bkey_err(_k) ?: (_do);					\
 		}));								\
-	} while (!_ret3 && bch2_btree_iter_advance(_trans, &(_iter)));		\
+	} while (!_ret3 && bch2_btree_iter_advance(&(_iter)));			\
 										\
 	bch2_trans_iter_exit((_trans), &(_iter));				\
 	_ret3;									\
diff --git a/fs/bcachefs/tests.c b/fs/bcachefs/tests.c
index ea27df30cfcb..78101159fd6e 100644
--- a/fs/bcachefs/tests.c
+++ b/fs/bcachefs/tests.c
@@ -43,7 +43,7 @@ static int test_delete(struct bch_fs *c, u64 nr)
 			     BTREE_ITER_intent);
 
 	ret = commit_do(trans, NULL, NULL, 0,
-		bch2_btree_iter_traverse(trans, &iter) ?:
+		bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &k.k_i, 0));
 	bch_err_msg(c, ret, "update error");
 	if (ret)
@@ -51,7 +51,7 @@ static int test_delete(struct bch_fs *c, u64 nr)
 
 	pr_info("deleting once");
 	ret = commit_do(trans, NULL, NULL, 0,
-		bch2_btree_iter_traverse(trans, &iter) ?:
+		bch2_btree_iter_traverse(&iter) ?:
 		bch2_btree_delete_at(trans, &iter, 0));
 	bch_err_msg(c, ret, "delete error (first)");
 	if (ret)
@@ -59,7 +59,7 @@ static int test_delete(struct bch_fs *c, u64 nr)
 
 	pr_info("deleting twice");
 	ret = commit_do(trans, NULL, NULL, 0,
-		bch2_btree_iter_traverse(trans, &iter) ?:
+		bch2_btree_iter_traverse(&iter) ?:
 		bch2_btree_delete_at(trans, &iter, 0));
 	bch_err_msg(c, ret, "delete error (second)");
 	if (ret)
@@ -83,7 +83,7 @@ static int test_delete_written(struct bch_fs *c, u64 nr)
 			     BTREE_ITER_intent);
 
 	ret = commit_do(trans, NULL, NULL, 0,
-		bch2_btree_iter_traverse(trans, &iter) ?:
+		bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &k.k_i, 0));
 	bch_err_msg(c, ret, "update error");
 	if (ret)
@@ -93,7 +93,7 @@ static int test_delete_written(struct bch_fs *c, u64 nr)
 	bch2_journal_flush_all_pins(&c->journal);
 
 	ret = commit_do(trans, NULL, NULL, 0,
-		bch2_btree_iter_traverse(trans, &iter) ?:
+		bch2_btree_iter_traverse(&iter) ?:
 		bch2_btree_delete_at(trans, &iter, 0));
 	bch_err_msg(c, ret, "delete error");
 	if (ret)
@@ -349,10 +349,10 @@ static int test_peek_end(struct bch_fs *c, u64 nr)
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
 			     SPOS(0, 0, U32_MAX), 0);
 
-	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX))));
+	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
-	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX))));
+	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
 	bch2_trans_iter_exit(trans, &iter);
@@ -370,10 +370,10 @@ static int test_peek_end_extents(struct bch_fs *c, u64 nr)
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
 			     SPOS(0, 0, U32_MAX), 0);
 
-	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX))));
+	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
-	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX))));
+	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
 	bch2_trans_iter_exit(trans, &iter);
@@ -484,7 +484,7 @@ static int test_snapshot_filter(struct bch_fs *c, u32 snapid_lo, u32 snapid_hi)
 	CLASS(btree_trans, trans)(c);
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
 			     SPOS(0, 0, snapid_lo), 0);
-	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX))));
+	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 
 	BUG_ON(k.k->p.snapshot != U32_MAX);
 
@@ -591,9 +591,9 @@ static int rand_lookup(struct bch_fs *c, u64 nr)
 			     SPOS(0, 0, U32_MAX), 0);
 
 	for (u64 i = 0; i < nr; i++) {
-		bch2_btree_iter_set_pos(trans, &iter, SPOS(0, test_rand(), U32_MAX));
+		bch2_btree_iter_set_pos(&iter, SPOS(0, test_rand(), U32_MAX));
 
-		lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek(trans, &iter)));
+		lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek(&iter)));
 		ret = bkey_err(k);
 		if (ret)
 			break;
@@ -611,9 +611,9 @@ static int rand_mixed_trans(struct btree_trans *trans,
 	struct bkey_s_c k;
 	int ret;
 
-	bch2_btree_iter_set_pos(trans, iter, SPOS(0, pos, U32_MAX));
+	bch2_btree_iter_set_pos(iter, SPOS(0, pos, U32_MAX));
 
-	k = bch2_btree_iter_peek(trans, iter);
+	k = bch2_btree_iter_peek(iter);
 	ret = bkey_err(k);
 	bch_err_msg(trans->c, ret, "lookup error");
 	if (ret)
@@ -658,7 +658,7 @@ static int __do_delete(struct btree_trans *trans, struct bpos pos)
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs, pos,
 			     BTREE_ITER_intent);
-	k = bch2_btree_iter_peek_max(trans, &iter, POS(0, U64_MAX));
+	k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX));
 	ret = bkey_err(k);
 	if (ret)
 		goto err;
diff --git a/fs/bcachefs/xattr.c b/fs/bcachefs/xattr.c
index 903e20cd34fa..f5b370269a60 100644
--- a/fs/bcachefs/xattr.c
+++ b/fs/bcachefs/xattr.c
@@ -168,7 +168,7 @@ int bch2_xattr_set(struct btree_trans *trans, subvol_inum inum,
 		   int type, int flags)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter inode_iter = {};
+	struct btree_iter inode_iter = { NULL };
 	int ret;
 
 	ret   = bch2_subvol_is_ro_trans(trans, inum.subvol) ?:
-- 
2.51.0


From 951d23507b08c21f5f59b0df10eddd07a5ef6b75 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 18:26:55 -0400
Subject: [PATCH 207/309] bcachefs: kill trans arg to bch2_trans_iter_exit()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/acl.c                   |  6 +--
 fs/bcachefs/alloc_background.c      | 42 +++++++++----------
 fs/bcachefs/alloc_foreground.c      |  6 +--
 fs/bcachefs/backpointers.c          | 26 ++++++------
 fs/bcachefs/btree_gc.c              |  4 +-
 fs/bcachefs/btree_iter.c            |  8 ++--
 fs/bcachefs/btree_iter.h            | 12 +++---
 fs/bcachefs/btree_key_cache.c       |  6 +--
 fs/bcachefs/btree_update.c          | 20 ++++-----
 fs/bcachefs/btree_update.h          |  4 +-
 fs/bcachefs/btree_update_interior.c | 12 +++---
 fs/bcachefs/btree_write_buffer.c    |  6 +--
 fs/bcachefs/buckets.c               |  6 +--
 fs/bcachefs/data_update.c           |  4 +-
 fs/bcachefs/dirent.c                | 14 +++----
 fs/bcachefs/ec.c                    | 18 ++++----
 fs/bcachefs/extent_update.c         |  4 +-
 fs/bcachefs/fs-io-buffered.c        |  2 +-
 fs/bcachefs/fs-io-direct.c          |  2 +-
 fs/bcachefs/fs-io.c                 |  4 +-
 fs/bcachefs/fs.c                    | 12 +++---
 fs/bcachefs/fsck.c                  | 64 ++++++++++++++---------------
 fs/bcachefs/inode.c                 | 34 +++++++--------
 fs/bcachefs/io_misc.c               | 10 ++---
 fs/bcachefs/io_read.c               | 12 +++---
 fs/bcachefs/io_read.h               |  4 +-
 fs/bcachefs/io_write.c              |  8 ++--
 fs/bcachefs/logged_ops.c            |  2 +-
 fs/bcachefs/lru.c                   |  4 +-
 fs/bcachefs/migrate.c               |  6 +--
 fs/bcachefs/move.c                  | 28 ++++++-------
 fs/bcachefs/movinggc.c              |  2 +-
 fs/bcachefs/namei.c                 | 32 +++++++--------
 fs/bcachefs/quota.c                 |  2 +-
 fs/bcachefs/rebalance.c             | 16 ++++----
 fs/bcachefs/recovery.c              |  6 +--
 fs/bcachefs/reflink.c               | 14 +++----
 fs/bcachefs/snapshot.c              | 34 +++++++--------
 fs/bcachefs/str_hash.c              | 10 ++---
 fs/bcachefs/str_hash.h              | 16 ++++----
 fs/bcachefs/subvolume.c             | 20 ++++-----
 fs/bcachefs/subvolume.h             |  2 +-
 fs/bcachefs/tests.c                 | 16 ++++----
 fs/bcachefs/xattr.c                 |  4 +-
 44 files changed, 283 insertions(+), 281 deletions(-)

diff --git a/fs/bcachefs/acl.c b/fs/bcachefs/acl.c
index 0098cd1cc002..3befa1f36e72 100644
--- a/fs/bcachefs/acl.c
+++ b/fs/bcachefs/acl.c
@@ -303,7 +303,7 @@ struct posix_acl *bch2_get_acl(struct inode *vinode, int type, bool rcu)
 	if (!IS_ERR_OR_NULL(acl))
 		set_cached_acl(&inode->v, type, acl);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return acl;
 }
 
@@ -379,7 +379,7 @@ int bch2_set_acl(struct mnt_idmap *idmap,
 	ret =   bch2_inode_write(trans, &inode_iter, &inode_u) ?:
 		bch2_trans_commit(trans, NULL, NULL, 0);
 btree_err:
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&inode_iter);
 
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
@@ -431,7 +431,7 @@ int bch2_acl_chmod(struct btree_trans *trans, subvol_inum inum,
 	*new_acl = acl;
 	acl = NULL;
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (!IS_ERR_OR_NULL(acl))
 		kfree(acl);
 	return ret;
diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index 9bdc70d23f4c..1c2cd841e8a0 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -487,7 +487,7 @@ bch2_trans_start_alloc_update_noupdate(struct btree_trans *trans, struct btree_i
 		goto err;
 	return a;
 err:
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	return ERR_PTR(ret);
 }
 
@@ -506,18 +506,18 @@ struct bkey_i_alloc_v4 *bch2_trans_start_alloc_update(struct btree_trans *trans,
 
 	if ((void *) k.v >= trans->mem &&
 	    (void *) k.v <  trans->mem + trans->mem_top) {
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		return container_of(bkey_s_c_to_alloc_v4(k).v, struct bkey_i_alloc_v4, v);
 	}
 
 	struct bkey_i_alloc_v4 *a = bch2_alloc_to_v4_mut_inlined(trans, k);
 	if (IS_ERR(a)) {
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		return a;
 	}
 
 	ret = bch2_trans_update_ip(trans, &iter, &a->k_i, flags, _RET_IP_);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return unlikely(ret) ? ERR_PTR(ret) : a;
 }
 
@@ -757,7 +757,7 @@ static int bch2_bucket_do_index(struct btree_trans *trans,
 
 	ret = bch2_btree_bit_mod_iter(trans, &iter, set);
 fsck_err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -793,7 +793,7 @@ static noinline int bch2_bucket_gen_update(struct btree_trans *trans,
 	g->v.gens[offset] = gen;
 
 	ret = bch2_trans_update(trans, &iter, &g->k_i, 0);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1071,7 +1071,7 @@ static struct bkey_s_c bch2_get_key_or_hole(struct btree_iter *iter, struct bpos
 		 */
 		k = bch2_btree_iter_peek_max(&iter2, end);
 		next = iter2.pos;
-		bch2_trans_iter_exit(iter->trans, &iter2);
+		bch2_trans_iter_exit(&iter2);
 
 		BUG_ON(next.offset >= iter->pos.offset + U32_MAX);
 
@@ -1363,7 +1363,7 @@ static int bch2_recheck_discard_freespace_key(struct btree_trans *trans, struct
 	ret = k.k->type != KEY_TYPE_set
 		? __bch2_check_discard_freespace_key(trans, &iter, &gen, FSCK_ERR_SILENT)
 		: 0;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1435,7 +1435,7 @@ int __bch2_check_discard_freespace_key(struct btree_trans *trans, struct btree_i
 out:
 fsck_err:
 	bch2_set_btree_iter_dontneed(&alloc_iter);
-	bch2_trans_iter_exit(trans, &alloc_iter);
+	bch2_trans_iter_exit(&alloc_iter);
 	return ret;
 delete:
 	if (!async_repair) {
@@ -1617,10 +1617,10 @@ int bch2_check_alloc_info(struct bch_fs *c)
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &bucket_gens_iter);
-	bch2_trans_iter_exit(trans, &freespace_iter);
-	bch2_trans_iter_exit(trans, &discard_iter);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&bucket_gens_iter);
+	bch2_trans_iter_exit(&freespace_iter);
+	bch2_trans_iter_exit(&discard_iter);
+	bch2_trans_iter_exit(&iter);
 	bch2_dev_put(ca);
 	ca = NULL;
 
@@ -1657,7 +1657,7 @@ int bch2_check_alloc_info(struct bch_fs *c)
 
 		bch2_btree_iter_set_pos(&iter, bpos_nosnap_successor(iter.pos));
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
@@ -1890,7 +1890,7 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 		discard_in_flight_remove(ca, iter.pos.offset);
 	if (!ret)
 		s->seen++;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1970,7 +1970,7 @@ static int bch2_do_discards_fast_one(struct btree_trans *trans,
 	ret = bch2_discard_one_bucket(trans, ca, &need_discard_iter, discard_pos_done, s, true);
 out:
 fsck_err:
-	bch2_trans_iter_exit(trans, &need_discard_iter);
+	bch2_trans_iter_exit(&need_discard_iter);
 	return ret;
 }
 
@@ -2063,7 +2063,7 @@ static int invalidate_one_bp(struct btree_trans *trans,
 
 	bch2_bkey_drop_device(bkey_i_to_s(n), ca->dev_idx);
 err:
-	bch2_trans_iter_exit(trans, &extent_iter);
+	bch2_trans_iter_exit(&extent_iter);
 	return ret;
 }
 
@@ -2164,7 +2164,7 @@ static int invalidate_one_bucket(struct btree_trans *trans,
 	--*nr_to_invalidate;
 out:
 fsck_err:
-	bch2_trans_iter_exit(trans, &alloc_iter);
+	bch2_trans_iter_exit(&alloc_iter);
 	return ret;
 }
 
@@ -2227,7 +2227,7 @@ static void bch2_do_invalidates_work(struct work_struct *work)
 
 		bch2_btree_iter_advance(&iter);
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 err:
 	bch2_bkey_buf_exit(&last_flushed, c);
 	enumerated_ref_put(&ca->io_ref[WRITE], BCH_DEV_WRITE_REF_do_invalidates);
@@ -2341,7 +2341,7 @@ int bch2_dev_freespace_init(struct bch_fs *c, struct bch_dev *ca,
 			break;
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret < 0) {
 		bch_err_msg(ca, ret, "initializing free space");
@@ -2445,7 +2445,7 @@ static int __bch2_bucket_io_time_reset(struct btree_trans *trans, unsigned dev,
 	ret   = bch2_trans_update(trans, &iter, &a->k_i, 0) ?:
 		bch2_trans_commit(trans, NULL, NULL, 0);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/alloc_foreground.c b/fs/bcachefs/alloc_foreground.c
index f2123d4c7584..70895afc0d0d 100644
--- a/fs/bcachefs/alloc_foreground.c
+++ b/fs/bcachefs/alloc_foreground.c
@@ -349,11 +349,11 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 			: NULL;
 next:
 		bch2_set_btree_iter_dontneed(&citer);
-		bch2_trans_iter_exit(trans, &citer);
+		bch2_trans_iter_exit(&citer);
 		if (ob)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	alloc_cursor = iter.pos.offset;
 
@@ -430,7 +430,7 @@ static struct open_bucket *bch2_bucket_alloc_freelist(struct btree_trans *trans,
 			break;
 	}
 fail:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	BUG_ON(ob && ret);
 
diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index e1a8eb25f8be..5f2339652055 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -180,7 +180,7 @@ int bch2_bucket_backpointer_mod_nowritebuffer(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, &bp_iter, &bp->k_i, 0);
 err:
-	bch2_trans_iter_exit(trans, &bp_iter);
+	bch2_trans_iter_exit(&bp_iter);
 	return ret;
 }
 
@@ -300,7 +300,7 @@ static struct btree *__bch2_backpointer_get_node(struct btree_trans *trans,
 		b = ret ? ERR_PTR(ret) : NULL;
 	}
 err:
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	return b;
 }
 
@@ -324,7 +324,7 @@ static struct bkey_s_c __bch2_backpointer_get_key(struct btree_trans *trans,
 				  iter_flags);
 	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 	if (bkey_err(k)) {
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 		return k;
 	}
 
@@ -344,7 +344,7 @@ static struct bkey_s_c __bch2_backpointer_get_key(struct btree_trans *trans,
 	    extent_matches_bp(c, bp.v->btree_id, bp.v->level, k, bp))
 		return k;
 
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 
 	if (!bp.v->level) {
 		int ret = backpointer_target_not_found(trans, bp, k, last_flushed, commit);
@@ -420,7 +420,7 @@ static int bch2_check_backpointer_has_valid_bucket(struct btree_trans *trans, st
 	}
 out:
 fsck_err:
-	bch2_trans_iter_exit(trans, &alloc_iter);
+	bch2_trans_iter_exit(&alloc_iter);
 	return ret;
 }
 
@@ -559,8 +559,8 @@ static int check_bp_exists(struct btree_trans *trans,
 out:
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &other_extent_iter);
-	bch2_trans_iter_exit(trans, &bp_iter);
+	bch2_trans_iter_exit(&other_extent_iter);
+	bch2_trans_iter_exit(&bp_iter);
 	return ret;
 check_existing_bp:
 	/* Do we have a backpointer for a different extent? */
@@ -726,7 +726,7 @@ static int check_btree_root_to_backpointers(struct btree_trans *trans,
 		goto err;
 
 	if (b != btree_node_root(c, b)) {
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		goto retry;
 	}
 
@@ -735,7 +735,7 @@ static int check_btree_root_to_backpointers(struct btree_trans *trans,
 	k = bkey_i_to_s_c(&b->key);
 	ret = check_extent_to_backpointers(trans, s, btree_id, b->c.level + 1, k);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -924,7 +924,7 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 
 		sectors[alloc_counter] += bp.v->bucket_len;
 	};
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
@@ -1024,7 +1024,7 @@ static int btree_node_get_and_pin(struct btree_trans *trans, struct bkey_i *k,
 	if (b)
 		bch2_node_pin(trans->c, b);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1179,7 +1179,7 @@ static int check_bucket_backpointer_pos_mismatch(struct btree_trans *trans,
 		return ret;
 
 	ret = check_bucket_backpointer_mismatch(trans, k, had_mismatch, last_flushed);
-	bch2_trans_iter_exit(trans, &alloc_iter);
+	bch2_trans_iter_exit(&alloc_iter);
 	return ret;
 }
 
@@ -1239,7 +1239,7 @@ static int check_one_backpointer(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index 368d1edf6f5c..b7f750cb31f2 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -731,7 +731,7 @@ static int bch2_gc_btree(struct btree_trans *trans,
 			goto err_root;
 
 		if (b != btree_node_root(c, b)) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			goto retry_root;
 		}
 
@@ -739,7 +739,7 @@ static int bch2_gc_btree(struct btree_trans *trans,
 		struct bkey_s_c k = bkey_i_to_s_c(&b->key);
 		ret = bch2_gc_mark_key(trans, btree, b->c.level + 1, NULL, NULL, k, initial);
 err_root:
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 	} while (bch2_err_matches(ret, BCH_ERR_transaction_restart));
 err:
 	bch_err_fn(c, ret);
diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index c7012c14be60..7e1046fe478f 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -315,7 +315,7 @@ static int __bch2_btree_iter_verify_ret(struct btree_iter *iter, struct bkey_s_c
 		      buf1.buf, buf2.buf);
 	}
 out:
-	bch2_trans_iter_exit(trans, &copy);
+	bch2_trans_iter_exit(&copy);
 	return ret;
 }
 
@@ -2893,7 +2893,7 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_iter *iter)
 				iter->k = iter2.k;
 				k.k = &iter->k;
 			}
-			bch2_trans_iter_exit(trans, &iter2);
+			bch2_trans_iter_exit(&iter2);
 		} else {
 			struct bpos pos = iter->pos;
 
@@ -3105,8 +3105,10 @@ static inline void btree_path_list_add(struct btree_trans *trans,
 	btree_trans_verify_sorted_refs(trans);
 }
 
-void bch2_trans_iter_exit(struct btree_trans *trans, struct btree_iter *iter)
+void bch2_trans_iter_exit(struct btree_iter *iter)
 {
+	struct btree_trans *trans = iter->trans;
+
 	if (iter->update_path)
 		bch2_path_put(trans, iter->update_path,
 			      iter->flags & BTREE_ITER_intent);
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 1be35e642ab0..3e2d84afc26e 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -478,7 +478,7 @@ static inline void bch2_btree_iter_set_snapshot(struct btree_iter *iter, u32 sna
 	bch2_btree_iter_set_pos(iter, pos);
 }
 
-void bch2_trans_iter_exit(struct btree_trans *, struct btree_iter *);
+void bch2_trans_iter_exit(struct btree_iter *);
 
 static inline enum btree_iter_update_trigger_flags
 bch2_btree_iter_flags(struct btree_trans *trans,
@@ -641,7 +641,7 @@ static inline struct bkey_s_c __bch2_bkey_get_iter(struct btree_trans *trans,
 	if (!bkey_err(k) && type && k.k->type != type)
 		k = bkey_s_c_err(-BCH_ERR_ENOENT_bkey_type_mismatch);
 	if (unlikely(bkey_err(k)))
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 	return k;
 }
 
@@ -682,7 +682,7 @@ static inline int __bch2_bkey_get_val_typed(struct btree_trans *trans,
 	int ret = bkey_err(k);
 	if (!ret) {
 		__bkey_val_copy(val, val_size, k);
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 	}
 
 	return ret;
@@ -717,7 +717,7 @@ u32 bch2_trans_begin(struct btree_trans *);
 			PTR_ERR_OR_ZERO(bch2_btree_iter_next_node(&_iter)));	\
 	} while (!_ret3);							\
 										\
-	bch2_trans_iter_exit((_trans), &(_iter));				\
+	bch2_trans_iter_exit(&(_iter));						\
 	_ret3;									\
 })
 
@@ -826,7 +826,7 @@ transaction_restart:							\
 		}));							\
 	} while (!_ret3 && bch2_btree_iter_advance(&(_iter)));		\
 									\
-	bch2_trans_iter_exit((_trans), &(_iter));			\
+	bch2_trans_iter_exit(&(_iter));					\
 	_ret3;								\
 })
 
@@ -871,7 +871,7 @@ transaction_restart:							\
 		}));							\
 	} while (!_ret3 && bch2_btree_iter_rewind(&(_iter)));		\
 									\
-	bch2_trans_iter_exit((_trans), &(_iter));			\
+	bch2_trans_iter_exit(&(_iter));					\
 	_ret3;								\
 })
 
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index 797aa6e5b100..bf376865d0ae 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -352,7 +352,7 @@ static noinline int btree_key_cache_fill(struct btree_trans *trans,
 	/* We're not likely to need this iterator again: */
 	bch2_set_btree_iter_dontneed(&iter);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -528,8 +528,8 @@ static int btree_key_cache_flush_pos(struct btree_trans *trans,
 		}
 	}
 out:
-	bch2_trans_iter_exit(trans, &b_iter);
-	bch2_trans_iter_exit(trans, &c_iter);
+	bch2_trans_iter_exit(&b_iter);
+	bch2_trans_iter_exit(&c_iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 36c957127eba..d2efb4b42bb4 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -117,7 +117,7 @@ static int need_whiteout_for_snapshot(struct btree_trans *trans,
 			break;
 		}
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -143,7 +143,7 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 			struct bkey_i *update = bch2_trans_kmalloc(trans, sizeof(struct bkey_i));
 			ret = PTR_ERR_OR_ZERO(update);
 			if (ret) {
-				bch2_trans_iter_exit(trans, &iter);
+				bch2_trans_iter_exit(&iter);
 				break;
 			}
 
@@ -154,7 +154,7 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 			ret = bch2_trans_update(trans, &iter, update,
 						BTREE_UPDATE_internal_snapshot_node);
 		}
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		if (ret)
 			break;
@@ -320,7 +320,7 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 	if (!bkey_deleted(&insert->k))
 		ret = bch2_btree_insert_nonextent(trans, btree_id, insert, flags);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -614,7 +614,7 @@ int bch2_bkey_get_empty_slot(struct btree_trans *trans, struct btree_iter *iter,
 
 	return 0;
 err:
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	return ret;
 }
 
@@ -638,7 +638,7 @@ int bch2_btree_insert_nonextent(struct btree_trans *trans,
 			     BTREE_ITER_intent);
 	ret   = bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, k, flags);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -650,7 +650,7 @@ int bch2_btree_insert_trans(struct btree_trans *trans, enum btree_id id,
 			     BTREE_ITER_intent|flags);
 	int ret = bch2_btree_iter_traverse(&iter) ?:
 		  bch2_trans_update(trans, &iter, k, flags);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -701,7 +701,7 @@ int bch2_btree_delete(struct btree_trans *trans,
 			     BTREE_ITER_intent);
 	ret   = bch2_btree_iter_traverse(&iter) ?:
 		bch2_btree_delete_at(trans, &iter, flags);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -767,7 +767,7 @@ int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret ?: trans_was_restarted(trans, restart_count);
 }
@@ -813,7 +813,7 @@ int bch2_btree_bit_mod(struct btree_trans *trans, enum btree_id btree,
 
 	int ret = bch2_btree_iter_traverse(&iter) ?:
 		  bch2_btree_bit_mod_iter(trans, &iter, set);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 633de3b3ac28..6790e0254a63 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -382,7 +382,7 @@ static inline struct bkey_i *__bch2_bkey_get_mut_noupdate(struct btree_trans *tr
 		? ERR_CAST(k.k)
 		: __bch2_bkey_make_mut_noupdate(trans, k, 0, min_bytes);
 	if (IS_ERR(ret))
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 	return ret;
 }
 
@@ -409,7 +409,7 @@ static inline struct bkey_i *__bch2_bkey_get_mut(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, iter, mut, flags);
 	if (ret) {
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 		return ERR_PTR(ret);
 	}
 
diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 7016e81f74e2..5f4f82967105 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -2235,7 +2235,7 @@ static int get_iter_to_node(struct btree_trans *trans, struct btree_iter *iter,
 	BUG_ON(!btree_node_hashed(b));
 	return 0;
 err:
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	return ret;
 }
 
@@ -2325,7 +2325,7 @@ int bch2_btree_node_rewrite_key(struct btree_trans *trans,
 		? bch2_btree_node_rewrite(trans, &iter, b, 0, flags)
 		: -ENOENT;
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -2347,7 +2347,7 @@ int bch2_btree_node_rewrite_pos(struct btree_trans *trans,
 
 	ret = bch2_btree_node_rewrite(trans, &iter, b, target, flags);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -2361,7 +2361,7 @@ int bch2_btree_node_rewrite_key_get_iter(struct btree_trans *trans,
 		return ret == -BCH_ERR_btree_node_dying ? 0 : ret;
 
 	ret = bch2_btree_node_rewrite(trans, &iter, b, 0, flags);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -2562,7 +2562,7 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 
 	bch2_btree_node_unlock_write(trans, btree_iter_path(trans, iter), b);
 out:
-	bch2_trans_iter_exit(trans, &iter2);
+	bch2_trans_iter_exit(&iter2);
 	return ret;
 err:
 	if (new_hash) {
@@ -2633,7 +2633,7 @@ int bch2_btree_node_update_key_get_iter(struct btree_trans *trans,
 
 	ret = bch2_btree_node_update_key(trans, &iter, b, new_key,
 					 commit_flags, skip_triggers);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/btree_write_buffer.c b/fs/bcachefs/btree_write_buffer.c
index cbadf989ec6a..036b718ae975 100644
--- a/fs/bcachefs/btree_write_buffer.c
+++ b/fs/bcachefs/btree_write_buffer.c
@@ -214,7 +214,7 @@ btree_write_buffered_insert(struct btree_trans *trans,
 	ret   = bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &wb->k,
 				  BTREE_UPDATE_internal_snapshot_node);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -378,7 +378,7 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 		}
 
 		if (!iter.path || iter.btree_id != k->btree) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			bch2_trans_iter_init(trans, &iter, k->btree, k->k.k.p,
 					     BTREE_ITER_intent|BTREE_ITER_all_snapshots);
 		}
@@ -412,7 +412,7 @@ static int bch2_btree_write_buffer_flush_locked(struct btree_trans *trans)
 		struct btree_path *path = btree_iter_path(trans, &iter);
 		bch2_btree_node_unlock_write(trans, path, path->l[0].b);
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret)
 		goto err;
diff --git a/fs/bcachefs/buckets.c b/fs/bcachefs/buckets.c
index 423e0732e6f8..0a357005e9e8 100644
--- a/fs/bcachefs/buckets.c
+++ b/fs/bcachefs/buckets.c
@@ -376,7 +376,7 @@ int bch2_check_fix_ptrs(struct btree_trans *trans,
 				bch2_trans_update(trans, &iter, new,
 						  BTREE_UPDATE_internal_snapshot_node|
 						  BTREE_TRIGGER_norun);
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			if (ret)
 				return ret;
 
@@ -694,7 +694,7 @@ static int bch2_trigger_stripe_ptr(struct btree_trans *trans,
 		acc.replicas.data_type = data_type;
 		ret = bch2_disk_accounting_mod(trans, &acc, &sectors, 1, false);
 err:
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		return ret;
 	}
 
@@ -995,7 +995,7 @@ static int __bch2_trans_mark_metadata_bucket(struct btree_trans *trans,
 		ret = bch2_trans_update(trans, &iter, &a->k_i, 0);
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index 23070bb6b60c..91edec7706b2 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -487,7 +487,7 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 		goto next;
 	}
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	BUG_ON(bch2_err_matches(ret, BCH_ERR_transaction_restart));
 	return ret;
 }
@@ -556,7 +556,7 @@ int bch2_update_unwritten_extent(struct btree_trans *trans,
 			k = bch2_btree_iter_peek_slot(&iter);
 			bkey_err(k);
 		}));
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		if (ret || !bch2_extents_match(k, bkey_i_to_s_c(update->k.k)))
 			break;
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index 5dc909eaeefd..3bcbb677a808 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -586,8 +586,8 @@ int bch2_dirent_rename(struct btree_trans *trans,
 		*src_offset = new_src->k.p.offset;
 	*dst_offset = new_dst->k.p.offset;
 out:
-	bch2_trans_iter_exit(trans, &src_iter);
-	bch2_trans_iter_exit(trans, &dst_iter);
+	bch2_trans_iter_exit(&src_iter);
+	bch2_trans_iter_exit(&dst_iter);
 	return ret;
 }
 
@@ -614,7 +614,7 @@ int bch2_dirent_lookup_trans(struct btree_trans *trans,
 		ret = -ENOENT;
 err:
 	if (ret)
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 	return ret;
 }
 
@@ -627,7 +627,7 @@ u64 bch2_dirent_lookup(struct bch_fs *c, subvol_inum dir,
 
 	int ret = lockrestart_do(trans,
 		bch2_dirent_lookup_trans(trans, &iter, dir, hash_info, name, inum, 0));
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -647,7 +647,7 @@ int bch2_empty_dir_snapshot(struct btree_trans *trans, u64 dir, u32 subvol, u32
 			ret = bch_err_throw(trans->c, ENOTEMPTY_dir_not_empty);
 			break;
 		}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -737,7 +737,7 @@ static int lookup_first_inode(struct btree_trans *trans, u64 inode_nr,
 	ret = bch_err_throw(trans->c, ENOENT_inode);
 found:
 	bch_err_msg(trans->c, ret, "fetching inode %llu", inode_nr);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -761,7 +761,7 @@ int bch2_fsck_remove_dirent(struct btree_trans *trans, struct bpos pos)
 		bch2_hash_delete_at(trans, bch2_dirent_hash_desc,
 				    &dir_hash_info, &iter,
 				    BTREE_UPDATE_internal_snapshot_node);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 err:
 	bch_err_fn(c, ret);
 	return ret;
diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index d154f85c5cd9..e735b1e9b275 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -800,7 +800,7 @@ static int get_stripe_key_trans(struct btree_trans *trans, u64 idx,
 	}
 	bkey_reassemble(&stripe->key, k);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -967,7 +967,7 @@ static int ec_stripe_delete(struct btree_trans *trans, u64 idx)
 	    stripe_lru_pos(bkey_s_c_to_stripe(k).v) == 1)
 		ret = bch2_btree_delete_at(trans, &iter, 0);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1063,7 +1063,7 @@ static int ec_stripe_key_update(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, &iter, &new->k_i, 0);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1087,7 +1087,7 @@ static int ec_stripe_update_extent(struct btree_trans *trans,
 	if (bp.v->level) {
 		struct btree_iter node_iter;
 		struct btree *b = bch2_backpointer_get_node(trans, bp, &node_iter, last_flushed);
-		bch2_trans_iter_exit(trans, &node_iter);
+		bch2_trans_iter_exit(&node_iter);
 
 		if (!b)
 			return 0;
@@ -1149,7 +1149,7 @@ static int ec_stripe_update_extent(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, &iter, n, 0);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1811,7 +1811,7 @@ static int __get_existing_stripe(struct btree_trans *trans,
 out:
 	bch2_set_btree_iter_dontneed(&iter);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1883,7 +1883,7 @@ static int __bch2_ec_stripe_head_reuse(struct btree_trans *trans, struct ec_stri
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &lru_iter);
+	bch2_trans_iter_exit(&lru_iter);
 	if (!ret)
 		ret = bch_err_throw(c, stripe_alloc_blocked);
 	if (ret == 1)
@@ -1948,7 +1948,7 @@ static int __bch2_ec_stripe_head_reserve(struct btree_trans *trans, struct ec_st
 
 	s->new_stripe.key.k.p = iter.pos;
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 err:
 	bch2_disk_reservation_put(c, &s->res);
@@ -2155,7 +2155,7 @@ static int bch2_invalidate_stripe_to_dev_from_alloc(struct btree_trans *trans, s
 		return ret;
 
 	ret = bch2_invalidate_stripe_to_dev(trans, &iter, s.s_c, k_a.k->p.inode, flags);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/extent_update.c b/fs/bcachefs/extent_update.c
index cedd68f3f9f2..0c1f6f2ec02c 100644
--- a/fs/bcachefs/extent_update.c
+++ b/fs/bcachefs/extent_update.c
@@ -92,7 +92,7 @@ static int count_iters_for_insert(struct btree_trans *trans,
 				break;
 			}
 		}
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		break;
 	}
@@ -126,7 +126,7 @@ int bch2_extent_atomic_end(struct btree_trans *trans,
 			break;
 	}
 err:
-	bch2_trans_iter_exit(trans, &copy);
+	bch2_trans_iter_exit(&copy);
 	return ret < 0 ? ret : 0;
 }
 
diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index 8001ec467121..b5b3a92cee00 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -251,7 +251,7 @@ static void bchfs_read(struct btree_trans *trans,
 		    !bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret) {
 		CLASS(printbuf, buf)();
diff --git a/fs/bcachefs/fs-io-direct.c b/fs/bcachefs/fs-io-direct.c
index e53fee0513fd..8d5b2468f4cd 100644
--- a/fs/bcachefs/fs-io-direct.c
+++ b/fs/bcachefs/fs-io-direct.c
@@ -281,7 +281,7 @@ static bool bch2_check_range_allocated(struct bch_fs *c, subvol_inum inum,
 	}
 
 	offset = iter.pos.offset;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 err:
 	if (bch2_err_matches(err, BCH_ERR_transaction_restart))
 		goto retry;
diff --git a/fs/bcachefs/fs-io.c b/fs/bcachefs/fs-io.c
index 4a4f97f0d4b9..92fe1de6e4a9 100644
--- a/fs/bcachefs/fs-io.c
+++ b/fs/bcachefs/fs-io.c
@@ -206,7 +206,7 @@ static int bch2_get_inode_journal_seq_trans(struct btree_trans *trans, subvol_in
 		ret = bch2_inode_write(trans, &iter, &u);
 	}
 fsck_err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -747,7 +747,7 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 		bch2_quota_reservation_put(c, inode, &quota_res);
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index b17ac884f8c6..bf75eed72e2d 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -141,7 +141,7 @@ int __must_check bch2_write_inode(struct bch_fs *c,
 	if (!ret)
 		bch2_inode_update_after_write(trans, inode, &inode_u, fields);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
@@ -692,7 +692,7 @@ static struct bch_inode_info *bch2_lookup_trans(struct btree_trans *trans,
 	if (ret)
 		goto err;
 out:
-	bch2_trans_iter_exit(trans, &dirent_iter);
+	bch2_trans_iter_exit(&dirent_iter);
 	return inode;
 err:
 	inode = ERR_PTR(ret);
@@ -1131,7 +1131,7 @@ int bch2_setattr_nonsize(struct mnt_idmap *idmap,
 		bch2_trans_commit(trans, NULL, NULL,
 				  BCH_TRANS_COMMIT_no_enospc);
 btree_err:
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&inode_iter);
 
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
@@ -1460,7 +1460,7 @@ static int bch2_next_fiemap_extent(struct btree_trans *trans,
 		k->k.p.offset += k->k.size;
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -2039,8 +2039,8 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 
-	bch2_trans_iter_exit(trans, &iter1);
-	bch2_trans_iter_exit(trans, &iter2);
+	bch2_trans_iter_exit(&iter1);
+	bch2_trans_iter_exit(&iter2);
 	return ret;
 }
 
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index d716cbe20976..de87a0e820bd 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -126,7 +126,7 @@ static int lookup_dirent_in_snapshot(struct btree_trans *trans,
 	struct bkey_s_c_dirent d = bkey_s_c_to_dirent(k);
 	*target = le64_to_cpu(d.v->d_inum);
 	*type = d.v->d_type;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -156,7 +156,7 @@ static int find_snapshot_tree_subvol(struct btree_trans *trans,
 	}
 	ret = bch_err_throw(trans->c, ENOENT_no_snapshot_tree_subvol);
 found:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -202,7 +202,7 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 			return ret;
 
 		subvol->v.inode = cpu_to_le64(reattaching_inum);
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 	}
 
 	subvol_inum root_inum = {
@@ -292,7 +292,7 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 				       BTREE_UPDATE_internal_snapshot_node);
 err:
 	bch_err_msg(c, ret, "creating lost+found");
-	bch2_trans_iter_exit(trans, &lostfound_iter);
+	bch2_trans_iter_exit(&lostfound_iter);
 	return ret;
 }
 
@@ -358,7 +358,7 @@ static int maybe_delete_dirent(struct btree_trans *trans, struct bpos d_pos, u32
 		ret = bch2_trans_update(trans, &iter, k, BTREE_UPDATE_internal_snapshot_node);
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -383,7 +383,7 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 			return ret;
 
 		subvol->v.fs_path_parent = BCACHEFS_ROOT_SUBVOL;
-		bch2_trans_iter_exit(trans, &subvol_iter);
+		bch2_trans_iter_exit(&subvol_iter);
 
 		u64 root_inum;
 		ret = subvol_lookup(trans, inode->bi_parent_subvol,
@@ -498,7 +498,7 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 					break;
 			}
 		}
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 	}
 
 	return ret;
@@ -532,7 +532,7 @@ static int remove_backpointer(struct btree_trans *trans,
 	int ret = bkey_err(d) ?:
 		  dirent_points_to_inode(c, d, inode) ?:
 		  bch2_fsck_remove_dirent(trans, d.k->p);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -585,7 +585,7 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 		int ret = bch2_inode_create(trans, &inode_iter, &new_inode, snapshotid, cpu) ?:
 			  bch2_btree_iter_traverse(&inode_iter) ?:
 			  bch2_inode_write(trans, &inode_iter, &new_inode);
-		bch2_trans_iter_exit(trans, &inode_iter);
+		bch2_trans_iter_exit(&inode_iter);
 		if (ret)
 			return ret;
 
@@ -620,7 +620,7 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 
 	s->v.subvol = cpu_to_le32(subvolid);
 	SET_BCH_SNAPSHOT_SUBVOL(&s->v, true);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	struct bkey_i_snapshot_tree *st = bch2_bkey_get_mut_typed(trans, &iter,
 			BTREE_ID_snapshot_trees, POS(0, snapshot_tree),
@@ -633,7 +633,7 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 	if (!st->v.master_subvol)
 		st->v.master_subvol = cpu_to_le32(subvolid);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -649,7 +649,7 @@ static int reconstruct_inode(struct btree_trans *trans, enum btree_id btree, u32
 
 		bch2_trans_iter_init(trans, &iter, BTREE_ID_extents, SPOS(inum, U64_MAX, snapshot), 0);
 		struct bkey_s_c k = bch2_btree_iter_peek_prev_min(&iter, POS(inum, 0));
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		int ret = bkey_err(k);
 		if (ret)
 			return ret;
@@ -867,7 +867,7 @@ static int get_inodes_all_snapshots(struct btree_trans *trans,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret)
 		return ret;
@@ -907,7 +907,7 @@ static int get_visible_inodes(struct btree_trans *trans,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -1049,7 +1049,7 @@ static int check_inode_deleted_list(struct btree_trans *trans, struct bpos p)
 	struct btree_iter iter;
 	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_deleted_inodes, p, 0);
 	int ret = bkey_err(k) ?: k.k->type == KEY_TYPE_set;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1107,7 +1107,7 @@ static int check_inode_dirent_inode(struct btree_trans *trans,
 out:
 	ret = 0;
 fsck_err:
-	bch2_trans_iter_exit(trans, &dirent_iter);
+	bch2_trans_iter_exit(&dirent_iter);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -1380,7 +1380,7 @@ static int find_oldest_inode_needs_reattach(struct btree_trans *trans,
 
 		*inode = parent_inode;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -1557,7 +1557,7 @@ static int check_key_has_inode(struct btree_trans *trans,
 out:
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &iter2);
+	bch2_trans_iter_exit(&iter2);
 	bch_err_fn(c, ret);
 	return ret;
 delete:
@@ -1594,7 +1594,7 @@ static int maybe_reconstruct_inum_btree(struct btree_trans *trans,
 		ret = 1;
 		break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret <= 0)
 		return ret;
@@ -1843,8 +1843,8 @@ static int overlapping_extents_found(struct btree_trans *trans,
 	}
 fsck_err:
 err:
-	bch2_trans_iter_exit(trans, &iter2);
-	bch2_trans_iter_exit(trans, &iter1);
+	bch2_trans_iter_exit(&iter2);
+	bch2_trans_iter_exit(&iter1);
 	return ret;
 }
 
@@ -2136,7 +2136,7 @@ static int find_snapshot_subvol(struct btree_trans *trans, u32 snapshot, u32 *su
 
 		struct bkey_s_c_subvolume s = bkey_s_c_to_subvolume(k);
 		if (bch2_snapshot_is_ancestor(trans->c, le32_to_cpu(s.v->snapshot), snapshot)) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			*subvolid = k.k->p.offset;
 			goto found;
 		}
@@ -2144,7 +2144,7 @@ static int find_snapshot_subvol(struct btree_trans *trans, u32 snapshot, u32 *su
 	if (!ret)
 		ret = -ENOENT;
 found:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -2283,7 +2283,7 @@ static int check_dirent_to_subvol(struct btree_trans *trans, struct btree_iter *
 out:
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &subvol_iter);
+	bch2_trans_iter_exit(&subvol_iter);
 	return ret;
 }
 
@@ -2434,7 +2434,7 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 							  hash_info,
 							  &delete_iter,
 							  BTREE_UPDATE_internal_snapshot_node);
-				bch2_trans_iter_exit(trans, &delete_iter);
+				bch2_trans_iter_exit(&delete_iter);
 				if (ret)
 					return ret;
 
@@ -2670,7 +2670,7 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 			break;
 		}
 
-		bch2_trans_iter_exit(trans, &parent_iter);
+		bch2_trans_iter_exit(&parent_iter);
 		bch2_trans_iter_init(trans, &parent_iter,
 				     BTREE_ID_subvolumes, POS(0, parent), 0);
 		k = bch2_btree_iter_peek_slot(&parent_iter);
@@ -2690,7 +2690,7 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 	}
 fsck_err:
 err:
-	bch2_trans_iter_exit(trans, &parent_iter);
+	bch2_trans_iter_exit(&parent_iter);
 	return ret;
 }
 
@@ -2730,7 +2730,7 @@ static int bch2_bi_depth_renumber_one(struct btree_trans *trans,
 			bch2_trans_commit(trans, NULL, NULL, 0);
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -2788,7 +2788,7 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 			goto out;
 
 		if (!ret && (ret = dirent_points_to_inode(c, d, &inode)))
-			bch2_trans_iter_exit(trans, &dirent_iter);
+			bch2_trans_iter_exit(&dirent_iter);
 
 		if (bch2_err_matches(ret, ENOENT)) {
 			printbuf_reset(&buf);
@@ -2798,13 +2798,13 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 			goto out;
 		}
 
-		bch2_trans_iter_exit(trans, &dirent_iter);
+		bch2_trans_iter_exit(&dirent_iter);
 
 		ret = darray_push(&path, inode.bi_inum);
 		if (ret)
 			return ret;
 
-		bch2_trans_iter_exit(trans, &inode_iter);
+		bch2_trans_iter_exit(&inode_iter);
 		inode_k = bch2_bkey_get_iter(trans, &inode_iter, BTREE_ID_inodes,
 					     SPOS(0, inode.bi_dir, snapshot), 0);
 
@@ -2863,7 +2863,7 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 		ret = bch2_bi_depth_renumber(trans, &path, snapshot, min_bi_depth);
 out:
 fsck_err:
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&inode_iter);
 	bch_err_fn(c, ret);
 	return ret;
 }
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index c033c8f9b11e..3f983a5b780c 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -364,7 +364,7 @@ int __bch2_inode_peek(struct btree_trans *trans,
 err:
 	if (warn)
 		bch_err_msg(trans->c, ret, "looking up inum %llu:%llu:", inum.subvol, inum.inum);
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	return ret;
 }
 
@@ -384,7 +384,7 @@ int bch2_inode_find_by_inum_snapshot(struct btree_trans *trans,
 		? bch2_inode_unpack(k, inode)
 		: -BCH_ERR_ENOENT_inode;
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -397,7 +397,7 @@ int bch2_inode_find_by_inum_nowarn_trans(struct btree_trans *trans,
 
 	ret = bch2_inode_peek_nowarn(trans, &iter, inode, inum, 0);
 	if (!ret)
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -410,7 +410,7 @@ int bch2_inode_find_by_inum_trans(struct btree_trans *trans,
 
 	ret = bch2_inode_peek(trans, &iter, inode, inum, 0);
 	if (!ret)
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -441,7 +441,7 @@ int bch2_inode_find_snapshot_root(struct btree_trans *trans, u64 inum,
 	/* We're only called when we know we have an inode for @inum */
 	BUG_ON(!ret);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -703,7 +703,7 @@ bch2_bkey_get_iter_snapshot_parent(struct btree_trans *trans, struct btree_iter
 		if (bch2_snapshot_is_ancestor(c, pos.snapshot, k.k->p.snapshot))
 			return k;
 
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	return ret ? bkey_s_c_err(ret) : bkey_s_c_null;
 }
 
@@ -719,7 +719,7 @@ bch2_inode_get_iter_snapshot_parent(struct btree_trans *trans, struct btree_iter
 	    bkey_is_inode(k.k))
 		return k;
 
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 	pos = k.k->p;
 	goto again;
 }
@@ -740,7 +740,7 @@ int __bch2_inode_has_child_snapshots(struct btree_trans *trans, struct bpos pos)
 			ret = 1;
 			break;
 		}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -792,7 +792,7 @@ static int update_parent_inode_has_children(struct btree_trans *trans, struct bp
 		bkey_inode_flags_set(bkey_i_to_s(update), f ^ BCH_INODE_has_child_snapshot);
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -998,7 +998,7 @@ bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *m
 		le32_add_cpu(&cursor->v.gen, 1);
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret ? ERR_PTR(ret) : cursor;
 }
 
@@ -1053,7 +1053,7 @@ int bch2_inode_create(struct btree_trans *trans,
 		ret = bch_err_throw(trans->c, ENOSPC_inode_create);
 
 	if (ret) {
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 		return ret;
 	}
 
@@ -1067,7 +1067,7 @@ int bch2_inode_create(struct btree_trans *trans,
 	k = bch2_btree_iter_peek_slot(iter);
 	ret = bkey_err(k);
 	if (ret) {
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 		return ret;
 	}
 
@@ -1127,7 +1127,7 @@ static int bch2_inode_delete_keys(struct btree_trans *trans,
 			break;
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1184,7 +1184,7 @@ int bch2_inode_rm(struct bch_fs *c, subvol_inum inum)
 		bch2_trans_commit(trans, NULL, NULL,
 				BCH_TRANS_COMMIT_no_enospc);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 
@@ -1358,7 +1358,7 @@ static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum
 		bch2_trans_commit(trans, NULL, NULL,
 				BCH_TRANS_COMMIT_no_enospc);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 
@@ -1383,7 +1383,7 @@ static int delete_ancestor_snapshot_inodes(struct btree_trans *trans, struct bpo
 
 	bool unlinked = bkey_is_unlinked_inode(k);
 	pos = k.k->p;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (!unlinked)
 		return 0;
@@ -1503,7 +1503,7 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 	}
 out:
 fsck_err:
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&inode_iter);
 	return ret;
 delete:
 	ret = bch2_btree_bit_mod_buffered(trans, BTREE_ID_deleted_inodes, pos, false);
diff --git a/fs/bcachefs/io_misc.c b/fs/bcachefs/io_misc.c
index 538f04fb3157..d3496eb8d682 100644
--- a/fs/bcachefs/io_misc.c
+++ b/fs/bcachefs/io_misc.c
@@ -230,7 +230,7 @@ int bch2_fpunch(struct bch_fs *c, subvol_inum inum, u64 start, u64 end,
 
 	int ret = bch2_fpunch_at(trans, &iter, inum, end, i_sectors_delta);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return bch2_err_matches(ret, BCH_ERR_transaction_restart) ? 0 : ret;
 }
@@ -259,7 +259,7 @@ static int truncate_set_isize(struct btree_trans *trans,
 		(inode_u.bi_size = new_i_size, 0) ?:
 		bch2_inode_write(trans, &iter, &inode_u);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -284,7 +284,7 @@ static int __bch2_resume_logged_op_truncate(struct btree_trans *trans,
 			     POS(inum.inum, round_up(new_i_size, block_bytes(c)) >> 9),
 			     BTREE_ITER_intent);
 	ret = bch2_fpunch_at(trans, &fpunch_iter, inum, U64_MAX, i_sectors_delta);
-	bch2_trans_iter_exit(trans, &fpunch_iter);
+	bch2_trans_iter_exit(&fpunch_iter);
 
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		ret = 0;
@@ -366,7 +366,7 @@ static int adjust_i_size(struct btree_trans *trans, subvol_inum inum,
 
 	ret = bch2_inode_write(trans, &iter, &inode_u);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -515,7 +515,7 @@ case LOGGED_OP_FINSERT_finish:
 	break;
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (warn_errors)
 		bch_err_fn(c, ret);
 	return ret;
diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index 870e8785ca1b..571b1b9c0fa1 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -540,7 +540,7 @@ static void get_rbio_extent(struct btree_trans *trans,
 			break;
 		}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 }
 
 static noinline int maybe_poison_extent(struct btree_trans *trans, struct bch_read_bio *rbio,
@@ -585,7 +585,7 @@ static noinline int maybe_poison_extent(struct btree_trans *trans, struct bch_re
 	if (u && !ret)
 		bch2_bkey_buf_copy(&u->k, c, new);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -620,7 +620,7 @@ static noinline int bch2_read_retry_nodecode(struct btree_trans *trans,
 				 bkey_i_to_s_c(u->k.k),
 				 0, failed, flags, -1);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart) ||
 	    bch2_err_matches(ret, BCH_ERR_data_read_retry))
@@ -803,7 +803,7 @@ static int __bch2_rbio_narrow_crcs(struct btree_trans *trans,
 	ret = bch2_trans_update(trans, &iter, new,
 				BTREE_UPDATE_internal_snapshot_node);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1067,7 +1067,7 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 
 	bch2_fs_inconsistent(c, "%s", buf.buf);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 }
 
 int __bch2_read_extent(struct btree_trans *trans, struct bch_read_bio *orig,
@@ -1514,7 +1514,7 @@ int __bch2_read(struct btree_trans *trans, struct bch_read_bio *rbio,
 			bch2_rbio_done(rbio);
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	bch2_bkey_buf_exit(&sk, c);
 	return ret;
 }
diff --git a/fs/bcachefs/io_read.h b/fs/bcachefs/io_read.h
index 9d63d5914b20..1e1c0476bd03 100644
--- a/fs/bcachefs/io_read.h
+++ b/fs/bcachefs/io_read.h
@@ -108,12 +108,12 @@ static inline int bch2_read_indirect_extent(struct btree_trans *trans,
 		return ret;
 
 	if (bkey_deleted(k.k)) {
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		return bch_err_throw(c, missing_indirect_extent);
 	}
 
 	bch2_bkey_buf_reassemble(extent, c, k);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index b2f7e992b435..6b9f8b5e55dc 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -198,7 +198,7 @@ int bch2_sum_sector_overwrites(struct btree_trans *trans,
 			break;
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -295,7 +295,7 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 				BTREE_UPDATE_internal_snapshot_node|
 				inode_update_flags);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -407,7 +407,7 @@ static int bch2_write_index_default(struct bch_write_op *op)
 					&op->res,
 					op->new_i_size, &op->i_sectors_delta,
 					op->flags & BCH_WRITE_check_enospc);
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			continue;
@@ -1433,7 +1433,7 @@ static void bch2_nocow_write(struct bch_write_op *op)
 		bch2_btree_iter_advance(&iter);
 	}
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 err:
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
diff --git a/fs/bcachefs/logged_ops.c b/fs/bcachefs/logged_ops.c
index 0367ea37e857..38cdacc6b067 100644
--- a/fs/bcachefs/logged_ops.c
+++ b/fs/bcachefs/logged_ops.c
@@ -81,7 +81,7 @@ static int __bch2_logged_op_start(struct btree_trans *trans, struct bkey_i *k)
 	k->k.p = iter.pos;
 
 	ret = bch2_trans_update(trans, &iter, k, 0);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/lru.c b/fs/bcachefs/lru.c
index 76109b37d681..39ae70e5c81b 100644
--- a/fs/bcachefs/lru.c
+++ b/fs/bcachefs/lru.c
@@ -112,7 +112,7 @@ int bch2_lru_check_set(struct btree_trans *trans,
 	}
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &lru_iter);
+	bch2_trans_iter_exit(&lru_iter);
 	return ret;
 }
 
@@ -197,7 +197,7 @@ static int bch2_check_lru_key(struct btree_trans *trans,
 	}
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/migrate.c b/fs/bcachefs/migrate.c
index 60acef7f6bfb..a66d01d04e57 100644
--- a/fs/bcachefs/migrate.c
+++ b/fs/bcachefs/migrate.c
@@ -111,7 +111,7 @@ static int bch2_dev_btree_drop_key(struct btree_trans *trans,
 
 	ret = drop_btree_ptrs(trans, &iter, b, dev_idx, flags);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -184,7 +184,7 @@ static int bch2_dev_metadata_drop(struct bch_fs *c,
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			goto retry;
 
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		if (ret)
 			goto err;
@@ -228,7 +228,7 @@ static int data_drop_bp(struct btree_trans *trans, unsigned dev_idx,
 	else
 		ret = bch2_dev_usrdata_drop_key(trans, &iter, k, dev_idx, flags);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index d08fdb81188a..ae9fb58702ba 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -527,7 +527,7 @@ int bch2_move_get_io_opts_one(struct btree_trans *trans,
 		bch2_inode_unpack(inode_k, &inode);
 		bch2_inode_opts_get(io_opts, c, &inode);
 	}
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&inode_iter);
 	/* seem to be spinning here? */
 out:
 	return bch2_get_update_rebalance_opts(trans, io_opts, extent_iter, extent_k);
@@ -596,12 +596,12 @@ static struct bkey_s_c bch2_lookup_indirect_extent_for_move(struct btree_trans *
 
 	struct bkey_s_c k = bch2_btree_iter_peek(iter);
 	if (!k.k || bkey_err(k)) {
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 		return k;
 	}
 
 	if (bkey_lt(reflink_pos, bkey_start_pos(k.k))) {
-		bch2_trans_iter_exit(trans, iter);
+		bch2_trans_iter_exit(iter);
 		return bkey_s_c_null;
 	}
 
@@ -652,7 +652,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 			goto root_err;
 
 		if (b != btree_node_root(c, b)) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			goto retry_root;
 		}
 
@@ -676,7 +676,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 
 root_err:
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart)) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			goto retry_root;
 		}
 
@@ -717,7 +717,7 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 		    REFLINK_P_MAY_UPDATE_OPTIONS(bkey_s_c_to_reflink_p(k).v)) {
 			struct bkey_s_c_reflink_p p = bkey_s_c_to_reflink_p(k);
 
-			bch2_trans_iter_exit(trans, &reflink_iter);
+			bch2_trans_iter_exit(&reflink_iter);
 			k = bch2_lookup_indirect_extent_for_move(trans, &reflink_iter, p);
 			ret = bkey_err(k);
 			if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
@@ -785,8 +785,8 @@ int bch2_move_data_btree(struct moving_context *ctxt,
 			break;
 	}
 out:
-	bch2_trans_iter_exit(trans, &reflink_iter);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&reflink_iter);
+	bch2_trans_iter_exit(&iter);
 	bch2_bkey_buf_exit(&sk, c);
 	per_snapshot_io_opts_exit(&snapshot_io_opts);
 
@@ -936,7 +936,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 		if (!bp.v->level) {
 			ret = bch2_move_get_io_opts_one(trans, &io_opts, &iter, k);
 			if (ret) {
-				bch2_trans_iter_exit(trans, &iter);
+				bch2_trans_iter_exit(&iter);
 				continue;
 			}
 		}
@@ -949,13 +949,13 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 					    pred, arg, p);
 
 		if (!p) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			goto next;
 		}
 
 		if (data_opts.scrub &&
 		    !bch2_dev_idx_is_online(c, data_opts.read_dev)) {
-			bch2_trans_iter_exit(trans, &iter);
+			bch2_trans_iter_exit(&iter);
 			ret = bch_err_throw(c, device_offline);
 			break;
 		}
@@ -974,7 +974,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 		else
 			ret = bch2_btree_node_scrub(trans, bp.v->btree_id, bp.v->level, k, data_opts.read_dev);
 
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			continue;
@@ -996,7 +996,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 		bch2_check_bucket_backpointer_mismatch(trans, ca, check_mismatch_done++,
 						       copygc, &last_flushed);
 err:
-	bch2_trans_iter_exit(trans, &bp_iter);
+	bch2_trans_iter_exit(&bp_iter);
 	bch2_bkey_buf_exit(&sk, c);
 	bch2_bkey_buf_exit(&last_flushed, c);
 	return ret;
@@ -1137,7 +1137,7 @@ static int bch2_move_btree(struct bch_fs *c,
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			goto retry;
 
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 
 		if (kthread && kthread_should_stop())
 			break;
diff --git a/fs/bcachefs/movinggc.c b/fs/bcachefs/movinggc.c
index 9192b1fc3594..f391eceef4f4 100644
--- a/fs/bcachefs/movinggc.c
+++ b/fs/bcachefs/movinggc.c
@@ -90,7 +90,7 @@ static int bch2_bucket_is_movable(struct btree_trans *trans,
 
 	ret = lru_idx && lru_idx <= time;
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index aeb675298b72..cfed2041c2c3 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -197,8 +197,8 @@ int bch2_create_trans(struct btree_trans *trans,
 	ret   = bch2_btree_iter_traverse(&inode_iter) ?:
 		bch2_inode_write(trans, &inode_iter, new_inode);
 err:
-	bch2_trans_iter_exit(trans, &inode_iter);
-	bch2_trans_iter_exit(trans, &dir_iter);
+	bch2_trans_iter_exit(&inode_iter);
+	bch2_trans_iter_exit(&dir_iter);
 	return ret;
 }
 
@@ -254,8 +254,8 @@ int bch2_link_trans(struct btree_trans *trans,
 	ret =   bch2_inode_write(trans, &dir_iter, dir_u) ?:
 		bch2_inode_write(trans, &inode_iter, inode_u);
 err:
-	bch2_trans_iter_exit(trans, &dir_iter);
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&dir_iter);
+	bch2_trans_iter_exit(&inode_iter);
 	return ret;
 }
 
@@ -347,9 +347,9 @@ int bch2_unlink_trans(struct btree_trans *trans,
 		bch2_inode_write(trans, &dir_iter, dir_u) ?:
 		bch2_inode_write(trans, &inode_iter, inode_u);
 err:
-	bch2_trans_iter_exit(trans, &inode_iter);
-	bch2_trans_iter_exit(trans, &dirent_iter);
-	bch2_trans_iter_exit(trans, &dir_iter);
+	bch2_trans_iter_exit(&inode_iter);
+	bch2_trans_iter_exit(&dirent_iter);
+	bch2_trans_iter_exit(&dir_iter);
 	return ret;
 }
 
@@ -393,7 +393,7 @@ static int subvol_update_parent(struct btree_trans *trans, u32 subvol, u32 new_p
 		return ret;
 
 	s->v.fs_path_parent = cpu_to_le32(new_parent);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -582,10 +582,10 @@ int bch2_rename_trans(struct btree_trans *trans,
 		 ? bch2_inode_write(trans, &dst_inode_iter, dst_inode_u)
 		 : 0);
 err:
-	bch2_trans_iter_exit(trans, &dst_inode_iter);
-	bch2_trans_iter_exit(trans, &src_inode_iter);
-	bch2_trans_iter_exit(trans, &dst_dir_iter);
-	bch2_trans_iter_exit(trans, &src_dir_iter);
+	bch2_trans_iter_exit(&dst_inode_iter);
+	bch2_trans_iter_exit(&src_inode_iter);
+	bch2_trans_iter_exit(&dst_dir_iter);
+	bch2_trans_iter_exit(&src_dir_iter);
 	return ret;
 }
 
@@ -701,7 +701,7 @@ static int __bch2_inum_to_path(struct btree_trans *trans,
 
 		prt_char(path, '/');
 
-		bch2_trans_iter_exit(trans, &d_iter);
+		bch2_trans_iter_exit(&d_iter);
 	}
 
 	if (orig_pos == path->pos)
@@ -854,7 +854,7 @@ static int bch2_check_dirent_inode_dirent(struct btree_trans *trans,
 out:
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &bp_iter);
+	bch2_trans_iter_exit(&bp_iter);
 	bch_err_fn(c, ret);
 	return ret;
 }
@@ -931,14 +931,14 @@ static int bch2_propagate_has_case_insensitive(struct btree_trans *trans, subvol
 		if (ret)
 			break;
 
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		if (subvol_inum_eq(inum, BCACHEFS_ROOT_SUBVOL_INUM))
 			break;
 
 		inum = parent_inum(inum, &inode);
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/quota.c b/fs/bcachefs/quota.c
index ae4dc4e1b3be..64a7f5eeeb5c 100644
--- a/fs/bcachefs/quota.c
+++ b/fs/bcachefs/quota.c
@@ -820,7 +820,7 @@ static int bch2_set_quota_trans(struct btree_trans *trans,
 		new_quota->v.c[Q_INO].hardlimit = cpu_to_le64(qdq->d_ino_hardlimit);
 
 	ret = bch2_trans_update(trans, &iter, &new_quota->k_i, 0);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index d4500c051146..f2918804fab5 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -259,7 +259,7 @@ int bch2_set_rebalance_needs_scan_trans(struct btree_trans *trans, u64 inum)
 
 	ret = bch2_trans_update(trans, &iter, &cookie->k_i, 0);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -295,7 +295,7 @@ static int bch2_clear_rebalance_needs_scan(struct btree_trans *trans, u64 inum,
 	if (v == cookie)
 		ret = bch2_btree_delete_at(trans, &iter, 0);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -332,7 +332,7 @@ static struct bkey_s_c next_rebalance_extent(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 
-	bch2_trans_iter_exit(trans, extent_iter);
+	bch2_trans_iter_exit(extent_iter);
 	bch2_trans_iter_init(trans, extent_iter,
 			     work_pos.inode ? BTREE_ID_extents : BTREE_ID_reflink,
 			     work_pos,
@@ -576,8 +576,8 @@ static int do_rebalance(struct moving_context *ctxt)
 		bch2_btree_iter_advance(&rebalance_work_iter);
 	}
 
-	bch2_trans_iter_exit(trans, &extent_iter);
-	bch2_trans_iter_exit(trans, &rebalance_work_iter);
+	bch2_trans_iter_exit(&extent_iter);
+	bch2_trans_iter_exit(&rebalance_work_iter);
 	bch2_move_stats_exit(&r->scan_stats, c);
 
 	if (!ret &&
@@ -779,7 +779,7 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 	    extent_iter->btree_id == BTREE_ID_reflink &&
 	    (!rebalance_k.k ||
 	     rebalance_k.k->p.inode >= BCACHEFS_ROOT_INO)) {
-		bch2_trans_iter_exit(trans, extent_iter);
+		bch2_trans_iter_exit(extent_iter);
 		bch2_trans_iter_init(trans, extent_iter,
 				     BTREE_ID_extents, POS_MIN,
 				     BTREE_ITER_prefetch|
@@ -874,7 +874,7 @@ int bch2_check_rebalance_work(struct bch_fs *c)
 	}
 
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch2_trans_iter_exit(trans, &extent_iter);
-	bch2_trans_iter_exit(trans, &rebalance_iter);
+	bch2_trans_iter_exit(&extent_iter);
+	bch2_trans_iter_exit(&rebalance_iter);
 	return ret < 0 ? ret : 0;
 }
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index b7a7adbed608..c57ff235a97a 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -234,7 +234,7 @@ static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, &iter, new, BTREE_TRIGGER_norun);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -297,7 +297,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 			goto out;
 		}
 
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
 					  BTREE_MAX_DEPTH, 0, iter_flags);
 		ret =   bch2_btree_iter_traverse(&iter) ?:
@@ -322,7 +322,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, &iter, k->k, update_flags);
 out:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/reflink.c b/fs/bcachefs/reflink.c
index 6bce82f5d72b..07cebc697b38 100644
--- a/fs/bcachefs/reflink.c
+++ b/fs/bcachefs/reflink.c
@@ -277,13 +277,13 @@ struct bkey_s_c bch2_lookup_indirect_extent(struct btree_trans *trans,
 		int ret = bch2_indirect_extent_missing_error(trans, p, reflink_offset,
 							     missing_end, should_commit);
 		if (ret) {
-			bch2_trans_iter_exit(trans, iter);
+			bch2_trans_iter_exit(iter);
 			return bkey_s_c_err(ret);
 		}
 	} else if (unlikely(REFLINK_P_ERROR(p.v))) {
 		int ret = bch2_indirect_extent_not_missing(trans, p, should_commit);
 		if (ret) {
-			bch2_trans_iter_exit(trans, iter);
+			bch2_trans_iter_exit(iter);
 			return bkey_s_c_err(ret);
 		}
 	}
@@ -357,7 +357,7 @@ static int trans_trigger_reflink_p_segment(struct btree_trans *trans,
 	*idx = k.k->p.offset;
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -558,7 +558,7 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	ret = bch2_trans_update(trans, extent_iter, &r_p->k_i,
 				BTREE_UPDATE_internal_snapshot_node);
 err:
-	bch2_trans_iter_exit(trans, &reflink_iter);
+	bch2_trans_iter_exit(&reflink_iter);
 
 	return ret;
 }
@@ -721,8 +721,8 @@ s64 bch2_remap_range(struct bch_fs *c,
 					true);
 		bch2_disk_reservation_put(c, &disk_res);
 	}
-	bch2_trans_iter_exit(trans, &dst_iter);
-	bch2_trans_iter_exit(trans, &src_iter);
+	bch2_trans_iter_exit(&dst_iter);
+	bch2_trans_iter_exit(&src_iter);
 
 	BUG_ON(!ret && !bkey_eq(dst_iter.pos, dst_end));
 	BUG_ON(bkey_gt(dst_iter.pos, dst_end));
@@ -747,7 +747,7 @@ s64 bch2_remap_range(struct bch_fs *c,
 						  BCH_TRANS_COMMIT_no_enospc);
 		}
 
-		bch2_trans_iter_exit(trans, &inode_iter);
+		bch2_trans_iter_exit(&inode_iter);
 	} while (bch2_err_matches(ret2, BCH_ERR_transaction_restart));
 err:
 	bch2_bkey_buf_exit(&new_src, c);
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index ca3208942e2a..dfdc54ffd57d 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -74,7 +74,7 @@ __bch2_snapshot_tree_create(struct btree_trans *trans)
 
 	s_t = bch2_bkey_alloc(trans, &iter, 0, snapshot_tree);
 	ret = PTR_ERR_OR_ZERO(s_t);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret ? ERR_PTR(ret) : s_t;
 }
 
@@ -450,7 +450,7 @@ static int bch2_snapshot_tree_master_subvol(struct btree_trans *trans,
 			break;
 		}
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (!ret && !found) {
 		struct bkey_i_subvolume *u;
@@ -563,7 +563,7 @@ static int check_snapshot_tree(struct btree_trans *trans,
 out:
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &snapshot_iter);
+	bch2_trans_iter_exit(&snapshot_iter);
 	return ret;
 }
 
@@ -685,7 +685,7 @@ static int snapshot_tree_ptr_repair(struct btree_trans *trans,
 		*s = u->v;
 	}
 err:
-	bch2_trans_iter_exit(trans, &root_iter);
+	bch2_trans_iter_exit(&root_iter);
 	return ret;
 }
 
@@ -868,7 +868,7 @@ static int check_snapshot_exists(struct btree_trans *trans, u32 id)
 			break;
 		}
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret)
 		return ret;
@@ -898,7 +898,7 @@ static int check_snapshot_exists(struct btree_trans *trans, u32 id)
 			break;
 		}
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return  bch2_snapshot_table_make_room(c, id) ?:
 		bch2_btree_insert_trans(trans, BTREE_ID_snapshots, &snapshot->k_i, 0);
@@ -1100,7 +1100,7 @@ int __bch2_get_snapshot_overwrites(struct btree_trans *trans,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	if (ret)
 		darray_exit(s);
 
@@ -1132,7 +1132,7 @@ int bch2_snapshot_node_set_deleted(struct btree_trans *trans, u32 id)
 	SET_BCH_SNAPSHOT_SUBVOL(&s->v, false);
 	s->v.subvol = 0;
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1257,10 +1257,10 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 		set_bkey_val_u64s(&s->k, 0);
 	}
 err:
-	bch2_trans_iter_exit(trans, &tree_iter);
-	bch2_trans_iter_exit(trans, &p_iter);
-	bch2_trans_iter_exit(trans, &c_iter);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&tree_iter);
+	bch2_trans_iter_exit(&p_iter);
+	bch2_trans_iter_exit(&c_iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1322,7 +1322,7 @@ static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
 		new_snapids[i]	= iter.pos.offset;
 	}
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1364,7 +1364,7 @@ static int bch2_snapshot_node_create_children(struct btree_trans *trans, u32 par
 	n_parent->v.subvol = 0;
 	SET_BCH_SNAPSHOT_SUBVOL(&n_parent->v, false);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1489,7 +1489,7 @@ static int delete_dead_snapshots_process_key(struct btree_trans *trans,
 			 : 0) ?:
 			bch2_btree_delete_at(trans, iter,
 					     BTREE_UPDATE_internal_snapshot_node);
-		bch2_trans_iter_exit(trans, &dst_iter);
+		bch2_trans_iter_exit(&dst_iter);
 		return ret;
 	}
 
@@ -1623,7 +1623,7 @@ static int delete_dead_snapshot_keys_v2(struct btree_trans *trans)
 			bch2_btree_iter_advance(&iter);
 		}
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	if (ret)
 		goto err;
@@ -1953,7 +1953,7 @@ int __bch2_key_has_snapshot_overwrites(struct btree_trans *trans,
 			break;
 		}
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
diff --git a/fs/bcachefs/str_hash.c b/fs/bcachefs/str_hash.c
index 3e08e55d2dc1..a6503ec58acc 100644
--- a/fs/bcachefs/str_hash.c
+++ b/fs/bcachefs/str_hash.c
@@ -26,7 +26,7 @@ static int bch2_dirent_has_target(struct btree_trans *trans, struct bkey_s_c_dir
 			return ret;
 
 		ret = bkey_is_inode(k.k);
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		return ret;
 	}
 }
@@ -206,7 +206,7 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 		bch_err_throw(c, transaction_restart_nested);
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -328,7 +328,7 @@ int bch2_str_hash_repair_key(struct btree_trans *trans,
 	}
 out:
 fsck_err:
-	bch2_trans_iter_exit(trans, dup_iter);
+	bch2_trans_iter_exit(dup_iter);
 	if (free_snapshots_seen)
 		darray_exit(&s->ids);
 	return ret;
@@ -371,11 +371,11 @@ int __bch2_str_hash_check_key(struct btree_trans *trans,
 		if (bkey_deleted(k.k))
 			goto bad_hash;
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 fsck_err:
 	return ret;
 bad_hash:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	/*
 	 * Before doing any repair, check hash_info itself:
 	 */
diff --git a/fs/bcachefs/str_hash.h b/fs/bcachefs/str_hash.h
index f4031e37ef96..7b4e7e9eb993 100644
--- a/fs/bcachefs/str_hash.h
+++ b/fs/bcachefs/str_hash.h
@@ -173,7 +173,7 @@ bch2_hash_lookup_in_snapshot(struct btree_trans *trans,
 			break;
 		}
 	}
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 
 	return bkey_s_c_err(ret ?: bch_err_throw(trans->c, ENOENT_str_hash_lookup));
 }
@@ -215,7 +215,7 @@ bch2_hash_hole(struct btree_trans *trans,
 			   BTREE_ITER_slots|BTREE_ITER_intent, k, ret)
 		if (!is_visible_key(desc, inum, k))
 			return 0;
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(iter);
 
 	return ret ?: bch_err_throw(trans->c, ENOSPC_str_hash_create);
 }
@@ -246,7 +246,7 @@ int bch2_hash_needs_whiteout(struct btree_trans *trans,
 		}
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -289,14 +289,14 @@ struct bkey_s_c bch2_hash_set_or_get_in_snapshot(struct btree_trans *trans,
 	if (!ret)
 		ret = bch_err_throw(c, ENOSPC_str_hash_create);
 out:
-	bch2_trans_iter_exit(trans, &slot);
-	bch2_trans_iter_exit(trans, iter);
+	bch2_trans_iter_exit(&slot);
+	bch2_trans_iter_exit(iter);
 	return ret ? bkey_s_c_err(ret) : bkey_s_c_null;
 found:
 	found = true;
 not_found:
 	if (found && (flags & STR_HASH_must_create)) {
-		bch2_trans_iter_exit(trans, &slot);
+		bch2_trans_iter_exit(&slot);
 		return k;
 	} else if (!found && (flags & STR_HASH_must_replace)) {
 		ret = bch_err_throw(c, ENOENT_str_hash_set_must_replace);
@@ -326,7 +326,7 @@ int bch2_hash_set_in_snapshot(struct btree_trans *trans,
 	if (ret)
 		return ret;
 	if (k.k) {
-		bch2_trans_iter_exit(trans, &iter);
+		bch2_trans_iter_exit(&iter);
 		return bch_err_throw(trans->c, EEXIST_str_hash_set);
 	}
 
@@ -389,7 +389,7 @@ int bch2_hash_delete(struct btree_trans *trans,
 		return ret;
 
 	ret = bch2_hash_delete_at(trans, desc, info, &iter, 0);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index ae3b06d70130..b6d0dc0a46de 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -176,7 +176,7 @@ static int check_subvol(struct btree_trans *trans,
 	}
 err:
 fsck_err:
-	bch2_trans_iter_exit(trans, &subvol_children_iter);
+	bch2_trans_iter_exit(&subvol_children_iter);
 	return ret;
 }
 
@@ -301,7 +301,7 @@ int bch2_subvol_has_children(struct btree_trans *trans, u32 subvol)
 
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_subvolume_children, POS(subvol, 0), 0);
 	struct bkey_s_c k = bch2_btree_iter_peek(&iter);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 
 	return bkey_err(k) ?: k.k && k.k->p.inode == subvol
 		? bch_err_throw(trans->c, ENOTEMPTY_subvol_not_empty)
@@ -373,7 +373,7 @@ int __bch2_subvolume_get_snapshot(struct btree_trans *trans, u32 subvolid,
 
 	if (likely(!ret))
 		*snapid = le32_to_cpu(subvol.v->snapshot);
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -486,9 +486,9 @@ static int __bch2_subvolume_delete(struct btree_trans *trans, u32 subvolid)
 	ret =   bch2_btree_delete_at(trans, &subvol_iter, 0) ?:
 		bch2_snapshot_node_set_deleted(trans, snapid);
 err:
-	bch2_trans_iter_exit(trans, &snapshot_tree_iter);
-	bch2_trans_iter_exit(trans, &snapshot_iter);
-	bch2_trans_iter_exit(trans, &subvol_iter);
+	bch2_trans_iter_exit(&snapshot_tree_iter);
+	bch2_trans_iter_exit(&snapshot_iter);
+	bch2_trans_iter_exit(&subvol_iter);
 	return ret;
 }
 
@@ -590,7 +590,7 @@ int bch2_subvolume_unlink(struct btree_trans *trans, u32 subvolid)
 
 	SET_BCH_SUBVOLUME_UNLINKED(&n->v, true);
 	n->v.fs_path_parent = 0;
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -665,8 +665,8 @@ int bch2_subvolume_create(struct btree_trans *trans, u64 inode,
 	*new_subvolid	= new_subvol->k.p.offset;
 	*new_snapshotid	= new_nodes[0];
 err:
-	bch2_trans_iter_exit(trans, &src_iter);
-	bch2_trans_iter_exit(trans, &dst_iter);
+	bch2_trans_iter_exit(&src_iter);
+	bch2_trans_iter_exit(&dst_iter);
 	return ret;
 }
 
@@ -727,7 +727,7 @@ static int __bch2_fs_upgrade_for_subvolumes(struct btree_trans *trans)
 
 	ret = bch2_inode_write(trans, &iter, &inode);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/subvolume.h b/fs/bcachefs/subvolume.h
index 3ee80821732c..d076104fd4ef 100644
--- a/fs/bcachefs/subvolume.h
+++ b/fs/bcachefs/subvolume.h
@@ -62,7 +62,7 @@ bch2_btree_iter_peek_in_subvolume_max_type(struct btree_iter *iter, struct bpos
 		}));								\
 	} while (!_ret3 && bch2_btree_iter_advance(&(_iter)));			\
 										\
-	bch2_trans_iter_exit((_trans), &(_iter));				\
+	bch2_trans_iter_exit(&(_iter));						\
 	_ret3;									\
 })
 
diff --git a/fs/bcachefs/tests.c b/fs/bcachefs/tests.c
index 78101159fd6e..4628ff84eefc 100644
--- a/fs/bcachefs/tests.c
+++ b/fs/bcachefs/tests.c
@@ -65,7 +65,7 @@ static int test_delete(struct bch_fs *c, u64 nr)
 	if (ret)
 		goto err;
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -99,7 +99,7 @@ static int test_delete_written(struct bch_fs *c, u64 nr)
 	if (ret)
 		goto err;
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -355,7 +355,7 @@ static int test_peek_end(struct bch_fs *c, u64 nr)
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -376,7 +376,7 @@ static int test_peek_end_extents(struct bch_fs *c, u64 nr)
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -488,7 +488,7 @@ static int test_snapshot_filter(struct bch_fs *c, u32 snapid_lo, u32 snapid_hi)
 
 	BUG_ON(k.k->p.snapshot != U32_MAX);
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -599,7 +599,7 @@ static int rand_lookup(struct bch_fs *c, u64 nr)
 			break;
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -646,7 +646,7 @@ static int rand_mixed(struct bch_fs *c, u64 nr)
 			break;
 	}
 
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -668,7 +668,7 @@ static int __do_delete(struct btree_trans *trans, struct bpos pos)
 
 	ret = bch2_btree_delete_at(trans, &iter, 0);
 err:
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/xattr.c b/fs/bcachefs/xattr.c
index f5b370269a60..6094b568dd33 100644
--- a/fs/bcachefs/xattr.c
+++ b/fs/bcachefs/xattr.c
@@ -157,7 +157,7 @@ static int bch2_xattr_get_trans(struct btree_trans *trans, struct bch_inode_info
 		else
 			memcpy(buffer, xattr_val(xattr.v), ret);
 	}
-	bch2_trans_iter_exit(trans, &iter);
+	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -184,7 +184,7 @@ int bch2_xattr_set(struct btree_trans *trans, subvol_inum inum,
 	inode_u->bi_ctime = bch2_current_time(c);
 
 	ret = bch2_inode_write(trans, &inode_iter, inode_u);
-	bch2_trans_iter_exit(trans, &inode_iter);
+	bch2_trans_iter_exit(&inode_iter);
 
 	if (ret)
 		return ret;
-- 
2.51.0


From ec44587f8d9c6a010f04d30e2c7fab866facd34e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 20:05:00 -0400
Subject: [PATCH 208/309] bcachefs: for_each_btree_key_continue() no longer
 exits iter

Prep work for more CLASS() conversion.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c    | 3 +++
 fs/bcachefs/btree_gc.c        | 1 +
 fs/bcachefs/btree_iter.h      | 5 +++--
 fs/bcachefs/disk_accounting.c | 1 +
 fs/bcachefs/subvolume.h       | 5 +++--
 5 files changed, 11 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 5f2339652055..42c321d42721 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -835,6 +835,7 @@ static int bch2_check_extents_to_backpointers_pass(struct btree_trans *trans,
 				check_extent_to_backpointers(trans, s, btree_id, level, k) ?:
 				bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc);
 			}));
+			bch2_trans_iter_exit(&iter);
 			if (ret)
 				return ret;
 
@@ -1060,6 +1061,7 @@ static int bch2_pin_backpointer_nodes_with_missing(struct btree_trans *trans,
 
 		bch2_btree_node_prefetch(trans, path, tmp.k, path->btree_id, path->level - 1);
 	}));
+	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
@@ -1089,6 +1091,7 @@ static int bch2_pin_backpointer_nodes_with_missing(struct btree_trans *trans,
 
 		ret;
 	}));
+	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index b7f750cb31f2..ce3c7750a922 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -713,6 +713,7 @@ static int bch2_gc_btree(struct btree_trans *trans,
 			gc_pos_set(c, gc_pos_btree(btree, level, k.k->p));
 			bch2_gc_mark_key(trans, btree, level, &prev, &iter, k, initial);
 		}));
+		bch2_trans_iter_exit(&iter);
 		if (ret)
 			goto err;
 	}
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 3e2d84afc26e..9fcfd00c88f7 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -826,7 +826,6 @@ transaction_restart:							\
 		}));							\
 	} while (!_ret3 && bch2_btree_iter_advance(&(_iter)));		\
 									\
-	bch2_trans_iter_exit(&(_iter));					\
 	_ret3;								\
 })
 
@@ -842,7 +841,9 @@ transaction_restart:							\
 	bch2_trans_iter_init((_trans), &(_iter), (_btree_id),		\
 			     (_start), (_flags));			\
 									\
-	for_each_btree_key_max_continue(_trans, _iter, _end, _flags, _k, _do);\
+	int _ret = for_each_btree_key_max_continue(_trans, _iter, _end, _flags, _k, _do);\
+	bch2_trans_iter_exit(&(_iter));					\
+	_ret;								\
 })
 
 #define for_each_btree_key(_trans, _iter, _btree_id,			\
diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 484261da6d25..f96530c70262 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -784,6 +784,7 @@ int bch2_accounting_read(struct bch_fs *c)
 
 			accounting_read_key(trans, k);
 		}));
+	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
diff --git a/fs/bcachefs/subvolume.h b/fs/bcachefs/subvolume.h
index d076104fd4ef..b39ff39b252d 100644
--- a/fs/bcachefs/subvolume.h
+++ b/fs/bcachefs/subvolume.h
@@ -62,7 +62,6 @@ bch2_btree_iter_peek_in_subvolume_max_type(struct btree_iter *iter, struct bpos
 		}));								\
 	} while (!_ret3 && bch2_btree_iter_advance(&(_iter)));			\
 										\
-	bch2_trans_iter_exit(&(_iter));						\
 	_ret3;									\
 })
 
@@ -73,8 +72,10 @@ bch2_btree_iter_peek_in_subvolume_max_type(struct btree_iter *iter, struct bpos
 	bch2_trans_iter_init((_trans), &(_iter), (_btree_id),			\
 			     (_start), (_flags));				\
 										\
-	for_each_btree_key_in_subvolume_max_continue(_trans, _iter,		\
+	int _ret = for_each_btree_key_in_subvolume_max_continue(_trans, _iter,	\
 					_end, _subvolid, _flags, _k, _do);	\
+	bch2_trans_iter_exit(&(_iter));						\
+	_ret;									\
 })
 
 int bch2_subvolume_unlink(struct btree_trans *, u32);
-- 
2.51.0


From 8b744f7717e648be834b43e5f92f98953ddf0479 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 19:15:17 -0400
Subject: [PATCH 209/309] bcachefs: CLASS(btree_iter)

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c         |  27 +++----
 fs/bcachefs/btree_iter.h         |  90 ++++++++++++-----------
 fs/bcachefs/btree_key_cache.c    |  46 +++++-------
 fs/bcachefs/btree_update.c       |  93 +++++++++--------------
 fs/bcachefs/btree_write_buffer.c |  11 +--
 fs/bcachefs/data_update.c        |   4 +-
 fs/bcachefs/dirent.c             |  22 +++---
 fs/bcachefs/fs-io-buffered.c     |   4 +-
 fs/bcachefs/fs-io.c              |   6 +-
 fs/bcachefs/fs.c                 |  28 +++----
 fs/bcachefs/fsck.c               |  36 ++++-----
 fs/bcachefs/inode.c              |   5 +-
 fs/bcachefs/io_misc.c            |  25 +++----
 fs/bcachefs/io_read.c            |  21 ++----
 fs/bcachefs/io_write.c           |   8 +-
 fs/bcachefs/move.c               |   5 +-
 fs/bcachefs/rebalance.c          |  58 ++++++---------
 fs/bcachefs/reflink.c            |  19 ++---
 fs/bcachefs/snapshot.c           |  32 ++++----
 fs/bcachefs/subvolume.c          |   5 +-
 fs/bcachefs/subvolume.h          |  11 +--
 fs/bcachefs/tests.c              | 122 +++++++++++--------------------
 22 files changed, 264 insertions(+), 414 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 7e1046fe478f..ff580f76a641 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -275,9 +275,6 @@ static void __bch2_btree_iter_verify_entry_exit(struct btree_iter *iter)
 static int __bch2_btree_iter_verify_ret(struct btree_iter *iter, struct bkey_s_c k)
 {
 	struct btree_trans *trans = iter->trans;
-	struct btree_iter copy;
-	struct bkey_s_c prev;
-	int ret = 0;
 
 	if (!(iter->flags & BTREE_ITER_filter_snapshots))
 		return 0;
@@ -289,16 +286,16 @@ static int __bch2_btree_iter_verify_ret(struct btree_iter *iter, struct bkey_s_c
 					  iter->snapshot,
 					  k.k->p.snapshot));
 
-	bch2_trans_iter_init(trans, &copy, iter->btree_id, iter->pos,
-			     BTREE_ITER_nopreserve|
-			     BTREE_ITER_all_snapshots);
-	prev = bch2_btree_iter_prev(&copy);
+	CLASS(btree_iter, copy)(trans, iter->btree_id, iter->pos,
+				BTREE_ITER_nopreserve|
+				BTREE_ITER_all_snapshots);
+	struct bkey_s_c prev = bch2_btree_iter_prev(&copy);
 	if (!prev.k)
-		goto out;
+		return 0;
 
-	ret = bkey_err(prev);
+	int ret = bkey_err(prev);
 	if (ret)
-		goto out;
+		return ret;
 
 	if (bkey_eq(prev.k->p, k.k->p) &&
 	    bch2_snapshot_is_ancestor(trans->c, iter->snapshot,
@@ -314,9 +311,8 @@ static int __bch2_btree_iter_verify_ret(struct btree_iter *iter, struct bkey_s_c
 		      iter->snapshot,
 		      buf1.buf, buf2.buf);
 	}
-out:
-	bch2_trans_iter_exit(&copy);
-	return ret;
+
+	return 0;
 }
 
 void __bch2_assert_pos_locked(struct btree_trans *trans, enum btree_id id,
@@ -3127,11 +3123,12 @@ void bch2_trans_iter_exit(struct btree_iter *iter)
 void bch2_trans_iter_init_outlined(struct btree_trans *trans,
 			  struct btree_iter *iter,
 			  enum btree_id btree_id, struct bpos pos,
-			  enum btree_iter_update_trigger_flags flags)
+			  enum btree_iter_update_trigger_flags flags,
+			  unsigned long ip)
 {
 	bch2_trans_iter_init_common(trans, iter, btree_id, pos, 0, 0,
 			       bch2_btree_iter_flags(trans, btree_id, 0, flags),
-			       _RET_IP_);
+			       ip);
 }
 
 void bch2_trans_node_iter_init(struct btree_trans *trans,
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 9fcfd00c88f7..dcc587ec7dd7 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -535,7 +535,8 @@ static inline void bch2_trans_iter_init_common(struct btree_trans *trans,
 
 void bch2_trans_iter_init_outlined(struct btree_trans *, struct btree_iter *,
 			  enum btree_id, struct bpos,
-			  enum btree_iter_update_trigger_flags);
+			  enum btree_iter_update_trigger_flags,
+			  unsigned long ip);
 
 static inline void bch2_trans_iter_init(struct btree_trans *trans,
 			  struct btree_iter *iter,
@@ -546,11 +547,25 @@ static inline void bch2_trans_iter_init(struct btree_trans *trans,
 	    __builtin_constant_p(flags))
 		bch2_trans_iter_init_common(trans, iter, btree, pos, 0, 0,
 				bch2_btree_iter_flags(trans, btree, 0, flags),
-				_THIS_IP_);
+				_RET_IP_);
 	else
-		bch2_trans_iter_init_outlined(trans, iter, btree, pos, flags);
+		bch2_trans_iter_init_outlined(trans, iter, btree, pos, flags, _RET_IP_);
 }
 
+#define bch2_trans_iter_class_init(_trans, _btree, _pos, _flags)		\
+({										\
+	struct btree_iter iter;							\
+	bch2_trans_iter_init(_trans, &iter, (_btree), (_pos), (_flags));	\
+	iter;									\
+})
+
+DEFINE_CLASS(btree_iter, struct btree_iter,
+	     bch2_trans_iter_exit(&_T),
+	     bch2_trans_iter_class_init(trans, btree, pos, flags),
+	     struct btree_trans *trans,
+	     enum btree_id btree, struct bpos pos,
+	     enum btree_iter_update_trigger_flags flags);
+
 void bch2_trans_node_iter_init(struct btree_trans *, struct btree_iter *,
 			       enum btree_id, struct bpos,
 			       unsigned, unsigned,
@@ -806,7 +821,7 @@ transaction_restart:							\
 	if (!_ret2)							\
 		bch2_trans_verify_not_restarted(_trans, _restart_count);\
 									\
-	_ret2 ?: trans_was_restarted(_trans, _orig_restart_count);		\
+	_ret2 ?: trans_was_restarted(_trans, _orig_restart_count);	\
 })
 
 #define for_each_btree_key_max_continue(_trans, _iter,			\
@@ -832,48 +847,37 @@ transaction_restart:							\
 #define for_each_btree_key_continue(_trans, _iter, _flags, _k, _do)	\
 	for_each_btree_key_max_continue(_trans, _iter, SPOS_MAX, _flags, _k, _do)
 
-#define for_each_btree_key_max(_trans, _iter, _btree_id,		\
-				_start, _end, _flags, _k, _do)		\
-({									\
-	bch2_trans_begin(trans);					\
-									\
-	struct btree_iter _iter;					\
-	bch2_trans_iter_init((_trans), &(_iter), (_btree_id),		\
-			     (_start), (_flags));			\
-									\
-	int _ret = for_each_btree_key_max_continue(_trans, _iter, _end, _flags, _k, _do);\
-	bch2_trans_iter_exit(&(_iter));					\
-	_ret;								\
+#define for_each_btree_key_max(_trans, _iter, _btree_id,			\
+				_start, _end, _flags, _k, _do)			\
+({										\
+	bch2_trans_begin(trans);						\
+										\
+	CLASS(btree_iter, _iter)((_trans), (_btree_id), (_start), (_flags));	\
+	for_each_btree_key_max_continue(_trans, _iter, _end, _flags, _k, _do);	\
 })
 
-#define for_each_btree_key(_trans, _iter, _btree_id,			\
-			   _start, _flags, _k, _do)			\
-	for_each_btree_key_max(_trans, _iter, _btree_id, _start,	\
-				 SPOS_MAX, _flags, _k, _do)
+#define for_each_btree_key(_trans, _iter, _btree_id, _start, _flags, _k, _do)	\
+	for_each_btree_key_max(_trans, _iter, _btree_id, _start, SPOS_MAX, _flags, _k, _do)
 
-#define for_each_btree_key_reverse(_trans, _iter, _btree_id,		\
-				   _start, _flags, _k, _do)		\
-({									\
-	struct btree_iter _iter;					\
-	struct bkey_s_c _k;						\
-	int _ret3 = 0;							\
-									\
-	bch2_trans_iter_init((_trans), &(_iter), (_btree_id),		\
-			     (_start), (_flags));			\
-									\
-	do {								\
-		_ret3 = lockrestart_do(_trans, ({			\
-			(_k) = bch2_btree_iter_peek_prev_type(&(_iter),	\
-							(_flags));	\
-			if (!(_k).k)					\
-				break;					\
-									\
-			bkey_err(_k) ?: (_do);				\
-		}));							\
-	} while (!_ret3 && bch2_btree_iter_rewind(&(_iter)));		\
-									\
-	bch2_trans_iter_exit(&(_iter));					\
-	_ret3;								\
+#define for_each_btree_key_reverse(_trans, _iter, _btree_id,			\
+				   _start, _flags, _k, _do)			\
+({										\
+	int _ret3 = 0;								\
+										\
+	CLASS(btree_iter, iter)((_trans), (_btree_id), (_start), (_flags));	\
+										\
+	do {									\
+		_ret3 = lockrestart_do(_trans, ({				\
+			struct bkey_s_c _k =					\
+				bch2_btree_iter_peek_prev_type(&(_iter), (_flags));\
+			if (!(_k).k)						\
+				break;						\
+										\
+			bkey_err(_k) ?: (_do);					\
+		}));								\
+	} while (!_ret3 && bch2_btree_iter_rewind(&(_iter)));			\
+										\
+	_ret3;									\
 })
 
 #define for_each_btree_key_commit(_trans, _iter, _btree_id,		\
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index bf376865d0ae..72c803f7b8d1 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -322,19 +322,16 @@ static noinline int btree_key_cache_fill(struct btree_trans *trans,
 	}
 
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
-	struct bkey_s_c k;
-	int ret;
 
-	bch2_trans_iter_init(trans, &iter, ck_path->btree_id, ck_path->pos,
-			     BTREE_ITER_intent|
-			     BTREE_ITER_key_cache_fill|
-			     BTREE_ITER_cached_nofill);
+	CLASS(btree_iter, iter)(trans, ck_path->btree_id, ck_path->pos,
+				BTREE_ITER_intent|
+				BTREE_ITER_key_cache_fill|
+				BTREE_ITER_cached_nofill);
 	iter.flags &= ~BTREE_ITER_with_journal;
-	k = bch2_btree_iter_peek_slot(&iter);
-	ret = bkey_err(k);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
+	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	/* Recheck after btree lookup, before allocating: */
 	ck_path = trans->paths + ck_path_idx;
@@ -344,15 +341,13 @@ static noinline int btree_key_cache_fill(struct btree_trans *trans,
 
 	ret = btree_key_cache_create(trans, btree_iter_path(trans, &iter), ck_path, k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (trace_key_cache_fill_enabled())
 		do_trace_key_cache_fill(trans, ck_path, k);
 out:
 	/* We're not likely to need this iterator again: */
 	bch2_set_btree_iter_dontneed(&iter);
-err:
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -424,35 +419,34 @@ static int btree_key_cache_flush_pos(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct journal *j = &c->journal;
-	struct btree_iter c_iter, b_iter;
 	struct bkey_cached *ck = NULL;
 	int ret;
 
-	bch2_trans_iter_init(trans, &b_iter, key.btree_id, key.pos,
-			     BTREE_ITER_slots|
-			     BTREE_ITER_intent|
-			     BTREE_ITER_all_snapshots);
-	bch2_trans_iter_init(trans, &c_iter, key.btree_id, key.pos,
-			     BTREE_ITER_cached|
-			     BTREE_ITER_intent);
+	CLASS(btree_iter, b_iter)(trans, key.btree_id, key.pos,
+				  BTREE_ITER_slots|
+				  BTREE_ITER_intent|
+				  BTREE_ITER_all_snapshots);
+	CLASS(btree_iter, c_iter)(trans, key.btree_id, key.pos,
+				  BTREE_ITER_cached|
+				  BTREE_ITER_intent);
 	b_iter.flags &= ~BTREE_ITER_with_key_cache;
 
 	ret = bch2_btree_iter_traverse(&c_iter);
 	if (ret)
-		goto out;
+		return ret;
 
 	ck = (void *) btree_iter_path(trans, &c_iter)->l[0].b;
 	if (!ck)
-		goto out;
+		return 0;
 
 	if (!test_bit(BKEY_CACHED_DIRTY, &ck->flags)) {
 		if (evict)
 			goto evict;
-		goto out;
+		return 0;
 	}
 
 	if (journal_seq && ck->journal.seq != journal_seq)
-		goto out;
+		return 0;
 
 	trans->journal_res.seq = ck->journal.seq;
 
@@ -528,8 +522,6 @@ static int btree_key_cache_flush_pos(struct btree_trans *trans,
 		}
 	}
 out:
-	bch2_trans_iter_exit(&b_iter);
-	bch2_trans_iter_exit(&c_iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index d2efb4b42bb4..1b1b5bb9e915 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -268,18 +268,16 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 				    struct bkey_i *insert,
 				    enum btree_iter_update_trigger_flags flags)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k;
 	enum btree_id btree_id = orig_iter->btree_id;
-	int ret = 0;
 
-	bch2_trans_iter_init(trans, &iter, btree_id, bkey_start_pos(&insert->k),
-			     BTREE_ITER_intent|
-			     BTREE_ITER_with_updates|
-			     BTREE_ITER_not_extents);
-	k = bch2_btree_iter_peek_max(&iter, POS(insert->k.p.inode, U64_MAX));
-	if ((ret = bkey_err(k)))
-		goto err;
+	CLASS(btree_iter, iter)(trans, btree_id, bkey_start_pos(&insert->k),
+				BTREE_ITER_intent|
+				BTREE_ITER_with_updates|
+				BTREE_ITER_not_extents);
+	struct bkey_s_c k = bch2_btree_iter_peek_max(&iter, POS(insert->k.p.inode, U64_MAX));
+	int ret = bkey_err(k);
+	if (ret)
+		return ret;
 	if (!k.k)
 		goto out;
 
@@ -287,7 +285,7 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 		if (bch2_bkey_maybe_mergable(k.k, &insert->k)) {
 			ret = extent_front_merge(trans, &iter, k, &insert, flags);
 			if (ret)
-				goto err;
+				return ret;
 		}
 
 		goto next;
@@ -298,7 +296,7 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 
 		ret = bch2_trans_update_extent_overwrite(trans, &iter, flags, k, bkey_i_to_s_c(insert));
 		if (ret)
-			goto err;
+			return ret;
 
 		if (done)
 			goto out;
@@ -306,7 +304,7 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 		bch2_btree_iter_advance(&iter);
 		k = bch2_btree_iter_peek_max(&iter, POS(insert->k.p.inode, U64_MAX));
 		if ((ret = bkey_err(k)))
-			goto err;
+			return ret;
 		if (!k.k)
 			goto out;
 	}
@@ -314,15 +312,12 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 	if (bch2_bkey_maybe_mergable(&insert->k, k.k)) {
 		ret = extent_back_merge(trans, &iter, insert, k);
 		if (ret)
-			goto err;
+			return ret;
 	}
 out:
-	if (!bkey_deleted(&insert->k))
-		ret = bch2_btree_insert_nonextent(trans, btree_id, insert, flags);
-err:
-	bch2_trans_iter_exit(&iter);
-
-	return ret;
+	return !bkey_deleted(&insert->k)
+		? bch2_btree_insert_nonextent(trans, btree_id, insert, flags)
+		: 0;
 }
 
 static inline struct btree_insert_entry *
@@ -629,29 +624,21 @@ int bch2_btree_insert_nonextent(struct btree_trans *trans,
 				enum btree_id btree, struct bkey_i *k,
 				enum btree_iter_update_trigger_flags flags)
 {
-	struct btree_iter iter;
-	int ret;
-
-	bch2_trans_iter_init(trans, &iter, btree, k->k.p,
-			     BTREE_ITER_cached|
-			     BTREE_ITER_not_extents|
-			     BTREE_ITER_intent);
-	ret   = bch2_btree_iter_traverse(&iter) ?:
+	CLASS(btree_iter, iter)(trans, btree, k->k.p,
+				BTREE_ITER_cached|
+				BTREE_ITER_not_extents|
+				BTREE_ITER_intent);
+	return  bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, k, flags);
-	bch2_trans_iter_exit(&iter);
-	return ret;
 }
 
-int bch2_btree_insert_trans(struct btree_trans *trans, enum btree_id id,
+int bch2_btree_insert_trans(struct btree_trans *trans, enum btree_id btree,
 			    struct bkey_i *k, enum btree_iter_update_trigger_flags flags)
 {
-	struct btree_iter iter;
-	bch2_trans_iter_init(trans, &iter, id, bkey_start_pos(&k->k),
-			     BTREE_ITER_intent|flags);
-	int ret = bch2_btree_iter_traverse(&iter) ?:
-		  bch2_trans_update(trans, &iter, k, flags);
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	CLASS(btree_iter, iter)(trans, btree, bkey_start_pos(&k->k),
+				BTREE_ITER_intent|flags);
+	return  bch2_btree_iter_traverse(&iter) ?:
+		bch2_trans_update(trans, &iter, k, flags);
 }
 
 /**
@@ -693,30 +680,24 @@ int bch2_btree_delete(struct btree_trans *trans,
 		      enum btree_id btree, struct bpos pos,
 		      enum btree_iter_update_trigger_flags flags)
 {
-	struct btree_iter iter;
-	int ret;
-
-	bch2_trans_iter_init(trans, &iter, btree, pos,
-			     BTREE_ITER_cached|
-			     BTREE_ITER_intent);
-	ret   = bch2_btree_iter_traverse(&iter) ?:
+	CLASS(btree_iter, iter)(trans, btree, pos,
+				BTREE_ITER_cached|
+				BTREE_ITER_intent);
+	return  bch2_btree_iter_traverse(&iter) ?:
 		bch2_btree_delete_at(trans, &iter, flags);
-	bch2_trans_iter_exit(&iter);
-
-	return ret;
 }
 
-int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
+int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id btree,
 				  struct bpos start, struct bpos end,
 				  enum btree_iter_update_trigger_flags flags,
 				  u64 *journal_seq)
 {
 	u32 restart_count = trans->restart_count;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 
-	bch2_trans_iter_init(trans, &iter, id, start, BTREE_ITER_intent|flags);
+	CLASS(btree_iter, iter)(trans, btree, start, BTREE_ITER_intent|flags);
+
 	while ((k = bch2_btree_iter_peek_max(&iter, end)).k) {
 		struct disk_reservation disk_res =
 			bch2_disk_reservation_init(trans->c, 0);
@@ -767,7 +748,6 @@ int bch2_btree_delete_range_trans(struct btree_trans *trans, enum btree_id id,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	return ret ?: trans_was_restarted(trans, restart_count);
 }
@@ -808,13 +788,10 @@ int bch2_btree_bit_mod_iter(struct btree_trans *trans, struct btree_iter *iter,
 int bch2_btree_bit_mod(struct btree_trans *trans, enum btree_id btree,
 		       struct bpos pos, bool set)
 {
-	struct btree_iter iter;
-	bch2_trans_iter_init(trans, &iter, btree, pos, BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, btree, pos, BTREE_ITER_intent);
 
-	int ret = bch2_btree_iter_traverse(&iter) ?:
-		  bch2_btree_bit_mod_iter(trans, &iter, set);
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return  bch2_btree_iter_traverse(&iter) ?:
+		bch2_btree_bit_mod_iter(trans, &iter, set);
 }
 
 int bch2_btree_bit_mod_buffered(struct btree_trans *trans, enum btree_id btree,
diff --git a/fs/bcachefs/btree_write_buffer.c b/fs/bcachefs/btree_write_buffer.c
index 036b718ae975..afad11831e1d 100644
--- a/fs/bcachefs/btree_write_buffer.c
+++ b/fs/bcachefs/btree_write_buffer.c
@@ -203,19 +203,14 @@ static int
 btree_write_buffered_insert(struct btree_trans *trans,
 			  struct btree_write_buffered_key *wb)
 {
-	struct btree_iter iter;
-	int ret;
-
-	bch2_trans_iter_init(trans, &iter, wb->btree, bkey_start_pos(&wb->k.k),
-			     BTREE_ITER_cached|BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, wb->btree, bkey_start_pos(&wb->k.k),
+				BTREE_ITER_cached|BTREE_ITER_intent);
 
 	trans->journal_res.seq = wb->journal_seq;
 
-	ret   = bch2_btree_iter_traverse(&iter) ?:
+	return  bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &wb->k,
 				  BTREE_UPDATE_internal_snapshot_node);
-	bch2_trans_iter_exit(&iter);
-	return ret;
 }
 
 static void move_keys_from_inc_to_flushing(struct btree_write_buffer *wb)
diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index 91edec7706b2..01838a3a189d 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -258,11 +258,10 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 					   struct bch_write_op *op)
 {
 	struct bch_fs *c = op->c;
-	struct btree_iter iter;
 	struct data_update *m = container_of(op, struct data_update, op);
 	int ret = 0;
 
-	bch2_trans_iter_init(trans, &iter, m->btree_id,
+	CLASS(btree_iter, iter)(trans, m->btree_id,
 			     bkey_start_pos(&bch2_keylist_front(&op->insert_keys)->k),
 			     BTREE_ITER_slots|BTREE_ITER_intent);
 
@@ -487,7 +486,6 @@ static int __bch2_data_update_index_update(struct btree_trans *trans,
 		goto next;
 	}
 out:
-	bch2_trans_iter_exit(&iter);
 	BUG_ON(bch2_err_matches(ret, BCH_ERR_transaction_restart));
 	return ret;
 }
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index 3bcbb677a808..50b6409be20a 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -744,24 +744,22 @@ static int lookup_first_inode(struct btree_trans *trans, u64 inode_nr,
 int bch2_fsck_remove_dirent(struct btree_trans *trans, struct bpos pos)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
-	struct bch_inode_unpacked dir_inode;
-	struct bch_hash_info dir_hash_info;
-	int ret;
 
-	ret = lookup_first_inode(trans, pos.inode, &dir_inode);
+	struct bch_inode_unpacked dir_inode;
+	int ret = lookup_first_inode(trans, pos.inode, &dir_inode);
 	if (ret)
 		goto err;
 
-	dir_hash_info = bch2_hash_info_init(c, &dir_inode);
+	{
+		struct bch_hash_info dir_hash_info = bch2_hash_info_init(c, &dir_inode);
 
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_dirents, pos, BTREE_ITER_intent);
+		CLASS(btree_iter, iter)(trans, BTREE_ID_dirents, pos, BTREE_ITER_intent);
 
-	ret =   bch2_btree_iter_traverse(&iter) ?:
-		bch2_hash_delete_at(trans, bch2_dirent_hash_desc,
-				    &dir_hash_info, &iter,
-				    BTREE_UPDATE_internal_snapshot_node);
-	bch2_trans_iter_exit(&iter);
+		ret =   bch2_btree_iter_traverse(&iter) ?:
+			bch2_hash_delete_at(trans, bch2_dirent_hash_desc,
+					    &dir_hash_info, &iter,
+					    BTREE_UPDATE_internal_snapshot_node);
+	}
 err:
 	bch_err_fn(c, ret);
 	return ret;
diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index b5b3a92cee00..0005569ecace 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -157,7 +157,6 @@ static void bchfs_read(struct btree_trans *trans,
 		       struct readpages_iter *readpages_iter)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_buf sk;
 	int flags = BCH_READ_retry_if_stale|
 		BCH_READ_may_promote;
@@ -167,7 +166,7 @@ static void bchfs_read(struct btree_trans *trans,
 
 	bch2_bkey_buf_init(&sk);
 	bch2_trans_begin(trans);
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
+	CLASS(btree_iter, iter)(trans, BTREE_ID_extents,
 			     POS(inum.inum, rbio->bio.bi_iter.bi_sector),
 			     BTREE_ITER_slots);
 	while (1) {
@@ -251,7 +250,6 @@ static void bchfs_read(struct btree_trans *trans,
 		    !bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			break;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	if (ret) {
 		CLASS(printbuf, buf)();
diff --git a/fs/bcachefs/fs-io.c b/fs/bcachefs/fs-io.c
index 92fe1de6e4a9..de0d965f3fde 100644
--- a/fs/bcachefs/fs-io.c
+++ b/fs/bcachefs/fs-io.c
@@ -626,15 +626,14 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 			     u64 start_sector, u64 end_sector)
 {
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
 	struct bpos end_pos = POS(inode->v.i_ino, end_sector);
 	struct bch_io_opts opts;
 	int ret = 0;
 
 	bch2_inode_opts_get(&opts, c, &inode->ei_inode);
 
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
+	CLASS(btree_trans, trans)(c);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_extents,
 			POS(inode->v.i_ino, start_sector),
 			BTREE_ITER_slots|BTREE_ITER_intent);
 
@@ -747,7 +746,6 @@ static noinline int __bchfs_fallocate(struct bch_inode_info *inode, int mode,
 		bch2_quota_reservation_put(c, inode, &quota_res);
 	}
 
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index bf75eed72e2d..3b289f696612 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -1397,21 +1397,20 @@ static int bch2_next_fiemap_extent(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	struct btree_iter iter;
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
-			     SPOS(inode->ei_inum.inum, start, snapshot), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_extents,
+				SPOS(inode->ei_inum.inum, start, snapshot), 0);
 
 	struct bkey_s_c k =
 		bch2_btree_iter_peek_max(&iter, POS(inode->ei_inum.inum, end));
 	ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	u64 pagecache_end = k.k ? max(start, bkey_start_offset(k.k)) : end;
 
 	ret = bch2_next_fiemap_pagecache_extent(trans, inode, start, pagecache_end, cur);
 	if (ret)
-		goto err;
+		return ret;
 
 	struct bpos pagecache_start = bkey_start_pos(&cur->kbuf.k->k);
 
@@ -1447,7 +1446,7 @@ static int bch2_next_fiemap_extent(struct btree_trans *trans,
 		ret = bch2_read_indirect_extent(trans, &data_btree, &offset_into_extent,
 						&cur->kbuf);
 		if (ret)
-			goto err;
+			return ret;
 
 		struct bkey_i *k = cur->kbuf.k;
 		sectors = min_t(unsigned, sectors, k->k.size - offset_into_extent);
@@ -1459,9 +1458,8 @@ static int bch2_next_fiemap_extent(struct btree_trans *trans,
 		k->k.p = iter.pos;
 		k->k.p.offset += k->k.size;
 	}
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return 0;
 }
 
 static int bch2_fiemap(struct inode *vinode, struct fiemap_extent_info *info,
@@ -1948,8 +1946,6 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 	struct bch_inode_info *inode	= to_bch_ei(child->d_inode);
 	struct bch_inode_info *dir	= to_bch_ei(parent->d_inode);
 	struct bch_fs *c = inode->v.i_sb->s_fs_info;
-	struct btree_iter iter1;
-	struct btree_iter iter2;
 	struct bkey_s_c k;
 	struct bkey_s_c_dirent d;
 	struct bch_inode_unpacked inode_u;
@@ -1963,10 +1959,10 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 		return -EINVAL;
 
 	CLASS(btree_trans, trans)(c);
-	bch2_trans_iter_init(trans, &iter1, BTREE_ID_dirents,
-			     POS(dir->ei_inode.bi_inum, 0), 0);
-	bch2_trans_iter_init(trans, &iter2, BTREE_ID_dirents,
-			     POS(dir->ei_inode.bi_inum, 0), 0);
+	CLASS(btree_iter, iter1)(trans, BTREE_ID_dirents,
+				 POS(dir->ei_inode.bi_inum, 0), 0);
+	CLASS(btree_iter, iter2)(trans, BTREE_ID_dirents,
+				 POS(dir->ei_inode.bi_inum, 0), 0);
 retry:
 	bch2_trans_begin(trans);
 
@@ -2039,8 +2035,6 @@ static int bch2_get_name(struct dentry *parent, char *name, struct dentry *child
 	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 		goto retry;
 
-	bch2_trans_iter_exit(&iter1);
-	bch2_trans_iter_exit(&iter2);
 	return ret;
 }
 
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index de87a0e820bd..f971e6993f2b 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -645,11 +645,8 @@ static int reconstruct_inode(struct btree_trans *trans, enum btree_id btree, u32
 
 	switch (btree) {
 	case BTREE_ID_extents: {
-		struct btree_iter iter = {};
-
-		bch2_trans_iter_init(trans, &iter, BTREE_ID_extents, SPOS(inum, U64_MAX, snapshot), 0);
+		CLASS(btree_iter, iter)(trans, BTREE_ID_extents, SPOS(inum, U64_MAX, snapshot), 0);
 		struct bkey_s_c k = bch2_btree_iter_peek_prev_min(&iter, POS(inum, 0));
-		bch2_trans_iter_exit(&iter);
 		int ret = bkey_err(k);
 		if (ret)
 			return ret;
@@ -1740,15 +1737,15 @@ static int overlapping_extents_found(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	CLASS(printbuf, buf)();
-	struct btree_iter iter1, iter2 = {};
+	struct btree_iter iter2 = {};
 	struct bkey_s_c k1, k2;
 	int ret;
 
 	BUG_ON(bkey_le(pos1, bkey_start_pos(&pos2)));
 
-	bch2_trans_iter_init(trans, &iter1, btree, pos1,
-			     BTREE_ITER_all_snapshots|
-			     BTREE_ITER_not_extents);
+	CLASS(btree_iter, iter1)(trans, btree, pos1,
+				 BTREE_ITER_all_snapshots|
+				 BTREE_ITER_not_extents);
 	k1 = bch2_btree_iter_peek_max(&iter1, POS(pos1.inode, U64_MAX));
 	ret = bkey_err(k1);
 	if (ret)
@@ -1844,7 +1841,6 @@ static int overlapping_extents_found(struct btree_trans *trans,
 fsck_err:
 err:
 	bch2_trans_iter_exit(&iter2);
-	bch2_trans_iter_exit(&iter1);
 	return ret;
 }
 
@@ -2424,8 +2420,7 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 					(printbuf_reset(&buf),
 					 bch2_bkey_val_to_text(&buf, c, k),
 					 buf.buf))) {
-				struct btree_iter delete_iter;
-				bch2_trans_iter_init(trans, &delete_iter,
+				CLASS(btree_iter, delete_iter)(trans,
 						     BTREE_ID_dirents,
 						     SPOS(k.k->p.inode, k.k->p.offset, *i),
 						     BTREE_ITER_intent);
@@ -2434,7 +2429,6 @@ static int check_dirent(struct btree_trans *trans, struct btree_iter *iter,
 							  hash_info,
 							  &delete_iter,
 							  BTREE_UPDATE_internal_snapshot_node);
-				bch2_trans_iter_exit(&delete_iter);
 				if (ret)
 					return ret;
 
@@ -2628,7 +2622,6 @@ int bch2_check_root(struct bch_fs *c)
 static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter, struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter parent_iter = {};
 	CLASS(darray_u32, subvol_path)();
 	CLASS(printbuf, buf)();
 	int ret = 0;
@@ -2636,6 +2629,8 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 	if (k.k->type != KEY_TYPE_subvolume)
 		return 0;
 
+	CLASS(btree_iter, parent_iter)(trans, BTREE_ID_subvolumes, POS_MIN, 0);
+
 	subvol_inum start = {
 		.subvol = k.k->p.offset,
 		.inum	= le64_to_cpu(bkey_s_c_to_subvolume(k).v->inode),
@@ -2644,7 +2639,7 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 	while (k.k->p.offset != BCACHEFS_ROOT_SUBVOL) {
 		ret = darray_push(&subvol_path, k.k->p.offset);
 		if (ret)
-			goto err;
+			return ret;
 
 		struct bkey_s_c_subvolume s = bkey_s_c_to_subvolume(k);
 
@@ -2663,20 +2658,18 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 
 			ret = bch2_inum_to_path(trans, start, &buf);
 			if (ret)
-				goto err;
+				return ret;
 
 			if (fsck_err(trans, subvol_loop, "%s", buf.buf))
 				ret = reattach_subvol(trans, s);
 			break;
 		}
 
-		bch2_trans_iter_exit(&parent_iter);
-		bch2_trans_iter_init(trans, &parent_iter,
-				     BTREE_ID_subvolumes, POS(0, parent), 0);
+		bch2_btree_iter_set_pos(&parent_iter, POS(0, parent));
 		k = bch2_btree_iter_peek_slot(&parent_iter);
 		ret = bkey_err(k);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (fsck_err_on(k.k->type != KEY_TYPE_subvolume,
 				trans, subvol_unreachable,
@@ -2684,13 +2677,10 @@ static int check_subvol_path(struct btree_trans *trans, struct btree_iter *iter,
 				(printbuf_reset(&buf),
 				 bch2_bkey_val_to_text(&buf, c, s.s_c),
 				 buf.buf))) {
-			ret = reattach_subvol(trans, s);
-			break;
+			return reattach_subvol(trans, s);
 		}
 	}
 fsck_err:
-err:
-	bch2_trans_iter_exit(&parent_iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 3f983a5b780c..838da956b4e1 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -1080,7 +1080,6 @@ int bch2_inode_create(struct btree_trans *trans,
 static int bch2_inode_delete_keys(struct btree_trans *trans,
 				  subvol_inum inum, enum btree_id id)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	struct bkey_i delete;
 	struct bpos end = POS(inum.inum, U64_MAX);
@@ -1091,8 +1090,7 @@ static int bch2_inode_delete_keys(struct btree_trans *trans,
 	 * We're never going to be deleting partial extents, no need to use an
 	 * extent iterator:
 	 */
-	bch2_trans_iter_init(trans, &iter, id, POS(inum.inum, 0),
-			     BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, id, POS(inum.inum, 0), BTREE_ITER_intent);
 
 	while (1) {
 		bch2_trans_begin(trans);
@@ -1127,7 +1125,6 @@ static int bch2_inode_delete_keys(struct btree_trans *trans,
 			break;
 	}
 
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/io_misc.c b/fs/bcachefs/io_misc.c
index d3496eb8d682..fa0b06e17d17 100644
--- a/fs/bcachefs/io_misc.c
+++ b/fs/bcachefs/io_misc.c
@@ -222,16 +222,11 @@ int bch2_fpunch(struct bch_fs *c, subvol_inum inum, u64 start, u64 end,
 		s64 *i_sectors_delta)
 {
 	CLASS(btree_trans, trans)(c);
-
-	struct btree_iter iter;
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
-			     POS(inum.inum, start),
-			     BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_extents, POS(inum.inum, start),
+				BTREE_ITER_intent);
 
 	int ret = bch2_fpunch_at(trans, &iter, inum, end, i_sectors_delta);
 
-	bch2_trans_iter_exit(&iter);
-
 	return bch2_err_matches(ret, BCH_ERR_transaction_restart) ? 0 : ret;
 }
 
@@ -268,7 +263,6 @@ static int __bch2_resume_logged_op_truncate(struct btree_trans *trans,
 					    u64 *i_sectors_delta)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter fpunch_iter;
 	struct bkey_i_logged_op_truncate *op = bkey_i_to_logged_op_truncate(op_k);
 	subvol_inum inum = { le32_to_cpu(op->v.subvol), le64_to_cpu(op->v.inum) };
 	u64 new_i_size = le64_to_cpu(op->v.new_i_size);
@@ -280,14 +274,15 @@ static int __bch2_resume_logged_op_truncate(struct btree_trans *trans,
 	if (ret)
 		goto err;
 
-	bch2_trans_iter_init(trans, &fpunch_iter, BTREE_ID_extents,
-			     POS(inum.inum, round_up(new_i_size, block_bytes(c)) >> 9),
-			     BTREE_ITER_intent);
-	ret = bch2_fpunch_at(trans, &fpunch_iter, inum, U64_MAX, i_sectors_delta);
-	bch2_trans_iter_exit(&fpunch_iter);
+	{
+		CLASS(btree_iter, fpunch_iter)(trans, BTREE_ID_extents,
+					       POS(inum.inum, round_up(new_i_size, block_bytes(c)) >> 9),
+					       BTREE_ITER_intent);
+		ret = bch2_fpunch_at(trans, &fpunch_iter, inum, U64_MAX, i_sectors_delta);
 
-	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
-		ret = 0;
+		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
+			ret = 0;
+	}
 err:
 	if (warn_errors)
 		bch_err_fn(c, ret);
diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index 571b1b9c0fa1..26eea9ba1f4f 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -1030,13 +1030,10 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 						   struct bch_extent_ptr ptr)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	CLASS(printbuf, buf)();
-	int ret;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_alloc,
-			     PTR_BUCKET_POS(ca, &ptr),
-			     BTREE_ITER_cached);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_alloc,
+				PTR_BUCKET_POS(ca, &ptr),
+				BTREE_ITER_cached);
 
 	int gen = bucket_gen_get(ca, iter.pos.offset);
 	if (gen >= 0) {
@@ -1048,7 +1045,7 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 
 		prt_printf(&buf, "memory gen: %u", gen);
 
-		ret = lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_slot(&iter)));
+		int ret = lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_slot(&iter)));
 		if (!ret) {
 			prt_newline(&buf);
 			bch2_bkey_val_to_text(&buf, c, k);
@@ -1066,8 +1063,6 @@ static noinline void read_from_stale_dirty_pointer(struct btree_trans *trans,
 	}
 
 	bch2_fs_inconsistent(c, "%s", buf.buf);
-
-	bch2_trans_iter_exit(&iter);
 }
 
 int __bch2_read_extent(struct btree_trans *trans, struct bch_read_bio *orig,
@@ -1411,7 +1406,6 @@ int __bch2_read(struct btree_trans *trans, struct bch_read_bio *rbio,
 		unsigned flags)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_buf sk;
 	struct bkey_s_c k;
 	enum btree_id data_btree;
@@ -1420,9 +1414,9 @@ int __bch2_read(struct btree_trans *trans, struct bch_read_bio *rbio,
 	EBUG_ON(rbio->data_update);
 
 	bch2_bkey_buf_init(&sk);
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
-			     POS(inum.inum, bvec_iter.bi_sector),
-			     BTREE_ITER_slots);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_extents,
+				POS(inum.inum, bvec_iter.bi_sector),
+				BTREE_ITER_slots);
 
 	while (1) {
 		data_btree = BTREE_ID_extents;
@@ -1514,7 +1508,6 @@ int __bch2_read(struct btree_trans *trans, struct bch_read_bio *rbio,
 			bch2_rbio_done(rbio);
 	}
 
-	bch2_trans_iter_exit(&iter);
 	bch2_bkey_buf_exit(&sk, c);
 	return ret;
 }
diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index 6b9f8b5e55dc..a53f3278a612 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -374,7 +374,6 @@ static int bch2_write_index_default(struct bch_write_op *op)
 	struct bkey_buf sk;
 	struct keylist *keys = &op->insert_keys;
 	struct bkey_i *k = bch2_keylist_front(keys);
-	struct btree_iter iter;
 	subvol_inum inum = {
 		.subvol = op->subvol,
 		.inum	= k->k.p.inode,
@@ -399,15 +398,14 @@ static int bch2_write_index_default(struct bch_write_op *op)
 		if (ret)
 			break;
 
-		bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
-				     bkey_start_pos(&sk.k->k),
-				     BTREE_ITER_slots|BTREE_ITER_intent);
+		CLASS(btree_iter, iter)(trans, BTREE_ID_extents,
+					bkey_start_pos(&sk.k->k),
+					BTREE_ITER_slots|BTREE_ITER_intent);
 
 		ret =   bch2_extent_update(trans, inum, &iter, sk.k,
 					&op->res,
 					op->new_i_size, &op->i_sectors_delta,
 					op->flags & BCH_WRITE_check_enospc);
-		bch2_trans_iter_exit(&iter);
 
 		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
 			continue;
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index ae9fb58702ba..76cc13f62884 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -853,7 +853,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 	struct bch_fs *c = trans->c;
 	bool is_kthread = current->flags & PF_KTHREAD;
 	struct bch_io_opts io_opts = bch2_opts_to_inode_opts(c->opts);
-	struct btree_iter iter = {}, bp_iter = {};
+	struct btree_iter iter = {};
 	struct bkey_buf sk;
 	struct bkey_s_c k;
 	struct bkey_buf last_flushed;
@@ -878,7 +878,7 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 	 */
 	bch2_trans_begin(trans);
 
-	bch2_trans_iter_init(trans, &bp_iter, BTREE_ID_backpointers, bp_start, 0);
+	CLASS(btree_iter, bp_iter)(trans, BTREE_ID_backpointers, bp_start, 0);
 
 	ret = bch2_btree_write_buffer_tryflush(trans);
 	if (!bch2_err_matches(ret, EROFS))
@@ -996,7 +996,6 @@ static int __bch2_move_data_phys(struct moving_context *ctxt,
 		bch2_check_bucket_backpointer_mismatch(trans, ca, check_mismatch_done++,
 						       copygc, &last_flushed);
 err:
-	bch2_trans_iter_exit(&bp_iter);
 	bch2_bkey_buf_exit(&sk, c);
 	bch2_bkey_buf_exit(&last_flushed, c);
 	return ret;
diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index f2918804fab5..c0c5fe961a83 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -235,14 +235,13 @@ static const char * const bch2_rebalance_state_strs[] = {
 
 int bch2_set_rebalance_needs_scan_trans(struct btree_trans *trans, u64 inum)
 {
-	struct btree_iter iter;
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_rebalance_work,
-			     SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
-			     BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_rebalance_work,
+				SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
+				BTREE_ITER_intent);
 	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	u64 v = k.k->type == KEY_TYPE_cookie
 		? le64_to_cpu(bkey_s_c_to_cookie(k).v->cookie)
@@ -251,16 +250,13 @@ int bch2_set_rebalance_needs_scan_trans(struct btree_trans *trans, u64 inum)
 	struct bkey_i_cookie *cookie = bch2_trans_kmalloc(trans, sizeof(*cookie));
 	ret = PTR_ERR_OR_ZERO(cookie);
 	if (ret)
-		goto err;
+		return ret;
 
 	bkey_cookie_init(&cookie->k_i);
 	cookie->k.p = iter.pos;
 	cookie->v.cookie = cpu_to_le64(v + 1);
 
-	ret = bch2_trans_update(trans, &iter, &cookie->k_i, 0);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_trans_update(trans, &iter, &cookie->k_i, 0);
 }
 
 int bch2_set_rebalance_needs_scan(struct bch_fs *c, u64 inum)
@@ -279,24 +275,21 @@ int bch2_set_fs_needs_rebalance(struct bch_fs *c)
 
 static int bch2_clear_rebalance_needs_scan(struct btree_trans *trans, u64 inum, u64 cookie)
 {
-	struct btree_iter iter;
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_rebalance_work,
-			     SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
-			     BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_rebalance_work,
+				SPOS(inum, REBALANCE_WORK_SCAN_OFFSET, U32_MAX),
+				BTREE_ITER_intent);
 	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	u64 v = k.k->type == KEY_TYPE_cookie
 		? le64_to_cpu(bkey_s_c_to_cookie(k).v->cookie)
 		: 0;
 
-	if (v == cookie)
-		ret = bch2_btree_delete_at(trans, &iter, 0);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return v == cookie
+		? bch2_btree_delete_at(trans, &iter, 0)
+		: 0;
 }
 
 static struct bkey_s_c next_rebalance_entry(struct btree_trans *trans,
@@ -531,7 +524,7 @@ static int do_rebalance(struct moving_context *ctxt)
 	struct btree_trans *trans = ctxt->trans;
 	struct bch_fs *c = trans->c;
 	struct bch_fs_rebalance *r = &c->rebalance;
-	struct btree_iter rebalance_work_iter, extent_iter = { NULL };
+	struct btree_iter extent_iter = { NULL };
 	struct bkey_s_c k;
 	u32 kick = r->kick;
 	int ret = 0;
@@ -541,9 +534,9 @@ static int do_rebalance(struct moving_context *ctxt)
 	bch2_move_stats_init(&r->work_stats, "rebalance_work");
 	bch2_move_stats_init(&r->scan_stats, "rebalance_scan");
 
-	bch2_trans_iter_init(trans, &rebalance_work_iter,
-			     BTREE_ID_rebalance_work, POS_MIN,
-			     BTREE_ITER_all_snapshots);
+	CLASS(btree_iter, rebalance_work_iter)(trans,
+					       BTREE_ID_rebalance_work, POS_MIN,
+					       BTREE_ITER_all_snapshots);
 
 	while (!bch2_move_ratelimit(ctxt)) {
 		if (!bch2_rebalance_enabled(c)) {
@@ -577,7 +570,6 @@ static int do_rebalance(struct moving_context *ctxt)
 	}
 
 	bch2_trans_iter_exit(&extent_iter);
-	bch2_trans_iter_exit(&rebalance_work_iter);
 	bch2_move_stats_exit(&r->scan_stats, c);
 
 	if (!ret &&
@@ -845,15 +837,10 @@ static int check_rebalance_work_one(struct btree_trans *trans,
 int bch2_check_rebalance_work(struct bch_fs *c)
 {
 	CLASS(btree_trans, trans)(c);
-	struct btree_iter rebalance_iter, extent_iter;
-	int ret = 0;
-
-	bch2_trans_iter_init(trans, &extent_iter,
-			     BTREE_ID_reflink, POS_MIN,
-			     BTREE_ITER_prefetch);
-	bch2_trans_iter_init(trans, &rebalance_iter,
-			     BTREE_ID_rebalance_work, POS_MIN,
-			     BTREE_ITER_prefetch);
+	CLASS(btree_iter, extent_iter)(trans, BTREE_ID_reflink, POS_MIN,
+				       BTREE_ITER_prefetch);
+	CLASS(btree_iter, rebalance_iter)(trans, BTREE_ID_rebalance_work, POS_MIN,
+					  BTREE_ITER_prefetch);
 
 	struct bkey_buf last_flushed;
 	bch2_bkey_buf_init(&last_flushed);
@@ -862,6 +849,7 @@ int bch2_check_rebalance_work(struct bch_fs *c)
 	struct progress_indicator_state progress;
 	bch2_progress_init(&progress, c, BIT_ULL(BTREE_ID_rebalance_work));
 
+	int ret = 0;
 	while (!ret) {
 		progress_update_iter(trans, &progress, &rebalance_iter);
 
@@ -874,7 +862,5 @@ int bch2_check_rebalance_work(struct bch_fs *c)
 	}
 
 	bch2_bkey_buf_exit(&last_flushed, c);
-	bch2_trans_iter_exit(&extent_iter);
-	bch2_trans_iter_exit(&rebalance_iter);
 	return ret < 0 ? ret : 0;
 }
diff --git a/fs/bcachefs/reflink.c b/fs/bcachefs/reflink.c
index 07cebc697b38..c083deb83ff7 100644
--- a/fs/bcachefs/reflink.c
+++ b/fs/bcachefs/reflink.c
@@ -497,13 +497,12 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	if (orig->k.type == KEY_TYPE_inline_data)
 		bch2_check_set_feature(c, BCH_FEATURE_reflink_inline_data);
 
-	struct btree_iter reflink_iter;
-	bch2_trans_iter_init(trans, &reflink_iter, BTREE_ID_reflink, POS_MAX,
-			     BTREE_ITER_intent);
+	CLASS(btree_iter, reflink_iter)(trans, BTREE_ID_reflink, POS_MAX,
+					BTREE_ITER_intent);
 	struct bkey_s_c k = bch2_btree_iter_peek_prev(&reflink_iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	/*
 	 * XXX: we're assuming that 56 bits will be enough for the life of the
@@ -516,7 +515,7 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	struct bkey_i *r_v = bch2_trans_kmalloc(trans, sizeof(__le64) + bkey_bytes(&orig->k));
 	ret = PTR_ERR_OR_ZERO(r_v);
 	if (ret)
-		goto err;
+		return ret;
 
 	bkey_init(&r_v->k);
 	r_v->k.type	= bkey_type_to_indirect(&orig->k);
@@ -532,7 +531,7 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 
 	ret = bch2_trans_update(trans, &reflink_iter, r_v, 0);
 	if (ret)
-		goto err;
+		return ret;
 
 	/*
 	 * orig is in a bkey_buf which statically allocates 5 64s for the val,
@@ -555,12 +554,8 @@ static int bch2_make_extent_indirect(struct btree_trans *trans,
 	if (reflink_p_may_update_opts_field)
 		SET_REFLINK_P_MAY_UPDATE_OPTIONS(&r_p->v, true);
 
-	ret = bch2_trans_update(trans, extent_iter, &r_p->k_i,
-				BTREE_UPDATE_internal_snapshot_node);
-err:
-	bch2_trans_iter_exit(&reflink_iter);
-
-	return ret;
+	return bch2_trans_update(trans, extent_iter, &r_p->k_i,
+				 BTREE_UPDATE_internal_snapshot_node);
 }
 
 static struct bkey_s_c get_next_src(struct btree_iter *iter, struct bpos end)
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index dfdc54ffd57d..1b7b21494479 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -1270,35 +1270,30 @@ static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
 			  unsigned nr_snapids)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_i_snapshot *n;
-	struct bkey_s_c k;
-	unsigned i, j;
 	u32 depth = bch2_snapshot_depth(c, parent);
-	int ret;
 
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_snapshots,
-			     POS_MIN, BTREE_ITER_intent);
-	k = bch2_btree_iter_peek(&iter);
-	ret = bkey_err(k);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_snapshots,
+				POS_MIN, BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek(&iter);
+	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
-	for (i = 0; i < nr_snapids; i++) {
+	for (unsigned i = 0; i < nr_snapids; i++) {
 		k = bch2_btree_iter_prev_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (!k.k || !k.k->p.offset) {
-			ret = bch_err_throw(c, ENOSPC_snapshot_create);
-			goto err;
+			return bch_err_throw(c, ENOSPC_snapshot_create);
 		}
 
 		n = bch2_bkey_alloc(trans, &iter, 0, snapshot);
 		ret = PTR_ERR_OR_ZERO(n);
 		if (ret)
-			goto err;
+			return ret;
 
 		n->v.flags	= 0;
 		n->v.parent	= cpu_to_le32(parent);
@@ -1308,7 +1303,7 @@ static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
 		n->v.btime.lo	= cpu_to_le64(bch2_current_time(c));
 		n->v.btime.hi	= 0;
 
-		for (j = 0; j < ARRAY_SIZE(n->v.skip); j++)
+		for (unsigned j = 0; j < ARRAY_SIZE(n->v.skip); j++)
 			n->v.skip[j] = cpu_to_le32(bch2_snapshot_skiplist_get(c, parent));
 
 		bubble_sort(n->v.skip, ARRAY_SIZE(n->v.skip), cmp_le32);
@@ -1317,13 +1312,12 @@ static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
 		ret = __bch2_mark_snapshot(trans, BTREE_ID_snapshots, 0,
 					 bkey_s_c_null, bkey_i_to_s_c(&n->k_i), 0);
 		if (ret)
-			goto err;
+			return ret;
 
 		new_snapids[i]	= iter.pos.offset;
 	}
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return 0;
 }
 
 /*
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index b6d0dc0a46de..c3066dc56601 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -297,11 +297,8 @@ int bch2_subvolume_trigger(struct btree_trans *trans,
 
 int bch2_subvol_has_children(struct btree_trans *trans, u32 subvol)
 {
-	struct btree_iter iter;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_subvolume_children, POS(subvol, 0), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_subvolume_children, POS(subvol, 0), 0);
 	struct bkey_s_c k = bch2_btree_iter_peek(&iter);
-	bch2_trans_iter_exit(&iter);
 
 	return bkey_err(k) ?: k.k && k.k->p.inode == subvol
 		? bch_err_throw(trans->c, ENOTEMPTY_subvol_not_empty)
diff --git a/fs/bcachefs/subvolume.h b/fs/bcachefs/subvolume.h
index b39ff39b252d..b6d7c1f4a256 100644
--- a/fs/bcachefs/subvolume.h
+++ b/fs/bcachefs/subvolume.h
@@ -48,12 +48,11 @@ bch2_btree_iter_peek_in_subvolume_max_type(struct btree_iter *iter, struct bpos
 #define for_each_btree_key_in_subvolume_max_continue(_trans, _iter,		\
 					 _end, _subvolid, _flags, _k, _do)	\
 ({										\
-	struct bkey_s_c _k;							\
 	int _ret3 = 0;								\
 										\
 	do {									\
 		_ret3 = lockrestart_do(_trans, ({				\
-			(_k) = bch2_btree_iter_peek_in_subvolume_max_type(&(_iter),	\
+			struct bkey_s_c _k = bch2_btree_iter_peek_in_subvolume_max_type(&(_iter),\
 						_end, _subvolid, (_flags));	\
 			if (!(_k).k)						\
 				break;						\
@@ -68,14 +67,10 @@ bch2_btree_iter_peek_in_subvolume_max_type(struct btree_iter *iter, struct bpos
 #define for_each_btree_key_in_subvolume_max(_trans, _iter, _btree_id,		\
 				_start, _end, _subvolid, _flags, _k, _do)	\
 ({										\
-	struct btree_iter _iter;						\
-	bch2_trans_iter_init((_trans), &(_iter), (_btree_id),			\
-			     (_start), (_flags));				\
+	CLASS(btree_iter, _iter)((_trans), (_btree_id), (_start), (_flags));	\
 										\
-	int _ret = for_each_btree_key_in_subvolume_max_continue(_trans, _iter,	\
+	for_each_btree_key_in_subvolume_max_continue(_trans, _iter,		\
 					_end, _subvolid, _flags, _k, _do);	\
-	bch2_trans_iter_exit(&(_iter));						\
-	_ret;									\
 })
 
 int bch2_subvolume_unlink(struct btree_trans *, u32);
diff --git a/fs/bcachefs/tests.c b/fs/bcachefs/tests.c
index 4628ff84eefc..baaaedf68422 100644
--- a/fs/bcachefs/tests.c
+++ b/fs/bcachefs/tests.c
@@ -31,23 +31,19 @@ static void delete_test_keys(struct bch_fs *c)
 
 static int test_delete(struct bch_fs *c, u64 nr)
 {
-	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
 	struct bkey_i_cookie k;
-	int ret;
-
 	bkey_cookie_init(&k.k_i);
 	k.k.p.snapshot = U32_MAX;
 
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs, k.k.p,
-			     BTREE_ITER_intent);
+	CLASS(btree_trans, trans)(c);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, k.k.p, BTREE_ITER_intent);
 
-	ret = commit_do(trans, NULL, NULL, 0,
+	int ret = commit_do(trans, NULL, NULL, 0,
 		bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &k.k_i, 0));
 	bch_err_msg(c, ret, "update error");
 	if (ret)
-		goto err;
+		return ret;
 
 	pr_info("deleting once");
 	ret = commit_do(trans, NULL, NULL, 0,
@@ -55,7 +51,7 @@ static int test_delete(struct bch_fs *c, u64 nr)
 		bch2_btree_delete_at(trans, &iter, 0));
 	bch_err_msg(c, ret, "delete error (first)");
 	if (ret)
-		goto err;
+		return ret;
 
 	pr_info("deleting twice");
 	ret = commit_do(trans, NULL, NULL, 0,
@@ -63,31 +59,26 @@ static int test_delete(struct bch_fs *c, u64 nr)
 		bch2_btree_delete_at(trans, &iter, 0));
 	bch_err_msg(c, ret, "delete error (second)");
 	if (ret)
-		goto err;
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+		return ret;
+
+	return 0;
 }
 
 static int test_delete_written(struct bch_fs *c, u64 nr)
 {
-	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
 	struct bkey_i_cookie k;
-	int ret;
-
 	bkey_cookie_init(&k.k_i);
 	k.k.p.snapshot = U32_MAX;
 
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs, k.k.p,
-			     BTREE_ITER_intent);
+	CLASS(btree_trans, trans)(c);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, k.k.p, BTREE_ITER_intent);
 
-	ret = commit_do(trans, NULL, NULL, 0,
+	int ret = commit_do(trans, NULL, NULL, 0,
 		bch2_btree_iter_traverse(&iter) ?:
 		bch2_trans_update(trans, &iter, &k.k_i, 0));
 	bch_err_msg(c, ret, "update error");
 	if (ret)
-		goto err;
+		return ret;
 
 	bch2_trans_unlock(trans);
 	bch2_journal_flush_all_pins(&c->journal);
@@ -97,10 +88,9 @@ static int test_delete_written(struct bch_fs *c, u64 nr)
 		bch2_btree_delete_at(trans, &iter, 0));
 	bch_err_msg(c, ret, "delete error");
 	if (ret)
-		goto err;
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+		return ret;
+
+	return 0;
 }
 
 static int test_iterate(struct bch_fs *c, u64 nr)
@@ -343,19 +333,15 @@ static int test_peek_end(struct bch_fs *c, u64 nr)
 	delete_test_keys(c);
 
 	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
-	struct bkey_s_c k;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
-			     SPOS(0, 0, U32_MAX), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, SPOS(0, 0, U32_MAX), 0);
 
+	struct bkey_s_c k;
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
-	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -364,19 +350,15 @@ static int test_peek_end_extents(struct bch_fs *c, u64 nr)
 	delete_test_keys(c);
 
 	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
-	struct bkey_s_c k;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_extents,
-			     SPOS(0, 0, U32_MAX), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_extents, SPOS(0, 0, U32_MAX), 0);
 
+	struct bkey_s_c k;
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
 	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 	BUG_ON(k.k);
 
-	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -470,25 +452,21 @@ static int test_extent_create_overlapping(struct bch_fs *c, u64 inum)
 /* Test skipping over keys in unrelated snapshots: */
 static int test_snapshot_filter(struct bch_fs *c, u32 snapid_lo, u32 snapid_hi)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k;
 	struct bkey_i_cookie cookie;
-	int ret;
-
 	bkey_cookie_init(&cookie.k_i);
 	cookie.k.p.snapshot = snapid_hi;
-	ret = bch2_btree_insert(c, BTREE_ID_xattrs, &cookie.k_i, NULL, 0, 0);
+	int ret = bch2_btree_insert(c, BTREE_ID_xattrs, &cookie.k_i, NULL, 0, 0);
 	if (ret)
 		return ret;
 
 	CLASS(btree_trans, trans)(c);
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
-			     SPOS(0, 0, snapid_lo), 0);
-	lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, SPOS(0, 0, snapid_lo), 0);
+
+	struct bkey_s_c k;
+	ret = lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX))));
 
 	BUG_ON(k.k->p.snapshot != U32_MAX);
 
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -583,24 +561,18 @@ static int rand_insert_multi(struct bch_fs *c, u64 nr)
 static int rand_lookup(struct bch_fs *c, u64 nr)
 {
 	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
-	struct bkey_s_c k;
-	int ret = 0;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
-			     SPOS(0, 0, U32_MAX), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, SPOS(0, 0, U32_MAX), 0);
 
 	for (u64 i = 0; i < nr; i++) {
 		bch2_btree_iter_set_pos(&iter, SPOS(0, test_rand(), U32_MAX));
 
-		lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek(&iter)));
-		ret = bkey_err(k);
+		struct bkey_s_c k;
+		int ret = lockrestart_do(trans, bkey_err(k = bch2_btree_iter_peek(&iter)));
 		if (ret)
-			break;
+			return ret;
 	}
 
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return 0;
 }
 
 static int rand_mixed_trans(struct btree_trans *trans,
@@ -631,45 +603,33 @@ static int rand_mixed_trans(struct btree_trans *trans,
 static int rand_mixed(struct bch_fs *c, u64 nr)
 {
 	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
-	struct bkey_i_cookie cookie;
-	int ret = 0;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs,
-			     SPOS(0, 0, U32_MAX), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, SPOS(0, 0, U32_MAX), 0);
 
 	for (u64 i = 0; i < nr; i++) {
 		u64 rand = test_rand();
-		ret = commit_do(trans, NULL, NULL, 0,
+		struct bkey_i_cookie cookie;
+		int ret = commit_do(trans, NULL, NULL, 0,
 			rand_mixed_trans(trans, &iter, &cookie, i, rand));
 		if (ret)
-			break;
+			return ret;
 	}
 
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return 0;
 }
 
 static int __do_delete(struct btree_trans *trans, struct bpos pos)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k;
-	int ret = 0;
-
-	bch2_trans_iter_init(trans, &iter, BTREE_ID_xattrs, pos,
-			     BTREE_ITER_intent);
-	k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX));
-	ret = bkey_err(k);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_xattrs, pos,
+				BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_max(&iter, POS(0, U64_MAX));
+	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (!k.k)
-		goto err;
+		return 0;
 
-	ret = bch2_btree_delete_at(trans, &iter, 0);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_btree_delete_at(trans, &iter, 0);
 }
 
 static int rand_delete(struct bch_fs *c, u64 nr)
-- 
2.51.0


From f093c5a375f082cdf090db6b1a1ff8176b1dbf2b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 22:47:08 -0400
Subject: [PATCH 210/309] bcachefs: Kill most bch2_bkey_get_iter() uses

CLASS(btree_iter, ...); peek_slot() is now more concise.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_background.c | 166 +++++++++++++++------------------
 fs/bcachefs/alloc_foreground.c |  27 +++---
 fs/bcachefs/backpointers.c     |  73 ++++++---------
 fs/bcachefs/btree_update.c     |   8 +-
 fs/bcachefs/ec.c               |  78 ++++++----------
 fs/bcachefs/fsck.c             |  53 +++++------
 fs/bcachefs/inode.c            |  81 +++++++---------
 fs/bcachefs/io_read.c          |  47 ++++------
 fs/bcachefs/io_write.c         |  27 +++---
 fs/bcachefs/lru.c              |  24 ++---
 fs/bcachefs/move.c             |  31 +++---
 fs/bcachefs/movinggc.c         |  16 ++--
 fs/bcachefs/quota.c            |  11 +--
 fs/bcachefs/reflink.c          |  30 +++---
 fs/bcachefs/snapshot.c         |  12 +--
 fs/bcachefs/str_hash.c         |   8 +-
 fs/bcachefs/subvolume.c        |  51 ++++------
 17 files changed, 308 insertions(+), 435 deletions(-)

diff --git a/fs/bcachefs/alloc_background.c b/fs/bcachefs/alloc_background.c
index 1c2cd841e8a0..3fc728efbf5c 100644
--- a/fs/bcachefs/alloc_background.c
+++ b/fs/bcachefs/alloc_background.c
@@ -473,13 +473,14 @@ struct bkey_i_alloc_v4 *
 bch2_trans_start_alloc_update_noupdate(struct btree_trans *trans, struct btree_iter *iter,
 				       struct bpos pos)
 {
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, iter, BTREE_ID_alloc, pos,
-					       BTREE_ITER_with_updates|
-					       BTREE_ITER_cached|
-					       BTREE_ITER_intent);
+	bch2_trans_iter_init(trans, iter, BTREE_ID_alloc, pos,
+			     BTREE_ITER_with_updates|
+			     BTREE_ITER_cached|
+			     BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 	int ret = bkey_err(k);
 	if (unlikely(ret))
-		return ERR_PTR(ret);
+		goto err;
 
 	struct bkey_i_alloc_v4 *a = bch2_alloc_to_v4_mut_inlined(trans, k);
 	ret = PTR_ERR_OR_ZERO(a);
@@ -495,29 +496,24 @@ __flatten
 struct bkey_i_alloc_v4 *bch2_trans_start_alloc_update(struct btree_trans *trans, struct bpos pos,
 						      enum btree_iter_update_trigger_flags flags)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_alloc, pos,
-					       BTREE_ITER_with_updates|
-					       BTREE_ITER_cached|
-					       BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_alloc, pos,
+				BTREE_ITER_with_updates|
+				BTREE_ITER_cached|
+				BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (unlikely(ret))
 		return ERR_PTR(ret);
 
 	if ((void *) k.v >= trans->mem &&
-	    (void *) k.v <  trans->mem + trans->mem_top) {
-		bch2_trans_iter_exit(&iter);
+	    (void *) k.v <  trans->mem + trans->mem_top)
 		return container_of(bkey_s_c_to_alloc_v4(k).v, struct bkey_i_alloc_v4, v);
-	}
 
 	struct bkey_i_alloc_v4 *a = bch2_alloc_to_v4_mut_inlined(trans, k);
-	if (IS_ERR(a)) {
-		bch2_trans_iter_exit(&iter);
+	if (IS_ERR(a))
 		return a;
-	}
 
 	ret = bch2_trans_update_ip(trans, &iter, &a->k_i, flags, _RET_IP_);
-	bch2_trans_iter_exit(&iter);
 	return unlikely(ret) ? ERR_PTR(ret) : a;
 }
 
@@ -744,8 +740,8 @@ static int bch2_bucket_do_index(struct btree_trans *trans,
 		return 0;
 	}
 
-	struct btree_iter iter;
-	struct bkey_s_c old = bch2_bkey_get_iter(trans, &iter, btree, pos, BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, btree, pos, BTREE_ITER_intent);
+	struct bkey_s_c old = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(old);
 	if (ret)
 		return ret;
@@ -755,30 +751,25 @@ static int bch2_bucket_do_index(struct btree_trans *trans,
 					 trans, alloc_k, set,
 					 btree == BTREE_ID_need_discard, false);
 
-	ret = bch2_btree_bit_mod_iter(trans, &iter, set);
+	return bch2_btree_bit_mod_iter(trans, &iter, set);
 fsck_err:
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
 static noinline int bch2_bucket_gen_update(struct btree_trans *trans,
 					   struct bpos bucket, u8 gen)
 {
-	struct btree_iter iter;
-	unsigned offset;
-	struct bpos pos = alloc_gens_pos(bucket, &offset);
-	struct bkey_i_bucket_gens *g;
-	struct bkey_s_c k;
-	int ret;
-
-	g = bch2_trans_kmalloc(trans, sizeof(*g));
-	ret = PTR_ERR_OR_ZERO(g);
+	struct bkey_i_bucket_gens *g = bch2_trans_kmalloc(trans, sizeof(*g));
+	int ret = PTR_ERR_OR_ZERO(g);
 	if (ret)
 		return ret;
 
-	k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_bucket_gens, pos,
-			       BTREE_ITER_intent|
-			       BTREE_ITER_with_updates);
+	unsigned offset;
+	struct bpos pos = alloc_gens_pos(bucket, &offset);
+
+	CLASS(btree_iter, iter)(trans, BTREE_ID_bucket_gens, pos,
+				BTREE_ITER_intent|BTREE_ITER_with_updates);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1353,8 +1344,8 @@ struct check_discard_freespace_key_async {
 
 static int bch2_recheck_discard_freespace_key(struct btree_trans *trans, struct bbpos pos)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, pos.btree, pos.pos, 0);
+	CLASS(btree_iter, iter)(trans, pos.btree, pos.pos, 0);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1797,16 +1788,12 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct bpos pos = need_discard_iter->pos;
-	struct btree_iter iter = { NULL };
-	struct bkey_s_c k;
-	struct bkey_i_alloc_v4 *a;
-	CLASS(printbuf, buf)();
 	bool discard_locked = false;
 	int ret = 0;
 
 	if (bch2_bucket_is_open_safe(c, pos.inode, pos.offset)) {
 		s->open++;
-		goto out;
+		return 0;
 	}
 
 	u64 seq_ready = bch2_bucket_journal_seq_ready(&c->buckets_waiting_for_journal,
@@ -1814,30 +1801,29 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 	if (seq_ready > c->journal.flushed_seq_ondisk) {
 		if (seq_ready > c->journal.flushing_seq)
 			s->need_journal_commit++;
-		goto out;
+		return 0;
 	}
 
-	k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_alloc,
-			       need_discard_iter->pos,
-			       BTREE_ITER_cached);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_alloc, need_discard_iter->pos, BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	ret = bkey_err(k);
 	if (ret)
-		goto out;
+		return ret;
 
-	a = bch2_alloc_to_v4_mut(trans, k);
+	struct bkey_i_alloc_v4 *a = bch2_alloc_to_v4_mut(trans, k);
 	ret = PTR_ERR_OR_ZERO(a);
 	if (ret)
-		goto out;
+		return ret;
 
 	if (a->v.data_type != BCH_DATA_need_discard) {
 		if (need_discard_or_freespace_err(trans, k, true, true, true)) {
 			ret = bch2_btree_bit_mod_iter(trans, need_discard_iter, false);
 			if (ret)
-				goto out;
+				return ret;
 			goto commit;
 		}
 
-		goto out;
+		return 0;
 	}
 
 	if (!fastpath) {
@@ -1890,7 +1876,6 @@ static int bch2_discard_one_bucket(struct btree_trans *trans,
 		discard_in_flight_remove(ca, iter.pos.offset);
 	if (!ret)
 		s->seen++;
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -1954,9 +1939,8 @@ static int bch2_do_discards_fast_one(struct btree_trans *trans,
 				     struct bpos *discard_pos_done,
 				     struct discard_buckets_state *s)
 {
-	struct btree_iter need_discard_iter;
-	struct bkey_s_c discard_k = bch2_bkey_get_iter(trans, &need_discard_iter,
-					BTREE_ID_need_discard, POS(ca->dev_idx, bucket), 0);
+	CLASS(btree_iter, need_discard_iter)(trans, BTREE_ID_need_discard, POS(ca->dev_idx, bucket), 0);
+	struct bkey_s_c discard_k = bch2_btree_iter_peek_slot(&need_discard_iter);
 	int ret = bkey_err(discard_k);
 	if (ret)
 		return ret;
@@ -1965,12 +1949,10 @@ static int bch2_do_discards_fast_one(struct btree_trans *trans,
 			    trans, discarding_bucket_not_in_need_discard_btree,
 			    "attempting to discard bucket %u:%llu not in need_discard btree",
 			    ca->dev_idx, bucket))
-		goto out;
+		return 0;
 
-	ret = bch2_discard_one_bucket(trans, ca, &need_discard_iter, discard_pos_done, s, true);
-out:
+	return bch2_discard_one_bucket(trans, ca, &need_discard_iter, discard_pos_done, s, true);
 fsck_err:
-	bch2_trans_iter_exit(&need_discard_iter);
 	return ret;
 }
 
@@ -2106,7 +2088,6 @@ static int invalidate_one_bucket(struct btree_trans *trans,
 	struct bch_fs *c = trans->c;
 	CLASS(printbuf, buf)();
 	struct bpos bucket = u64_to_bucket(lru_k.k->p.offset);
-	struct btree_iter alloc_iter = {};
 	int ret = 0;
 
 	if (*nr_to_invalidate <= 0)
@@ -2117,54 +2098,53 @@ static int invalidate_one_bucket(struct btree_trans *trans,
 			     "lru key points to nonexistent device:bucket %llu:%llu",
 			     bucket.inode, bucket.offset))
 			return bch2_btree_bit_mod_buffered(trans, BTREE_ID_lru, lru_iter->pos, false);
-		goto out;
+		return 0;
 	}
 
 	if (bch2_bucket_is_open_safe(c, bucket.inode, bucket.offset))
 		return 0;
 
-	struct bkey_s_c alloc_k = bch2_bkey_get_iter(trans, &alloc_iter,
-						     BTREE_ID_alloc, bucket,
-						     BTREE_ITER_cached);
-	ret = bkey_err(alloc_k);
-	if (ret)
-		return ret;
+	{
+		CLASS(btree_iter, alloc_iter)(trans, BTREE_ID_alloc, bucket, BTREE_ITER_cached);
+		struct bkey_s_c alloc_k = bch2_btree_iter_peek_slot(&alloc_iter);
+		ret = bkey_err(alloc_k);
+		if (ret)
+			return ret;
 
-	struct bch_alloc_v4 a_convert;
-	const struct bch_alloc_v4 *a = bch2_alloc_to_v4(alloc_k, &a_convert);
+		struct bch_alloc_v4 a_convert;
+		const struct bch_alloc_v4 *a = bch2_alloc_to_v4(alloc_k, &a_convert);
 
-	/* We expect harmless races here due to the btree write buffer: */
-	if (lru_pos_time(lru_iter->pos) != alloc_lru_idx_read(*a))
-		goto out;
+		/* We expect harmless races here due to the btree write buffer: */
+		if (lru_pos_time(lru_iter->pos) != alloc_lru_idx_read(*a))
+			return 0;
 
-	/*
-	 * Impossible since alloc_lru_idx_read() only returns nonzero if the
-	 * bucket is supposed to be on the cached bucket LRU (i.e.
-	 * BCH_DATA_cached)
-	 *
-	 * bch2_lru_validate() also disallows lru keys with lru_pos_time() == 0
-	 */
-	BUG_ON(a->data_type != BCH_DATA_cached);
-	BUG_ON(a->dirty_sectors);
+		/*
+		 * Impossible since alloc_lru_idx_read() only returns nonzero if the
+		 * bucket is supposed to be on the cached bucket LRU (i.e.
+		 * BCH_DATA_cached)
+		 *
+		 * bch2_lru_validate() also disallows lru keys with lru_pos_time() == 0
+		 */
+		BUG_ON(a->data_type != BCH_DATA_cached);
+		BUG_ON(a->dirty_sectors);
 
-	if (!a->cached_sectors) {
-		bch2_check_bucket_backpointer_mismatch(trans, ca, bucket.offset,
-						       true, last_flushed);
-		goto out;
-	}
+		if (!a->cached_sectors) {
+			bch2_check_bucket_backpointer_mismatch(trans, ca, bucket.offset,
+							       true, last_flushed);
+			return 0;
+		}
 
-	unsigned cached_sectors = a->cached_sectors;
-	u8 gen = a->gen;
+		unsigned cached_sectors = a->cached_sectors;
+		u8 gen = a->gen;
 
-	ret = invalidate_one_bucket_by_bps(trans, ca, bucket, gen, last_flushed);
-	if (ret)
-		goto out;
+		ret = invalidate_one_bucket_by_bps(trans, ca, bucket, gen, last_flushed);
+		if (ret)
+			return ret;
 
-	trace_and_count(c, bucket_invalidate, c, bucket.inode, bucket.offset, cached_sectors);
-	--*nr_to_invalidate;
-out:
+		trace_and_count(c, bucket_invalidate, c, bucket.inode, bucket.offset, cached_sectors);
+		--*nr_to_invalidate;
+	}
 fsck_err:
-	bch2_trans_iter_exit(&alloc_iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/alloc_foreground.c b/fs/bcachefs/alloc_foreground.c
index 70895afc0d0d..a5a9b030811b 100644
--- a/fs/bcachefs/alloc_foreground.c
+++ b/fs/bcachefs/alloc_foreground.c
@@ -285,8 +285,8 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct bch_dev *ca = req->ca;
-	struct btree_iter iter, citer;
-	struct bkey_s_c k, ck;
+	struct btree_iter iter;
+	struct bkey_s_c k;
 	struct open_bucket *ob = NULL;
 	u64 first_bucket = ca->mi.first_bucket;
 	u64 *dev_alloc_cursor = &ca->alloc_cursor[req->btree_bitmap];
@@ -333,25 +333,22 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 			continue;
 
 		/* now check the cached key to serialize concurrent allocs of the bucket */
-		ck = bch2_bkey_get_iter(trans, &citer, BTREE_ID_alloc, k.k->p, BTREE_ITER_cached);
+		CLASS(btree_iter, citer)(trans, BTREE_ID_alloc, k.k->p, BTREE_ITER_cached|BTREE_ITER_nopreserve);
+		struct bkey_s_c ck = bch2_btree_iter_peek_slot(&citer);
 		ret = bkey_err(ck);
 		if (ret)
 			break;
 
 		a = bch2_alloc_to_v4(ck, &a_convert);
-		if (a->data_type != BCH_DATA_free)
-			goto next;
-
-		req->counters.buckets_seen++;
+		if (a->data_type == BCH_DATA_free) {
+			req->counters.buckets_seen++;
 
-		ob = may_alloc_bucket(c, req, k.k->p)
-			? __try_alloc_bucket(c, req, k.k->p.offset, a->gen, cl)
-			: NULL;
-next:
-		bch2_set_btree_iter_dontneed(&citer);
-		bch2_trans_iter_exit(&citer);
-		if (ob)
-			break;
+			ob = may_alloc_bucket(c, req, k.k->p)
+				? __try_alloc_bucket(c, req, k.k->p.offset, a->gen, cl)
+				: NULL;
+			if (ob)
+				break;
+		}
 	}
 	bch2_trans_iter_exit(&iter);
 
diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 42c321d42721..adb2f1a3b95a 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -154,12 +154,10 @@ int bch2_bucket_backpointer_mod_nowritebuffer(struct btree_trans *trans,
 				struct bkey_i_backpointer *bp,
 				bool insert)
 {
-	struct btree_iter bp_iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &bp_iter, BTREE_ID_backpointers,
-			       bp->k.p,
-			       BTREE_ITER_intent|
-			       BTREE_ITER_slots|
-			       BTREE_ITER_with_updates);
+	CLASS(btree_iter, bp_iter)(trans, BTREE_ID_backpointers, bp->k.p,
+				   BTREE_ITER_intent|
+				   BTREE_ITER_with_updates);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&bp_iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -170,7 +168,7 @@ int bch2_bucket_backpointer_mod_nowritebuffer(struct btree_trans *trans,
 	       memcmp(bkey_s_c_to_backpointer(k).v, &bp->v, sizeof(bp->v)))) {
 		ret = backpointer_mod_err(trans, orig_k, bp, k, insert);
 		if (ret)
-			goto err;
+			return ret;
 	}
 
 	if (!insert) {
@@ -178,10 +176,7 @@ int bch2_bucket_backpointer_mod_nowritebuffer(struct btree_trans *trans,
 		set_bkey_val_u64s(&bp->k, 0);
 	}
 
-	ret = bch2_trans_update(trans, &bp_iter, &bp->k_i, 0);
-err:
-	bch2_trans_iter_exit(&bp_iter);
-	return ret;
+	return bch2_trans_update(trans, &bp_iter, &bp->k_i, 0);
 }
 
 static int bch2_backpointer_del(struct btree_trans *trans, struct bpos pos)
@@ -384,8 +379,6 @@ static int bch2_check_backpointer_has_valid_bucket(struct btree_trans *trans, st
 		return 0;
 
 	struct bch_fs *c = trans->c;
-	struct btree_iter alloc_iter = { NULL };
-	struct bkey_s_c alloc_k;
 	CLASS(printbuf, buf)();
 	int ret = 0;
 
@@ -393,34 +386,35 @@ static int bch2_check_backpointer_has_valid_bucket(struct btree_trans *trans, st
 	if (!bp_pos_to_bucket_nodev_noerror(c, k.k->p, &bucket)) {
 		ret = bch2_backpointers_maybe_flush(trans, k, last_flushed);
 		if (ret)
-			goto out;
+			return ret;
 
 		if (fsck_err(trans, backpointer_to_missing_device,
 			     "backpointer for missing device:\n%s",
 			     (bch2_bkey_val_to_text(&buf, c, k), buf.buf)))
 			ret = bch2_backpointer_del(trans, k.k->p);
-		goto out;
+		return ret;
 	}
 
-	alloc_k = bch2_bkey_get_iter(trans, &alloc_iter, BTREE_ID_alloc, bucket, 0);
-	ret = bkey_err(alloc_k);
-	if (ret)
-		goto out;
-
-	if (alloc_k.k->type != KEY_TYPE_alloc_v4) {
-		ret = bch2_backpointers_maybe_flush(trans, k, last_flushed);
+	{
+		CLASS(btree_iter, alloc_iter)(trans, BTREE_ID_alloc, bucket, 0);
+		struct bkey_s_c alloc_k = bch2_btree_iter_peek_slot(&alloc_iter);
+		ret = bkey_err(alloc_k);
 		if (ret)
-			goto out;
+			return ret;
 
-		if (fsck_err(trans, backpointer_to_missing_alloc,
-			     "backpointer for nonexistent alloc key: %llu:%llu:0\n%s",
-			     alloc_iter.pos.inode, alloc_iter.pos.offset,
-			     (bch2_bkey_val_to_text(&buf, c, k), buf.buf)))
-			ret = bch2_backpointer_del(trans, k.k->p);
+		if (alloc_k.k->type != KEY_TYPE_alloc_v4) {
+			ret = bch2_backpointers_maybe_flush(trans, k, last_flushed);
+			if (ret)
+				return ret;
+
+			if (fsck_err(trans, backpointer_to_missing_alloc,
+				     "backpointer for nonexistent alloc key: %llu:%llu:0\n%s",
+				     alloc_iter.pos.inode, alloc_iter.pos.offset,
+				     (bch2_bkey_val_to_text(&buf, c, k), buf.buf)))
+				ret = bch2_backpointer_del(trans, k.k->p);
+		}
 	}
-out:
 fsck_err:
-	bch2_trans_iter_exit(&alloc_iter);
 	return ret;
 }
 
@@ -542,17 +536,17 @@ static int check_bp_exists(struct btree_trans *trans,
 	    bpos_gt(bp->k.p, s->bp_end))
 		return 0;
 
-	struct btree_iter bp_iter;
-	struct bkey_s_c bp_k = bch2_bkey_get_iter(trans, &bp_iter, BTREE_ID_backpointers, bp->k.p, 0);
+	CLASS(btree_iter, bp_iter)(trans, BTREE_ID_backpointers, bp->k.p, 0);
+	struct bkey_s_c bp_k = bch2_btree_iter_peek_slot(&bp_iter);
 	int ret = bkey_err(bp_k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (bp_k.k->type != KEY_TYPE_backpointer ||
 	    memcmp(bkey_s_c_to_backpointer(bp_k).v, &bp->v, sizeof(bp->v))) {
 		ret = bch2_btree_write_buffer_maybe_flush(trans, orig_k, &s->last_flushed);
 		if (ret)
-			goto err;
+			return ret;
 
 		goto check_existing_bp;
 	}
@@ -560,7 +554,6 @@ static int check_bp_exists(struct btree_trans *trans,
 err:
 fsck_err:
 	bch2_trans_iter_exit(&other_extent_iter);
-	bch2_trans_iter_exit(&bp_iter);
 	return ret;
 check_existing_bp:
 	/* Do we have a backpointer for a different extent? */
@@ -1173,17 +1166,13 @@ static int check_bucket_backpointer_pos_mismatch(struct btree_trans *trans,
 						 bool *had_mismatch,
 						 struct bkey_buf *last_flushed)
 {
-	struct btree_iter alloc_iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &alloc_iter,
-					       BTREE_ID_alloc, bucket,
-					       BTREE_ITER_cached);
+	CLASS(btree_iter, alloc_iter)(trans, BTREE_ID_alloc, bucket, BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&alloc_iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ret;
 
-	ret = check_bucket_backpointer_mismatch(trans, k, had_mismatch, last_flushed);
-	bch2_trans_iter_exit(&alloc_iter);
-	return ret;
+	return check_bucket_backpointer_mismatch(trans, k, had_mismatch, last_flushed);
 }
 
 int bch2_check_bucket_backpointer_mismatch(struct btree_trans *trans,
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 1b1b5bb9e915..09c75ac2d5a1 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -131,10 +131,8 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 	darray_for_each(*s, id) {
 		pos.snapshot = *id;
 
-		struct btree_iter iter;
-		struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, btree, pos,
-						       BTREE_ITER_not_extents|
-						       BTREE_ITER_intent);
+		CLASS(btree_iter, iter)(trans, btree, pos, BTREE_ITER_not_extents|BTREE_ITER_intent);
+		struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 		ret = bkey_err(k);
 		if (ret)
 			break;
@@ -143,7 +141,6 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 			struct bkey_i *update = bch2_trans_kmalloc(trans, sizeof(struct bkey_i));
 			ret = PTR_ERR_OR_ZERO(update);
 			if (ret) {
-				bch2_trans_iter_exit(&iter);
 				break;
 			}
 
@@ -154,7 +151,6 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 			ret = bch2_trans_update(trans, &iter, update,
 						BTREE_UPDATE_internal_snapshot_node);
 		}
-		bch2_trans_iter_exit(&iter);
 
 		if (ret)
 			break;
diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index e735b1e9b275..fa8967c3f87b 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -785,23 +785,15 @@ static void ec_block_io(struct bch_fs *c, struct ec_stripe_buf *buf,
 static int get_stripe_key_trans(struct btree_trans *trans, u64 idx,
 				struct ec_stripe_buf *stripe)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k;
-	int ret;
-
-	k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_stripes,
-			       POS(0, idx), BTREE_ITER_slots);
-	ret = bkey_err(k);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_stripes, POS(0, idx), BTREE_ITER_slots);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
+	int ret = bkey_err(k);
 	if (ret)
-		goto err;
-	if (k.k->type != KEY_TYPE_stripe) {
-		ret = -ENOENT;
-		goto err;
-	}
+		return ret;
+	if (k.k->type != KEY_TYPE_stripe)
+		return -ENOENT;
 	bkey_reassemble(&stripe->key, k);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return 0;
 }
 
 /* recovery read path: */
@@ -950,13 +942,11 @@ static void bch2_stripe_close(struct bch_fs *c, struct ec_stripe_new *s)
 
 static int ec_stripe_delete(struct btree_trans *trans, u64 idx)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter,
-					       BTREE_ID_stripes, POS(0, idx),
-					       BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_stripes, POS(0, idx), BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	/*
 	 * We expect write buffer races here
@@ -965,10 +955,9 @@ static int ec_stripe_delete(struct btree_trans *trans, u64 idx)
 	if (k.k->type == KEY_TYPE_stripe &&
 	    !bch2_stripe_is_open(trans->c, idx) &&
 	    stripe_lru_pos(bkey_s_c_to_stripe(k).v) == 1)
-		ret = bch2_btree_delete_at(trans, &iter, 0);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+		return bch2_btree_delete_at(trans, &iter, 0);
+
+	return 0;
 }
 
 /*
@@ -1009,20 +998,17 @@ static int ec_stripe_key_update(struct btree_trans *trans,
 	struct bch_fs *c = trans->c;
 	bool create = !old;
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_stripes,
-					       new->k.p, BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_stripes, new->k.p, BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (bch2_fs_inconsistent_on(k.k->type != (create ? KEY_TYPE_deleted : KEY_TYPE_stripe),
 				    c, "error %s stripe: got existing key type %s",
 				    create ? "creating" : "updating",
-				    bch2_bkey_types[k.k->type])) {
-		ret = -EINVAL;
-		goto err;
-	}
+				    bch2_bkey_types[k.k->type]))
+		return -EINVAL;
 
 	if (k.k->type == KEY_TYPE_stripe) {
 		const struct bch_stripe *v = bkey_s_c_to_stripe(k).v;
@@ -1042,8 +1028,7 @@ static int ec_stripe_key_update(struct btree_trans *trans,
 				prt_str(&buf, "\nnew: ");
 				bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&new->k_i));
 				bch2_fs_inconsistent(c, "%s", buf.buf);
-				ret = -EINVAL;
-				goto err;
+				return -EINVAL;
 			}
 
 			/*
@@ -1061,10 +1046,7 @@ static int ec_stripe_key_update(struct btree_trans *trans,
 		}
 	}
 
-	ret = bch2_trans_update(trans, &iter, &new->k_i, 0);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_trans_update(trans, &iter, &new->k_i, 0);
 }
 
 static int ec_stripe_update_extent(struct btree_trans *trans,
@@ -1785,20 +1767,19 @@ static int __get_existing_stripe(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter,
-					  BTREE_ID_stripes, POS(0, idx), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_stripes, POS(0, idx), BTREE_ITER_nopreserve);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	/* We expect write buffer races here */
 	if (k.k->type != KEY_TYPE_stripe)
-		goto out;
+		return 0;
 
 	struct bkey_s_c_stripe s = bkey_s_c_to_stripe(k);
 	if (stripe_lru_pos(s.v) <= 1)
-		goto out;
+		return 0;
 
 	if (s.v->disk_label		== head->disk_label &&
 	    s.v->algorithm		== head->algo &&
@@ -1806,13 +1787,10 @@ static int __get_existing_stripe(struct btree_trans *trans,
 	    le16_to_cpu(s.v->sectors)	== head->blocksize &&
 	    bch2_try_open_stripe(c, head->s, idx)) {
 		bkey_reassemble(&stripe->key, k);
-		ret = 1;
+		return 1;
 	}
-out:
-	bch2_set_btree_iter_dontneed(&iter);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return 0;
 }
 
 static int init_new_stripe_from_existing(struct bch_fs *c, struct ec_stripe_new *s)
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index f971e6993f2b..9a48a3a12139 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -333,11 +333,11 @@ static inline bool inode_should_reattach(struct bch_inode_unpacked *inode)
 
 static int maybe_delete_dirent(struct btree_trans *trans, struct bpos d_pos, u32 snapshot)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_dirents,
-					SPOS(d_pos.inode, d_pos.offset, snapshot),
-					BTREE_ITER_intent|
-					BTREE_ITER_with_updates);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_dirents,
+				SPOS(d_pos.inode, d_pos.offset, snapshot),
+				BTREE_ITER_intent|
+				BTREE_ITER_with_updates);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -350,16 +350,15 @@ static int maybe_delete_dirent(struct btree_trans *trans, struct bpos d_pos, u32
 		struct bkey_i *k = bch2_trans_kmalloc(trans, sizeof(*k));
 		ret = PTR_ERR_OR_ZERO(k);
 		if (ret)
-			goto err;
+			return ret;
 
 		bkey_init(&k->k);
 		k->k.type = KEY_TYPE_whiteout;
 		k->k.p = iter.pos;
-		ret = bch2_trans_update(trans, &iter, k, BTREE_UPDATE_internal_snapshot_node);
+		return bch2_trans_update(trans, &iter, k, BTREE_UPDATE_internal_snapshot_node);
 	}
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return 0;
 }
 
 static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *inode)
@@ -1043,11 +1042,9 @@ static struct bkey_s_c_dirent inode_get_dirent(struct btree_trans *trans,
 
 static int check_inode_deleted_list(struct btree_trans *trans, struct bpos p)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_deleted_inodes, p, 0);
-	int ret = bkey_err(k) ?: k.k->type == KEY_TYPE_set;
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	CLASS(btree_iter, iter)(trans, BTREE_ID_deleted_inodes, p, 0);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
+	return bkey_err(k) ?: k.k->type == KEY_TYPE_set;
 }
 
 static int check_inode_dirent_inode(struct btree_trans *trans,
@@ -1906,6 +1903,7 @@ static int check_extent_overbig(struct btree_trans *trans, struct btree_iter *it
 	return 0;
 }
 
+noinline_for_stack
 static int check_extent(struct btree_trans *trans, struct btree_iter *iter,
 			struct bkey_s_c k,
 			struct inode_walker *inode,
@@ -2703,25 +2701,23 @@ static int bch2_bi_depth_renumber_one(struct btree_trans *trans,
 				      u64 inum, u32 snapshot,
 				      u32 new_depth)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
-					       SPOS(0, inum, snapshot), 0);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_inodes, SPOS(0, inum, snapshot), 0);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 
 	struct bch_inode_unpacked inode;
 	int ret = bkey_err(k) ?:
 		!bkey_is_inode(k.k) ? -BCH_ERR_ENOENT_inode
 		: bch2_inode_unpack(k, &inode);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (inode.bi_depth != new_depth) {
 		inode.bi_depth = new_depth;
-		ret = __bch2_fsck_write_inode(trans, &inode) ?:
-			bch2_trans_commit(trans, NULL, NULL, 0);
+		return __bch2_fsck_write_inode(trans, &inode) ?:
+			 bch2_trans_commit(trans, NULL, NULL, 0);
 	}
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return 0;
 }
 
 static int bch2_bi_depth_renumber(struct btree_trans *trans, darray_u64 *path,
@@ -2746,7 +2742,6 @@ static int bch2_bi_depth_renumber(struct btree_trans *trans, darray_u64 *path,
 static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter inode_iter = {};
 	CLASS(darray_u64, path)();
 	CLASS(printbuf, buf)();
 	u32 snapshot = inode_k.k->p.snapshot;
@@ -2761,6 +2756,8 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 	if (ret)
 		return ret;
 
+	CLASS(btree_iter, inode_iter)(trans, BTREE_ID_inodes, POS_MIN, 0);
+
 	/*
 	 * If we're running full fsck, check_dirents() will have already ran,
 	 * and we shouldn't see any missing backpointers here - otherwise that's
@@ -2794,9 +2791,8 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 		if (ret)
 			return ret;
 
-		bch2_trans_iter_exit(&inode_iter);
-		inode_k = bch2_bkey_get_iter(trans, &inode_iter, BTREE_ID_inodes,
-					     SPOS(0, inode.bi_dir, snapshot), 0);
+		bch2_btree_iter_set_pos(&inode_iter, SPOS(0, inode.bi_dir, snapshot));
+		inode_k = bch2_btree_iter_peek_slot(&inode_iter);
 
 		struct bch_inode_unpacked parent_inode;
 		ret = bkey_err(inode_k) ?:
@@ -2853,7 +2849,6 @@ static int check_path_loop(struct btree_trans *trans, struct bkey_s_c inode_k)
 		ret = bch2_bi_depth_renumber(trans, &path, snapshot, min_bi_depth);
 out:
 fsck_err:
-	bch2_trans_iter_exit(&inode_iter);
 	bch_err_fn(c, ret);
 	return ret;
 }
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 838da956b4e1..ab4c651ba731 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -345,12 +345,12 @@ int __bch2_inode_peek(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, iter, BTREE_ID_inodes,
-					       SPOS(0, inum.inum, snapshot),
-					       flags|BTREE_ITER_cached);
+	bch2_trans_iter_init(trans, iter, BTREE_ID_inodes, SPOS(0, inum.inum, snapshot),
+			     flags|BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 	ret = bkey_err(k);
 	if (ret)
-		return ret;
+		goto err;
 
 	ret = bkey_is_inode(k.k) ? 0 : -BCH_ERR_ENOENT_inode;
 	if (ret)
@@ -373,19 +373,15 @@ int bch2_inode_find_by_inum_snapshot(struct btree_trans *trans,
 					    struct bch_inode_unpacked *inode,
 					    unsigned flags)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
-					       SPOS(0, inode_nr, snapshot), flags);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_inodes, SPOS(0, inode_nr, snapshot), flags);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
-	ret = bkey_is_inode(k.k)
+	return bkey_is_inode(k.k)
 		? bch2_inode_unpack(k, inode)
 		: -BCH_ERR_ENOENT_inode;
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
 }
 
 int bch2_inode_find_by_inum_nowarn_trans(struct btree_trans *trans,
@@ -961,11 +957,10 @@ bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *m
 
 	cursor_idx &= ~(~0ULL << c->opts.shard_inode_numbers_bits);
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter,
-					BTREE_ID_logged_ops,
-					POS(LOGGED_OPS_INUM_inode_cursors, cursor_idx),
-					BTREE_ITER_cached);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_logged_ops,
+				POS(LOGGED_OPS_INUM_inode_cursors, cursor_idx),
+				BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ERR_PTR(ret);
@@ -974,9 +969,8 @@ bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *m
 		k.k->type == KEY_TYPE_inode_alloc_cursor
 		? bch2_bkey_make_mut_typed(trans, &iter, &k, 0, inode_alloc_cursor)
 		: bch2_bkey_alloc(trans, &iter, 0, inode_alloc_cursor);
-	ret = PTR_ERR_OR_ZERO(cursor);
-	if (ret)
-		goto err;
+	if (IS_ERR(cursor))
+		return cursor;
 
 	if (c->opts.inodes_32bit) {
 		*min = BLOCKDEV_INODE_MAX;
@@ -997,9 +991,8 @@ bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *m
 		cursor->v.idx = cpu_to_le64(*min);
 		le32_add_cpu(&cursor->v.gen, 1);
 	}
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret ? ERR_PTR(ret) : cursor;
+
+	return cursor;
 }
 
 /*
@@ -1303,9 +1296,6 @@ static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum
 {
 	struct bch_fs *c = trans->c;
 	struct btree_iter iter = { NULL };
-	struct bkey_i_inode_generation delete;
-	struct bch_inode_unpacked inode_u;
-	struct bkey_s_c k;
 	int ret;
 
 	do {
@@ -1327,8 +1317,8 @@ static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum
 retry:
 	bch2_trans_begin(trans);
 
-	k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
-			       SPOS(0, inum, snapshot), BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
+					       SPOS(0, inum, snapshot), BTREE_ITER_intent);
 	ret = bkey_err(k);
 	if (ret)
 		goto err;
@@ -1341,12 +1331,14 @@ static noinline int __bch2_inode_rm_snapshot(struct btree_trans *trans, u64 inum
 		goto err;
 	}
 
+	struct bch_inode_unpacked inode_u;
 	bch2_inode_unpack(k, &inode_u);
 
 	/* Subvolume root? */
 	if (inode_u.bi_subvol)
 		bch_warn(c, "deleting inode %llu marked as unlinked, but also a subvolume root!?", inode_u.bi_inum);
 
+	struct bkey_i_inode_generation delete;
 	bkey_inode_generation_init(&delete.k_i);
 	delete.k.p = iter.pos;
 	delete.v.bi_generation = cpu_to_le32(inode_u.bi_generation + 1);
@@ -1406,12 +1398,11 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 				    bool from_deleted_inodes)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter inode_iter;
-	struct bkey_s_c k;
 	CLASS(printbuf, buf)();
 	int ret;
 
-	k = bch2_bkey_get_iter(trans, &inode_iter, BTREE_ID_inodes, pos, BTREE_ITER_cached);
+	CLASS(btree_iter, inode_iter)(trans, BTREE_ID_inodes, pos, BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&inode_iter);
 	ret = bkey_err(k);
 	if (ret)
 		return ret;
@@ -1423,11 +1414,11 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 			pos.offset, pos.snapshot))
 		goto delete;
 	if (ret)
-		goto out;
+		return ret;
 
 	ret = bch2_inode_unpack(k, inode);
 	if (ret)
-		goto out;
+		return ret;
 
 	if (S_ISDIR(inode->bi_mode)) {
 		ret = bch2_empty_dir_snapshot(trans, pos.offset, 0, pos.snapshot);
@@ -1438,7 +1429,7 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 				pos.offset, pos.snapshot))
 			goto delete;
 		if (ret)
-			goto out;
+			return ret;
 	}
 
 	ret = inode->bi_flags & BCH_INODE_unlinked ? 0 : bch_err_throw(c, inode_not_unlinked);
@@ -1448,7 +1439,7 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 			pos.offset, pos.snapshot))
 		goto delete;
 	if (ret)
-		goto out;
+		return ret;
 
 	ret = !(inode->bi_flags & BCH_INODE_has_child_snapshot)
 		? 0 : bch_err_throw(c, inode_has_child_snapshot);
@@ -1459,11 +1450,11 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 			pos.offset, pos.snapshot))
 		goto delete;
 	if (ret)
-		goto out;
+		return ret;
 
 	ret = bch2_inode_has_child_snapshots(trans, k.k->p);
 	if (ret < 0)
-		goto out;
+		return ret;
 
 	if (ret) {
 		if (fsck_err(trans, inode_has_child_snapshots_wrong,
@@ -1474,13 +1465,12 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 			inode->bi_flags |= BCH_INODE_has_child_snapshot;
 			ret = __bch2_fsck_write_inode(trans, inode);
 			if (ret)
-				goto out;
+				return ret;
 		}
 
 		if (!from_deleted_inodes) {
-			ret =   bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
+			return  bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
 				bch_err_throw(c, inode_has_child_snapshot);
-			goto out;
 		}
 
 		goto delete;
@@ -1491,20 +1481,15 @@ static int may_delete_deleted_inode(struct btree_trans *trans, struct bpos pos,
 		if (test_bit(BCH_FS_clean_recovery, &c->flags) &&
 		    !fsck_err(trans, deleted_inode_but_clean,
 			      "filesystem marked as clean but have deleted inode %llu:%u",
-			      pos.offset, pos.snapshot)) {
-			ret = 0;
-			goto out;
-		}
+			      pos.offset, pos.snapshot))
+			return 0;
 
 		ret = 1;
 	}
-out:
 fsck_err:
-	bch2_trans_iter_exit(&inode_iter);
 	return ret;
 delete:
-	ret = bch2_btree_bit_mod_buffered(trans, BTREE_ID_deleted_inodes, pos, false);
-	goto out;
+	return bch2_btree_bit_mod_buffered(trans, BTREE_ID_deleted_inodes, pos, false);
 }
 
 static int may_delete_deleted_inum(struct btree_trans *trans, subvol_inum inum,
diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index 26eea9ba1f4f..c4f0f9d8f959 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -559,15 +559,14 @@ static noinline int maybe_poison_extent(struct btree_trans *trans, struct bch_re
 	if (flags & BIT_ULL(BCH_EXTENT_FLAG_poisoned))
 		return 0;
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, btree, bkey_start_pos(read_k.k),
-					       BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, btree, bkey_start_pos(read_k.k), BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ret;
 
 	if (!bkey_and_val_eq(k, read_k))
-		goto out;
+		return 0;
 
 	struct bkey_i *new = bch2_trans_kmalloc(trans,
 					bkey_bytes(k.k) + sizeof(struct bch_extent_flags));
@@ -576,17 +575,17 @@ static noinline int maybe_poison_extent(struct btree_trans *trans, struct bch_re
 		bch2_bkey_extent_flags_set(c, new, flags|BIT_ULL(BCH_EXTENT_FLAG_poisoned)) ?:
 		bch2_trans_update(trans, &iter, new, BTREE_UPDATE_internal_snapshot_node) ?:
 		bch2_trans_commit(trans, NULL, NULL, 0);
+	if (ret)
+		return ret;
 
 	/*
 	 * Propagate key change back to data update path, in particular so it
 	 * knows the extent has been poisoned and it's safe to change the
 	 * checksum
 	 */
-	if (u && !ret)
+	if (u)
 		bch2_bkey_buf_copy(&u->k, c, new);
-out:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return 0;
 }
 
 static noinline int bch2_read_retry_nodecode(struct btree_trans *trans,
@@ -755,56 +754,48 @@ static int __bch2_rbio_narrow_crcs(struct btree_trans *trans,
 {
 	struct bch_fs *c = rbio->c;
 	u64 data_offset = rbio->data_pos.offset - rbio->pick.crc.offset;
-	struct bch_extent_crc_unpacked new_crc;
-	struct btree_iter iter;
-	struct bkey_i *new;
-	struct bkey_s_c k;
 	int ret = 0;
 
 	if (crc_is_compressed(rbio->pick.crc))
 		return 0;
 
-	k = bch2_bkey_get_iter(trans, &iter, rbio->data_btree, rbio->data_pos,
-			       BTREE_ITER_slots|BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, rbio->data_btree, rbio->data_pos, BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	if ((ret = bkey_err(k)))
-		goto out;
+		return ret;
 
 	if (bversion_cmp(k.k->bversion, rbio->version) ||
 	    !bch2_bkey_matches_ptr(c, k, rbio->pick.ptr, data_offset))
-		goto out;
+		return 0;
 
 	/* Extent was merged? */
 	if (bkey_start_offset(k.k) < data_offset ||
 	    k.k->p.offset > data_offset + rbio->pick.crc.uncompressed_size)
-		goto out;
+		return 0;
 
+	struct bch_extent_crc_unpacked new_crc;
 	if (bch2_rechecksum_bio(c, &rbio->bio, rbio->version,
 			rbio->pick.crc, NULL, &new_crc,
 			bkey_start_offset(k.k) - data_offset, k.k->size,
 			rbio->pick.crc.csum_type)) {
 		bch_err(c, "error verifying existing checksum while narrowing checksum (memory corruption?)");
-		ret = 0;
-		goto out;
+		return 0;
 	}
 
 	/*
 	 * going to be temporarily appending another checksum entry:
 	 */
-	new = bch2_trans_kmalloc(trans, bkey_bytes(k.k) +
-				 sizeof(struct bch_extent_crc128));
+	struct bkey_i *new = bch2_trans_kmalloc(trans, bkey_bytes(k.k) +
+						sizeof(struct bch_extent_crc128));
 	if ((ret = PTR_ERR_OR_ZERO(new)))
-		goto out;
+		return ret;
 
 	bkey_reassemble(new, k);
 
 	if (!bch2_bkey_narrow_crcs(new, new_crc))
-		goto out;
+		return 0;
 
-	ret = bch2_trans_update(trans, &iter, new,
-				BTREE_UPDATE_internal_snapshot_node);
-out:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_trans_update(trans, &iter, new, BTREE_UPDATE_internal_snapshot_node);
 }
 
 static noinline void bch2_rbio_narrow_crcs(struct bch_read_bio *rbio)
diff --git a/fs/bcachefs/io_write.c b/fs/bcachefs/io_write.c
index a53f3278a612..1d83dcc9731e 100644
--- a/fs/bcachefs/io_write.c
+++ b/fs/bcachefs/io_write.c
@@ -220,13 +220,13 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 	 */
 	unsigned inode_update_flags = BTREE_UPDATE_nojournal;
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
-			      SPOS(0,
-				   extent_iter->pos.inode,
-				   extent_iter->snapshot),
-			      BTREE_ITER_intent|
-			      BTREE_ITER_cached);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_inodes,
+				SPOS(0,
+				     extent_iter->pos.inode,
+				     extent_iter->snapshot),
+				BTREE_ITER_intent|
+				BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (unlikely(ret))
 		return ret;
@@ -238,7 +238,7 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 	struct bkey_i *k_mut = bch2_trans_kmalloc_nomemzero(trans, bkey_bytes(k.k) + 8);
 	ret = PTR_ERR_OR_ZERO(k_mut);
 	if (unlikely(ret))
-		goto err;
+		return ret;
 
 	bkey_reassemble(k_mut, k);
 
@@ -246,7 +246,7 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 		k_mut = bch2_inode_to_v3(trans, k_mut);
 		ret = PTR_ERR_OR_ZERO(k_mut);
 		if (unlikely(ret))
-			goto err;
+			return ret;
 	}
 
 	struct bkey_i_inode_v3 *inode = bkey_i_to_inode_v3(k_mut);
@@ -291,12 +291,9 @@ static inline int bch2_extent_update_i_size_sectors(struct btree_trans *trans,
 		inode_update_flags = 0;
 	}
 
-	ret = bch2_trans_update(trans, &iter, &inode->k_i,
-				BTREE_UPDATE_internal_snapshot_node|
-				inode_update_flags);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_trans_update(trans, &iter, &inode->k_i,
+				 BTREE_UPDATE_internal_snapshot_node|
+				 inode_update_flags);
 }
 
 int bch2_extent_update(struct btree_trans *trans,
diff --git a/fs/bcachefs/lru.c b/fs/bcachefs/lru.c
index 39ae70e5c81b..b9c0834498dd 100644
--- a/fs/bcachefs/lru.c
+++ b/fs/bcachefs/lru.c
@@ -88,10 +88,8 @@ int bch2_lru_check_set(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	CLASS(printbuf, buf)();
-	struct btree_iter lru_iter;
-	struct bkey_s_c lru_k =
-		bch2_bkey_get_iter(trans, &lru_iter, BTREE_ID_lru,
-				   lru_pos(lru_id, dev_bucket, time), 0);
+	CLASS(btree_iter, lru_iter)(trans, BTREE_ID_lru, lru_pos(lru_id, dev_bucket, time), 0);
+	struct bkey_s_c lru_k = bch2_btree_iter_peek_slot(&lru_iter);
 	int ret = bkey_err(lru_k);
 	if (ret)
 		return ret;
@@ -99,7 +97,7 @@ int bch2_lru_check_set(struct btree_trans *trans,
 	if (lru_k.k->type != KEY_TYPE_set) {
 		ret = bch2_btree_write_buffer_maybe_flush(trans, referring_k, last_flushed);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (fsck_err(trans, alloc_key_to_missing_lru_entry,
 			     "missing %s lru entry\n%s",
@@ -107,12 +105,10 @@ int bch2_lru_check_set(struct btree_trans *trans,
 			     (bch2_bkey_val_to_text(&buf, c, referring_k), buf.buf))) {
 			ret = bch2_lru_set(trans, lru_id, dev_bucket, time);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	}
-err:
 fsck_err:
-	bch2_trans_iter_exit(&lru_iter);
 	return ret;
 }
 
@@ -171,11 +167,11 @@ static int bch2_check_lru_key(struct btree_trans *trans,
 
 	struct bbpos bp = lru_pos_to_bp(lru_k);
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, bp.btree, bp.pos, 0);
+	CLASS(btree_iter, iter)(trans, bp.btree, bp.pos, 0);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
-		goto err;
+		return ret;
 
 	enum bch_lru_type type = lru_type(lru_k);
 	u64 idx = bkey_lru_type_idx(c, type, k);
@@ -183,7 +179,7 @@ static int bch2_check_lru_key(struct btree_trans *trans,
 	if (lru_pos_time(lru_k.k->p) != idx) {
 		ret = bch2_btree_write_buffer_maybe_flush(trans, lru_k, last_flushed);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (fsck_err(trans, lru_entry_bad,
 			     "incorrect lru entry: lru %s time %llu\n"
@@ -193,11 +189,9 @@ static int bch2_check_lru_key(struct btree_trans *trans,
 			     lru_pos_time(lru_k.k->p),
 			     (bch2_bkey_val_to_text(&buf1, c, lru_k), buf1.buf),
 			     (bch2_bkey_val_to_text(&buf2, c, k), buf2.buf)))
-			ret = bch2_btree_bit_mod_buffered(trans, BTREE_ID_lru, lru_iter->pos, false);
+			return bch2_btree_bit_mod_buffered(trans, BTREE_ID_lru, lru_iter->pos, false);
 	}
-err:
 fsck_err:
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 76cc13f62884..a38996f5366f 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -511,25 +511,22 @@ int bch2_move_get_io_opts_one(struct btree_trans *trans,
 	*io_opts = bch2_opts_to_inode_opts(c->opts);
 
 	/* reflink btree? */
-	if (!extent_k.k->p.inode)
-		goto out;
-
-	struct btree_iter inode_iter;
-	struct bkey_s_c inode_k = bch2_bkey_get_iter(trans, &inode_iter, BTREE_ID_inodes,
-			       SPOS(0, extent_k.k->p.inode, extent_k.k->p.snapshot),
-			       BTREE_ITER_cached);
-	int ret = bkey_err(inode_k);
-	if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
-		return ret;
+	if (extent_k.k->p.inode) {
+		CLASS(btree_iter, inode_iter)(trans, BTREE_ID_inodes,
+				       SPOS(0, extent_k.k->p.inode, extent_k.k->p.snapshot),
+				       BTREE_ITER_cached);
+		struct bkey_s_c inode_k = bch2_btree_iter_peek_slot(&inode_iter);
+		int ret = bkey_err(inode_k);
+		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
+			return ret;
 
-	if (!ret && bkey_is_inode(inode_k.k)) {
-		struct bch_inode_unpacked inode;
-		bch2_inode_unpack(inode_k, &inode);
-		bch2_inode_opts_get(io_opts, c, &inode);
+		if (!ret && bkey_is_inode(inode_k.k)) {
+			struct bch_inode_unpacked inode;
+			bch2_inode_unpack(inode_k, &inode);
+			bch2_inode_opts_get(io_opts, c, &inode);
+		}
 	}
-	bch2_trans_iter_exit(&inode_iter);
-	/* seem to be spinning here? */
-out:
+
 	return bch2_get_update_rebalance_opts(trans, io_opts, extent_iter, extent_k);
 }
 
diff --git a/fs/bcachefs/movinggc.c b/fs/bcachefs/movinggc.c
index f391eceef4f4..b0cbe3c1aab6 100644
--- a/fs/bcachefs/movinggc.c
+++ b/fs/bcachefs/movinggc.c
@@ -64,23 +64,22 @@ static int bch2_bucket_is_movable(struct btree_trans *trans,
 	if (bch2_bucket_is_open(c, b->k.bucket.inode, b->k.bucket.offset))
 		return 0;
 
-	struct btree_iter iter;
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_alloc,
-				       b->k.bucket, BTREE_ITER_cached);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_alloc, b->k.bucket, BTREE_ITER_cached);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (ret)
 		return ret;
 
 	CLASS(bch2_dev_bucket_tryget, ca)(c, k.k->p);
 	if (!ca)
-		goto out;
+		return 0;
 
 	if (bch2_bucket_bitmap_test(&ca->bucket_backpointer_mismatch, b->k.bucket.offset))
-		goto out;
+		return 0;
 
 	if (ca->mi.state != BCH_MEMBER_STATE_rw ||
 	    !bch2_dev_is_online(ca))
-		goto out;
+		return 0;
 
 	struct bch_alloc_v4 _a;
 	const struct bch_alloc_v4 *a = bch2_alloc_to_v4(k, &_a);
@@ -88,10 +87,7 @@ static int bch2_bucket_is_movable(struct btree_trans *trans,
 	b->sectors	= bch2_bucket_sectors_dirty(*a);
 	u64 lru_idx	= alloc_lru_idx_fragmentation(*a, ca);
 
-	ret = lru_idx && lru_idx <= time;
-out:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return lru_idx && lru_idx <= time;
 }
 
 static void move_bucket_free(struct buckets_in_flight *list,
diff --git a/fs/bcachefs/quota.c b/fs/bcachefs/quota.c
index 64a7f5eeeb5c..eaa43ad9baa6 100644
--- a/fs/bcachefs/quota.c
+++ b/fs/bcachefs/quota.c
@@ -798,10 +798,9 @@ static int bch2_set_quota_trans(struct btree_trans *trans,
 				struct bkey_i_quota *new_quota,
 				struct qc_dqblk *qdq)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k =
-		bch2_bkey_get_iter(trans, &iter, BTREE_ID_quotas, new_quota->k.p,
-				   BTREE_ITER_slots|BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_quotas, new_quota->k.p,
+				BTREE_ITER_slots|BTREE_ITER_intent);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 	int ret = bkey_err(k);
 	if (unlikely(ret))
 		return ret;
@@ -819,9 +818,7 @@ static int bch2_set_quota_trans(struct btree_trans *trans,
 	if (qdq->d_fieldmask & QC_INO_HARD)
 		new_quota->v.c[Q_INO].hardlimit = cpu_to_le64(qdq->d_ino_hardlimit);
 
-	ret = bch2_trans_update(trans, &iter, &new_quota->k_i, 0);
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_trans_update(trans, &iter, &new_quota->k_i, 0);
 }
 
 static int bch2_set_quota(struct super_block *sb, struct kqid qid,
diff --git a/fs/bcachefs/reflink.c b/fs/bcachefs/reflink.c
index c083deb83ff7..238a362de19e 100644
--- a/fs/bcachefs/reflink.c
+++ b/fs/bcachefs/reflink.c
@@ -264,32 +264,32 @@ struct bkey_s_c bch2_lookup_indirect_extent(struct btree_trans *trans,
 
 	u64 reflink_offset = REFLINK_P_IDX(p.v) + *offset_into_extent;
 
-	struct bkey_s_c k = bch2_bkey_get_iter(trans, iter, BTREE_ID_reflink,
-				       POS(0, reflink_offset), iter_flags);
-	if (bkey_err(k))
-		return k;
+	bch2_trans_iter_init(trans, iter, BTREE_ID_reflink, POS(0, reflink_offset), iter_flags);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
+	int ret = bkey_err(k);
+	if (ret)
+		goto err;
 
 	if (unlikely(!bkey_extent_is_reflink_data(k.k))) {
 		u64 missing_end = min(k.k->p.offset,
 				      REFLINK_P_IDX(p.v) + p.k->size + le32_to_cpu(p.v->back_pad));
 		BUG_ON(reflink_offset == missing_end);
 
-		int ret = bch2_indirect_extent_missing_error(trans, p, reflink_offset,
-							     missing_end, should_commit);
-		if (ret) {
-			bch2_trans_iter_exit(iter);
-			return bkey_s_c_err(ret);
-		}
+		ret = bch2_indirect_extent_missing_error(trans, p, reflink_offset,
+							 missing_end, should_commit);
+		if (ret)
+			goto err;
 	} else if (unlikely(REFLINK_P_ERROR(p.v))) {
-		int ret = bch2_indirect_extent_not_missing(trans, p, should_commit);
-		if (ret) {
-			bch2_trans_iter_exit(iter);
-			return bkey_s_c_err(ret);
-		}
+		ret = bch2_indirect_extent_not_missing(trans, p, should_commit);
+		if (ret)
+			goto err;
 	}
 
 	*offset_into_extent = reflink_offset - bkey_start_offset(k.k);
 	return k;
+err:
+	bch2_trans_iter_exit(iter);
+	return bkey_s_c_err(ret);
 }
 
 /* reflink pointer trigger */
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 1b7b21494479..46a21b088a91 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -1468,23 +1468,19 @@ static int delete_dead_snapshots_process_key(struct btree_trans *trans,
 
 		new->k.p.snapshot = live_child;
 
-		struct btree_iter dst_iter;
-		struct bkey_s_c dst_k = bch2_bkey_get_iter(trans, &dst_iter,
-							   iter->btree_id, new->k.p,
-							   BTREE_ITER_all_snapshots|
-							   BTREE_ITER_intent);
+		CLASS(btree_iter, dst_iter)(trans, iter->btree_id, new->k.p,
+					    BTREE_ITER_all_snapshots|BTREE_ITER_intent);
+		struct bkey_s_c dst_k = bch2_btree_iter_peek_slot(&dst_iter);
 		ret = bkey_err(dst_k);
 		if (ret)
 			return ret;
 
-		ret =   (bkey_deleted(dst_k.k)
+		return (bkey_deleted(dst_k.k)
 			 ? bch2_trans_update(trans, &dst_iter, new,
 					     BTREE_UPDATE_internal_snapshot_node)
 			 : 0) ?:
 			bch2_btree_delete_at(trans, iter,
 					     BTREE_UPDATE_internal_snapshot_node);
-		bch2_trans_iter_exit(&dst_iter);
-		return ret;
 	}
 
 	return 0;
diff --git a/fs/bcachefs/str_hash.c b/fs/bcachefs/str_hash.c
index a6503ec58acc..68392fb6532e 100644
--- a/fs/bcachefs/str_hash.c
+++ b/fs/bcachefs/str_hash.c
@@ -18,16 +18,14 @@ static int bch2_dirent_has_target(struct btree_trans *trans, struct bkey_s_c_dir
 			return ret;
 		return !ret;
 	} else {
-		struct btree_iter iter;
-		struct bkey_s_c k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
+		CLASS(btree_iter, iter)(trans, BTREE_ID_inodes,
 				SPOS(0, le64_to_cpu(d.v->d_inum), d.k->p.snapshot), 0);
+		struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
 		int ret = bkey_err(k);
 		if (ret)
 			return ret;
 
-		ret = bkey_is_inode(k.k);
-		bch2_trans_iter_exit(&iter);
-		return ret;
+		return bkey_is_inode(k.k);
 	}
 }
 
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index c3066dc56601..a38a58ef7a8c 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -46,7 +46,6 @@ static int check_subvol(struct btree_trans *trans,
 			struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter subvol_children_iter = {};
 	struct bch_subvolume subvol;
 	struct bch_snapshot snapshot;
 	CLASS(printbuf, buf)();
@@ -81,30 +80,28 @@ static int check_subvol(struct btree_trans *trans,
 			bch2_bkey_make_mut_typed(trans, iter, &k, 0, subvolume);
 		ret = PTR_ERR_OR_ZERO(n);
 		if (ret)
-			goto err;
+			return ret;
 
 		n->v.fs_path_parent = 0;
 	}
 
 	if (subvol.fs_path_parent) {
-		struct bpos pos = subvolume_children_pos(k);
-
-		struct bkey_s_c subvol_children_k =
-			bch2_bkey_get_iter(trans, &subvol_children_iter,
-					   BTREE_ID_subvolume_children, pos, 0);
+		CLASS(btree_iter, subvol_children_iter)(trans,
+					BTREE_ID_subvolume_children, subvolume_children_pos(k), 0);
+		struct bkey_s_c subvol_children_k = bch2_btree_iter_peek_slot(&subvol_children_iter);
 		ret = bkey_err(subvol_children_k);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (fsck_err_on(subvol_children_k.k->type != KEY_TYPE_set,
 				trans, subvol_children_not_set,
 				"subvolume not set in subvolume_children btree at %llu:%llu\n%s",
-				pos.inode, pos.offset,
+				subvol_children_iter.pos.inode, subvol_children_iter.pos.offset,
 				(printbuf_reset(&buf),
 				 bch2_bkey_val_to_text(&buf, c, k), buf.buf))) {
-			ret = bch2_btree_bit_mod(trans, BTREE_ID_subvolume_children, pos, true);
+			ret = bch2_btree_bit_mod(trans, BTREE_ID_subvolume_children, subvol_children_iter.pos, true);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	}
 
@@ -122,7 +119,7 @@ static int check_subvol(struct btree_trans *trans,
 			inode.bi_snapshot = le32_to_cpu(subvol.snapshot);
 			ret = __bch2_fsck_write_inode(trans, &inode);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	} else if (bch2_err_matches(ret, ENOENT)) {
 		if (fsck_err(trans, subvol_to_missing_root,
@@ -142,10 +139,10 @@ static int check_subvol(struct btree_trans *trans,
 			inode.bi_parent_subvol		= le32_to_cpu(subvol.fs_path_parent);
 			ret = __bch2_fsck_write_inode(trans, &inode);
 			if (ret)
-				goto err;
+				return ret;
 		}
 	} else {
-		goto err;
+		return ret;
 	}
 
 	if (!BCH_SUBVOLUME_SNAP(&subvol)) {
@@ -159,7 +156,7 @@ static int check_subvol(struct btree_trans *trans,
 				"%s: snapshot tree %u not found", __func__, snapshot_tree);
 
 		if (ret)
-			goto err;
+			return ret;
 
 		if (fsck_err_on(le32_to_cpu(st.master_subvol) != k.k->p.offset,
 				trans, subvol_not_master_and_not_snapshot,
@@ -169,14 +166,12 @@ static int check_subvol(struct btree_trans *trans,
 				bch2_bkey_make_mut_typed(trans, iter, &k, 0, subvolume);
 			ret = PTR_ERR_OR_ZERO(s);
 			if (ret)
-				goto err;
+				return ret;
 
 			SET_BCH_SUBVOLUME_SNAP(&s->v, true);
 		}
 	}
-err:
 fsck_err:
-	bch2_trans_iter_exit(&subvol_children_iter);
 	return ret;
 }
 
@@ -699,33 +694,25 @@ int bch2_initialize_subvolumes(struct bch_fs *c)
 
 static int __bch2_fs_upgrade_for_subvolumes(struct btree_trans *trans)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k;
-	struct bch_inode_unpacked inode;
-	int ret;
-
-	k = bch2_bkey_get_iter(trans, &iter, BTREE_ID_inodes,
-			       SPOS(0, BCACHEFS_ROOT_INO, U32_MAX), 0);
-	ret = bkey_err(k);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_inodes, SPOS(0, BCACHEFS_ROOT_INO, U32_MAX), 0);
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(&iter);
+	int ret = bkey_err(k);
 	if (ret)
 		return ret;
 
 	if (!bkey_is_inode(k.k)) {
 		struct bch_fs *c = trans->c;
 		bch_err(c, "root inode not found");
-		ret = bch_err_throw(c, ENOENT_inode);
-		goto err;
+		return bch_err_throw(c, ENOENT_inode);
 	}
 
+	struct bch_inode_unpacked inode;
 	ret = bch2_inode_unpack(k, &inode);
 	BUG_ON(ret);
 
 	inode.bi_subvol = BCACHEFS_ROOT_SUBVOL;
 
-	ret = bch2_inode_write(trans, &iter, &inode);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_inode_write(trans, &iter, &inode);
 }
 
 /* set bi_subvol on root inode */
-- 
2.51.0


From c5ff4c9f1ef4b842c2f35c90fc1019754bae6a5f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 19:33:19 -0400
Subject: [PATCH 211/309] bcachefs: for_each_btree_key_norestart() uses
 CLASS(btree_iter)

Kill a bunch of bch2_trans_iter_exit() calls.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/alloc_foreground.c |  8 +----
 fs/bcachefs/backpointers.c     |  4 +--
 fs/bcachefs/btree_iter.h       | 45 ++++++++++++++--------------
 fs/bcachefs/btree_update.c     |  2 --
 fs/bcachefs/dirent.c           |  4 ---
 fs/bcachefs/ec.c               | 29 ++++++------------
 fs/bcachefs/extent_update.c    |  5 +---
 fs/bcachefs/fs-io-direct.c     | 15 ++++------
 fs/bcachefs/fsck.c             | 54 ++++++++++------------------------
 fs/bcachefs/inode.c            | 20 +++++--------
 fs/bcachefs/snapshot.c         | 47 +++++++++++------------------
 fs/bcachefs/str_hash.c         | 20 ++++++-------
 fs/bcachefs/str_hash.h         | 19 ++++++++----
 13 files changed, 103 insertions(+), 169 deletions(-)

diff --git a/fs/bcachefs/alloc_foreground.c b/fs/bcachefs/alloc_foreground.c
index a5a9b030811b..0a5b3d31d52c 100644
--- a/fs/bcachefs/alloc_foreground.c
+++ b/fs/bcachefs/alloc_foreground.c
@@ -285,7 +285,6 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	struct bch_dev *ca = req->ca;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	struct open_bucket *ob = NULL;
 	u64 first_bucket = ca->mi.first_bucket;
@@ -306,7 +305,7 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 again:
 	for_each_btree_key_norestart(trans, iter, BTREE_ID_alloc, POS(ca->dev_idx, alloc_cursor),
 			   BTREE_ITER_slots, k, ret) {
-		u64 bucket = k.k->p.offset;
+		u64 bucket = alloc_cursor = k.k->p.offset;
 
 		if (bkey_ge(k.k->p, POS(ca->dev_idx, ca->mi.nbuckets)))
 			break;
@@ -350,9 +349,6 @@ bch2_bucket_alloc_early(struct btree_trans *trans,
 				break;
 		}
 	}
-	bch2_trans_iter_exit(&iter);
-
-	alloc_cursor = iter.pos.offset;
 
 	if (!ob && ret)
 		ob = ERR_PTR(ret);
@@ -372,7 +368,6 @@ static struct open_bucket *bch2_bucket_alloc_freelist(struct btree_trans *trans,
 						      struct closure *cl)
 {
 	struct bch_dev *ca = req->ca;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	struct open_bucket *ob = NULL;
 	u64 *dev_alloc_cursor = &ca->alloc_cursor[req->btree_bitmap];
@@ -427,7 +422,6 @@ static struct open_bucket *bch2_bucket_alloc_freelist(struct btree_trans *trans,
 			break;
 	}
 fail:
-	bch2_trans_iter_exit(&iter);
 
 	BUG_ON(ob && ret);
 
diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index adb2f1a3b95a..45d3db41225a 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -887,7 +887,6 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 	if (!ca)
 		return 0;
 
-	struct btree_iter iter;
 	struct bkey_s_c bp_k;
 	int ret = 0;
 	for_each_btree_key_max_norestart(trans, iter, BTREE_ID_backpointers,
@@ -903,7 +902,7 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 		     bp.v->pad)) {
 			ret = bch2_backpointer_del(trans, bp_k.k->p);
 			if (ret)
-				break;
+				return ret;
 
 			need_commit = true;
 			continue;
@@ -918,7 +917,6 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 
 		sectors[alloc_counter] += bp.v->bucket_len;
 	};
-	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index dcc587ec7dd7..64e143e6920f 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -906,36 +906,35 @@ transaction_restart:							\
 
 struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_iter *);
 
-#define for_each_btree_key_max_norestart(_trans, _iter, _btree_id,	\
-			   _start, _end, _flags, _k, _ret)		\
-	for (bch2_trans_iter_init((_trans), &(_iter), (_btree_id),	\
-				  (_start), (_flags));			\
-	     (_k) = bch2_btree_iter_peek_max_type(&(_iter), _end, _flags),\
-	     !((_ret) = bkey_err(_k)) && (_k).k;			\
+#define for_each_btree_key_max_norestart(_trans, _iter, _btree_id,			\
+			   _start, _end, _flags, _k, _ret)				\
+	for (CLASS(btree_iter, _iter)((_trans), (_btree_id), (_start), (_flags));	\
+	     (_k) = bch2_btree_iter_peek_max_type(&(_iter), _end, _flags),		\
+	     !((_ret) = bkey_err(_k)) && (_k).k;					\
 	     bch2_btree_iter_advance(&(_iter)))
 
-#define for_each_btree_key_max_continue_norestart(_iter, _end, _flags, _k, _ret)\
-	for (;									\
-	     (_k) = bch2_btree_iter_peek_max_type(&(_iter), _end, _flags),	\
-	     !((_ret) = bkey_err(_k)) && (_k).k;				\
-	     bch2_btree_iter_advance(&(_iter)))
-
-#define for_each_btree_key_norestart(_trans, _iter, _btree_id,		\
-			   _start, _flags, _k, _ret)			\
-	for_each_btree_key_max_norestart(_trans, _iter, _btree_id, _start,\
+#define for_each_btree_key_norestart(_trans, _iter, _btree_id,				\
+				     _start, _flags, _k, _ret)				\
+	for_each_btree_key_max_norestart(_trans, _iter, _btree_id, _start,		\
 					  SPOS_MAX, _flags, _k, _ret)
 
-#define for_each_btree_key_reverse_norestart(_trans, _iter, _btree_id,	\
-					     _start, _flags, _k, _ret)	\
-	for (bch2_trans_iter_init((_trans), &(_iter), (_btree_id),	\
-				  (_start), (_flags));			\
-	     (_k) = bch2_btree_iter_peek_prev_type(&(_iter), _flags),	\
-	     !((_ret) = bkey_err(_k)) && (_k).k;			\
-	     bch2_btree_iter_rewind(&(_iter)))
+#define for_each_btree_key_max_continue_norestart(_iter, _end, _flags, _k, _ret)	\
+	for (;										\
+	     (_k) = bch2_btree_iter_peek_max_type(&(_iter), _end, _flags),		\
+	     !((_ret) = bkey_err(_k)) && (_k).k;					\
+	     bch2_btree_iter_advance(&(_iter)))
 
-#define for_each_btree_key_continue_norestart(_iter, _flags, _k, _ret)	\
+#define for_each_btree_key_continue_norestart(_iter, _flags, _k, _ret)			\
 	for_each_btree_key_max_continue_norestart(_iter, SPOS_MAX, _flags, _k, _ret)
 
+#define for_each_btree_key_reverse_norestart(_trans, _iter, _btree_id,			\
+					     _start, _flags, _k, _ret)			\
+	for (CLASS(btree_iter, _iter)((_trans), (_btree_id),				\
+				      (_start), (_flags));				\
+	     (_k) = bch2_btree_iter_peek_prev_type(&(_iter), _flags),			\
+	     !((_ret) = bkey_err(_k)) && (_k).k;					\
+	     bch2_btree_iter_rewind(&(_iter)))
+
 /*
  * This should not be used in a fastpath, without first trying _do in
  * nonblocking mode - it will cause excessive transaction restarts and
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 09c75ac2d5a1..566478728aa2 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -95,7 +95,6 @@ static noinline int extent_back_merge(struct btree_trans *trans,
 static int need_whiteout_for_snapshot(struct btree_trans *trans,
 				      enum btree_id btree_id, struct bpos pos)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	u32 snapshot = pos.snapshot;
 	int ret;
@@ -117,7 +116,6 @@ static int need_whiteout_for_snapshot(struct btree_trans *trans,
 			break;
 		}
 	}
-	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index 50b6409be20a..cb44b35e0f1d 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -633,7 +633,6 @@ u64 bch2_dirent_lookup(struct bch_fs *c, subvol_inum dir,
 
 int bch2_empty_dir_snapshot(struct btree_trans *trans, u64 dir, u32 subvol, u32 snapshot)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -647,7 +646,6 @@ int bch2_empty_dir_snapshot(struct btree_trans *trans, u64 dir, u32 subvol, u32
 			ret = bch_err_throw(trans->c, ENOTEMPTY_dir_not_empty);
 			break;
 		}
-	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -721,7 +719,6 @@ int bch2_readdir(struct bch_fs *c, subvol_inum inum,
 static int lookup_first_inode(struct btree_trans *trans, u64 inode_nr,
 			      struct bch_inode_unpacked *inode)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -737,7 +734,6 @@ static int lookup_first_inode(struct btree_trans *trans, u64 inode_nr,
 	ret = bch_err_throw(trans->c, ENOENT_inode);
 found:
 	bch_err_msg(trans->c, ret, "fetching inode %llu", inode_nr);
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index fa8967c3f87b..4b7c7193de76 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -1849,7 +1849,6 @@ static int __bch2_ec_stripe_head_reuse(struct btree_trans *trans, struct ec_stri
 	if (may_create_new_stripe(c))
 		return -1;
 
-	struct btree_iter lru_iter;
 	struct bkey_s_c lru_k;
 	int ret = 0;
 
@@ -1861,7 +1860,6 @@ static int __bch2_ec_stripe_head_reuse(struct btree_trans *trans, struct ec_stri
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(&lru_iter);
 	if (!ret)
 		ret = bch_err_throw(c, stripe_alloc_blocked);
 	if (ret == 1)
@@ -1876,7 +1874,6 @@ static int __bch2_ec_stripe_head_reserve(struct btree_trans *trans, struct ec_st
 					 struct ec_stripe_new *s)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	struct bpos min_pos = POS(0, 1);
 	struct bpos start_pos = bpos_max(min_pos, POS(0, c->ec_stripe_hint));
@@ -1897,6 +1894,8 @@ static int __bch2_ec_stripe_head_reserve(struct btree_trans *trans, struct ec_st
 	 */
 	for_each_btree_key_norestart(trans, iter, BTREE_ID_stripes, start_pos,
 			   BTREE_ITER_slots|BTREE_ITER_intent, k, ret) {
+		c->ec_stripe_hint = iter.pos.offset;
+
 		if (bkey_gt(k.k->p, POS(0, U32_MAX))) {
 			if (start_pos.offset) {
 				start_pos = min_pos;
@@ -1909,28 +1908,18 @@ static int __bch2_ec_stripe_head_reserve(struct btree_trans *trans, struct ec_st
 		}
 
 		if (bkey_deleted(k.k) &&
-		    bch2_try_open_stripe(c, s, k.k->p.offset))
+		    bch2_try_open_stripe(c, s, k.k->p.offset)) {
+			ret = ec_stripe_mem_alloc(trans, &iter);
+			if (ret)
+				bch2_stripe_close(c, s);
+			s->new_stripe.key.k.p = iter.pos;
 			break;
+		}
 	}
 
-	c->ec_stripe_hint = iter.pos.offset;
-
 	if (ret)
-		goto err;
-
-	ret = ec_stripe_mem_alloc(trans, &iter);
-	if (ret) {
-		bch2_stripe_close(c, s);
-		goto err;
-	}
-
-	s->new_stripe.key.k.p = iter.pos;
-out:
-	bch2_trans_iter_exit(&iter);
+		bch2_disk_reservation_put(c, &s->res);
 	return ret;
-err:
-	bch2_disk_reservation_put(c, &s->res);
-	goto out;
 }
 
 struct ec_stripe_head *bch2_ec_stripe_head_get(struct btree_trans *trans,
diff --git a/fs/bcachefs/extent_update.c b/fs/bcachefs/extent_update.c
index 0c1f6f2ec02c..c4b0ea1adaa8 100644
--- a/fs/bcachefs/extent_update.c
+++ b/fs/bcachefs/extent_update.c
@@ -68,7 +68,6 @@ static int count_iters_for_insert(struct btree_trans *trans,
 		u64 idx = REFLINK_P_IDX(p.v);
 		unsigned sectors = bpos_min(*end, p.k->p).offset -
 			bkey_start_offset(p.k);
-		struct btree_iter iter;
 		struct bkey_s_c r_k;
 
 		for_each_btree_key_norestart(trans, iter,
@@ -88,11 +87,9 @@ static int count_iters_for_insert(struct btree_trans *trans,
 						    r_k.k->p.offset - idx);
 
 				*end = bpos_min(*end, pos);
-				ret = 1;
-				break;
+				return 1;
 			}
 		}
-		bch2_trans_iter_exit(&iter);
 
 		break;
 	}
diff --git a/fs/bcachefs/fs-io-direct.c b/fs/bcachefs/fs-io-direct.c
index 8d5b2468f4cd..79823234160f 100644
--- a/fs/bcachefs/fs-io-direct.c
+++ b/fs/bcachefs/fs-io-direct.c
@@ -253,11 +253,9 @@ static bool bch2_check_range_allocated(struct bch_fs *c, subvol_inum inum,
 				       unsigned nr_replicas, bool compressed)
 {
 	CLASS(btree_trans, trans)(c);
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	u64 end = offset + size;
 	u32 snapshot;
-	bool ret = true;
 	int err;
 retry:
 	bch2_trans_begin(trans);
@@ -269,24 +267,21 @@ static bool bch2_check_range_allocated(struct bch_fs *c, subvol_inum inum,
 	for_each_btree_key_norestart(trans, iter, BTREE_ID_extents,
 			   SPOS(inum.inum, offset, snapshot),
 			   BTREE_ITER_slots, k, err) {
+		offset = iter.pos.offset;
+
 		if (bkey_ge(bkey_start_pos(k.k), POS(inum.inum, end)))
 			break;
 
 		if (k.k->p.snapshot != snapshot ||
 		    nr_replicas > bch2_bkey_replicas(c, k) ||
-		    (!compressed && bch2_bkey_sectors_compressed(k))) {
-			ret = false;
-			break;
-		}
+		    (!compressed && bch2_bkey_sectors_compressed(k)))
+			return false;
 	}
-
-	offset = iter.pos.offset;
-	bch2_trans_iter_exit(&iter);
 err:
 	if (bch2_err_matches(err, BCH_ERR_transaction_restart))
 		goto retry;
 
-	return err ? false : ret;
+	return !err;
 }
 
 static noinline bool bch2_dio_write_check_allocated(struct dio_write *dio)
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 9a48a3a12139..dc79f70114a0 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -137,7 +137,6 @@ static int lookup_dirent_in_snapshot(struct btree_trans *trans,
 static int find_snapshot_tree_subvol(struct btree_trans *trans,
 				     u32 tree_id, u32 *subvol)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -151,13 +150,11 @@ static int find_snapshot_tree_subvol(struct btree_trans *trans,
 
 		if (s.v->subvol) {
 			*subvol = le32_to_cpu(s.v->subvol);
-			goto found;
+			return 0;
 		}
 	}
-	ret = bch_err_throw(trans->c, ENOENT_no_snapshot_tree_subvol);
-found:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return ret ?: bch_err_throw(trans->c, ENOENT_no_snapshot_tree_subvol);
 }
 
 /* Get lost+found, create if it doesn't exist: */
@@ -454,7 +451,6 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 	 */
 	if (!inode->bi_subvol && bch2_snapshot_is_leaf(c, inode->bi_snapshot) <= 0) {
 		CLASS(snapshot_id_list, whiteouts_done)();
-		struct btree_iter iter;
 		struct bkey_s_c k;
 
 		darray_init(&whiteouts_done);
@@ -473,19 +469,16 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 			struct bch_inode_unpacked child_inode;
 			ret = bch2_inode_unpack(k, &child_inode);
 			if (ret)
-				break;
+				return ret;
 
 			if (!inode_should_reattach(&child_inode)) {
-				ret = maybe_delete_dirent(trans,
-							  SPOS(lostfound.bi_inum, inode->bi_dir_offset,
-							       dirent_snapshot),
-							  k.k->p.snapshot);
-				if (ret)
-					break;
-
-				ret = snapshot_list_add(c, &whiteouts_done, k.k->p.snapshot);
+				ret =   maybe_delete_dirent(trans,
+							    SPOS(lostfound.bi_inum, inode->bi_dir_offset,
+								 dirent_snapshot),
+							    k.k->p.snapshot) ?:
+					snapshot_list_add(c, &whiteouts_done, k.k->p.snapshot);
 				if (ret)
-					break;
+					return ret;
 			} else {
 				iter.snapshot = k.k->p.snapshot;
 				child_inode.bi_dir = inode->bi_dir;
@@ -494,10 +487,9 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 				ret = bch2_inode_write_flags(trans, &iter, &child_inode,
 							     BTREE_UPDATE_internal_snapshot_node);
 				if (ret)
-					break;
+					return ret;
 			}
 		}
-		bch2_trans_iter_exit(&iter);
 	}
 
 	return ret;
@@ -843,7 +835,6 @@ static int get_inodes_all_snapshots(struct btree_trans *trans,
 				    struct inode_walker *w, u64 inum)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -863,7 +854,6 @@ static int get_inodes_all_snapshots(struct btree_trans *trans,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	if (ret)
 		return ret;
@@ -879,7 +869,6 @@ static int get_visible_inodes(struct btree_trans *trans,
 			      u64 inum)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -903,7 +892,6 @@ static int get_visible_inodes(struct btree_trans *trans,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -1342,7 +1330,6 @@ static int find_oldest_inode_needs_reattach(struct btree_trans *trans,
 					    struct bch_inode_unpacked *inode)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 
@@ -1374,7 +1361,6 @@ static int find_oldest_inode_needs_reattach(struct btree_trans *trans,
 
 		*inode = parent_inode;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
@@ -1457,13 +1443,12 @@ static int check_key_has_inode(struct btree_trans *trans,
 {
 	struct bch_fs *c = trans->c;
 	CLASS(printbuf, buf)();
-	struct btree_iter iter2 = {};
 	int ret = PTR_ERR_OR_ZERO(i);
 	if (ret)
 		return ret;
 
 	if (k.k->type == KEY_TYPE_whiteout)
-		goto out;
+		return 0;
 
 	bool have_inode = i && !i->whiteout;
 
@@ -1471,7 +1456,7 @@ static int check_key_has_inode(struct btree_trans *trans,
 		goto reconstruct;
 
 	if (have_inode && btree_matches_i_mode(iter->btree_id, i->inode.bi_mode))
-		goto out;
+		return 0;
 
 	prt_printf(&buf, ", ");
 
@@ -1551,7 +1536,6 @@ static int check_key_has_inode(struct btree_trans *trans,
 out:
 err:
 fsck_err:
-	bch2_trans_iter_exit(&iter2);
 	bch_err_fn(c, ret);
 	return ret;
 delete:
@@ -1577,7 +1561,6 @@ static int maybe_reconstruct_inum_btree(struct btree_trans *trans,
 					u64 inum, u32 snapshot,
 					enum btree_id btree)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 
@@ -1588,7 +1571,6 @@ static int maybe_reconstruct_inum_btree(struct btree_trans *trans,
 		ret = 1;
 		break;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	if (ret <= 0)
 		return ret;
@@ -2120,7 +2102,6 @@ static int check_subdir_dirents_count(struct btree_trans *trans, struct inode_wa
 /* find a subvolume that's a descendent of @snapshot: */
 static int find_snapshot_subvol(struct btree_trans *trans, u32 snapshot, u32 *subvolid)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -2132,14 +2113,11 @@ static int find_snapshot_subvol(struct btree_trans *trans, u32 snapshot, u32 *su
 		if (bch2_snapshot_is_ancestor(trans->c, le32_to_cpu(s.v->snapshot), snapshot)) {
 			bch2_trans_iter_exit(&iter);
 			*subvolid = k.k->p.offset;
-			goto found;
+			return 0;
 		}
 	}
-	if (!ret)
-		ret = -ENOENT;
-found:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return ret ?: -ENOENT;
 }
 
 noinline_for_stack
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index ab4c651ba731..85013e8d6166 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -420,7 +420,6 @@ int bch2_inode_find_by_inum(struct bch_fs *c, subvol_inum inum,
 int bch2_inode_find_snapshot_root(struct btree_trans *trans, u64 inum,
 				  struct bch_inode_unpacked *root)
 {
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 
@@ -429,15 +428,11 @@ int bch2_inode_find_snapshot_root(struct btree_trans *trans, u64 inum,
 					     BTREE_ITER_all_snapshots, k, ret) {
 		if (k.k->p.offset != inum)
 			break;
-		if (bkey_is_inode(k.k)) {
-			ret = bch2_inode_unpack(k, root);
-			goto out;
-		}
+		if (bkey_is_inode(k.k))
+			return bch2_inode_unpack(k, root);
 	}
 	/* We're only called when we know we have an inode for @inum */
 	BUG_ON(!ret);
-out:
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -692,10 +687,11 @@ bch2_bkey_get_iter_snapshot_parent(struct btree_trans *trans, struct btree_iter
 	struct bkey_s_c k;
 	int ret = 0;
 
-	for_each_btree_key_max_norestart(trans, *iter, btree,
-					  bpos_successor(pos),
-					  SPOS(pos.inode, pos.offset, U32_MAX),
-					  flags|BTREE_ITER_all_snapshots, k, ret)
+	bch2_trans_iter_init(trans, iter, btree, bpos_successor(pos),
+			     flags|BTREE_ITER_all_snapshots);
+
+	for_each_btree_key_max_continue_norestart(*iter, SPOS(pos.inode, pos.offset, U32_MAX),
+						  flags|BTREE_ITER_all_snapshots, k, ret)
 		if (bch2_snapshot_is_ancestor(c, pos.snapshot, k.k->p.snapshot))
 			return k;
 
@@ -723,7 +719,6 @@ bch2_inode_get_iter_snapshot_parent(struct btree_trans *trans, struct btree_iter
 int __bch2_inode_has_child_snapshots(struct btree_trans *trans, struct bpos pos)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 
@@ -736,7 +731,6 @@ int __bch2_inode_has_child_snapshots(struct btree_trans *trans, struct bpos pos)
 			ret = 1;
 			break;
 		}
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 46a21b088a91..2019595253bc 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -431,9 +431,7 @@ static int bch2_snapshot_tree_master_subvol(struct btree_trans *trans,
 					    u32 snapshot_root, u32 *subvol_id)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
-	bool found = false;
 	int ret;
 
 	for_each_btree_key_norestart(trans, iter, BTREE_ID_subvolumes, POS_MIN,
@@ -446,28 +444,26 @@ static int bch2_snapshot_tree_master_subvol(struct btree_trans *trans,
 			continue;
 		if (!BCH_SUBVOLUME_SNAP(s.v)) {
 			*subvol_id = s.k->p.offset;
-			found = true;
-			break;
+			return 0;
 		}
 	}
-	bch2_trans_iter_exit(&iter);
-
-	if (!ret && !found) {
-		struct bkey_i_subvolume *u;
-
-		*subvol_id = bch2_snapshot_oldest_subvol(c, snapshot_root, NULL);
+	if (ret)
+		return ret;
 
-		u = bch2_bkey_get_mut_typed(trans, &iter,
-					    BTREE_ID_subvolumes, POS(0, *subvol_id),
-					    0, subvolume);
-		ret = PTR_ERR_OR_ZERO(u);
-		if (ret)
-			return ret;
+	*subvol_id = bch2_snapshot_oldest_subvol(c, snapshot_root, NULL);
 
-		SET_BCH_SUBVOLUME_SNAP(&u->v, false);
-	}
+	struct btree_iter iter;
+	struct bkey_i_subvolume *u =
+		bch2_bkey_get_mut_typed(trans, &iter,
+					BTREE_ID_subvolumes, POS(0, *subvol_id),
+					0, subvolume);
+	ret = PTR_ERR_OR_ZERO(u);
+	if (ret)
+		return ret;
 
-	return ret;
+	SET_BCH_SUBVOLUME_SNAP(&u->v, false);
+	bch2_trans_iter_exit(&iter);
+	return 0;
 }
 
 static int check_snapshot_tree(struct btree_trans *trans,
@@ -855,7 +851,6 @@ static int check_snapshot_exists(struct btree_trans *trans, u32 id)
 	struct bch_fs *c = trans->c;
 
 	/* Do we need to reconstruct the snapshot_tree entry as well? */
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 	u32 tree_id = 0;
@@ -868,7 +863,6 @@ static int check_snapshot_exists(struct btree_trans *trans, u32 id)
 			break;
 		}
 	}
-	bch2_trans_iter_exit(&iter);
 
 	if (ret)
 		return ret;
@@ -898,7 +892,6 @@ static int check_snapshot_exists(struct btree_trans *trans, u32 id)
 			break;
 		}
 	}
-	bch2_trans_iter_exit(&iter);
 
 	return  bch2_snapshot_table_make_room(c, id) ?:
 		bch2_btree_insert_trans(trans, BTREE_ID_snapshots, &snapshot->k_i, 0);
@@ -1083,7 +1076,6 @@ int __bch2_get_snapshot_overwrites(struct btree_trans *trans,
 				   snapshot_id_list *s)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret = 0;
 
@@ -1100,7 +1092,6 @@ int __bch2_get_snapshot_overwrites(struct btree_trans *trans,
 		if (ret)
 			break;
 	}
-	bch2_trans_iter_exit(&iter);
 	if (ret)
 		darray_exit(s);
 
@@ -1927,7 +1918,6 @@ int __bch2_key_has_snapshot_overwrites(struct btree_trans *trans,
 				       struct bpos pos)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	int ret;
 
@@ -1938,12 +1928,9 @@ int __bch2_key_has_snapshot_overwrites(struct btree_trans *trans,
 		if (!bkey_eq(pos, k.k->p))
 			break;
 
-		if (bch2_snapshot_is_ancestor(c, k.k->p.snapshot, pos.snapshot)) {
-			ret = 1;
-			break;
-		}
+		if (bch2_snapshot_is_ancestor(c, k.k->p.snapshot, pos.snapshot))
+			return 1;
 	}
-	bch2_trans_iter_exit(&iter);
 
 	return ret;
 }
diff --git a/fs/bcachefs/str_hash.c b/fs/bcachefs/str_hash.c
index 68392fb6532e..ce2a54902a64 100644
--- a/fs/bcachefs/str_hash.c
+++ b/fs/bcachefs/str_hash.c
@@ -121,7 +121,6 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 				struct bch_inode_unpacked *snapshot_root)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter;
 	struct bkey_s_c k;
 	CLASS(printbuf, buf)();
 	bool need_commit = false;
@@ -178,7 +177,7 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 	}
 
 	if (ret)
-		goto err;
+		return ret;
 
 	if (!need_commit) {
 		printbuf_reset(&buf);
@@ -196,15 +195,12 @@ int bch2_repair_inode_hash_info(struct btree_trans *trans,
 		prt_printf(&buf, " %llx %llx", hash_info->siphash_key.k0, hash_info->siphash_key.k1);
 #endif
 		bch2_print_str(c, KERN_ERR, buf.buf);
-		ret = bch_err_throw(c, fsck_repair_unimplemented);
-		goto err;
+		return bch_err_throw(c, fsck_repair_unimplemented);
 	}
 
 	ret = bch2_trans_commit(trans, NULL, NULL, BCH_TRANS_COMMIT_no_enospc) ?:
 		bch_err_throw(c, transaction_restart_nested);
-err:
 fsck_err:
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -349,10 +345,14 @@ int __bch2_str_hash_check_key(struct btree_trans *trans,
 	if (hash_k.k->p.offset < hash)
 		goto bad_hash;
 
-	for_each_btree_key_norestart(trans, iter, desc->btree_id,
-				     SPOS(hash_k.k->p.inode, hash, hash_k.k->p.snapshot),
-				     BTREE_ITER_slots|
-				     BTREE_ITER_with_updates, k, ret) {
+	bch2_trans_iter_init(trans, &iter, desc->btree_id,
+			     SPOS(hash_k.k->p.inode, hash, hash_k.k->p.snapshot),
+			     BTREE_ITER_slots|
+			     BTREE_ITER_with_updates);
+
+	for_each_btree_key_continue_norestart(iter,
+			BTREE_ITER_slots|
+			BTREE_ITER_with_updates, k, ret) {
 		if (bkey_eq(k.k->p, hash_k.k->p))
 			break;
 
diff --git a/fs/bcachefs/str_hash.h b/fs/bcachefs/str_hash.h
index 7b4e7e9eb993..8c0fb44929cc 100644
--- a/fs/bcachefs/str_hash.h
+++ b/fs/bcachefs/str_hash.h
@@ -159,8 +159,11 @@ bch2_hash_lookup_in_snapshot(struct btree_trans *trans,
 	struct bkey_s_c k;
 	int ret;
 
-	for_each_btree_key_max_norestart(trans, *iter, desc.btree_id,
-			   SPOS(inum.inum, desc.hash_key(info, key), snapshot),
+	bch2_trans_iter_init(trans, iter,
+			     desc.btree_id, SPOS(inum.inum, desc.hash_key(info, key), snapshot),
+			     BTREE_ITER_slots|flags);
+
+	for_each_btree_key_max_continue_norestart(*iter,
 			   POS(inum.inum, U64_MAX),
 			   BTREE_ITER_slots|flags, k, ret) {
 		if (is_visible_key(desc, inum, k)) {
@@ -209,8 +212,11 @@ bch2_hash_hole(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	for_each_btree_key_max_norestart(trans, *iter, desc.btree_id,
-			   SPOS(inum.inum, desc.hash_key(info, key), snapshot),
+	bch2_trans_iter_init(trans, iter,  desc.btree_id,
+			     SPOS(inum.inum, desc.hash_key(info, key), snapshot),
+			     BTREE_ITER_slots|BTREE_ITER_intent);
+
+	for_each_btree_key_max_continue_norestart(*iter,
 			   POS(inum.inum, U64_MAX),
 			   BTREE_ITER_slots|BTREE_ITER_intent, k, ret)
 		if (!is_visible_key(desc, inum, k))
@@ -265,10 +271,13 @@ struct bkey_s_c bch2_hash_set_or_get_in_snapshot(struct btree_trans *trans,
 	bool found = false;
 	int ret;
 
-	for_each_btree_key_max_norestart(trans, *iter, desc.btree_id,
+	bch2_trans_iter_init(trans, iter, desc.btree_id,
 			   SPOS(insert->k.p.inode,
 				desc.hash_bkey(info, bkey_i_to_s_c(insert)),
 				snapshot),
+			   BTREE_ITER_slots|BTREE_ITER_intent|flags);
+
+	for_each_btree_key_max_continue_norestart(*iter,
 			   POS(insert->k.p.inode, U64_MAX),
 			   BTREE_ITER_slots|BTREE_ITER_intent|flags, k, ret) {
 		if (is_visible_key(desc, inum, k)) {
-- 
2.51.0


From 4baaaa5ce682511cd4c07ee31b44cf1832ce06d3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 31 Jul 2025 15:44:10 -0400
Subject: [PATCH 212/309] bcachefs: Kill bch2_bkey_get_iter_typed()

More CLASS() conversion.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.h | 17 +++++++---
 fs/bcachefs/ec.c         | 10 ++----
 fs/bcachefs/fsck.c       | 14 ++++----
 fs/bcachefs/namei.c      | 16 ++++-----
 fs/bcachefs/snapshot.c   | 72 ++++++++++++++++------------------------
 fs/bcachefs/subvolume.c  | 50 +++++++++-------------------
 6 files changed, 74 insertions(+), 105 deletions(-)

diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index 64e143e6920f..be5983dcd3fc 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -654,7 +654,7 @@ static inline struct bkey_s_c __bch2_bkey_get_iter(struct btree_trans *trans,
 	k = bch2_btree_iter_peek_slot(iter);
 
 	if (!bkey_err(k) && type && k.k->type != type)
-		k = bkey_s_c_err(-BCH_ERR_ENOENT_bkey_type_mismatch);
+		k = bkey_s_c_err(bch_err_throw(trans->c, ENOENT_bkey_type_mismatch));
 	if (unlikely(bkey_err(k)))
 		bch2_trans_iter_exit(iter);
 	return k;
@@ -668,9 +668,18 @@ static inline struct bkey_s_c bch2_bkey_get_iter(struct btree_trans *trans,
 	return __bch2_bkey_get_iter(trans, iter, btree, pos, flags, 0);
 }
 
-#define bch2_bkey_get_iter_typed(_trans, _iter, _btree_id, _pos, _flags, _type)\
-	bkey_s_c_to_##_type(__bch2_bkey_get_iter(_trans, _iter,			\
-				       _btree_id, _pos, _flags, KEY_TYPE_##_type))
+static inline struct bkey_s_c __bch2_bkey_get_typed(struct btree_iter *iter,
+						    enum bch_bkey_type type)
+{
+	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
+
+	if (!bkey_err(k) && k.k->type != type)
+		k = bkey_s_c_err(bch_err_throw(iter->trans->c, ENOENT_bkey_type_mismatch));
+	return k;
+}
+
+#define bch2_bkey_get_typed(_iter, _type)						\
+	bkey_s_c_to_##_type(__bch2_bkey_get_typed(_iter, KEY_TYPE_##_type))
 
 static inline void __bkey_val_copy(void *dst_v, unsigned dst_size, struct bkey_s_c src_k)
 {
diff --git a/fs/bcachefs/ec.c b/fs/bcachefs/ec.c
index 4b7c7193de76..c2840cb674b2 100644
--- a/fs/bcachefs/ec.c
+++ b/fs/bcachefs/ec.c
@@ -2113,17 +2113,13 @@ static int bch2_invalidate_stripe_to_dev_from_alloc(struct btree_trans *trans, s
 		return bch_err_throw(c, invalidate_stripe_to_dev);
 	}
 
-	struct btree_iter iter;
-	struct bkey_s_c_stripe s =
-		bch2_bkey_get_iter_typed(trans, &iter, BTREE_ID_stripes, POS(0, a->stripe),
-					 BTREE_ITER_slots, stripe);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_stripes, POS(0, a->stripe), 0);
+	struct bkey_s_c_stripe s = bch2_bkey_get_typed(&iter, stripe);
 	int ret = bkey_err(s);
 	if (ret)
 		return ret;
 
-	ret = bch2_invalidate_stripe_to_dev(trans, &iter, s.s_c, k_a.k->p.inode, flags);
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return bch2_invalidate_stripe_to_dev(trans, &iter, s.s_c, k_a.k->p.inode, flags);
 }
 
 int bch2_dev_remove_stripes(struct bch_fs *c, unsigned dev_idx, unsigned flags)
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index dc79f70114a0..e236bc1fc65b 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -499,7 +499,11 @@ static struct bkey_s_c_dirent dirent_get_by_pos(struct btree_trans *trans,
 						struct btree_iter *iter,
 						struct bpos pos)
 {
-	return bch2_bkey_get_iter_typed(trans, iter, BTREE_ID_dirents, pos, 0, dirent);
+	bch2_trans_iter_init(trans, iter, BTREE_ID_dirents, pos, 0);
+	struct bkey_s_c_dirent d = bch2_bkey_get_typed(iter, dirent);
+	if (bkey_err(d.s_c))
+		bch2_trans_iter_exit(iter);
+	return d;
 }
 
 static int remove_backpointer(struct btree_trans *trans,
@@ -2177,15 +2181,13 @@ static int check_dirent_to_subvol(struct btree_trans *trans, struct btree_iter *
 		struct bkey_i_dirent *new_dirent = bch2_bkey_make_mut_typed(trans, iter, &d.s_c, 0, dirent);
 		ret = PTR_ERR_OR_ZERO(new_dirent);
 		if (ret)
-			goto err;
+			return ret;
 
 		new_dirent->v.d_parent_subvol = cpu_to_le32(new_parent_subvol);
 	}
 
-	struct bkey_s_c_subvolume s =
-		bch2_bkey_get_iter_typed(trans, &subvol_iter,
-					 BTREE_ID_subvolumes, POS(0, target_subvol),
-					 0, subvolume);
+	bch2_trans_iter_init(trans, &subvol_iter, BTREE_ID_subvolumes, POS(0, target_subvol), 0);
+	struct bkey_s_c_subvolume s = bch2_bkey_get_typed(&subvol_iter, subvolume);
 	ret = bkey_err(s.s_c);
 	if (ret && !bch2_err_matches(ret, ENOENT))
 		goto err;
diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index cfed2041c2c3..5066d37a3638 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -687,10 +687,9 @@ static int __bch2_inum_to_path(struct btree_trans *trans,
 				goto disconnected;
 		}
 
-		struct btree_iter d_iter;
-		struct bkey_s_c_dirent d = bch2_bkey_get_iter_typed(trans, &d_iter,
-				BTREE_ID_dirents, SPOS(inode.bi_dir, inode.bi_dir_offset, snapshot),
-				0, dirent);
+		CLASS(btree_iter, d_iter)(trans, BTREE_ID_dirents,
+					  SPOS(inode.bi_dir, inode.bi_dir_offset, snapshot), 0);
+		struct bkey_s_c_dirent d = bch2_bkey_get_typed(&d_iter, dirent);
 		ret = bkey_err(d.s_c);
 		if (ret)
 			goto disconnected;
@@ -700,8 +699,6 @@ static int __bch2_inum_to_path(struct btree_trans *trans,
 		prt_bytes_reversed(path, dirent_name.name, dirent_name.len);
 
 		prt_char(path, '/');
-
-		bch2_trans_iter_exit(&d_iter);
 	}
 
 	if (orig_pos == path->pos)
@@ -779,10 +776,9 @@ static int bch2_check_dirent_inode_dirent(struct btree_trans *trans,
 		return __bch2_fsck_write_inode(trans, target);
 	}
 
-	struct bkey_s_c_dirent bp_dirent =
-		bch2_bkey_get_iter_typed(trans, &bp_iter, BTREE_ID_dirents,
-			      SPOS(target->bi_dir, target->bi_dir_offset, target->bi_snapshot),
-			      0, dirent);
+	bch2_trans_iter_init(trans, &bp_iter, BTREE_ID_dirents,
+			     SPOS(target->bi_dir, target->bi_dir_offset, target->bi_snapshot), 0);
+	struct bkey_s_c_dirent bp_dirent = bch2_bkey_get_typed(&bp_iter, dirent);
 	ret = bkey_err(bp_dirent);
 	if (ret && !bch2_err_matches(ret, ENOENT))
 		goto err;
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 2019595253bc..56de79998712 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -471,27 +471,21 @@ static int check_snapshot_tree(struct btree_trans *trans,
 			       struct bkey_s_c k)
 {
 	struct bch_fs *c = trans->c;
-	struct bkey_s_c_snapshot_tree st;
-	struct bch_snapshot s;
-	struct bch_subvolume subvol;
 	CLASS(printbuf, buf)();
-	struct btree_iter snapshot_iter = {};
-	u32 root_id;
-	int ret;
 
 	if (k.k->type != KEY_TYPE_snapshot_tree)
 		return 0;
 
-	st = bkey_s_c_to_snapshot_tree(k);
-	root_id = le32_to_cpu(st.v->root_snapshot);
+	struct bkey_s_c_snapshot_tree st = bkey_s_c_to_snapshot_tree(k);
+	u32 root_id = le32_to_cpu(st.v->root_snapshot);
 
-	struct bkey_s_c_snapshot snapshot_k =
-		bch2_bkey_get_iter_typed(trans, &snapshot_iter, BTREE_ID_snapshots,
-					 POS(0, root_id), 0, snapshot);
-	ret = bkey_err(snapshot_k);
+	CLASS(btree_iter, snapshot_iter)(trans, BTREE_ID_snapshots, POS(0, root_id), 0);
+	struct bkey_s_c_snapshot snapshot_k = bch2_bkey_get_typed(&snapshot_iter, snapshot);
+	int ret = bkey_err(snapshot_k);
 	if (ret && !bch2_err_matches(ret, ENOENT))
-		goto err;
+		return ret;
 
+	struct bch_snapshot s;
 	if (!ret)
 		bkey_val_copy(&s, snapshot_k);
 
@@ -505,17 +499,16 @@ static int check_snapshot_tree(struct btree_trans *trans,
 			 ret
 			 ? prt_printf(&buf, "(%s)", bch2_err_str(ret))
 			 : bch2_bkey_val_to_text(&buf, c, snapshot_k.s_c),
-			 buf.buf))) {
-		ret = bch2_btree_delete_at(trans, iter, 0);
-		goto err;
-	}
+			 buf.buf)))
+		return bch2_btree_delete_at(trans, iter, 0);
 
 	if (!st.v->master_subvol)
-		goto out;
+		return 0;
 
+	struct bch_subvolume subvol;
 	ret = bch2_subvolume_get(trans, le32_to_cpu(st.v->master_subvol), false, &subvol);
 	if (ret && !bch2_err_matches(ret, ENOENT))
-		goto err;
+		return ret;
 
 	if (fsck_err_on(ret,
 			trans, snapshot_tree_to_missing_subvol,
@@ -540,26 +533,21 @@ static int check_snapshot_tree(struct btree_trans *trans,
 		ret = bch2_snapshot_tree_master_subvol(trans, root_id, &subvol_id);
 		bch_err_fn(c, ret);
 
-		if (bch2_err_matches(ret, ENOENT)) { /* nothing to be done here */
-			ret = 0;
-			goto err;
-		}
+		if (bch2_err_matches(ret, ENOENT)) /* nothing to be done here */
+			return 0;
 
 		if (ret)
-			goto err;
+			return ret;
 
 		u = bch2_bkey_make_mut_typed(trans, iter, &k, 0, snapshot_tree);
 		ret = PTR_ERR_OR_ZERO(u);
 		if (ret)
-			goto err;
+			return ret;
 
 		u->v.master_subvol = cpu_to_le32(subvol_id);
 		st = snapshot_tree_i_to_s_c(u);
 	}
-out:
-err:
 fsck_err:
-	bch2_trans_iter_exit(&snapshot_iter);
 	return ret;
 }
 
@@ -637,22 +625,19 @@ static int snapshot_tree_ptr_repair(struct btree_trans *trans,
 				    struct bch_snapshot *s)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter root_iter;
-	struct bch_snapshot_tree s_t;
-	struct bkey_s_c_snapshot root;
 	struct bkey_i_snapshot *u;
-	u32 root_id = bch2_snapshot_root(c, k.k->p.offset), tree_id;
-	int ret;
+	u32 root_id = bch2_snapshot_root(c, k.k->p.offset);
 
-	root = bch2_bkey_get_iter_typed(trans, &root_iter,
-			       BTREE_ID_snapshots, POS(0, root_id),
-			       BTREE_ITER_with_updates, snapshot);
-	ret = bkey_err(root);
+	CLASS(btree_iter, root_iter)(trans, BTREE_ID_snapshots, POS(0, root_id),
+				     BTREE_ITER_with_updates);
+	struct bkey_s_c_snapshot root = bch2_bkey_get_typed(&root_iter, snapshot);
+	int ret = bkey_err(root);
 	if (ret)
-		goto err;
+		return ret;
 
-	tree_id = le32_to_cpu(root.v->tree);
+	u32 tree_id = le32_to_cpu(root.v->tree);
 
+	struct bch_snapshot_tree s_t;
 	ret = bch2_snapshot_tree_lookup(trans, tree_id, &s_t);
 	if (ret && !bch2_err_matches(ret, ENOENT))
 		return ret;
@@ -664,7 +649,7 @@ static int snapshot_tree_ptr_repair(struct btree_trans *trans,
 				bch2_snapshot_oldest_subvol(c, root_id, NULL),
 				&tree_id);
 		if (ret)
-			goto err;
+			return ret;
 
 		u->v.tree = cpu_to_le32(tree_id);
 		if (k.k->p.offset == root_id)
@@ -675,14 +660,13 @@ static int snapshot_tree_ptr_repair(struct btree_trans *trans,
 		u = bch2_bkey_make_mut_typed(trans, iter, &k, 0, snapshot);
 		ret = PTR_ERR_OR_ZERO(u);
 		if (ret)
-			goto err;
+			return ret;
 
 		u->v.tree = cpu_to_le32(tree_id);
 		*s = u->v;
 	}
-err:
-	bch2_trans_iter_exit(&root_iter);
-	return ret;
+
+	return 0;
 }
 
 static int check_snapshot(struct btree_trans *trans,
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index a38a58ef7a8c..9145b7e73481 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -350,22 +350,16 @@ int bch2_snapshot_get_subvol(struct btree_trans *trans, u32 snapshot,
 int __bch2_subvolume_get_snapshot(struct btree_trans *trans, u32 subvolid,
 				  u32 *snapid, bool warn)
 {
-	struct btree_iter iter;
-	struct bkey_s_c_subvolume subvol;
-	int ret;
-
-	subvol = bch2_bkey_get_iter_typed(trans, &iter,
-					  BTREE_ID_subvolumes, POS(0, subvolid),
-					  BTREE_ITER_cached|BTREE_ITER_with_updates,
-					  subvolume);
-	ret = bkey_err(subvol);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_subvolumes, POS(0, subvolid),
+				BTREE_ITER_cached|BTREE_ITER_with_updates);
+	struct bkey_s_c_subvolume subvol = bch2_bkey_get_typed(&iter, subvolume);
+	int ret = bkey_err(subvol);
 
 	if (bch2_err_matches(ret, ENOENT))
 		ret = bch2_subvolume_missing(trans->c, subvolid) ?: ret;
 
 	if (likely(!ret))
 		*snapid = le32_to_cpu(subvol.v->snapshot);
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -426,42 +420,35 @@ static int bch2_subvolumes_reparent(struct btree_trans *trans, u32 subvolid_to_d
  */
 static int __bch2_subvolume_delete(struct btree_trans *trans, u32 subvolid)
 {
-	struct btree_iter subvol_iter = {}, snapshot_iter = {}, snapshot_tree_iter = {};
-
-	struct bkey_s_c_subvolume subvol =
-		bch2_bkey_get_iter_typed(trans, &subvol_iter,
-				BTREE_ID_subvolumes, POS(0, subvolid),
-				BTREE_ITER_cached|BTREE_ITER_intent,
-				subvolume);
+	CLASS(btree_iter, subvol_iter)(trans, BTREE_ID_subvolumes, POS(0, subvolid),
+				       BTREE_ITER_cached|BTREE_ITER_intent);
+	struct bkey_s_c_subvolume subvol = bch2_bkey_get_typed(&subvol_iter, subvolume);
 	int ret = bkey_err(subvol);
 	if (bch2_err_matches(ret, ENOENT))
 		ret = bch2_subvolume_missing(trans->c, subvolid) ?: ret;
 	if (ret)
-		goto err;
+		return ret;
 
 	u32 snapid = le32_to_cpu(subvol.v->snapshot);
 
-	struct bkey_s_c_snapshot snapshot =
-		bch2_bkey_get_iter_typed(trans, &snapshot_iter,
-				BTREE_ID_snapshots, POS(0, snapid),
-				0, snapshot);
+	CLASS(btree_iter, snapshot_iter)(trans, BTREE_ID_snapshots, POS(0, snapid), 0);
+	struct bkey_s_c_snapshot snapshot = bch2_bkey_get_typed(&snapshot_iter, snapshot);
 	ret = bkey_err(snapshot);
 	bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT), trans->c,
 				"missing snapshot %u", snapid);
 	if (ret)
-		goto err;
+		return ret;
 
 	u32 treeid = le32_to_cpu(snapshot.v->tree);
 
+	CLASS(btree_iter, snapshot_tree_iter)(trans, BTREE_ID_snapshot_trees, POS(0, treeid), 0);
 	struct bkey_s_c_snapshot_tree snapshot_tree =
-		bch2_bkey_get_iter_typed(trans, &snapshot_tree_iter,
-				BTREE_ID_snapshot_trees, POS(0, treeid),
-				0, snapshot_tree);
+		bch2_bkey_get_typed(&snapshot_tree_iter, snapshot_tree);
 	ret = bkey_err(snapshot_tree);
 	bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT), trans->c,
 				"missing snapshot tree %u", treeid);
 	if (ret)
-		goto err;
+		return ret;
 
 	if (le32_to_cpu(snapshot_tree.v->master_subvol) == subvolid) {
 		struct bkey_i_snapshot_tree *snapshot_tree_mut =
@@ -470,18 +457,13 @@ static int __bch2_subvolume_delete(struct btree_trans *trans, u32 subvolid)
 						 0, snapshot_tree);
 		ret = PTR_ERR_OR_ZERO(snapshot_tree_mut);
 		if (ret)
-			goto err;
+			return ret;
 
 		snapshot_tree_mut->v.master_subvol = 0;
 	}
 
-	ret =   bch2_btree_delete_at(trans, &subvol_iter, 0) ?:
+	return  bch2_btree_delete_at(trans, &subvol_iter, 0) ?:
 		bch2_snapshot_node_set_deleted(trans, snapid);
-err:
-	bch2_trans_iter_exit(&snapshot_tree_iter);
-	bch2_trans_iter_exit(&snapshot_iter);
-	bch2_trans_iter_exit(&subvol_iter);
-	return ret;
 }
 
 static int bch2_subvolume_delete(struct btree_trans *trans, u32 subvolid)
-- 
2.51.0


From efcae873b6d82142ee3d0f2567d8c949e9f513d6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 31 Jul 2025 15:48:25 -0400
Subject: [PATCH 213/309] bcachefs: __bch2_bkey_get_val_typed() uses
 CLASS(btree_iter)

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.h | 9 +++------
 1 file changed, 3 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index be5983dcd3fc..a7c2087bc4a1 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -701,14 +701,11 @@ static inline int __bch2_bkey_get_val_typed(struct btree_trans *trans,
 				enum bch_bkey_type type,
 				unsigned val_size, void *val)
 {
-	struct btree_iter iter;
-	struct bkey_s_c k = __bch2_bkey_get_iter(trans, &iter, btree, pos, flags, type);
+	CLASS(btree_iter, iter)(trans, btree, pos, flags);
+	struct bkey_s_c k = __bch2_bkey_get_typed(&iter, type);
 	int ret = bkey_err(k);
-	if (!ret) {
+	if (!ret)
 		__bkey_val_copy(val, val_size, k);
-		bch2_trans_iter_exit(&iter);
-	}
-
 	return ret;
 }
 
-- 
2.51.0


From 84ea5479ccb1a7b54b95bc8acdf23f695157f97f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 31 Jul 2025 16:07:51 -0400
Subject: [PATCH 214/309] bcachefs: Convert bch2_bkey_get_mut() to
 CLASS(btree_iter)

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.h   |  2 +-
 fs/bcachefs/btree_update.h | 50 +++++++--------------
 fs/bcachefs/buckets.c      | 18 +++-----
 fs/bcachefs/fsck.c         | 16 ++-----
 fs/bcachefs/namei.c        |  4 +-
 fs/bcachefs/snapshot.c     | 91 ++++++++++++--------------------------
 fs/bcachefs/subvolume.c    | 30 ++++---------
 7 files changed, 66 insertions(+), 145 deletions(-)

diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index a7c2087bc4a1..b117cb5d7f94 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -673,7 +673,7 @@ static inline struct bkey_s_c __bch2_bkey_get_typed(struct btree_iter *iter,
 {
 	struct bkey_s_c k = bch2_btree_iter_peek_slot(iter);
 
-	if (!bkey_err(k) && k.k->type != type)
+	if (!bkey_err(k) && type && k.k->type != type)
 		k = bkey_s_c_err(bch_err_throw(iter->trans->c, ENOENT_bkey_type_mismatch));
 	return k;
 }
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 6790e0254a63..663739db82b1 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -370,72 +370,52 @@ static inline struct bkey_i *bch2_bkey_make_mut(struct btree_trans *trans,
 	bkey_i_to_##_type(__bch2_bkey_make_mut(_trans, _iter, _k, _flags,\
 				KEY_TYPE_##_type, sizeof(struct bkey_i_##_type)))
 
-static inline struct bkey_i *__bch2_bkey_get_mut_noupdate(struct btree_trans *trans,
-					 struct btree_iter *iter,
-					 unsigned btree_id, struct bpos pos,
-					 enum btree_iter_update_trigger_flags flags,
+static inline struct bkey_i *__bch2_bkey_get_mut_noupdate(struct btree_iter *iter,
 					 unsigned type, unsigned min_bytes)
 {
-	struct bkey_s_c k = __bch2_bkey_get_iter(trans, iter,
-				btree_id, pos, flags|BTREE_ITER_intent, type);
-	struct bkey_i *ret = IS_ERR(k.k)
+	struct bkey_s_c k = __bch2_bkey_get_typed(iter, type);
+	return IS_ERR(k.k)
 		? ERR_CAST(k.k)
-		: __bch2_bkey_make_mut_noupdate(trans, k, 0, min_bytes);
-	if (IS_ERR(ret))
-		bch2_trans_iter_exit(iter);
-	return ret;
+		: __bch2_bkey_make_mut_noupdate(iter->trans, k, 0, min_bytes);
 }
 
-static inline struct bkey_i *bch2_bkey_get_mut_noupdate(struct btree_trans *trans,
-					       struct btree_iter *iter,
-					       unsigned btree_id, struct bpos pos,
-					       enum btree_iter_update_trigger_flags flags)
+static inline struct bkey_i *bch2_bkey_get_mut_noupdate(struct btree_iter *iter)
 {
-	return __bch2_bkey_get_mut_noupdate(trans, iter, btree_id, pos, flags, 0, 0);
+	return __bch2_bkey_get_mut_noupdate(iter, 0, 0);
 }
 
 static inline struct bkey_i *__bch2_bkey_get_mut(struct btree_trans *trans,
-					 struct btree_iter *iter,
-					 unsigned btree_id, struct bpos pos,
+					 enum btree_id btree, struct bpos pos,
 					 enum btree_iter_update_trigger_flags flags,
 					 unsigned type, unsigned min_bytes)
 {
-	struct bkey_i *mut = __bch2_bkey_get_mut_noupdate(trans, iter,
-				btree_id, pos, flags|BTREE_ITER_intent, type, min_bytes);
-	int ret;
-
+	CLASS(btree_iter, iter)(trans, btree, pos, flags|BTREE_ITER_intent);
+	struct bkey_i *mut = __bch2_bkey_get_mut_noupdate(&iter, type, min_bytes);
 	if (IS_ERR(mut))
 		return mut;
-
-	ret = bch2_trans_update(trans, iter, mut, flags);
-	if (ret) {
-		bch2_trans_iter_exit(iter);
+	int ret = bch2_trans_update(trans, &iter, mut, flags);
+	if (ret)
 		return ERR_PTR(ret);
-	}
-
 	return mut;
 }
 
 static inline struct bkey_i *bch2_bkey_get_mut_minsize(struct btree_trans *trans,
-						       struct btree_iter *iter,
 						       unsigned btree_id, struct bpos pos,
 						       enum btree_iter_update_trigger_flags flags,
 						       unsigned min_bytes)
 {
-	return __bch2_bkey_get_mut(trans, iter, btree_id, pos, flags, 0, min_bytes);
+	return __bch2_bkey_get_mut(trans, btree_id, pos, flags, 0, min_bytes);
 }
 
 static inline struct bkey_i *bch2_bkey_get_mut(struct btree_trans *trans,
-					       struct btree_iter *iter,
 					       unsigned btree_id, struct bpos pos,
 					       enum btree_iter_update_trigger_flags flags)
 {
-	return __bch2_bkey_get_mut(trans, iter, btree_id, pos, flags, 0, 0);
+	return __bch2_bkey_get_mut(trans, btree_id, pos, flags, 0, 0);
 }
 
-#define bch2_bkey_get_mut_typed(_trans, _iter, _btree_id, _pos, _flags, _type)\
-	bkey_i_to_##_type(__bch2_bkey_get_mut(_trans, _iter,		\
-			_btree_id, _pos, _flags,			\
+#define bch2_bkey_get_mut_typed(_trans, _btree_id, _pos, _flags, _type)			\
+	bkey_i_to_##_type(__bch2_bkey_get_mut(_trans, _btree_id, _pos, _flags,		\
 			KEY_TYPE_##_type, sizeof(struct bkey_i_##_type)))
 
 static inline struct bkey_i *__bch2_bkey_alloc(struct btree_trans *trans, struct btree_iter *iter,
diff --git a/fs/bcachefs/buckets.c b/fs/bcachefs/buckets.c
index 0a357005e9e8..87a6f4dce296 100644
--- a/fs/bcachefs/buckets.c
+++ b/fs/bcachefs/buckets.c
@@ -663,24 +663,23 @@ static int bch2_trigger_stripe_ptr(struct btree_trans *trans,
 	struct bch_fs *c = trans->c;
 
 	if (flags & BTREE_TRIGGER_transactional) {
-		struct btree_iter iter;
-		struct bkey_i_stripe *s = bch2_bkey_get_mut_typed(trans, &iter,
-				BTREE_ID_stripes, POS(0, p.ec.idx),
-				BTREE_ITER_with_updates, stripe);
+		struct bkey_i_stripe *s = bch2_bkey_get_mut_typed(trans,
+							BTREE_ID_stripes, POS(0, p.ec.idx),
+							BTREE_ITER_with_updates,
+							stripe);
 		int ret = PTR_ERR_OR_ZERO(s);
 		if (unlikely(ret)) {
 			bch2_trans_inconsistent_on(bch2_err_matches(ret, ENOENT), trans,
 				"pointer to nonexistent stripe %llu",
 				(u64) p.ec.idx);
-			goto err;
+			return ret;
 		}
 
 		if (!bch2_ptr_matches_stripe(&s->v, p)) {
 			bch2_trans_inconsistent(trans,
 				"stripe pointer doesn't match stripe %llu",
 				(u64) p.ec.idx);
-			ret = bch_err_throw(c, trigger_stripe_pointer);
-			goto err;
+			return bch_err_throw(c, trigger_stripe_pointer);
 		}
 
 		stripe_blockcount_set(&s->v, p.ec.block,
@@ -692,10 +691,7 @@ static int bch2_trigger_stripe_ptr(struct btree_trans *trans,
 		acc.type = BCH_DISK_ACCOUNTING_replicas;
 		bch2_bkey_to_replicas(&acc.replicas, bkey_i_to_s_c(&s->k_i));
 		acc.replicas.data_type = data_type;
-		ret = bch2_disk_accounting_mod(trans, &acc, &sectors, 1, false);
-err:
-		bch2_trans_iter_exit(&iter);
-		return ret;
+		return bch2_disk_accounting_mod(trans, &acc, &sectors, 1, false);
 	}
 
 	if (flags & BTREE_TRIGGER_gc) {
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index e236bc1fc65b..8d5ea217798e 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -190,8 +190,7 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 		return ret;
 
 	if (!subvol.inode) {
-		struct btree_iter iter;
-		struct bkey_i_subvolume *subvol = bch2_bkey_get_mut_typed(trans, &iter,
+		struct bkey_i_subvolume *subvol = bch2_bkey_get_mut_typed(trans,
 				BTREE_ID_subvolumes, POS(0, subvolid),
 				0, subvolume);
 		ret = PTR_ERR_OR_ZERO(subvol);
@@ -199,7 +198,6 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 			return ret;
 
 		subvol->v.inode = cpu_to_le64(reattaching_inum);
-		bch2_trans_iter_exit(&iter);
 	}
 
 	subvol_inum root_inum = {
@@ -369,9 +367,8 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 	if (inode->bi_subvol) {
 		inode->bi_parent_subvol = BCACHEFS_ROOT_SUBVOL;
 
-		struct btree_iter subvol_iter;
 		struct bkey_i_subvolume *subvol =
-			bch2_bkey_get_mut_typed(trans, &subvol_iter,
+			bch2_bkey_get_mut_typed(trans,
 						BTREE_ID_subvolumes, POS(0, inode->bi_subvol),
 						0, subvolume);
 		ret = PTR_ERR_OR_ZERO(subvol);
@@ -379,7 +376,6 @@ static int reattach_inode(struct btree_trans *trans, struct bch_inode_unpacked *
 			return ret;
 
 		subvol->v.fs_path_parent = BCACHEFS_ROOT_SUBVOL;
-		bch2_trans_iter_exit(&subvol_iter);
 
 		u64 root_inum;
 		ret = subvol_lookup(trans, inode->bi_parent_subvol,
@@ -602,8 +598,7 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 	if (ret)
 		return ret;
 
-	struct btree_iter iter;
-	struct bkey_i_snapshot *s = bch2_bkey_get_mut_typed(trans, &iter,
+	struct bkey_i_snapshot *s = bch2_bkey_get_mut_typed(trans,
 			BTREE_ID_snapshots, POS(0, snapshotid),
 			0, snapshot);
 	ret = PTR_ERR_OR_ZERO(s);
@@ -615,9 +610,8 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 
 	s->v.subvol = cpu_to_le32(subvolid);
 	SET_BCH_SNAPSHOT_SUBVOL(&s->v, true);
-	bch2_trans_iter_exit(&iter);
 
-	struct bkey_i_snapshot_tree *st = bch2_bkey_get_mut_typed(trans, &iter,
+	struct bkey_i_snapshot_tree *st = bch2_bkey_get_mut_typed(trans,
 			BTREE_ID_snapshot_trees, POS(0, snapshot_tree),
 			0, snapshot_tree);
 	ret = PTR_ERR_OR_ZERO(st);
@@ -627,8 +621,6 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 
 	if (!st->v.master_subvol)
 		st->v.master_subvol = cpu_to_le32(subvolid);
-
-	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index 5066d37a3638..d1019052f182 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -383,9 +383,8 @@ bool bch2_reinherit_attrs(struct bch_inode_unpacked *dst_u,
 
 static int subvol_update_parent(struct btree_trans *trans, u32 subvol, u32 new_parent)
 {
-	struct btree_iter iter;
 	struct bkey_i_subvolume *s =
-		bch2_bkey_get_mut_typed(trans, &iter,
+		bch2_bkey_get_mut_typed(trans,
 			BTREE_ID_subvolumes, POS(0, subvol),
 			BTREE_ITER_cached, subvolume);
 	int ret = PTR_ERR_OR_ZERO(s);
@@ -393,7 +392,6 @@ static int subvol_update_parent(struct btree_trans *trans, u32 subvol, u32 new_p
 		return ret;
 
 	s->v.fs_path_parent = cpu_to_le32(new_parent);
-	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 56de79998712..5a1f81749661 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -452,17 +452,14 @@ static int bch2_snapshot_tree_master_subvol(struct btree_trans *trans,
 
 	*subvol_id = bch2_snapshot_oldest_subvol(c, snapshot_root, NULL);
 
-	struct btree_iter iter;
 	struct bkey_i_subvolume *u =
-		bch2_bkey_get_mut_typed(trans, &iter,
-					BTREE_ID_subvolumes, POS(0, *subvol_id),
+		bch2_bkey_get_mut_typed(trans, BTREE_ID_subvolumes, POS(0, *subvol_id),
 					0, subvolume);
 	ret = PTR_ERR_OR_ZERO(u);
 	if (ret)
 		return ret;
 
 	SET_BCH_SUBVOLUME_SNAP(&u->v, false);
-	bch2_trans_iter_exit(&iter);
 	return 0;
 }
 
@@ -1087,28 +1084,21 @@ int __bch2_get_snapshot_overwrites(struct btree_trans *trans,
  */
 int bch2_snapshot_node_set_deleted(struct btree_trans *trans, u32 id)
 {
-	struct btree_iter iter;
 	struct bkey_i_snapshot *s =
-		bch2_bkey_get_mut_typed(trans, &iter,
-				    BTREE_ID_snapshots, POS(0, id),
-				    0, snapshot);
+		bch2_bkey_get_mut_typed(trans, BTREE_ID_snapshots, POS(0, id), 0, snapshot);
 	int ret = PTR_ERR_OR_ZERO(s);
-	if (unlikely(ret)) {
-		bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT),
-					trans->c, "missing snapshot %u", id);
+	bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT), trans->c, "missing snapshot %u", id);
+	if (unlikely(ret))
 		return ret;
-	}
 
 	/* already deleted? */
 	if (BCH_SNAPSHOT_WILL_DELETE(&s->v))
-		goto err;
+		return 0;
 
 	SET_BCH_SNAPSHOT_WILL_DELETE(&s->v, true);
 	SET_BCH_SNAPSHOT_SUBVOL(&s->v, false);
 	s->v.subvol = 0;
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return 0;
 }
 
 static inline void normalize_snapshot_child_pointers(struct bch_snapshot *s)
@@ -1120,22 +1110,17 @@ static inline void normalize_snapshot_child_pointers(struct bch_snapshot *s)
 static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter iter, p_iter = {};
-	struct btree_iter c_iter = {};
-	struct btree_iter tree_iter = {};
 	u32 parent_id, child_id;
 	unsigned i;
-	int ret = 0;
 
 	struct bkey_i_snapshot *s =
-		bch2_bkey_get_mut_typed(trans, &iter, BTREE_ID_snapshots, POS(0, id),
-					BTREE_ITER_intent, snapshot);
-	ret = PTR_ERR_OR_ZERO(s);
+		bch2_bkey_get_mut_typed(trans, BTREE_ID_snapshots, POS(0, id), 0, snapshot);
+	int ret = PTR_ERR_OR_ZERO(s);
 	bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT), c,
 				"missing snapshot %u", id);
 
 	if (ret)
-		goto err;
+		return ret;
 
 	BUG_ON(BCH_SNAPSHOT_DELETED(&s->v));
 	BUG_ON(s->v.children[1]);
@@ -1144,16 +1129,14 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 	child_id = le32_to_cpu(s->v.children[0]);
 
 	if (parent_id) {
-		struct bkey_i_snapshot *parent;
-
-		parent = bch2_bkey_get_mut_typed(trans, &p_iter,
-				     BTREE_ID_snapshots, POS(0, parent_id),
-				     0, snapshot);
+		struct bkey_i_snapshot *parent =
+			bch2_bkey_get_mut_typed(trans, BTREE_ID_snapshots, POS(0, parent_id),
+						0, snapshot);
 		ret = PTR_ERR_OR_ZERO(parent);
 		bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT), c,
 					"missing snapshot %u", parent_id);
 		if (unlikely(ret))
-			goto err;
+			return ret;
 
 		/* find entry in parent->children for node being deleted */
 		for (i = 0; i < 2; i++)
@@ -1163,7 +1146,7 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 		if (bch2_fs_inconsistent_on(i == 2, c,
 					"snapshot %u missing child pointer to %u",
 					parent_id, id))
-			goto err;
+			return ret;
 
 		parent->v.children[i] = cpu_to_le32(child_id);
 
@@ -1171,16 +1154,14 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 	}
 
 	if (child_id) {
-		struct bkey_i_snapshot *child;
-
-		child = bch2_bkey_get_mut_typed(trans, &c_iter,
-				     BTREE_ID_snapshots, POS(0, child_id),
-				     0, snapshot);
+		struct bkey_i_snapshot *child =
+			bch2_bkey_get_mut_typed(trans, BTREE_ID_snapshots, POS(0, child_id),
+						0, snapshot);
 		ret = PTR_ERR_OR_ZERO(child);
 		bch2_fs_inconsistent_on(bch2_err_matches(ret, ENOENT), c,
 					"missing snapshot %u", child_id);
 		if (unlikely(ret))
-			goto err;
+			return ret;
 
 		child->v.parent = cpu_to_le32(parent_id);
 
@@ -1197,16 +1178,15 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 		 * snapshot_tree entry to point to the new root, or delete it if
 		 * this is the last snapshot ID in this tree:
 		 */
-		struct bkey_i_snapshot_tree *s_t;
 
 		BUG_ON(s->v.children[1]);
 
-		s_t = bch2_bkey_get_mut_typed(trans, &tree_iter,
+		struct bkey_i_snapshot_tree *s_t = bch2_bkey_get_mut_typed(trans,
 				BTREE_ID_snapshot_trees, POS(0, le32_to_cpu(s->v.tree)),
 				0, snapshot_tree);
 		ret = PTR_ERR_OR_ZERO(s_t);
 		if (ret)
-			goto err;
+			return ret;
 
 		if (s->v.children[0]) {
 			s_t->v.root_snapshot = s->v.children[0];
@@ -1231,12 +1211,8 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 		s->k.type = KEY_TYPE_deleted;
 		set_bkey_val_u64s(&s->k, 0);
 	}
-err:
-	bch2_trans_iter_exit(&tree_iter);
-	bch2_trans_iter_exit(&p_iter);
-	bch2_trans_iter_exit(&c_iter);
-	bch2_trans_iter_exit(&iter);
-	return ret;
+
+	return 0;
 }
 
 static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
@@ -1248,8 +1224,7 @@ static int create_snapids(struct btree_trans *trans, u32 parent, u32 tree,
 	struct bkey_i_snapshot *n;
 	u32 depth = bch2_snapshot_depth(c, parent);
 
-	CLASS(btree_iter, iter)(trans, BTREE_ID_snapshots,
-				POS_MIN, BTREE_ITER_intent);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_snapshots, POS_MIN, BTREE_ITER_intent);
 	struct bkey_s_c k = bch2_btree_iter_peek(&iter);
 	int ret = bkey_err(k);
 	if (ret)
@@ -1303,14 +1278,9 @@ static int bch2_snapshot_node_create_children(struct btree_trans *trans, u32 par
 			      u32 *snapshot_subvols,
 			      unsigned nr_snapids)
 {
-	struct btree_iter iter;
-	struct bkey_i_snapshot *n_parent;
-	int ret = 0;
-
-	n_parent = bch2_bkey_get_mut_typed(trans, &iter,
-			BTREE_ID_snapshots, POS(0, parent),
-			0, snapshot);
-	ret = PTR_ERR_OR_ZERO(n_parent);
+	struct bkey_i_snapshot *n_parent =
+		bch2_bkey_get_mut_typed(trans, BTREE_ID_snapshots, POS(0, parent), 0, snapshot);
+	int ret = PTR_ERR_OR_ZERO(n_parent);
 	if (unlikely(ret)) {
 		if (bch2_err_matches(ret, ENOENT))
 			bch_err(trans->c, "snapshot %u not found", parent);
@@ -1319,22 +1289,19 @@ static int bch2_snapshot_node_create_children(struct btree_trans *trans, u32 par
 
 	if (n_parent->v.children[0] || n_parent->v.children[1]) {
 		bch_err(trans->c, "Trying to add child snapshot nodes to parent that already has children");
-		ret = -EINVAL;
-		goto err;
+		return -EINVAL;
 	}
 
 	ret = create_snapids(trans, parent, le32_to_cpu(n_parent->v.tree),
 			     new_snapids, snapshot_subvols, nr_snapids);
 	if (ret)
-		goto err;
+		return ret;
 
 	n_parent->v.children[0] = cpu_to_le32(new_snapids[0]);
 	n_parent->v.children[1] = cpu_to_le32(new_snapids[1]);
 	n_parent->v.subvol = 0;
 	SET_BCH_SNAPSHOT_SUBVOL(&n_parent->v, false);
-err:
-	bch2_trans_iter_exit(&iter);
-	return ret;
+	return 0;
 }
 
 /*
diff --git a/fs/bcachefs/subvolume.c b/fs/bcachefs/subvolume.c
index 9145b7e73481..6023ae46ca72 100644
--- a/fs/bcachefs/subvolume.c
+++ b/fs/bcachefs/subvolume.c
@@ -539,13 +539,8 @@ static int bch2_subvolume_wait_for_pagecache_and_delete_hook(struct btree_trans
 
 int bch2_subvolume_unlink(struct btree_trans *trans, u32 subvolid)
 {
-	struct btree_iter iter;
-	struct bkey_i_subvolume *n;
-	struct subvolume_unlink_hook *h;
-	int ret = 0;
-
-	h = bch2_trans_kmalloc(trans, sizeof(*h));
-	ret = PTR_ERR_OR_ZERO(h);
+	struct subvolume_unlink_hook *h = bch2_trans_kmalloc(trans, sizeof(*h));
+	int ret = PTR_ERR_OR_ZERO(h);
 	if (ret)
 		return ret;
 
@@ -553,9 +548,9 @@ int bch2_subvolume_unlink(struct btree_trans *trans, u32 subvolid)
 	h->subvol	= subvolid;
 	bch2_trans_commit_hook(trans, &h->h);
 
-	n = bch2_bkey_get_mut_typed(trans, &iter,
-			BTREE_ID_subvolumes, POS(0, subvolid),
-			BTREE_ITER_cached, subvolume);
+	struct bkey_i_subvolume *n =
+		bch2_bkey_get_mut_typed(trans, BTREE_ID_subvolumes, POS(0, subvolid),
+					BTREE_ITER_cached, subvolume);
 	ret = PTR_ERR_OR_ZERO(n);
 	if (bch2_err_matches(ret, ENOENT))
 		ret = bch2_subvolume_missing(trans->c, subvolid) ?: ret;
@@ -564,7 +559,6 @@ int bch2_subvolume_unlink(struct btree_trans *trans, u32 subvolid)
 
 	SET_BCH_SUBVOLUME_UNLINKED(&n->v, true);
 	n->v.fs_path_parent = 0;
-	bch2_trans_iter_exit(&iter);
 	return ret;
 }
 
@@ -576,7 +570,7 @@ int bch2_subvolume_create(struct btree_trans *trans, u64 inode,
 			  bool ro)
 {
 	struct bch_fs *c = trans->c;
-	struct btree_iter dst_iter, src_iter = (struct btree_iter) { NULL };
+	struct btree_iter dst_iter;
 	struct bkey_i_subvolume *new_subvol = NULL;
 	struct bkey_i_subvolume *src_subvol = NULL;
 	u32 parent = 0, new_nodes[2], snapshot_subvols[2];
@@ -595,9 +589,8 @@ int bch2_subvolume_create(struct btree_trans *trans, u64 inode,
 	if (src_subvolid) {
 		/* Creating a snapshot: */
 
-		src_subvol = bch2_bkey_get_mut_typed(trans, &src_iter,
-				BTREE_ID_subvolumes, POS(0, src_subvolid),
-				BTREE_ITER_cached, subvolume);
+		src_subvol = bch2_bkey_get_mut_typed(trans, BTREE_ID_subvolumes, POS(0, src_subvolid),
+						     BTREE_ITER_cached, subvolume);
 		ret = PTR_ERR_OR_ZERO(src_subvol);
 		if (bch2_err_matches(ret, ENOENT))
 			ret = bch2_subvolume_missing(trans->c, src_subvolid) ?: ret;
@@ -613,12 +606,8 @@ int bch2_subvolume_create(struct btree_trans *trans, u64 inode,
 	if (ret)
 		goto err;
 
-	if (src_subvolid) {
+	if (src_subvolid)
 		src_subvol->v.snapshot = cpu_to_le32(new_nodes[1]);
-		ret = bch2_trans_update(trans, &src_iter, &src_subvol->k_i, 0);
-		if (ret)
-			goto err;
-	}
 
 	new_subvol = bch2_bkey_alloc(trans, &dst_iter, 0, subvolume);
 	ret = PTR_ERR_OR_ZERO(new_subvol);
@@ -639,7 +628,6 @@ int bch2_subvolume_create(struct btree_trans *trans, u64 inode,
 	*new_subvolid	= new_subvol->k.p.offset;
 	*new_snapshotid	= new_nodes[0];
 err:
-	bch2_trans_iter_exit(&src_iter);
 	bch2_trans_iter_exit(&dst_iter);
 	return ret;
 }
-- 
2.51.0


From a77e4c69457007df9c6c29ce73c28229326b836a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 19:58:34 -0400
Subject: [PATCH 215/309] bcachefs: bch2_set_version_incompat() no longer takes
 sb_lock unless writing sb

We're going to be using this in bch2_trans_update_extent(), so it needs
some optimizing.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h |  4 ++--
 fs/bcachefs/super-io.c | 37 +++++++++++++++++++++----------------
 fs/bcachefs/super.c    |  1 -
 3 files changed, 23 insertions(+), 19 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index 45c15bdaa6f4..cdf593c59922 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -845,8 +845,8 @@ struct bch_fs {
 		unsigned long	errors_silent[BITS_TO_LONGS(BCH_FSCK_ERR_MAX)];
 		u64		btrees_lost_data;
 	}			sb;
-	DARRAY(enum bcachefs_metadata_version)
-				incompat_versions_requested;
+
+	unsigned long		incompat_versions_requested[BITS_TO_LONGS(BCH_VERSION_MINOR(bcachefs_metadata_version_current))];
 
 	struct unicode_map	*cf_encoding;
 
diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index c88759964575..be7ed612d28f 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -68,28 +68,33 @@ enum bcachefs_metadata_version bch2_latest_compatible_version(enum bcachefs_meta
 
 int bch2_set_version_incompat(struct bch_fs *c, enum bcachefs_metadata_version version)
 {
-	guard(mutex)(&c->sb_lock);
-
 	if (((c->sb.features & BIT_ULL(BCH_FEATURE_incompat_version_field)) &&
 	     version <= c->sb.version_incompat_allowed)) {
-		SET_BCH_SB_VERSION_INCOMPAT(c->disk_sb.sb,
-			max(BCH_SB_VERSION_INCOMPAT(c->disk_sb.sb), version));
-		bch2_write_super(c);
+		guard(mutex)(&c->sb_lock);
+
+		if (version > c->sb.version_incompat) {
+			SET_BCH_SB_VERSION_INCOMPAT(c->disk_sb.sb,
+				max(BCH_SB_VERSION_INCOMPAT(c->disk_sb.sb), version));
+			bch2_write_super(c);
+		}
 		return 0;
 	} else {
-		darray_for_each(c->incompat_versions_requested, i)
-			if (version == *i)
-				return bch_err_throw(c, may_not_use_incompat_feature);
+		BUILD_BUG_ON(BCH_VERSION_MAJOR(bcachefs_metadata_version_current) != 1);
 
-		darray_push(&c->incompat_versions_requested, version);
-		CLASS(printbuf, buf)();
-		prt_str(&buf, "requested incompat feature ");
-		bch2_version_to_text(&buf, version);
-		prt_str(&buf, " currently not enabled, allowed up to ");
-		bch2_version_to_text(&buf, version);
-		prt_printf(&buf, "\n  set version_upgrade=incompat to enable");
+		unsigned minor = BCH_VERSION_MINOR(version);
+
+		if (!test_bit(minor, c->incompat_versions_requested) &&
+		    !test_and_set_bit(minor, c->incompat_versions_requested)) {
+			CLASS(printbuf, buf)();
+			prt_str(&buf, "requested incompat feature ");
+			bch2_version_to_text(&buf, version);
+			prt_str(&buf, " currently not enabled, allowed up to ");
+			bch2_version_to_text(&buf, version);
+			prt_printf(&buf, "\n  set version_upgrade=incompat to enable");
+
+			bch_notice(c, "%s", buf.buf);
+		}
 
-		bch_notice(c, "%s", buf.buf);
 		return bch_err_throw(c, may_not_use_incompat_feature);
 	}
 }
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index b3b2d8353a36..b0019488f586 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -653,7 +653,6 @@ static void __bch2_fs_free(struct bch_fs *c)
 		free_percpu(c->online_reserved);
 	}
 
-	darray_exit(&c->incompat_versions_requested);
 	darray_exit(&c->btree_roots_extra);
 	free_percpu(c->pcpu);
 	free_percpu(c->usage);
-- 
2.51.0


From 4521cf474590e519f9f80e713074050947976c70 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 28 May 2025 15:52:43 -0400
Subject: [PATCH 216/309] bcachefs: BTREE_ITER_nofilter_whiteouts

Add a flag to tell btree_iter_peek() to return whiteouts that we find,
even though we're filtering out keys in unrelated snapshots.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c      | 4 ++--
 fs/bcachefs/btree_key_cache.c | 1 +
 fs/bcachefs/btree_types.h     | 1 +
 3 files changed, 4 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index ff580f76a641..a67babf69d39 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2451,7 +2451,7 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_iter *iter, struct bpos en
 			}
 
 			if (bkey_whiteout(k.k) &&
-			    !(iter->flags & BTREE_ITER_key_cache_fill)) {
+			    !(iter->flags & BTREE_ITER_nofilter_whiteouts)) {
 				search_key = bkey_successor(iter, k.k->p);
 				continue;
 			}
@@ -2867,7 +2867,7 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_iter *iter)
 
 		if (unlikely(k.k->type == KEY_TYPE_whiteout &&
 			     (iter->flags & BTREE_ITER_filter_snapshots) &&
-			     !(iter->flags & BTREE_ITER_key_cache_fill)))
+			     !(iter->flags & BTREE_ITER_nofilter_whiteouts)))
 			iter->k.type = KEY_TYPE_deleted;
 	} else {
 		struct bpos next;
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index 72c803f7b8d1..4890cbc88e7c 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -325,6 +325,7 @@ static noinline int btree_key_cache_fill(struct btree_trans *trans,
 
 	CLASS(btree_iter, iter)(trans, ck_path->btree_id, ck_path->pos,
 				BTREE_ITER_intent|
+				BTREE_ITER_nofilter_whiteouts|
 				BTREE_ITER_key_cache_fill|
 				BTREE_ITER_cached_nofill);
 	iter.flags &= ~BTREE_ITER_with_journal;
diff --git a/fs/bcachefs/btree_types.h b/fs/bcachefs/btree_types.h
index ffa250008d91..619f9d2c7580 100644
--- a/fs/bcachefs/btree_types.h
+++ b/fs/bcachefs/btree_types.h
@@ -229,6 +229,7 @@ struct btree_node_iter {
 	x(snapshot_field)			\
 	x(all_snapshots)			\
 	x(filter_snapshots)			\
+	x(nofilter_whiteouts)			\
 	x(nopreserve)				\
 	x(cached_nofill)			\
 	x(key_cache_fill)			\
-- 
2.51.0


From dad1429b21a96c7152e797d8ef83b30bb5ff7ebf Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 30 Jul 2025 13:35:20 -0400
Subject: [PATCH 217/309] bcachefs: btree_id_is_extents_snapshots

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_types.h | 17 +++++++++++------
 1 file changed, 11 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/btree_types.h b/fs/bcachefs/btree_types.h
index 619f9d2c7580..e893eb938bb3 100644
--- a/fs/bcachefs/btree_types.h
+++ b/fs/bcachefs/btree_types.h
@@ -840,15 +840,15 @@ static inline bool btree_node_type_has_triggers(enum btree_node_type type)
 	return BIT_ULL(type) & BTREE_NODE_TYPE_HAS_TRIGGERS;
 }
 
-static inline bool btree_id_is_extents(enum btree_id btree)
-{
-	const u64 mask = 0
+static const u64 btree_is_extents_mask = 0
 #define x(name, nr, flags, ...)	|((!!((flags) & BTREE_IS_extents)) << nr)
-	BCH_BTREE_IDS()
+BCH_BTREE_IDS()
 #undef x
-	;
+;
 
-	return BIT_ULL(btree) & mask;
+static inline bool btree_id_is_extents(enum btree_id btree)
+{
+	return BIT_ULL(btree) & btree_is_extents_mask;
 }
 
 static inline bool btree_node_type_is_extents(enum btree_node_type type)
@@ -867,6 +867,11 @@ static inline bool btree_type_has_snapshots(enum btree_id btree)
 	return BIT_ULL(btree) & btree_has_snapshots_mask;
 }
 
+static inline bool btree_id_is_extents_snapshots(enum btree_id btree)
+{
+	return BIT_ULL(btree) & btree_has_snapshots_mask & btree_is_extents_mask;
+}
+
 static inline bool btree_type_has_snapshot_field(enum btree_id btree)
 {
 	const u64 mask = 0
-- 
2.51.0


From 16f567b3f558ae471a1a757f972d64591deebfae Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 1 Aug 2025 12:43:51 -0400
Subject: [PATCH 218/309] bcachefs: Kill non-extent uses of
 bch2_btree_insert_nonextent()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c       | 7 ++++---
 fs/bcachefs/inode.c      | 7 ++++---
 fs/bcachefs/logged_ops.h | 2 +-
 3 files changed, 9 insertions(+), 7 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 8d5ea217798e..6ccea09243ab 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -923,9 +923,10 @@ lookup_inode_for_snapshot(struct btree_trans *trans, struct inode_walker *w, str
 			bkey_init(&whiteout.k);
 			whiteout.k.type = KEY_TYPE_whiteout;
 			whiteout.k.p = SPOS(0, i->inode.bi_inum, k.k->p.snapshot);
-			ret = bch2_btree_insert_nonextent(trans, BTREE_ID_inodes,
-							  &whiteout,
-							  BTREE_UPDATE_internal_snapshot_node);
+			ret = bch2_btree_insert_trans(trans, BTREE_ID_inodes,
+						      &whiteout,
+						      BTREE_ITER_cached|
+						      BTREE_UPDATE_internal_snapshot_node);
 		}
 
 		if (ret)
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index 85013e8d6166..d5e5190f0663 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -463,9 +463,10 @@ int __bch2_fsck_write_inode(struct btree_trans *trans, struct bch_inode_unpacked
 	bch2_inode_pack(inode_p, inode);
 	inode_p->inode.k.p.snapshot = inode->bi_snapshot;
 
-	return bch2_btree_insert_nonextent(trans, BTREE_ID_inodes,
-				&inode_p->inode.k_i,
-				BTREE_UPDATE_internal_snapshot_node);
+	return bch2_btree_insert_trans(trans, BTREE_ID_inodes,
+				       &inode_p->inode.k_i,
+				       BTREE_ITER_cached|
+				       BTREE_UPDATE_internal_snapshot_node);
 }
 
 int bch2_fsck_write_inode(struct btree_trans *trans, struct bch_inode_unpacked *inode)
diff --git a/fs/bcachefs/logged_ops.h b/fs/bcachefs/logged_ops.h
index 30ae9ef737dd..6dea6e2ac7a8 100644
--- a/fs/bcachefs/logged_ops.h
+++ b/fs/bcachefs/logged_ops.h
@@ -10,7 +10,7 @@
 
 static inline int bch2_logged_op_update(struct btree_trans *trans, struct bkey_i *op)
 {
-	return bch2_btree_insert_nonextent(trans, BTREE_ID_logged_ops, op, 0);
+	return bch2_btree_insert_trans(trans, BTREE_ID_logged_ops, op, BTREE_ITER_cached);
 }
 
 int bch2_resume_logged_ops(struct bch_fs *);
-- 
2.51.0


From 65eecfbd26b133f2e9f5cdfe79d5e80e1a8f6db6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 1 Aug 2025 13:00:46 -0400
Subject: [PATCH 219/309] bcachefs: Simplify
 bch2_trans_update_extent_overwrite()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update.c | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 566478728aa2..6f3b57573cba 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -215,7 +215,7 @@ int bch2_trans_update_extent_overwrite(struct btree_trans *trans,
 			return ret;
 	}
 
-	if (bkey_le(old.k->p, new.k->p)) {
+	if (!back_split) {
 		update = bch2_trans_kmalloc(trans, sizeof(*update));
 		if ((ret = PTR_ERR_OR_ZERO(update)))
 			return ret;
@@ -238,9 +238,7 @@ int bch2_trans_update_extent_overwrite(struct btree_trans *trans,
 					  BTREE_UPDATE_internal_snapshot_node|flags);
 		if (ret)
 			return ret;
-	}
-
-	if (back_split) {
+	} else {
 		update = bch2_bkey_make_mut_noupdate(trans, old);
 		if ((ret = PTR_ERR_OR_ZERO(update)))
 			return ret;
-- 
2.51.0


From a28cbae7fddd015e7bc5941083e506d4a988ed83 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 1 Aug 2025 16:20:42 -0400
Subject: [PATCH 220/309] bcachefs: btree_node_is_root()

New helper for checking if a btree node is the root, with a new
assertion.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_cache.c           | 2 +-
 fs/bcachefs/btree_cache.h           | 8 ++++++++
 fs/bcachefs/btree_update_interior.c | 8 ++++++--
 3 files changed, 15 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/btree_cache.c b/fs/bcachefs/btree_cache.c
index 2f7c384a8c81..8716eedd43fc 100644
--- a/fs/bcachefs/btree_cache.c
+++ b/fs/bcachefs/btree_cache.c
@@ -214,7 +214,7 @@ void bch2_node_pin(struct bch_fs *c, struct btree *b)
 	struct btree_cache *bc = &c->btree_cache;
 
 	guard(mutex)(&bc->lock);
-	if (b != btree_node_root(c, b) && !btree_node_pinned(b)) {
+	if (!btree_node_is_root(c, b) && !btree_node_pinned(b)) {
 		set_btree_node_pinned(b);
 		list_move(&b->list, &bc->live[1].list);
 		bc->live[0].nr--;
diff --git a/fs/bcachefs/btree_cache.h b/fs/bcachefs/btree_cache.h
index 649e9dfd178a..035b2cb25077 100644
--- a/fs/bcachefs/btree_cache.h
+++ b/fs/bcachefs/btree_cache.h
@@ -144,6 +144,14 @@ static inline struct btree *btree_node_root(struct bch_fs *c, struct btree *b)
 	return r ? r->b : NULL;
 }
 
+static inline bool btree_node_is_root(struct bch_fs *c, struct btree *b)
+{
+	struct btree *root = btree_node_root(c, b);
+
+	BUG_ON(b != root && b->c.level >= root->c.level);
+	return b == root;
+}
+
 const char *bch2_btree_id_str(enum btree_id);	/* avoid */
 void bch2_btree_id_to_text(struct printbuf *, enum btree_id);
 void bch2_btree_id_level_to_text(struct printbuf *, enum btree_id, unsigned);
diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 5f4f82967105..76897cf15946 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -66,6 +66,10 @@ int bch2_btree_node_check_topology(struct btree_trans *trans, struct btree *b)
 	bkey_init(&prev.k->k);
 	bch2_btree_and_journal_iter_init_node_iter(trans, &iter, b);
 
+	/*
+	 * Don't use btree_node_is_root(): we're called by btree split, after
+	 * creating a new root but before setting it
+	 */
 	if (b == btree_node_root(c, b)) {
 		if (!bpos_eq(b->data->min_key, POS_MIN)) {
 			bch2_log_msg_start(c, &buf);
@@ -1655,7 +1659,7 @@ static int btree_split(struct btree_update *as, struct btree_trans *trans,
 	int ret = 0;
 
 	bch2_verify_btree_nr_keys(b);
-	BUG_ON(!parent && (b != btree_node_root(c, b)));
+	BUG_ON(!parent && !btree_node_is_root(c, b));
 	BUG_ON(parent && !btree_node_intent_locked(trans->paths + path, b->c.level + 1));
 
 	ret = bch2_btree_node_check_topology(trans, b);
@@ -2527,7 +2531,7 @@ static int __bch2_btree_node_update_key(struct btree_trans *trans,
 		if (ret)
 			goto err;
 	} else {
-		BUG_ON(btree_node_root(c, b) != b);
+		BUG_ON(!btree_node_is_root(c, b));
 
 		struct jset_entry *e = bch2_trans_jset_entry_alloc(trans,
 				       jset_u64s(new_key->k.u64s));
-- 
2.51.0


From ee176dea43ba0797bc69a9a658e9be52e9a58ee8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 1 Aug 2025 16:22:33 -0400
Subject: [PATCH 221/309] bcachefs: btree_check_root_boundaries()

Check and repair btree root min/max.

Reported-by: syzbot+9eb4c69fd4d4a1934f3a@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_gc.c         | 38 +++++++++++++++++++++++++++++++++-
 fs/bcachefs/sb-errors_format.h |  4 +++-
 2 files changed, 40 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index ce3c7750a922..6b91649688da 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -282,6 +282,41 @@ static int btree_check_node_boundaries(struct btree_trans *trans, struct btree *
 	return ret;
 }
 
+static int btree_check_root_boundaries(struct btree_trans *trans, struct btree *b)
+{
+	struct bch_fs *c = trans->c;
+	struct printbuf buf = PRINTBUF;
+	int ret = 0;
+
+	BUG_ON(b->key.k.type == KEY_TYPE_btree_ptr_v2 &&
+	       !bpos_eq(bkey_i_to_btree_ptr_v2(&b->key)->v.min_key,
+			b->data->min_key));
+
+	prt_str(&buf, "  at ");
+	bch2_btree_pos_to_text(&buf, c, b);
+
+	if (mustfix_fsck_err_on(!bpos_eq(b->data->min_key, POS_MIN),
+				trans, btree_node_topology_bad_root_min_key,
+			     "btree root with incorrect min_key%s", buf.buf)) {
+		ret = set_node_min(c, b, POS_MIN);
+		if (ret)
+			goto err;
+	}
+
+	if (mustfix_fsck_err_on(!bpos_eq(b->data->max_key, SPOS_MAX),
+				trans, btree_node_topology_bad_root_max_key,
+			     "btree root with incorrect min_key%s", buf.buf)) {
+		ret = set_node_max(c, b, SPOS_MAX);
+		if (ret)
+			goto err;
+	}
+
+err:
+fsck_err:
+	printbuf_exit(&buf);
+	return ret;
+}
+
 static int btree_repair_node_end(struct btree_trans *trans, struct btree *b,
 				 struct btree *child, struct bpos *pulled_from_scan)
 {
@@ -586,7 +621,8 @@ int bch2_check_topology(struct bch_fs *c)
 		struct btree *b = r->b;
 
 		btree_node_lock_nopath_nofail(trans, &b->c, SIX_LOCK_read);
-		ret = bch2_btree_repair_topology_recurse(trans, b, &pulled_from_scan);
+		ret =   btree_check_root_boundaries(trans, b) ?:
+			bch2_btree_repair_topology_recurse(trans, b, &pulled_from_scan);
 		six_unlock_read(&b->c.lock);
 
 		if (bch2_err_matches(ret, BCH_ERR_topology_repair_drop_this_node)) {
diff --git a/fs/bcachefs/sb-errors_format.h b/fs/bcachefs/sb-errors_format.h
index dd4ee46606d7..5317b1bfe2e5 100644
--- a/fs/bcachefs/sb-errors_format.h
+++ b/fs/bcachefs/sb-errors_format.h
@@ -76,6 +76,8 @@ enum bch_fsck_flags {
 	x(btree_node_read_error,				 62,	FSCK_AUTOFIX)	\
 	x(btree_node_topology_bad_min_key,			 63,	FSCK_AUTOFIX)	\
 	x(btree_node_topology_bad_max_key,			 64,	FSCK_AUTOFIX)	\
+	x(btree_node_topology_bad_root_min_key,			 323,	FSCK_AUTOFIX)	\
+	x(btree_node_topology_bad_root_max_key,			 324,	FSCK_AUTOFIX)	\
 	x(btree_node_topology_overwritten_by_prev_node,		 65,	FSCK_AUTOFIX)	\
 	x(btree_node_topology_overwritten_by_next_node,		 66,	FSCK_AUTOFIX)	\
 	x(btree_node_topology_interior_node_empty,		 67,	FSCK_AUTOFIX)	\
@@ -334,7 +336,7 @@ enum bch_fsck_flags {
 	x(dirent_stray_data_after_cf_name,			305,	0)		\
 	x(rebalance_work_incorrectly_set,			309,	FSCK_AUTOFIX)	\
 	x(rebalance_work_incorrectly_unset,			310,	FSCK_AUTOFIX)	\
-	x(MAX,							323,	0)
+	x(MAX,							325,	0)
 
 enum bch_sb_error_id {
 #define x(t, n, ...) BCH_FSCK_ERR_##t = n,
-- 
2.51.0


From 62649c460728db8610e73cf00990fd454e5c34f3 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Sat, 2 Aug 2025 13:05:11 +0800
Subject: [PATCH 222/309] bcachefs: Fix incorrect transaction handling

The ')' before the second '?:' is not correct, transaction restart
handling should include bch2_inode_hash_init_insert.

Reported-by: syzbot+d3fa2fb715cfcc9d201d@syzkaller.appspotmail.com
Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index 3b289f696612..b5e3090f1cb8 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -511,8 +511,8 @@ struct inode *bch2_vfs_inode_get(struct bch_fs *c, subvol_inum inum)
 	struct bch_subvolume subvol;
 	int ret = lockrestart_do(trans,
 		bch2_subvolume_get(trans, inum.subvol, true, &subvol) ?:
-		bch2_inode_find_by_inum_trans(trans, inum, &inode_u)) ?:
-		PTR_ERR_OR_ZERO(inode = bch2_inode_hash_init_insert(trans, inum, &inode_u, &subvol));
+		bch2_inode_find_by_inum_trans(trans, inum, &inode_u) ?:
+		PTR_ERR_OR_ZERO(inode = bch2_inode_hash_init_insert(trans, inum, &inode_u, &subvol)));
 
 	return ret ? ERR_PTR(ret) : &inode->v;
 }
-- 
2.51.0


From 79760fca5dfeeca689c2773d9bcc57362c9fc487 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 2 Aug 2025 11:28:31 -0400
Subject: [PATCH 223/309] bcachefs: Return proper error from
 bch2_snapshot_node_delete()

Not a functional issue; we called fs_inconsistent() which goes emergency
read-only, but fixing it may give better error messages in later
codepaths and it's the right thing to do.

Reported-by: kernel test robot <lkp@intel.com>
Reported-by: Dan Carpenter <dan.carpenter@linaro.org>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/errcode.h  | 1 +
 fs/bcachefs/snapshot.c | 2 +-
 2 files changed, 2 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/errcode.h b/fs/bcachefs/errcode.h
index cec8b0f47d3d..adc1f9315eab 100644
--- a/fs/bcachefs/errcode.h
+++ b/fs/bcachefs/errcode.h
@@ -119,6 +119,7 @@
 	x(ENOENT,			ENOENT_not_directory)			\
 	x(ENOENT,			ENOENT_directory_dead)			\
 	x(ENOENT,			ENOENT_subvolume)			\
+	x(ENOENT,			ENOENT_snapshot)			\
 	x(ENOENT,			ENOENT_snapshot_tree)			\
 	x(ENOENT,			ENOENT_dirent_doesnt_match_inode)	\
 	x(ENOENT,			ENOENT_dev_not_found)			\
diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 5a1f81749661..84f987d3a02a 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -1146,7 +1146,7 @@ static int bch2_snapshot_node_delete(struct btree_trans *trans, u32 id)
 		if (bch2_fs_inconsistent_on(i == 2, c,
 					"snapshot %u missing child pointer to %u",
 					parent_id, id))
-			return ret;
+			return bch_err_throw(c, ENOENT_snapshot);
 
 		parent->v.children[i] = cpu_to_le32(child_id);
 
-- 
2.51.0


From e8cf1d67dd28012921f7fd815bf6ebd587f53216 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 1 Aug 2025 22:35:58 -0400
Subject: [PATCH 224/309] bcachefs: bch2_member_to_text()

Factor out a helper for bcachefs-tools, for improving show-super.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-members.c | 116 +++++++++++++++++----------------------
 fs/bcachefs/sb-members.h |  25 +++++++++
 2 files changed, 76 insertions(+), 65 deletions(-)

diff --git a/fs/bcachefs/sb-members.c b/fs/bcachefs/sb-members.c
index 0573c7b00151..e3c73d903898 100644
--- a/fs/bcachefs/sb-members.c
+++ b/fs/bcachefs/sb-members.c
@@ -68,34 +68,13 @@ struct bch_member *bch2_members_v2_get_mut(struct bch_sb *sb, int i)
 	return __bch2_members_v2_get_mut(bch2_sb_field_get(sb, members_v2), i);
 }
 
-static struct bch_member members_v2_get(struct bch_sb_field_members_v2 *mi, int i)
-{
-	struct bch_member ret, *p = __bch2_members_v2_get_mut(mi, i);
-	memset(&ret, 0, sizeof(ret));
-	memcpy(&ret, p, min_t(size_t, le16_to_cpu(mi->member_bytes), sizeof(ret)));
-	return ret;
-}
-
-static struct bch_member *members_v1_get_mut(struct bch_sb_field_members_v1 *mi, int i)
-{
-	return (void *) mi->_members + (i * BCH_MEMBER_V1_BYTES);
-}
-
-static struct bch_member members_v1_get(struct bch_sb_field_members_v1 *mi, int i)
-{
-	struct bch_member ret, *p = members_v1_get_mut(mi, i);
-	memset(&ret, 0, sizeof(ret));
-	memcpy(&ret, p, min_t(size_t, BCH_MEMBER_V1_BYTES, sizeof(ret)));
-	return ret;
-}
-
 struct bch_member bch2_sb_member_get(struct bch_sb *sb, int i)
 {
 	struct bch_sb_field_members_v2 *mi2 = bch2_sb_field_get(sb, members_v2);
 	if (mi2)
-		return members_v2_get(mi2, i);
+		return bch2_members_v2_get(mi2, i);
 	struct bch_sb_field_members_v1 *mi1 = bch2_sb_field_get(sb, members_v1);
-	return members_v1_get(mi1, i);
+	return bch2_members_v1_get(mi1, i);
 }
 
 static int sb_members_v2_resize_entries(struct bch_fs *c)
@@ -211,33 +190,25 @@ static int validate_member(struct printbuf *err,
 	return 0;
 }
 
-static void member_to_text(struct printbuf *out,
-			   struct bch_member m,
-			   struct bch_sb_field_disk_groups *gi,
-			   struct bch_sb *sb,
-			   int i)
+void bch2_member_to_text(struct printbuf *out,
+			 struct bch_member *m,
+			 struct bch_sb_field_disk_groups *gi,
+			 struct bch_sb *sb,
+			 unsigned idx)
 {
-	unsigned data_have = bch2_sb_dev_has_data(sb, i);
-	u64 bucket_size = le16_to_cpu(m.bucket_size);
-	u64 device_size = le64_to_cpu(m.nbuckets) * bucket_size;
-
-	if (!bch2_member_alive(&m))
-		return;
-
-	prt_printf(out, "Device:\t%u\n", i);
-
-	printbuf_indent_add(out, 2);
+	u64 bucket_size = le16_to_cpu(m->bucket_size);
+	u64 device_size = le64_to_cpu(m->nbuckets) * bucket_size;
 
 	prt_printf(out, "Label:\t");
-	if (BCH_MEMBER_GROUP(&m))
+	if (BCH_MEMBER_GROUP(m))
 		bch2_disk_path_to_text_sb(out, sb,
-				BCH_MEMBER_GROUP(&m) - 1);
+				BCH_MEMBER_GROUP(m) - 1);
 	else
 		prt_printf(out, "(none)");
 	prt_newline(out);
 
 	prt_printf(out, "UUID:\t");
-	pr_uuid(out, m.uuid.b);
+	pr_uuid(out, m->uuid.b);
 	prt_newline(out);
 
 	prt_printf(out, "Size:\t");
@@ -245,40 +216,41 @@ static void member_to_text(struct printbuf *out,
 	prt_newline(out);
 
 	for (unsigned i = 0; i < BCH_MEMBER_ERROR_NR; i++)
-		prt_printf(out, "%s errors:\t%llu\n", bch2_member_error_strs[i], le64_to_cpu(m.errors[i]));
+		prt_printf(out, "%s errors:\t%llu\n", bch2_member_error_strs[i], le64_to_cpu(m->errors[i]));
 
 	for (unsigned i = 0; i < BCH_IOPS_NR; i++)
-		prt_printf(out, "%s iops:\t%u\n", bch2_iops_measurements[i], le32_to_cpu(m.iops[i]));
+		prt_printf(out, "%s iops:\t%u\n", bch2_iops_measurements[i], le32_to_cpu(m->iops[i]));
 
 	prt_printf(out, "Bucket size:\t");
 	prt_units_u64(out, bucket_size << 9);
 	prt_newline(out);
 
-	prt_printf(out, "First bucket:\t%u\n", le16_to_cpu(m.first_bucket));
-	prt_printf(out, "Buckets:\t%llu\n", le64_to_cpu(m.nbuckets));
+	prt_printf(out, "First bucket:\t%u\n", le16_to_cpu(m->first_bucket));
+	prt_printf(out, "Buckets:\t%llu\n", le64_to_cpu(m->nbuckets));
 
 	prt_printf(out, "Last mount:\t");
-	if (m.last_mount)
-		bch2_prt_datetime(out, le64_to_cpu(m.last_mount));
+	if (m->last_mount)
+		bch2_prt_datetime(out, le64_to_cpu(m->last_mount));
 	else
 		prt_printf(out, "(never)");
 	prt_newline(out);
 
-	prt_printf(out, "Last superblock write:\t%llu\n", le64_to_cpu(m.seq));
+	prt_printf(out, "Last superblock write:\t%llu\n", le64_to_cpu(m->seq));
 
 	prt_printf(out, "State:\t%s\n",
-		   BCH_MEMBER_STATE(&m) < BCH_MEMBER_STATE_NR
-		   ? bch2_member_states[BCH_MEMBER_STATE(&m)]
+		   BCH_MEMBER_STATE(m) < BCH_MEMBER_STATE_NR
+		   ? bch2_member_states[BCH_MEMBER_STATE(m)]
 		   : "unknown");
 
 	prt_printf(out, "Data allowed:\t");
-	if (BCH_MEMBER_DATA_ALLOWED(&m))
-		prt_bitflags(out, __bch2_data_types, BCH_MEMBER_DATA_ALLOWED(&m));
+	if (BCH_MEMBER_DATA_ALLOWED(m))
+		prt_bitflags(out, __bch2_data_types, BCH_MEMBER_DATA_ALLOWED(m));
 	else
 		prt_printf(out, "(none)");
 	prt_newline(out);
 
 	prt_printf(out, "Has data:\t");
+	unsigned data_have = bch2_sb_dev_has_data(sb, idx);
 	if (data_have)
 		prt_bitflags(out, __bch2_data_types, data_have);
 	else
@@ -286,22 +258,36 @@ static void member_to_text(struct printbuf *out,
 	prt_newline(out);
 
 	prt_printf(out, "Btree allocated bitmap blocksize:\t");
-	if (m.btree_bitmap_shift < 64)
-		prt_units_u64(out, 1ULL << m.btree_bitmap_shift);
+	if (m->btree_bitmap_shift < 64)
+		prt_units_u64(out, 1ULL << m->btree_bitmap_shift);
 	else
-		prt_printf(out, "(invalid shift %u)", m.btree_bitmap_shift);
+		prt_printf(out, "(invalid shift %u)", m->btree_bitmap_shift);
 	prt_newline(out);
 
 	prt_printf(out, "Btree allocated bitmap:\t");
-	bch2_prt_u64_base2_nbits(out, le64_to_cpu(m.btree_allocated_bitmap), 64);
+	bch2_prt_u64_base2_nbits(out, le64_to_cpu(m->btree_allocated_bitmap), 64);
 	prt_newline(out);
 
-	prt_printf(out, "Durability:\t%llu\n", BCH_MEMBER_DURABILITY(&m) ? BCH_MEMBER_DURABILITY(&m) - 1 : 1);
+	prt_printf(out, "Durability:\t%llu\n", BCH_MEMBER_DURABILITY(m) ? BCH_MEMBER_DURABILITY(m) - 1 : 1);
+
+	prt_printf(out, "Discard:\t%llu\n", BCH_MEMBER_DISCARD(m));
+	prt_printf(out, "Freespace initialized:\t%llu\n", BCH_MEMBER_FREESPACE_INITIALIZED(m));
+	prt_printf(out, "Resize on mount:\t%llu\n", BCH_MEMBER_RESIZE_ON_MOUNT(m));
+}
+
+static void member_to_text(struct printbuf *out,
+			   struct bch_member m,
+			   struct bch_sb_field_disk_groups *gi,
+			   struct bch_sb *sb,
+			   unsigned idx)
+{
+	if (!bch2_member_alive(&m))
+		return;
 
-	prt_printf(out, "Discard:\t%llu\n", BCH_MEMBER_DISCARD(&m));
-	prt_printf(out, "Freespace initialized:\t%llu\n", BCH_MEMBER_FREESPACE_INITIALIZED(&m));
-	prt_printf(out, "Resize on mount:\t%llu\n", BCH_MEMBER_RESIZE_ON_MOUNT(&m));
+	prt_printf(out, "Device:\t%u\n", idx);
 
+	printbuf_indent_add(out, 2);
+	bch2_member_to_text(out, &m, gi, sb, idx);
 	printbuf_indent_sub(out, 2);
 }
 
@@ -317,7 +303,7 @@ static int bch2_sb_members_v1_validate(struct bch_sb *sb, struct bch_sb_field *f
 	}
 
 	for (i = 0; i < sb->nr_devices; i++) {
-		struct bch_member m = members_v1_get(mi, i);
+		struct bch_member m = bch2_members_v1_get(mi, i);
 
 		int ret = validate_member(err, m, sb, i);
 		if (ret)
@@ -343,7 +329,7 @@ static void bch2_sb_members_v1_to_text(struct printbuf *out, struct bch_sb *sb,
 		prt_printf(out, "nr_devices mismatch: have %i entries, should be %u", nr, sb->nr_devices);
 
 	for (unsigned i = 0; i < min(sb->nr_devices, nr); i++)
-		member_to_text(out, members_v1_get(mi, i), gi, sb, i);
+		member_to_text(out, bch2_members_v1_get(mi, i), gi, sb, i);
 }
 
 const struct bch_sb_field_ops bch_sb_field_ops_members_v1 = {
@@ -377,7 +363,7 @@ static void bch2_sb_members_v2_to_text(struct printbuf *out, struct bch_sb *sb,
 	 */
 
 	for (unsigned i = 0; i < min(sb->nr_devices, nr); i++)
-		member_to_text(out, members_v2_get(mi, i), gi, sb, i);
+		member_to_text(out, bch2_members_v2_get(mi, i), gi, sb, i);
 }
 
 static int bch2_sb_members_v2_validate(struct bch_sb *sb, struct bch_sb_field *f,
@@ -394,7 +380,7 @@ static int bch2_sb_members_v2_validate(struct bch_sb *sb, struct bch_sb_field *f
 	}
 
 	for (unsigned i = 0; i < sb->nr_devices; i++) {
-		int ret = validate_member(err, members_v2_get(mi, i), sb, i);
+		int ret = validate_member(err, bch2_members_v2_get(mi, i), sb, i);
 		if (ret)
 			return ret;
 	}
@@ -430,7 +416,7 @@ void bch2_sb_members_to_cpu(struct bch_fs *c)
 	struct bch_sb_field_members_v2 *mi2 = bch2_sb_field_get(c->disk_sb.sb, members_v2);
 	if (mi2)
 		for (unsigned i = 0; i < c->sb.nr_devices; i++) {
-			struct bch_member m = members_v2_get(mi2, i);
+			struct bch_member m = bch2_members_v2_get(mi2, i);
 			bool removed = uuid_equal(&m.uuid, &BCH_SB_MEMBER_DELETED_UUID);
 			mod_bit(i, c->devs_removed.d, removed);
 		}
diff --git a/fs/bcachefs/sb-members.h b/fs/bcachefs/sb-members.h
index 35d4ab9b6197..6de999cf71cb 100644
--- a/fs/bcachefs/sb-members.h
+++ b/fs/bcachefs/sb-members.h
@@ -14,11 +14,36 @@ __bch2_members_v2_get_mut(struct bch_sb_field_members_v2 *mi, unsigned i)
 	return (void *) mi->_members + (i * le16_to_cpu(mi->member_bytes));
 }
 
+static inline struct bch_member bch2_members_v2_get(struct bch_sb_field_members_v2 *mi, int i)
+{
+	struct bch_member ret, *p = __bch2_members_v2_get_mut(mi, i);
+	memset(&ret, 0, sizeof(ret));
+	memcpy(&ret, p, min_t(size_t, le16_to_cpu(mi->member_bytes), sizeof(ret)));
+	return ret;
+}
+
+static inline struct bch_member *members_v1_get_mut(struct bch_sb_field_members_v1 *mi, int i)
+{
+	return (void *) mi->_members + (i * BCH_MEMBER_V1_BYTES);
+}
+
+static inline struct bch_member bch2_members_v1_get(struct bch_sb_field_members_v1 *mi, int i)
+{
+	struct bch_member ret, *p = members_v1_get_mut(mi, i);
+	memset(&ret, 0, sizeof(ret));
+	memcpy(&ret, p, min_t(size_t, BCH_MEMBER_V1_BYTES, sizeof(ret)));
+	return ret;
+}
+
 int bch2_sb_members_v2_init(struct bch_fs *c);
 int bch2_sb_members_cpy_v2_v1(struct bch_sb_handle *disk_sb);
 struct bch_member *bch2_members_v2_get_mut(struct bch_sb *sb, int i);
 struct bch_member bch2_sb_member_get(struct bch_sb *sb, int i);
 
+void bch2_member_to_text(struct printbuf *, struct bch_member *,
+			 struct bch_sb_field_disk_groups *,
+			 struct bch_sb *, unsigned);
+
 static inline bool bch2_dev_is_online(struct bch_dev *ca)
 {
 	return !enumerated_ref_is_zero(&ca->io_ref[READ]);
-- 
2.51.0


From 6cb7c709a6db5d1d7cef99908511302a237b457d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 2 Aug 2025 15:02:09 -0400
Subject: [PATCH 225/309] bcachefs: BCH_COUNTER_io_move_drop_only

Add two more counters for bch2_move_extent() exit paths that weren't
covered by other counters: every distinct way an io move completes needs
a counter.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/move.c               | 8 ++++++--
 fs/bcachefs/sb-counters_format.h | 2 ++
 2 files changed, 8 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index a38996f5366f..30fe269d531d 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -344,9 +344,13 @@ int bch2_move_extent(struct moving_context *ctxt,
 	if (!data_opts.rewrite_ptrs &&
 	    !data_opts.extra_replicas &&
 	    !data_opts.scrub) {
-		if (data_opts.kill_ptrs)
+		if (data_opts.kill_ptrs) {
+			this_cpu_add(c->counters[BCH_COUNTER_io_move_drop_only], k.k->size);
 			return bch2_extent_drop_ptrs(trans, iter, k, &io_opts, &data_opts);
-		return 0;
+		} else {
+			this_cpu_add(c->counters[BCH_COUNTER_io_move_noop], k.k->size);
+			return 0;
+		}
 	}
 
 	struct moving_io *io = allocate_dropping_locks(trans, ret,
diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index 2e3a56bfd085..f3ea53a55384 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -31,6 +31,8 @@ enum counters_flags {
 	x(io_move_fail,					38,	TYPE_COUNTER)	\
 	x(io_move_write_fail,				82,	TYPE_COUNTER)	\
 	x(io_move_start_fail,				39,	TYPE_COUNTER)	\
+	x(io_move_drop_only,				91,	TYPE_COUNTER)	\
+	x(io_move_noop,					92,	TYPE_COUNTER)	\
 	x(io_move_created_rebalance,			83,	TYPE_COUNTER)	\
 	x(io_move_evacuate_bucket,			84,	TYPE_COUNTER)	\
 	x(bucket_invalidate,				3,	TYPE_COUNTER)	\
-- 
2.51.0


From ac0e3289b6ce987a599f856fe29d683d4fa2ceb5 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 2 Aug 2025 21:01:28 -0400
Subject: [PATCH 226/309] bcachefs: bch2_fs_opt_version_init()

Centralize startup code for handling upgrades/downgrades, logging what
we're doing, and handling mount options, and call it from bch2_fs_alloc,
not when we start recovery - to fix "attempting to write superblock on
filesystem that wasn't version downgraded" when we use a filesystem
without starting it.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c | 193 +------------------------
 fs/bcachefs/super.c    | 314 ++++++++++++++++++++++++++++++++---------
 2 files changed, 246 insertions(+), 261 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index c57ff235a97a..21aa2edb13ac 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -626,93 +626,6 @@ static int read_btree_roots(struct bch_fs *c)
 	return ret;
 }
 
-static bool check_version_upgrade(struct bch_fs *c)
-{
-	unsigned latest_version	= bcachefs_metadata_version_current;
-	unsigned latest_compatible = min(latest_version,
-					 bch2_latest_compatible_version(c->sb.version));
-	unsigned old_version = c->sb.version_upgrade_complete ?: c->sb.version;
-	unsigned new_version = 0;
-	bool ret = false;
-
-	if (old_version < bcachefs_metadata_required_upgrade_below) {
-		if (c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible ||
-		    latest_compatible < bcachefs_metadata_required_upgrade_below)
-			new_version = latest_version;
-		else
-			new_version = latest_compatible;
-	} else {
-		switch (c->opts.version_upgrade) {
-		case BCH_VERSION_UPGRADE_compatible:
-			new_version = latest_compatible;
-			break;
-		case BCH_VERSION_UPGRADE_incompatible:
-			new_version = latest_version;
-			break;
-		case BCH_VERSION_UPGRADE_none:
-			new_version = min(old_version, latest_version);
-			break;
-		}
-	}
-
-	if (new_version > old_version) {
-		CLASS(printbuf, buf)();
-
-		if (old_version < bcachefs_metadata_required_upgrade_below)
-			prt_str(&buf, "Version upgrade required:\n");
-
-		if (old_version != c->sb.version) {
-			prt_str(&buf, "Version upgrade from ");
-			bch2_version_to_text(&buf, c->sb.version_upgrade_complete);
-			prt_str(&buf, " to ");
-			bch2_version_to_text(&buf, c->sb.version);
-			prt_str(&buf, " incomplete\n");
-		}
-
-		prt_printf(&buf, "Doing %s version upgrade from ",
-			   BCH_VERSION_MAJOR(old_version) != BCH_VERSION_MAJOR(new_version)
-			   ? "incompatible" : "compatible");
-		bch2_version_to_text(&buf, old_version);
-		prt_str(&buf, " to ");
-		bch2_version_to_text(&buf, new_version);
-		prt_newline(&buf);
-
-		struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
-		__le64 passes = ext->recovery_passes_required[0];
-		bch2_sb_set_upgrade(c, old_version, new_version);
-		passes = ext->recovery_passes_required[0] & ~passes;
-
-		if (passes) {
-			prt_str(&buf, "  running recovery passes: ");
-			prt_bitflags(&buf, bch2_recovery_passes,
-				     bch2_recovery_passes_from_stable(le64_to_cpu(passes)));
-		}
-
-		bch_notice(c, "%s", buf.buf);
-		ret = true;
-	}
-
-	if (new_version > c->sb.version_incompat_allowed &&
-	    c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible) {
-		CLASS(printbuf, buf)();
-
-		prt_str(&buf, "Now allowing incompatible features up to ");
-		bch2_version_to_text(&buf, new_version);
-		prt_str(&buf, ", previously allowed up to ");
-		bch2_version_to_text(&buf, c->sb.version_incompat_allowed);
-		prt_newline(&buf);
-
-		bch_notice(c, "%s", buf.buf);
-		ret = true;
-	}
-
-	if (ret)
-		bch2_sb_upgrade(c, new_version,
-				c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible);
-
-	return ret;
-}
-
 int bch2_fs_recovery(struct bch_fs *c)
 {
 	struct bch_sb_field_clean *clean = NULL;
@@ -732,108 +645,6 @@ int bch2_fs_recovery(struct bch_fs *c)
 		bch_info(c, "recovering from unclean shutdown");
 	}
 
-	if (!(c->sb.features & (1ULL << BCH_FEATURE_new_extent_overwrite))) {
-		bch_err(c, "feature new_extent_overwrite not set, filesystem no longer supported");
-		ret = -EINVAL;
-		goto err;
-	}
-
-	if (!c->sb.clean &&
-	    !(c->sb.features & (1ULL << BCH_FEATURE_extents_above_btree_updates))) {
-		bch_err(c, "filesystem needs recovery from older version; run fsck from older bcachefs-tools to fix");
-		ret = -EINVAL;
-		goto err;
-	}
-
-	if (c->opts.norecovery) {
-		c->opts.recovery_pass_last = c->opts.recovery_pass_last
-			? min(c->opts.recovery_pass_last, BCH_RECOVERY_PASS_snapshots_read)
-			: BCH_RECOVERY_PASS_snapshots_read;
-		c->opts.nochanges = true;
-	}
-
-	if (c->opts.nochanges)
-		c->opts.read_only = true;
-
-	if (c->opts.journal_rewind) {
-		bch_info(c, "rewinding journal, fsck required");
-		c->opts.fsck = true;
-	}
-
-	if (go_rw_in_recovery(c)) {
-		/*
-		 * start workqueues/kworkers early - kthread creation checks for
-		 * pending signals, which is _very_ annoying
-		 */
-		ret = bch2_fs_init_rw(c);
-		if (ret)
-			goto err;
-	}
-
-	mutex_lock(&c->sb_lock);
-	struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
-	bool write_sb = false;
-
-	if (BCH_SB_HAS_TOPOLOGY_ERRORS(c->disk_sb.sb)) {
-		ext->recovery_passes_required[0] |=
-			cpu_to_le64(bch2_recovery_passes_to_stable(BIT_ULL(BCH_RECOVERY_PASS_check_topology)));
-		write_sb = true;
-	}
-
-	u64 sb_passes = bch2_recovery_passes_from_stable(le64_to_cpu(ext->recovery_passes_required[0]));
-	if (sb_passes) {
-		CLASS(printbuf, buf)();
-		prt_str(&buf, "superblock requires following recovery passes to be run:\n  ");
-		prt_bitflags(&buf, bch2_recovery_passes, sb_passes);
-		bch_info(c, "%s", buf.buf);
-	}
-
-	if (bch2_check_version_downgrade(c)) {
-		CLASS(printbuf, buf)();
-
-		prt_str(&buf, "Version downgrade required:");
-
-		__le64 passes = ext->recovery_passes_required[0];
-		bch2_sb_set_downgrade(c,
-				      BCH_VERSION_MINOR(bcachefs_metadata_version_current),
-				      BCH_VERSION_MINOR(c->sb.version));
-		passes = ext->recovery_passes_required[0] & ~passes;
-		if (passes) {
-			prt_str(&buf, "\n  running recovery passes: ");
-			prt_bitflags(&buf, bch2_recovery_passes,
-				     bch2_recovery_passes_from_stable(le64_to_cpu(passes)));
-		}
-
-		bch_info(c, "%s", buf.buf);
-		write_sb = true;
-	}
-
-	if (check_version_upgrade(c))
-		write_sb = true;
-
-	c->opts.recovery_passes |= bch2_recovery_passes_from_stable(le64_to_cpu(ext->recovery_passes_required[0]));
-
-	if (c->sb.version_upgrade_complete < bcachefs_metadata_version_autofix_errors) {
-		SET_BCH_SB_ERROR_ACTION(c->disk_sb.sb, BCH_ON_ERROR_fix_safe);
-		write_sb = true;
-	}
-
-	if (write_sb)
-		bch2_write_super(c);
-	mutex_unlock(&c->sb_lock);
-
-	if (c->sb.clean)
-		set_bit(BCH_FS_clean_recovery, &c->flags);
-	if (c->opts.fsck)
-		set_bit(BCH_FS_in_fsck, &c->flags);
-	set_bit(BCH_FS_in_recovery, &c->flags);
-
-	ret = bch2_blacklist_table_initialize(c);
-	if (ret) {
-		bch_err(c, "error initializing blacklist table");
-		goto err;
-	}
-
 	bch2_journal_pos_from_member_info_resume(c);
 
 	if (!c->sb.clean || c->opts.retain_recovery_info) {
@@ -1053,8 +864,8 @@ int bch2_fs_recovery(struct bch_fs *c)
 	}
 
 	mutex_lock(&c->sb_lock);
-	ext = bch2_sb_field_get(c->disk_sb.sb, ext);
-	write_sb = false;
+	struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
+	bool write_sb = false;
 
 	if (BCH_SB_VERSION_UPGRADE_COMPLETE(c->disk_sb.sb) != le16_to_cpu(c->disk_sb.sb->version)) {
 		SET_BCH_SB_VERSION_UPGRADE_COMPLETE(c->disk_sb.sb, le16_to_cpu(c->disk_sb.sb->version));
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index b0019488f586..ef15e614f4f3 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -55,6 +55,7 @@
 #include "replicas.h"
 #include "sb-clean.h"
 #include "sb-counters.h"
+#include "sb-downgrade.h"
 #include "sb-errors.h"
 #include "sb-members.h"
 #include "snapshot.h"
@@ -842,6 +843,233 @@ int bch2_fs_init_rw(struct bch_fs *c)
 	return 0;
 }
 
+static bool check_version_upgrade(struct bch_fs *c)
+{
+	unsigned latest_version	= bcachefs_metadata_version_current;
+	unsigned latest_compatible = min(latest_version,
+					 bch2_latest_compatible_version(c->sb.version));
+	unsigned old_version = c->sb.version_upgrade_complete ?: c->sb.version;
+	unsigned new_version = 0;
+	bool ret = false;
+
+	if (old_version < bcachefs_metadata_required_upgrade_below) {
+		if (c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible ||
+		    latest_compatible < bcachefs_metadata_required_upgrade_below)
+			new_version = latest_version;
+		else
+			new_version = latest_compatible;
+	} else {
+		switch (c->opts.version_upgrade) {
+		case BCH_VERSION_UPGRADE_compatible:
+			new_version = latest_compatible;
+			break;
+		case BCH_VERSION_UPGRADE_incompatible:
+			new_version = latest_version;
+			break;
+		case BCH_VERSION_UPGRADE_none:
+			new_version = min(old_version, latest_version);
+			break;
+		}
+	}
+
+	if (new_version > old_version) {
+		CLASS(printbuf, buf)();
+
+		if (old_version < bcachefs_metadata_required_upgrade_below)
+			prt_str(&buf, "Version upgrade required:\n");
+
+		if (old_version != c->sb.version) {
+			prt_str(&buf, "Version upgrade from ");
+			bch2_version_to_text(&buf, c->sb.version_upgrade_complete);
+			prt_str(&buf, " to ");
+			bch2_version_to_text(&buf, c->sb.version);
+			prt_str(&buf, " incomplete\n");
+		}
+
+		prt_printf(&buf, "Doing %s version upgrade from ",
+			   BCH_VERSION_MAJOR(old_version) != BCH_VERSION_MAJOR(new_version)
+			   ? "incompatible" : "compatible");
+		bch2_version_to_text(&buf, old_version);
+		prt_str(&buf, " to ");
+		bch2_version_to_text(&buf, new_version);
+		prt_newline(&buf);
+
+		struct bch_sb_field_ext *ext = bch2_sb_field_get(c->disk_sb.sb, ext);
+		__le64 passes = ext->recovery_passes_required[0];
+		bch2_sb_set_upgrade(c, old_version, new_version);
+		passes = ext->recovery_passes_required[0] & ~passes;
+
+		if (passes) {
+			prt_str(&buf, "  running recovery passes: ");
+			prt_bitflags(&buf, bch2_recovery_passes,
+				     bch2_recovery_passes_from_stable(le64_to_cpu(passes)));
+		}
+
+		bch_notice(c, "%s", buf.buf);
+		ret = true;
+	}
+
+	if (new_version > c->sb.version_incompat_allowed &&
+	    c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible) {
+		CLASS(printbuf, buf)();
+
+		prt_str(&buf, "Now allowing incompatible features up to ");
+		bch2_version_to_text(&buf, new_version);
+		prt_str(&buf, ", previously allowed up to ");
+		bch2_version_to_text(&buf, c->sb.version_incompat_allowed);
+		prt_newline(&buf);
+
+		bch_notice(c, "%s", buf.buf);
+		ret = true;
+	}
+
+	if (ret)
+		bch2_sb_upgrade(c, new_version,
+				c->opts.version_upgrade == BCH_VERSION_UPGRADE_incompatible);
+
+	return ret;
+}
+
+noinline_for_stack
+static int bch2_fs_opt_version_init(struct bch_fs *c)
+{
+	int ret = 0;
+
+	if (c->opts.norecovery) {
+		c->opts.recovery_pass_last = c->opts.recovery_pass_last
+			? min(c->opts.recovery_pass_last, BCH_RECOVERY_PASS_snapshots_read)
+			: BCH_RECOVERY_PASS_snapshots_read;
+		c->opts.nochanges = true;
+	}
+
+	if (c->opts.nochanges)
+		c->opts.read_only = true;
+
+	if (c->opts.journal_rewind)
+		c->opts.fsck = true;
+
+	CLASS(printbuf, p)();
+	bch2_log_msg_start(c, &p);
+
+	prt_str(&p, "starting version ");
+	bch2_version_to_text(&p, c->sb.version);
+
+	bool first = true;
+	for (enum bch_opt_id i = 0; i < bch2_opts_nr; i++) {
+		const struct bch_option *opt = &bch2_opt_table[i];
+		u64 v = bch2_opt_get_by_id(&c->opts, i);
+
+		if (!(opt->flags & OPT_MOUNT))
+			continue;
+
+		if (v == bch2_opt_get_by_id(&bch2_opts_default, i))
+			continue;
+
+		prt_str(&p, first ? " opts=" : ",");
+		first = false;
+		bch2_opt_to_text(&p, c, c->disk_sb.sb, opt, v, OPT_SHOW_MOUNT_STYLE);
+	}
+
+	if (c->sb.version_incompat_allowed != c->sb.version) {
+		prt_printf(&p, "\nallowing incompatible features above ");
+		bch2_version_to_text(&p, c->sb.version_incompat_allowed);
+	}
+
+	if (c->opts.verbose) {
+		prt_printf(&p, "\nfeatures: ");
+		prt_bitflags(&p, bch2_sb_features, c->sb.features);
+	}
+
+	if (c->sb.multi_device) {
+		prt_printf(&p, "\nwith devices");
+		for_each_online_member(c, ca, BCH_DEV_READ_REF_bch2_online_devs) {
+			prt_char(&p, ' ');
+			prt_str(&p, ca->name);
+		}
+	}
+
+	if (c->cf_encoding)
+		prt_printf(&p, "\nUsing encoding defined by superblock: utf8-%u.%u.%u",
+			   unicode_major(BCH_FS_DEFAULT_UTF8_ENCODING),
+			   unicode_minor(BCH_FS_DEFAULT_UTF8_ENCODING),
+			   unicode_rev(BCH_FS_DEFAULT_UTF8_ENCODING));
+
+	if (c->opts.journal_rewind)
+		prt_printf(&p, "\nrewinding journal, fsck required");
+
+	scoped_guard(mutex, &c->sb_lock) {
+		struct bch_sb_field_ext *ext = bch2_sb_field_get_minsize(&c->disk_sb, ext,
+				sizeof(struct bch_sb_field_ext) / sizeof(u64));
+		if (!ext)
+			return bch_err_throw(c, ENOSPC_sb);
+
+		ret = bch2_sb_members_v2_init(c);
+		if (ret)
+			return ret;
+
+		__le64 now = cpu_to_le64(ktime_get_real_seconds());
+		for_each_online_member_rcu(c, ca)
+			bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx)->last_mount = now;
+
+		if (BCH_SB_HAS_TOPOLOGY_ERRORS(c->disk_sb.sb))
+			ext->recovery_passes_required[0] |=
+				cpu_to_le64(bch2_recovery_passes_to_stable(BIT_ULL(BCH_RECOVERY_PASS_check_topology)));
+
+		u64 sb_passes = bch2_recovery_passes_from_stable(le64_to_cpu(ext->recovery_passes_required[0]));
+		if (sb_passes) {
+			prt_str(&p, "\nsuperblock requires following recovery passes to be run:\n  ");
+			prt_bitflags(&p, bch2_recovery_passes, sb_passes);
+		}
+
+		if (bch2_check_version_downgrade(c)) {
+			prt_str(&p, "\nVersion downgrade required:");
+
+			__le64 passes = ext->recovery_passes_required[0];
+			bch2_sb_set_downgrade(c,
+					      BCH_VERSION_MINOR(bcachefs_metadata_version_current),
+					      BCH_VERSION_MINOR(c->sb.version));
+			passes = ext->recovery_passes_required[0] & ~passes;
+			if (passes) {
+				prt_str(&p, "\nrunning recovery passes: ");
+				prt_bitflags(&p, bch2_recovery_passes,
+					     bch2_recovery_passes_from_stable(le64_to_cpu(passes)));
+			}
+		}
+
+		check_version_upgrade(c);
+
+		c->opts.recovery_passes |= bch2_recovery_passes_from_stable(le64_to_cpu(ext->recovery_passes_required[0]));
+
+		if (c->sb.version_upgrade_complete < bcachefs_metadata_version_autofix_errors)
+			SET_BCH_SB_ERROR_ACTION(c->disk_sb.sb, BCH_ON_ERROR_fix_safe);
+
+		/* Don't write the superblock, defer that until we go rw */
+	}
+
+	if (c->sb.clean)
+		set_bit(BCH_FS_clean_recovery, &c->flags);
+	if (c->opts.fsck)
+		set_bit(BCH_FS_in_fsck, &c->flags);
+	set_bit(BCH_FS_in_recovery, &c->flags);
+
+	bch2_print_str(c, KERN_INFO, p.buf);
+
+	if (BCH_SB_INITIALIZED(c->disk_sb.sb)) {
+		if (!(c->sb.features & (1ULL << BCH_FEATURE_new_extent_overwrite))) {
+			bch_err(c, "feature new_extent_overwrite not set, filesystem no longer supported");
+			return -EINVAL;
+		}
+
+		if (!c->sb.clean &&
+		    !(c->sb.features & (1ULL << BCH_FEATURE_extents_above_btree_updates))) {
+			bch_err(c, "filesystem needs recovery from older version; run fsck from older bcachefs-tools to fix");
+			return -EINVAL;
+		}
+	}
+
+	return 0;
+}
+
 static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 				    bch_sb_handles *sbs)
 {
@@ -1013,6 +1241,7 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 
 	ret =
 	    bch2_fs_async_obj_init(c) ?:
+	    bch2_blacklist_table_initialize(c) ?:
 	    bch2_fs_btree_cache_init(c) ?:
 	    bch2_fs_btree_iter_init(c) ?:
 	    bch2_fs_btree_key_cache_init(&c->btree_key_cache) ?:
@@ -1063,7 +1292,7 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 	}
 #endif
 
-	for (i = 0; i < c->sb.nr_devices; i++) {
+	for (unsigned i = 0; i < c->sb.nr_devices; i++) {
 		if (!bch2_member_exists(c->disk_sb.sb, i))
 			continue;
 		ret = bch2_dev_alloc(c, i);
@@ -1078,6 +1307,20 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 			&c->clock_journal_res,
 			(sizeof(struct jset_entry_clock) / sizeof(u64)) * 2);
 
+	ret = bch2_fs_opt_version_init(c);
+	if (ret)
+		goto err;
+
+	/*
+	 * start workqueues/kworkers early - kthread creation checks for pending
+	 * signals, which is _very_ annoying
+	 */
+	if (go_rw_in_recovery(c)) {
+		ret = bch2_fs_init_rw(c);
+		if (ret)
+			goto err;
+	}
+
 	scoped_guard(mutex, &bch_fs_list_lock)
 		ret = bch2_fs_online(c);
 
@@ -1093,53 +1336,6 @@ static struct bch_fs *bch2_fs_alloc(struct bch_sb *sb, struct bch_opts *opts,
 	goto out;
 }
 
-noinline_for_stack
-static void print_mount_opts(struct bch_fs *c)
-{
-	enum bch_opt_id i;
-	CLASS(printbuf, p)();
-	bch2_log_msg_start(c, &p);
-
-	prt_str(&p, "starting version ");
-	bch2_version_to_text(&p, c->sb.version);
-
-	bool first = true;
-	for (i = 0; i < bch2_opts_nr; i++) {
-		const struct bch_option *opt = &bch2_opt_table[i];
-		u64 v = bch2_opt_get_by_id(&c->opts, i);
-
-		if (!(opt->flags & OPT_MOUNT))
-			continue;
-
-		if (v == bch2_opt_get_by_id(&bch2_opts_default, i))
-			continue;
-
-		prt_str(&p, first ? " opts=" : ",");
-		first = false;
-		bch2_opt_to_text(&p, c, c->disk_sb.sb, opt, v, OPT_SHOW_MOUNT_STYLE);
-	}
-
-	if (c->sb.version_incompat_allowed != c->sb.version) {
-		prt_printf(&p, "\nallowing incompatible features above ");
-		bch2_version_to_text(&p, c->sb.version_incompat_allowed);
-	}
-
-	if (c->opts.verbose) {
-		prt_printf(&p, "\nfeatures: ");
-		prt_bitflags(&p, bch2_sb_features, c->sb.features);
-	}
-
-	if (c->sb.multi_device) {
-		prt_printf(&p, "\nwith devices");
-		for_each_online_member(c, ca, BCH_DEV_READ_REF_bch2_online_devs) {
-			prt_char(&p, ' ');
-			prt_str(&p, ca->name);
-		}
-	}
-
-	bch2_print_str(c, KERN_INFO, p.buf);
-}
-
 static bool bch2_fs_may_start(struct bch_fs *c)
 {
 	struct bch_dev *ca;
@@ -1174,38 +1370,16 @@ static bool bch2_fs_may_start(struct bch_fs *c)
 
 int bch2_fs_start(struct bch_fs *c)
 {
-	time64_t now = ktime_get_real_seconds();
 	int ret = 0;
 
 	BUG_ON(test_bit(BCH_FS_started, &c->flags));
 
-	print_mount_opts(c);
-
-	if (c->cf_encoding)
-		bch_info(c, "Using encoding defined by superblock: utf8-%u.%u.%u",
-			 unicode_major(BCH_FS_DEFAULT_UTF8_ENCODING),
-			 unicode_minor(BCH_FS_DEFAULT_UTF8_ENCODING),
-			 unicode_rev(BCH_FS_DEFAULT_UTF8_ENCODING));
-
 	if (!bch2_fs_may_start(c))
 		return bch_err_throw(c, insufficient_devices_to_start);
 
 	scoped_guard(rwsem_write, &c->state_lock) {
-		guard(mutex)(&c->sb_lock);
-		if (!bch2_sb_field_get_minsize(&c->disk_sb, ext,
-				sizeof(struct bch_sb_field_ext) / sizeof(u64))) {
-			ret = bch_err_throw(c, ENOSPC_sb);
-			goto err;
-		}
-
-		ret = bch2_sb_members_v2_init(c);
-		if (ret)
-			goto err;
-
 		scoped_guard(rcu)
 			for_each_online_member_rcu(c, ca) {
-				bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx)->last_mount =
-					cpu_to_le64(now);
 				if (ca->mi.state == BCH_MEMBER_STATE_rw)
 					bch2_dev_allocator_add(c, ca);
 			}
-- 
2.51.0


From 669e288174b0c4f613bd9582b305d3f2ca24dfe2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sat, 2 Aug 2025 23:02:29 -0400
Subject: [PATCH 227/309] bcachefs: bch2_copygc_get_stripe_buckets()
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

It turns out, it's possible for a filesystem to run out of free space by
stranding disk space in stripes that have some blocks completely full
and others completely empty; previously, copygc didn't notice this.

This usually isn't a problem because new EC writes will reuse those
stripes, which releases the empty blocks. But if for some reason that
doesn't happen (perhaps we turned off EC? Perhaps we were very unlucky
with which extents got overwrote?), we want copygc to clean this up.

Now, copygc_dev_wait_amount checks for empty buckets of non-empty data
type (to pick up empty buckets that belong to a stripe), and we check if
there's overly much disk space stranded on stripes - if so, we evacuate
those.

Reported-by: Marcin Mirosaw <marcin@mejor.pl>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/lru.h      |  10 +++
 fs/bcachefs/movinggc.c | 188 ++++++++++++++++++++++++++++++-----------
 2 files changed, 151 insertions(+), 47 deletions(-)

diff --git a/fs/bcachefs/lru.h b/fs/bcachefs/lru.h
index 8abd0aa2083a..6f1e0a7b5db5 100644
--- a/fs/bcachefs/lru.h
+++ b/fs/bcachefs/lru.h
@@ -24,6 +24,16 @@ static inline struct bpos lru_pos(u16 lru_id, u64 dev_bucket, u64 time)
 	return pos;
 }
 
+static inline struct bpos lru_start(u16 lru_id)
+{
+	return lru_pos(lru_id, 0, 0);
+}
+
+static inline struct bpos lru_end(u16 lru_id)
+{
+	return lru_pos(lru_id, U64_MAX, LRU_TIME_MAX);
+}
+
 static inline enum bch_lru_type lru_type(struct bkey_s_c l)
 {
 	u16 lru_id = l.k->p.inode >> 48;
diff --git a/fs/bcachefs/movinggc.c b/fs/bcachefs/movinggc.c
index b0cbe3c1aab6..f36d60b8fb07 100644
--- a/fs/bcachefs/movinggc.c
+++ b/fs/bcachefs/movinggc.c
@@ -14,6 +14,7 @@
 #include "btree_write_buffer.h"
 #include "buckets.h"
 #include "clock.h"
+#include "ec.h"
 #include "errcode.h"
 #include "error.h"
 #include "lru.h"
@@ -131,72 +132,153 @@ static bool bucket_in_flight(struct buckets_in_flight *list,
 	return rhashtable_lookup_fast(list->table, &k, bch_move_bucket_params);
 }
 
+static int try_add_copygc_bucket(struct btree_trans *trans,
+				 struct buckets_in_flight *buckets_in_flight,
+				 struct bpos bucket, u64 lru_time)
+{
+	struct move_bucket b = { .k.bucket = bucket };
+
+	int ret = bch2_bucket_is_movable(trans, &b, lru_time);
+	if (ret <= 0)
+		return ret;
+
+	if (bucket_in_flight(buckets_in_flight, b.k))
+		return 0;
+
+	struct move_bucket *b_i = kmalloc(sizeof(*b_i), GFP_KERNEL);
+	if (!b_i)
+		return -ENOMEM;
+
+	*b_i = b;
+
+	ret = darray_push(&buckets_in_flight->to_evacuate, b_i);
+	if (ret) {
+		kfree(b_i);
+		return ret;
+	}
+
+	ret = rhashtable_lookup_insert_fast(buckets_in_flight->table, &b_i->hash,
+					    bch_move_bucket_params);
+	BUG_ON(ret);
+
+	size_t nr_to_get = max_t(size_t, 16U, buckets_in_flight->nr / 4);
+	return buckets_in_flight->to_evacuate.nr >= nr_to_get;
+}
+
 static int bch2_copygc_get_buckets(struct moving_context *ctxt,
 			struct buckets_in_flight *buckets_in_flight)
 {
 	struct btree_trans *trans = ctxt->trans;
-	struct bch_fs *c = trans->c;
-	size_t nr_to_get = max_t(size_t, 16U, buckets_in_flight->nr / 4);
-	size_t saw = 0, in_flight = 0, not_movable = 0, sectors = 0;
-	int ret;
 
-	move_buckets_wait(ctxt, buckets_in_flight, false);
+	int ret = for_each_btree_key_max(trans, iter, BTREE_ID_lru,
+				  lru_start(BCH_LRU_BUCKET_FRAGMENTATION),
+				  lru_end(BCH_LRU_BUCKET_FRAGMENTATION),
+				  0, k,
+		try_add_copygc_bucket(trans, buckets_in_flight,
+				      u64_to_bucket(k.k->p.offset),
+				      lru_pos_time(k.k->p))
+	);
 
-	ret = bch2_btree_write_buffer_tryflush(trans);
-	if (bch2_err_matches(ret, EROFS))
-		return ret;
+	return ret < 0 ? ret : 0;
+}
 
-	if (bch2_fs_fatal_err_on(ret, c, "%s: from bch2_btree_write_buffer_tryflush()", bch2_err_str(ret)))
-		return ret;
+static int bch2_copygc_get_stripe_buckets(struct moving_context *ctxt,
+			struct buckets_in_flight *buckets_in_flight)
+{
+	struct btree_trans *trans = ctxt->trans;
 
-	ret = for_each_btree_key_max(trans, iter, BTREE_ID_lru,
-				  lru_pos(BCH_LRU_BUCKET_FRAGMENTATION, 0, 0),
-				  lru_pos(BCH_LRU_BUCKET_FRAGMENTATION, U64_MAX, LRU_TIME_MAX),
-				  0, k, ({
-		struct move_bucket b = { .k.bucket = u64_to_bucket(k.k->p.offset) };
-		int ret2 = 0;
+	int ret = for_each_btree_key_max(trans, iter, BTREE_ID_lru,
+				  lru_start(BCH_LRU_STRIPE_FRAGMENTATION),
+				  lru_end(BCH_LRU_STRIPE_FRAGMENTATION),
+				  0, lru_k, ({
+		CLASS(btree_iter, s_iter)(trans, BTREE_ID_stripes, POS(0, lru_k.k->p.offset), 0);
+		struct bkey_s_c s_k = bch2_btree_iter_peek_slot(&s_iter);
+		int ret2 = bkey_err(s_k);
+		if (ret2)
+			goto err;
 
-		saw++;
+		if (s_k.k->type != KEY_TYPE_stripe)
+			continue;
 
-		ret2 = bch2_bucket_is_movable(trans, &b, lru_pos_time(k.k->p));
-		if (ret2 < 0)
-			goto err;
+		const struct bch_stripe *s = bkey_s_c_to_stripe(s_k).v;
 
-		if (!ret2)
-			not_movable++;
-		else if (bucket_in_flight(buckets_in_flight, b.k))
-			in_flight++;
-		else {
-			struct move_bucket *b_i = kmalloc(sizeof(*b_i), GFP_KERNEL);
-			ret2 = b_i ? 0 : -ENOMEM;
+		/* write buffer race? */
+		if (stripe_lru_pos(s) != lru_pos_time(lru_k.k->p))
+			continue;
+
+		unsigned nr_data = s->nr_blocks - s->nr_redundant;
+		for (unsigned i = 0; i < nr_data; i++) {
+			if (!stripe_blockcount_get(s, i))
+				continue;
+
+			const struct bch_extent_ptr *ptr = s->ptrs + i;
+			CLASS(bch2_dev_tryget, ca)(trans->c, ptr->dev);
+			if (unlikely(!ca))
+				continue;
+
+			ret2 = try_add_copygc_bucket(trans, buckets_in_flight,
+						     PTR_BUCKET_POS(ca, ptr), U64_MAX);
 			if (ret2)
-				goto err;
+				break;
+		}
+err:
+		ret2;
+	}));
 
-			*b_i = b;
+	return ret < 0 ? ret : 0;
+}
+
+static bool should_do_ec_copygc(struct btree_trans *trans)
+{
+	u64 stripe_frag_ratio = 0;
+
+	for_each_btree_key_max(trans, iter, BTREE_ID_lru,
+			       lru_start(BCH_LRU_STRIPE_FRAGMENTATION),
+			       lru_end(BCH_LRU_STRIPE_FRAGMENTATION),
+			       0, lru_k, ({
+		CLASS(btree_iter, s_iter)(trans, BTREE_ID_stripes, POS(0, lru_k.k->p.offset), 0);
+		struct bkey_s_c s_k = bch2_btree_iter_peek_slot(&s_iter);
+		int ret = bkey_err(s_k);
+		if (ret)
+			goto err;
 
-			ret2 = darray_push(&buckets_in_flight->to_evacuate, b_i);
-			if (ret2) {
-				kfree(b_i);
-				goto err;
-			}
+		if (s_k.k->type != KEY_TYPE_stripe)
+			continue;
 
-			ret2 = rhashtable_lookup_insert_fast(buckets_in_flight->table, &b_i->hash,
-							     bch_move_bucket_params);
-			BUG_ON(ret2);
+		const struct bch_stripe *s = bkey_s_c_to_stripe(s_k).v;
 
-			sectors += b.sectors;
-		}
+		/* write buffer race? */
+		if (stripe_lru_pos(s) != lru_pos_time(lru_k.k->p))
+			continue;
 
-		ret2 = buckets_in_flight->to_evacuate.nr >= nr_to_get;
+		unsigned nr_data = s->nr_blocks - s->nr_redundant, blocks_nonempty = 0;
+		for (unsigned i = 0; i < nr_data; i++)
+			blocks_nonempty += !!stripe_blockcount_get(s, i);
+
+		/* stripe is pending delete */
+		if (!blocks_nonempty)
+			continue;
+
+		/* This matches the calculation in alloc_lru_idx_fragmentation, so we can
+		 * directly compare without actually looking up the bucket pointed to by the
+		 * bucket fragmentation lru:
+		 */
+		stripe_frag_ratio = div_u64(blocks_nonempty * (1ULL << 31), nr_data);
+		break;
 err:
-		ret2;
+		ret;
 	}));
 
-	pr_debug("have: %zu (%zu) saw %zu in flight %zu not movable %zu got %zu (%zu)/%zu buckets ret %i",
-		 buckets_in_flight->nr, buckets_in_flight->sectors,
-		 saw, in_flight, not_movable, buckets_in_flight->to_evacuate.nr, sectors, nr_to_get, ret);
+	CLASS(btree_iter, iter)(trans, BTREE_ID_lru, lru_start(BCH_LRU_BUCKET_FRAGMENTATION), 0);
+	struct bkey_s_c lru_k;
 
-	return ret < 0 ? ret : 0;
+	lockrestart_do(trans, bkey_err(lru_k = bch2_btree_iter_peek_max(&iter,
+							lru_end(BCH_LRU_BUCKET_FRAGMENTATION))));
+
+	u64 bucket_frag_ratio = lru_k.k && !bkey_err(lru_k) ? lru_pos_time(lru_k.k->p) : 0;
+
+	/* Prefer normal bucket copygc */
+	return stripe_frag_ratio && stripe_frag_ratio * 2 < bucket_frag_ratio;
 }
 
 noinline
@@ -213,7 +295,18 @@ static int bch2_copygc(struct moving_context *ctxt,
 	u64 sectors_moved	= atomic64_read(&ctxt->stats->sectors_moved);
 	int ret = 0;
 
-	ret = bch2_copygc_get_buckets(ctxt, buckets_in_flight);
+	move_buckets_wait(ctxt, buckets_in_flight, false);
+
+	ret = bch2_btree_write_buffer_tryflush(trans);
+	if (bch2_err_matches(ret, EROFS))
+		goto err;
+
+	if (bch2_fs_fatal_err_on(ret, c, "%s: from bch2_btree_write_buffer_tryflush()", bch2_err_str(ret)))
+		goto err;
+
+	ret = should_do_ec_copygc(trans)
+		? bch2_copygc_get_stripe_buckets(ctxt, buckets_in_flight)
+		: bch2_copygc_get_buckets(ctxt, buckets_in_flight);
 	if (ret)
 		goto err;
 
@@ -265,7 +358,8 @@ static u64 bch2_copygc_dev_wait_amount(struct bch_dev *ca)
 
 	for (unsigned i = 0; i < BCH_DATA_NR; i++)
 		if (data_type_movable(i))
-			fragmented += usage_full.d[i].fragmented;
+			fragmented += usage_full.d[i].buckets * ca->mi.bucket_size -
+				usage_full.d[i].sectors;
 
 	return max(0LL, fragmented_allowed - fragmented);
 }
-- 
2.51.0


From b5d93a420475945422978583d22ed394630527e8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 24 Jul 2025 12:09:51 -0400
Subject: [PATCH 228/309] bcachefs:
 bcachefs_metadata_version_extent_snapshot_whiteouts

New on disk format version, with an incompat feature that enables
KEY_TYPE_extent_whiteout: extents inclusive of KEY_TYPE_whiteout do not
have monotonically increasing start position (which is a problem for
lookups that need to terminate), but extents inclusive of the new
KEY_TYPE_extent_whiteout do have monotonically increasing start
positions.

This patch updates the extent update path to use the new key type where
appropriate: next patches will update the btree iterator code to take
advantage of it.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_format.h | 11 ++++--
 fs/bcachefs/bkey_methods.c    |  6 +++-
 fs/bcachefs/bkey_types.h      |  5 +++
 fs/bcachefs/btree_iter.c      |  8 ++---
 fs/bcachefs/btree_update.c    | 67 +++++++++++++++++++++++++++++------
 fs/bcachefs/fsck.c            |  4 ++-
 6 files changed, 82 insertions(+), 19 deletions(-)

diff --git a/fs/bcachefs/bcachefs_format.h b/fs/bcachefs/bcachefs_format.h
index b4a04df5ea95..a8f59522e258 100644
--- a/fs/bcachefs/bcachefs_format.h
+++ b/fs/bcachefs/bcachefs_format.h
@@ -423,7 +423,8 @@ enum bch_bkey_type_flags {
 	x(logged_op_truncate,	32,	BKEY_TYPE_strict_btree_checks)	\
 	x(logged_op_finsert,	33,	BKEY_TYPE_strict_btree_checks)	\
 	x(accounting,		34,	BKEY_TYPE_strict_btree_checks)	\
-	x(inode_alloc_cursor,	35,	BKEY_TYPE_strict_btree_checks)
+	x(inode_alloc_cursor,	35,	BKEY_TYPE_strict_btree_checks)	\
+	x(extent_whiteout,	36,	BKEY_TYPE_strict_btree_checks)
 
 enum bch_bkey_type {
 #define x(name, nr, ...) KEY_TYPE_##name	= nr,
@@ -440,6 +441,10 @@ struct bch_whiteout {
 	struct bch_val		v;
 };
 
+struct bch_extent_whiteout {
+	struct bch_val		v;
+};
+
 struct bch_error {
 	struct bch_val		v;
 };
@@ -700,7 +705,8 @@ struct bch_sb_field_ext {
 	x(extent_flags,			BCH_VERSION(1, 25))		\
 	x(snapshot_deletion_v2,		BCH_VERSION(1, 26))		\
 	x(fast_device_removal,		BCH_VERSION(1, 27))		\
-	x(inode_has_case_insensitive,	BCH_VERSION(1, 28))
+	x(inode_has_case_insensitive,	BCH_VERSION(1, 28))		\
+	x(extent_snapshot_whiteouts,	BCH_VERSION(1, 29))
 
 enum bcachefs_metadata_version {
 	bcachefs_metadata_version_min = 9,
@@ -1340,6 +1346,7 @@ enum btree_id_flags {
 	  BTREE_IS_snapshots|							\
 	  BTREE_IS_data,							\
 	  BIT_ULL(KEY_TYPE_whiteout)|						\
+	  BIT_ULL(KEY_TYPE_extent_whiteout)|					\
 	  BIT_ULL(KEY_TYPE_error)|						\
 	  BIT_ULL(KEY_TYPE_cookie)|						\
 	  BIT_ULL(KEY_TYPE_extent)|						\
diff --git a/fs/bcachefs/bkey_methods.c b/fs/bcachefs/bkey_methods.c
index fcd8c82cba4f..75d73677c4d8 100644
--- a/fs/bcachefs/bkey_methods.c
+++ b/fs/bcachefs/bkey_methods.c
@@ -41,6 +41,10 @@ static int deleted_key_validate(struct bch_fs *c, struct bkey_s_c k,
 	.key_validate	= deleted_key_validate,		\
 })
 
+#define bch2_bkey_ops_extent_whiteout ((struct bkey_ops) {	\
+	.key_validate	= deleted_key_validate,		\
+})
+
 static int empty_val_key_validate(struct bch_fs *c, struct bkey_s_c k,
 				  struct bkey_validate_context from)
 {
@@ -203,7 +207,7 @@ int __bch2_bkey_validate(struct bch_fs *c, struct bkey_s_c k,
 			 ? bch2_bkey_types[k.k->type]
 			 : "(unknown)");
 
-	if (btree_node_type_is_extents(type) && !bkey_whiteout(k.k)) {
+	if (btree_node_type_is_extents(type) && !bkey_extent_whiteout(k.k)) {
 		bkey_fsck_err_on(k.k->size == 0,
 				 c, bkey_extent_size_zero,
 				 "size == 0");
diff --git a/fs/bcachefs/bkey_types.h b/fs/bcachefs/bkey_types.h
index b4f328f9853c..88a48ce63656 100644
--- a/fs/bcachefs/bkey_types.h
+++ b/fs/bcachefs/bkey_types.h
@@ -44,6 +44,11 @@ static inline void set_bkey_val_bytes(struct bkey *k, unsigned bytes)
 #define bkey_whiteout(_k)				\
 	((_k)->type == KEY_TYPE_deleted || (_k)->type == KEY_TYPE_whiteout)
 
+#define bkey_extent_whiteout(_k)				\
+	((_k)->type == KEY_TYPE_deleted ||			\
+	 (_k)->type == KEY_TYPE_whiteout ||			\
+	 (_k)->type == KEY_TYPE_extent_whiteout)
+
 /* bkey with split value, const */
 struct bkey_s_c {
 	const struct bkey	*k;
diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index a67babf69d39..1f30326f5b1c 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2450,7 +2450,7 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_iter *iter, struct bpos en
 				continue;
 			}
 
-			if (bkey_whiteout(k.k) &&
+			if (bkey_extent_whiteout(k.k) &&
 			    !(iter->flags & BTREE_ITER_nofilter_whiteouts)) {
 				search_key = bkey_successor(iter, k.k->p);
 				continue;
@@ -2711,7 +2711,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_iter *iter, struct bp
 					saved_path = 0;
 				}
 
-				if (!bkey_whiteout(k.k)) {
+				if (!bkey_extent_whiteout(k.k)) {
 					saved_path = btree_path_clone(trans, iter->path,
 								iter->flags & BTREE_ITER_intent,
 								_THIS_IP_);
@@ -2724,7 +2724,7 @@ struct bkey_s_c bch2_btree_iter_peek_prev_min(struct btree_iter *iter, struct bp
 				continue;
 			}
 
-			if (bkey_whiteout(k.k)) {
+			if (bkey_extent_whiteout(k.k)) {
 				search_key = bkey_predecessor(iter, k.k->p);
 				search_key.snapshot = U32_MAX;
 				continue;
@@ -2865,7 +2865,7 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_iter *iter)
 			iter->k = *k.k;
 		}
 
-		if (unlikely(k.k->type == KEY_TYPE_whiteout &&
+		if (unlikely(bkey_extent_whiteout(k.k) &&
 			     (iter->flags & BTREE_ITER_filter_snapshots) &&
 			     !(iter->flags & BTREE_ITER_nofilter_whiteouts)))
 			iter->k.type = KEY_TYPE_deleted;
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 6f3b57573cba..f59f018fe0d8 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -12,6 +12,7 @@
 #include "extents.h"
 #include "keylist.h"
 #include "snapshot.h"
+#include "super-io.h"
 #include "trace.h"
 
 #include <linux/string_helpers.h>
@@ -158,6 +159,21 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 	return ret;
 }
 
+static inline enum bch_bkey_type extent_whiteout_type(struct bch_fs *c, enum btree_id btree, const struct bkey *k)
+{
+	/*
+	 * KEY_TYPE_extent_whiteout indicates that there isn't a real extent
+	 * present at that position: key start positions inclusive of
+	 * KEY_TYPE_extent_whiteout (but not KEY_TYPE_whiteout) are
+	 * monotonically increasing
+	 */
+	return btree_id_is_extents_snapshots(btree) &&
+		bkey_deleted(k) &&
+		!bch2_request_incompat_feature(c, bcachefs_metadata_version_extent_snapshot_whiteouts)
+		? KEY_TYPE_extent_whiteout
+		: KEY_TYPE_whiteout;
+}
+
 int bch2_trans_update_extent_overwrite(struct btree_trans *trans,
 				       struct btree_iter *iter,
 				       enum btree_iter_update_trigger_flags flags,
@@ -224,14 +240,14 @@ int bch2_trans_update_extent_overwrite(struct btree_trans *trans,
 		update->k.p = old.k->p;
 		update->k.p.snapshot = new.k->p.snapshot;
 
-		if (new.k->p.snapshot != old.k->p.snapshot) {
-			update->k.type = KEY_TYPE_whiteout;
-		} else if (btree_type_has_snapshots(btree_id)) {
-			ret = need_whiteout_for_snapshot(trans, btree_id, update->k.p);
+		if (btree_type_has_snapshots(btree_id)) {
+			ret =   new.k->p.snapshot != old.k->p.snapshot
+				? 1
+				: need_whiteout_for_snapshot(trans, btree_id, update->k.p);
 			if (ret < 0)
 				return ret;
 			if (ret)
-				update->k.type = KEY_TYPE_whiteout;
+				update->k.type = extent_whiteout_type(trans->c, iter->btree_id, new.k);
 		}
 
 		ret = bch2_btree_insert_nonextent(trans, btree_id, update,
@@ -265,7 +281,8 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 	CLASS(btree_iter, iter)(trans, btree_id, bkey_start_pos(&insert->k),
 				BTREE_ITER_intent|
 				BTREE_ITER_with_updates|
-				BTREE_ITER_not_extents);
+				BTREE_ITER_not_extents|
+				BTREE_ITER_nofilter_whiteouts);
 	struct bkey_s_c k = bch2_btree_iter_peek_max(&iter, POS(insert->k.p.inode, U64_MAX));
 	int ret = bkey_err(k);
 	if (ret)
@@ -283,12 +300,40 @@ static int bch2_trans_update_extent(struct btree_trans *trans,
 		goto next;
 	}
 
-	while (bkey_gt(insert->k.p, bkey_start_pos(k.k))) {
-		bool done = bkey_lt(insert->k.p, k.k->p);
+	while (true) {
+		BUG_ON(bkey_le(k.k->p, bkey_start_pos(&insert->k)));
 
-		ret = bch2_trans_update_extent_overwrite(trans, &iter, flags, k, bkey_i_to_s_c(insert));
-		if (ret)
-			return ret;
+		/*
+		 * When KEY_TYPE_whiteout is included, bkey_start_pos is not
+		 * monotonically increasing
+		 */
+		if (k.k->type != KEY_TYPE_whiteout && bkey_le(insert->k.p, bkey_start_pos(k.k)))
+			break;
+
+		bool done = k.k->type != KEY_TYPE_whiteout && bkey_lt(insert->k.p, k.k->p);
+
+		if (bkey_extent_whiteout(k.k)) {
+			enum bch_bkey_type whiteout_type = extent_whiteout_type(trans->c, btree_id, &insert->k);
+
+			if (bkey_le(k.k->p, insert->k.p) &&
+			    k.k->type != whiteout_type) {
+				struct bkey_i *update = bch2_bkey_make_mut_noupdate(trans, k);
+				ret = PTR_ERR_OR_ZERO(update);
+				if (ret)
+					return ret;
+
+				update->k.p.snapshot = iter.snapshot;
+				update->k.type = whiteout_type;
+
+				ret = bch2_trans_update(trans, &iter, update, 0);
+				if (ret)
+					return ret;
+			}
+		} else {
+			ret = bch2_trans_update_extent_overwrite(trans, &iter, flags, k, bkey_i_to_s_c(insert));
+			if (ret)
+				return ret;
+		}
 
 		if (done)
 			goto out;
diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 6ccea09243ab..01c1c6372229 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -1444,7 +1444,7 @@ static int check_key_has_inode(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
-	if (k.k->type == KEY_TYPE_whiteout)
+	if (bkey_extent_whiteout(k.k))
 		return 0;
 
 	bool have_inode = i && !i->whiteout;
@@ -1924,7 +1924,9 @@ static int check_extent(struct btree_trans *trans, struct btree_iter *iter,
 						&inode->recalculate_sums);
 		if (ret)
 			goto err;
+	}
 
+	if (!bkey_extent_whiteout(k.k)) {
 		/*
 		 * Check inodes in reverse order, from oldest snapshots to
 		 * newest, starting from the inode that matches this extent's
-- 
2.51.0


From 3e62c6b29cd990613b395fd6c0f11bd4544f0b3e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 24 Jul 2025 22:37:37 -0400
Subject: [PATCH 229/309] bcachefs: peek() now takes advantage of
 KEY_TYPE_extent_whiteout

Fix slow lookups when extent snapshot whiteouts are present: keys
inclusive of KEY_TYPE_extent_whiteout (but not KEY_TYPE_whiteout) have
monotonically increasing start positions, so we can use them to
terminate a search.

Closes: https://github.com/koverstreet/bcachefs/issues/912
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 25 +++++++++++++++++++++----
 1 file changed, 21 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 1f30326f5b1c..d9ca194d1513 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2450,10 +2450,27 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_iter *iter, struct bpos en
 				continue;
 			}
 
-			if (bkey_extent_whiteout(k.k) &&
-			    !(iter->flags & BTREE_ITER_nofilter_whiteouts)) {
-				search_key = bkey_successor(iter, k.k->p);
-				continue;
+			if (!(iter->flags & BTREE_ITER_nofilter_whiteouts)) {
+				/*
+				 * KEY_TYPE_extent_whiteout indicates that there
+				 * are no extents that overlap with this
+				 * whiteout - meaning bkey_start_pos() is
+				 * monotonically increasing when including
+				 * KEY_TYPE_extent_whiteout (not
+				 * KEY_TYPE_whiteout).
+				 *
+				 * Without this @end wouldn't be able to
+				 * terminate searches and we'd have to scan
+				 * through tons of whiteouts:
+				 */
+				if (k.k->type == KEY_TYPE_extent_whiteout &&
+				    bkey_ge(k.k->p, end))
+					goto end;
+
+				if (bkey_extent_whiteout(k.k)) {
+					search_key = bkey_successor(iter, k.k->p);
+					continue;
+				}
 			}
 		}
 
-- 
2.51.0


From 0d9e9292d4923dff5a38a5328a00493a828cda70 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 24 Jul 2025 22:37:37 -0400
Subject: [PATCH 230/309] bcachefs: peek_slot() now takes advantage of
 KEY_TYPE_extent_whiteout

Kill another O(n^2) issue with extent snapshot overwrites - terminate
the search when we see KEY_TYPE_extent_whiteout.

Closes: https://github.com/koverstreet/bcachefs/issues/912
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 41 ++++++++++++++++++++++++----------------
 1 file changed, 25 insertions(+), 16 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index d9ca194d1513..8962c481e310 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2895,31 +2895,40 @@ struct bkey_s_c bch2_btree_iter_peek_slot(struct btree_iter *iter)
 
 		EBUG_ON(btree_iter_path(trans, iter)->level);
 
-		if (iter->flags & BTREE_ITER_intent) {
-			struct btree_iter iter2;
+		struct btree_iter iter2;
 
-			bch2_trans_copy_iter(&iter2, iter);
-			k = bch2_btree_iter_peek_max(&iter2, end);
+		bch2_trans_copy_iter(&iter2, iter);
+		iter2.flags |= BTREE_ITER_nofilter_whiteouts;
 
-			if (k.k && !bkey_err(k)) {
-				swap(iter->key_cache_path, iter2.key_cache_path);
-				iter->k = iter2.k;
-				k.k = &iter->k;
+		while (1) {
+			k = bch2_btree_iter_peek_max(&iter2, end);
+			if ((iter2.flags & BTREE_ITER_is_extents) &&
+			    k.k &&
+			    !bkey_err(k) &&
+			    k.k->type == KEY_TYPE_whiteout) {
+				bch2_btree_iter_set_pos(&iter2, k.k->p);
+				continue;
 			}
-			bch2_trans_iter_exit(&iter2);
-		} else {
-			struct bpos pos = iter->pos;
 
-			k = bch2_btree_iter_peek_max(iter, end);
-			if (unlikely(bkey_err(k)))
-				bch2_btree_iter_set_pos(iter, pos);
-			else
-				iter->pos = pos;
+			break;
 		}
 
+		if (k.k && !bkey_err(k)) {
+			swap(iter->key_cache_path, iter2.key_cache_path);
+			iter->k = iter2.k;
+			k.k = &iter->k;
+		}
+		bch2_trans_iter_exit(&iter2);
+
 		if (unlikely(bkey_err(k)))
 			goto out;
 
+		if (unlikely(k.k &&
+			     bkey_extent_whiteout(k.k) &&
+			     (iter->flags & BTREE_ITER_filter_snapshots) &&
+			     !(iter->flags & BTREE_ITER_nofilter_whiteouts)))
+			iter->k.type = KEY_TYPE_deleted;
+
 		next = k.k ? bkey_start_pos(k.k) : POS_MAX;
 
 		if (bkey_lt(iter->pos, next)) {
-- 
2.51.0


From 9c413b2bfd8a124ac6ad00c2209950f3316deb37 Mon Sep 17 00:00:00 2001
From: Qianfeng Rong <rongqianfeng@vivo.com>
Date: Sun, 3 Aug 2025 18:22:39 +0800
Subject: [PATCH 231/309] bcachefs: Remove redundant __GFP_NOWARN

GFP_NOWAIT already includes __GFP_NOWARN, so let's remove
the redundant __GFP_NOWARN.

Signed-off-by: Qianfeng Rong <rongqianfeng@vivo.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_cache.c        | 4 ++--
 fs/bcachefs/btree_io.c           | 2 +-
 fs/bcachefs/btree_iter.h         | 6 +++---
 fs/bcachefs/btree_trans_commit.c | 2 +-
 fs/bcachefs/fs.c                 | 2 +-
 5 files changed, 8 insertions(+), 8 deletions(-)

diff --git a/fs/bcachefs/btree_cache.c b/fs/bcachefs/btree_cache.c
index 8716eedd43fc..59638d09e1fd 100644
--- a/fs/bcachefs/btree_cache.c
+++ b/fs/bcachefs/btree_cache.c
@@ -788,7 +788,7 @@ struct btree *bch2_btree_node_mem_alloc(struct btree_trans *trans, bool pcpu_rea
 			goto got_node;
 		}
 
-	b = __btree_node_mem_alloc(c, GFP_NOWAIT|__GFP_NOWARN);
+	b = __btree_node_mem_alloc(c, GFP_NOWAIT);
 	if (b) {
 		bch2_btree_lock_init(&b->c, pcpu_read_locks ? SIX_LOCK_INIT_PCPU : 0, GFP_NOWAIT);
 	} else {
@@ -826,7 +826,7 @@ struct btree *bch2_btree_node_mem_alloc(struct btree_trans *trans, bool pcpu_rea
 
 	mutex_unlock(&bc->lock);
 
-	if (btree_node_data_alloc(c, b, GFP_NOWAIT|__GFP_NOWARN)) {
+	if (btree_node_data_alloc(c, b, GFP_NOWAIT)) {
 		bch2_trans_unlock(trans);
 		if (btree_node_data_alloc(c, b, GFP_KERNEL|__GFP_NOWARN))
 			goto err;
diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index 8a03cd75a64f..276cf088539e 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -131,7 +131,7 @@ static void *btree_bounce_alloc(struct bch_fs *c, size_t size,
 	BUG_ON(size > c->opts.btree_node_size);
 
 	*used_mempool = false;
-	p = kvmalloc(size, __GFP_NOWARN|GFP_NOWAIT);
+	p = kvmalloc(size, GFP_NOWAIT);
 	if (!p) {
 		*used_mempool = true;
 		p = mempool_alloc(&c->btree_bounce_pool, GFP_NOFS);
diff --git a/fs/bcachefs/btree_iter.h b/fs/bcachefs/btree_iter.h
index b117cb5d7f94..c8fc6ee01d96 100644
--- a/fs/bcachefs/btree_iter.h
+++ b/fs/bcachefs/btree_iter.h
@@ -954,7 +954,7 @@ struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_iter *);
 
 #define allocate_dropping_locks_errcode(_trans, _do)			\
 ({									\
-	gfp_t _gfp = GFP_NOWAIT|__GFP_NOWARN;				\
+	gfp_t _gfp = GFP_NOWAIT;					\
 	int _ret = _do;							\
 									\
 	if (bch2_err_matches(_ret, ENOMEM)) {				\
@@ -966,7 +966,7 @@ struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_iter *);
 
 #define allocate_dropping_locks(_trans, _ret, _do)			\
 ({									\
-	gfp_t _gfp = GFP_NOWAIT|__GFP_NOWARN;				\
+	gfp_t _gfp = GFP_NOWAIT;					\
 	typeof(_do) _p = _do;						\
 									\
 	_ret = 0;							\
@@ -979,7 +979,7 @@ struct bkey_s_c bch2_btree_iter_peek_and_restart_outlined(struct btree_iter *);
 
 #define allocate_dropping_locks_norelock(_trans, _lock_dropped, _do)	\
 ({									\
-	gfp_t _gfp = GFP_NOWAIT|__GFP_NOWARN;				\
+	gfp_t _gfp = GFP_NOWAIT;					\
 	typeof(_do) _p = _do;						\
 	_lock_dropped = false;						\
 	if (unlikely(!_p)) {						\
diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index 8b94a8156fbf..4d58bdb233e9 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -449,7 +449,7 @@ static int btree_key_can_insert_cached(struct btree_trans *trans, unsigned flags
 		return 0;
 
 	new_u64s	= roundup_pow_of_two(u64s);
-	new_k		= krealloc(ck->k, new_u64s * sizeof(u64), GFP_NOWAIT|__GFP_NOWARN);
+	new_k		= krealloc(ck->k, new_u64s * sizeof(u64), GFP_NOWAIT);
 	if (unlikely(!new_k))
 		return btree_key_can_insert_cached_slowpath(trans, flags, path, new_u64s);
 
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index b5e3090f1cb8..76d2647d9500 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -268,7 +268,7 @@ int bch2_inode_or_descendents_is_open(struct btree_trans *trans, struct bpos p)
 		rht_for_each_entry_rcu_from(inode, he, rht_ptr_rcu(bkt), tbl, hash, hash) {
 			if (inode->ei_inum.inum == inum) {
 				ret = darray_push_gfp(&subvols, inode->ei_inum.subvol,
-						      GFP_NOWAIT|__GFP_NOWARN);
+						      GFP_NOWAIT);
 				if (ret) {
 					rcu_read_unlock();
 					ret = darray_make_room(&subvols, 1);
-- 
2.51.0


From 375c5876356034d6e34695a3b7fdbde2e15c1cfc Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 13:09:42 -0400
Subject: [PATCH 232/309] bcachefs: rebalance: Batch reads from rebalance_work
 btree

Avoid unnecessary contention with btree write buffer flushing - batch up
reads from the rebalance_work btree in a darray.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/rebalance.c | 98 +++++++++++++++++++++++++----------------
 1 file changed, 61 insertions(+), 37 deletions(-)

diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index c0c5fe961a83..e1db63d75a99 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -292,12 +292,48 @@ static int bch2_clear_rebalance_needs_scan(struct btree_trans *trans, u64 inum,
 		: 0;
 }
 
-static struct bkey_s_c next_rebalance_entry(struct btree_trans *trans,
-					    struct btree_iter *work_iter)
+#define REBALANCE_WORK_BUF_NR		1024
+DEFINE_DARRAY_NAMED(darray_rebalance_work, struct bkey_i_cookie);
+
+static struct bkey_i *next_rebalance_entry(struct btree_trans *trans,
+					 darray_rebalance_work *buf, struct bpos *work_pos)
 {
-	return !kthread_should_stop()
-		? bch2_btree_iter_peek(work_iter)
-		: bkey_s_c_null;
+	if (unlikely(!buf->nr)) {
+		/*
+		 * Avoid contention with write buffer flush: buffer up rebalance
+		 * work entries in a darray
+		 */
+
+		BUG_ON(!buf->size);;
+
+		bch2_trans_begin(trans);
+
+		for_each_btree_key(trans, iter, BTREE_ID_rebalance_work, *work_pos,
+				   BTREE_ITER_all_snapshots|BTREE_ITER_prefetch, k, ({
+			/* we previously used darray_make_room */
+			BUG_ON(bkey_bytes(k.k) > sizeof(buf->data[0]));
+
+			bkey_reassemble(&darray_top(*buf).k_i, k);
+			buf->nr++;
+
+			*work_pos = bpos_successor(iter.pos);
+			if (buf->nr == buf->size)
+				break;
+			0;
+		}));
+
+		if (!buf->nr)
+			return NULL;
+
+		unsigned l = 0, r = buf->nr - 1;
+		while (l < r) {
+			swap(buf->data[l], buf->data[r]);
+			l++;
+			--r;
+		}
+	}
+
+	return &(&darray_pop(buf))->k_i;
 }
 
 static int bch2_bkey_clear_needs_rebalance(struct btree_trans *trans,
@@ -408,8 +444,9 @@ static int do_rebalance_extent(struct moving_context *ctxt,
 
 	bch2_bkey_buf_init(&sk);
 
-	ret = bkey_err(k = next_rebalance_extent(trans, work_pos,
-				extent_iter, &io_opts, &data_opts));
+	ret = lockrestart_do(trans,
+		bkey_err(k = next_rebalance_extent(trans, work_pos,
+				extent_iter, &io_opts, &data_opts)));
 	if (ret || !k.k)
 		goto out;
 
@@ -464,10 +501,9 @@ static int do_rebalance_scan(struct moving_context *ctxt, u64 inum, u64 cookie)
 	per_snapshot_io_opts_init(&snapshot_io_opts, c);
 
 	int ret = for_each_btree_key_max(trans, iter, BTREE_ID_extents,
-				      r->scan_start.pos, r->scan_end.pos,
-				      BTREE_ITER_all_snapshots|
-				      BTREE_ITER_not_extents|
-				      BTREE_ITER_prefetch, k, ({
+					 r->scan_start.pos, r->scan_end.pos,
+					 BTREE_ITER_all_snapshots|
+					 BTREE_ITER_prefetch, k, ({
 		ctxt->stats->pos = BBPOS(iter.btree_id, iter.pos);
 
 		struct bch_io_opts *io_opts = bch2_move_get_io_opts(trans,
@@ -524,49 +560,37 @@ static int do_rebalance(struct moving_context *ctxt)
 	struct btree_trans *trans = ctxt->trans;
 	struct bch_fs *c = trans->c;
 	struct bch_fs_rebalance *r = &c->rebalance;
-	struct btree_iter extent_iter = { NULL };
-	struct bkey_s_c k;
+	struct btree_iter extent_iter = {};
 	u32 kick = r->kick;
-	int ret = 0;
 
-	bch2_trans_begin(trans);
+	struct bpos work_pos = POS_MIN;
+	CLASS(darray_rebalance_work, work)();
+	int ret = darray_make_room(&work, REBALANCE_WORK_BUF_NR);
+	if (ret)
+		return ret;
 
 	bch2_move_stats_init(&r->work_stats, "rebalance_work");
 	bch2_move_stats_init(&r->scan_stats, "rebalance_scan");
 
-	CLASS(btree_iter, rebalance_work_iter)(trans,
-					       BTREE_ID_rebalance_work, POS_MIN,
-					       BTREE_ITER_all_snapshots);
-
 	while (!bch2_move_ratelimit(ctxt)) {
 		if (!bch2_rebalance_enabled(c)) {
 			bch2_moving_ctxt_flush_all(ctxt);
 			kthread_wait_freezable(bch2_rebalance_enabled(c) ||
 					       kthread_should_stop());
+			if (kthread_should_stop())
+				break;
 		}
 
-		if (kthread_should_stop())
+		struct bkey_i *k = next_rebalance_entry(trans, &work, &work_pos);
+		if (!k)
 			break;
 
-		bch2_trans_begin(trans);
-
-		ret = bkey_err(k = next_rebalance_entry(trans, &rebalance_work_iter));
-		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
-			continue;
-		if (ret || !k.k)
-			break;
-
-		ret = k.k->type == KEY_TYPE_cookie
-			? do_rebalance_scan(ctxt, k.k->p.inode,
-					    le64_to_cpu(bkey_s_c_to_cookie(k).v->cookie))
-			: do_rebalance_extent(ctxt, k.k->p, &extent_iter);
-
-		if (bch2_err_matches(ret, BCH_ERR_transaction_restart))
-			continue;
+		ret = k->k.type == KEY_TYPE_cookie
+			? do_rebalance_scan(ctxt, k->k.p.inode,
+					    le64_to_cpu(bkey_i_to_cookie(k)->v.cookie))
+			: do_rebalance_extent(ctxt, k->k.p, &extent_iter);
 		if (ret)
 			break;
-
-		bch2_btree_iter_advance(&rebalance_work_iter);
 	}
 
 	bch2_trans_iter_exit(&extent_iter);
-- 
2.51.0


From fc503b97523c6aef11b5e674c899e47c811e7acd Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 15:39:15 -0400
Subject: [PATCH 233/309] bcachefs: bch2_move_ratelimit() now uses freezable
 wait

Use a freezable wait when waiting on copygc so we don't prevent the
system from suspending.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/move.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 30fe269d531d..8457dd6b35ac 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -542,7 +542,7 @@ int bch2_move_ratelimit(struct moving_context *ctxt)
 
 	if (ctxt->wait_on_copygc && c->copygc_running) {
 		bch2_moving_ctxt_flush_all(ctxt);
-		wait_event_killable(c->copygc_running_wq,
+		wait_event_freezable(c->copygc_running_wq,
 				    !c->copygc_running ||
 				    (is_kthread && kthread_should_stop()));
 	}
-- 
2.51.0


From 3ee404f107b7d536580db8b267924aa73e88e966 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 15:55:10 -0400
Subject: [PATCH 234/309] bcachefs: Ensure btree node allocation obeys open
 bucket reserves

We keep a cache of allocated btree nodes because we might allocate and
then not use a btree node; check the open bucket reserve before
allocating from the cache.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_update_interior.c | 14 ++++++++++++++
 1 file changed, 14 insertions(+)

diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 76897cf15946..65ca54c5b0ff 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -336,6 +336,20 @@ static struct btree *__bch2_btree_node_alloc(struct btree_trans *trans,
 	BUG_ON(b->ob.nr);
 
 	mutex_lock(&c->btree_reserve_cache_lock);
+	if (unlikely(c->open_buckets_nr_free <= bch2_open_buckets_reserved(watermark))) {
+		guard(spinlock)(&c->freelist_lock);
+		if (c->open_buckets_nr_free <= bch2_open_buckets_reserved(watermark)) {
+			if (cl)
+				closure_wait(&c->open_buckets_wait, cl);
+
+			ret = cl
+				? bch_err_throw(c, bucket_alloc_blocked)
+				: bch_err_throw(c, open_buckets_empty);
+			mutex_unlock(&c->btree_reserve_cache_lock);
+			goto err;
+		}
+	}
+
 	if (c->btree_reserve_cache_nr > nr_reserve) {
 		for (struct btree_alloc *a = c->btree_reserve_cache;
 		     a < c->btree_reserve_cache + c->btree_reserve_cache_nr;) {
-- 
2.51.0


From cd129bf785b5bedb4e2c4d91bef9bbc1ed6af036 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 17:39:47 -0400
Subject: [PATCH 235/309] bcachefs: Fix "inode not unlinked" error after
 subvolume delete

2d33036ca936 introduced a serious bug in subvolume deletion, in a
mistaken attempt to add synchronization that was not needed

We currently don't revoke access to a subvolume being deleted, we
explicitly wait for files in that subvolume to be closed before deleting
it.

6.15 had other subvolume delete fixes which exposed this, leading to
the subvolume root inode being prematurely unlinked.

Currently this only results in dmesg warnings, and is otherwise
harmless, because we verify that the btree says the inode should be
deleted before actually deleting it.

Fixes: 2d33036ca936 ("bcachefs: Fix for 'missing subvolume' error")
Fixes: https://github.com/koverstreet/bcachefs/issues/913
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs.c | 8 --------
 1 file changed, 8 deletions(-)

diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index 76d2647d9500..52722a5e8526 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -826,14 +826,6 @@ int __bch2_unlink(struct inode *vdir, struct dentry *dentry,
 	bch2_inode_update_after_write(trans, inode, &inode_u,
 				      ATTR_MTIME);
 
-	if (inode_u.bi_subvol) {
-		/*
-		 * Subvolume deletion is asynchronous, but we still want to tell
-		 * the VFS that it's been deleted here:
-		 */
-		set_nlink(&inode->v, 0);
-	}
-
 	if (IS_CASEFOLDED(vdir))
 		d_invalidate(dentry);
 err:
-- 
2.51.0


From 10f95dd168e19083209c0ecbfbdfa419a391a810 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 5 Aug 2025 09:41:30 -0400
Subject: [PATCH 236/309] bcachefs: Delete faulty read_only/nochanges check in
 fs_open()

nochanges now implies read_only; this check was old, and should have
been deleted.

And when err_throw came in, we accidentally introduced a null pointer
deref.

Reported-by: syzbot+8f3825f100f660b04204@syzkaller.appspotmail.com
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 5 -----
 1 file changed, 5 deletions(-)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index ef15e614f4f3..09e7f8ae9922 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -2542,11 +2542,6 @@ struct bch_fs *bch2_fs_open(darray_const_str *devices,
 		BUG_ON(darray_push(&sbs, sb));
 	}
 
-	if (opts->nochanges && !opts->read_only) {
-		ret = bch_err_throw(c, erofs_nochanges);
-		goto err_print;
-	}
-
 	darray_for_each(sbs, sb)
 		if (!best || sb_cmp(sb->sb, best->sb) > 0)
 			best = sb;
-- 
2.51.0


From c9df9d7bc1fb6ad379acdc951c19a83fa0db5536 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 21:31:24 -0400
Subject: [PATCH 237/309] bcachefs: error_throw counter

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs.h           | 17 +++++++++--------
 fs/bcachefs/sb-counters_format.h |  3 ++-
 2 files changed, 11 insertions(+), 9 deletions(-)

diff --git a/fs/bcachefs/bcachefs.h b/fs/bcachefs/bcachefs.h
index cdf593c59922..16d08dfb5f19 100644
--- a/fs/bcachefs/bcachefs.h
+++ b/fs/bcachefs/bcachefs.h
@@ -386,14 +386,6 @@ do {									\
 			##__VA_ARGS__, bch2_err_str(_ret));		\
 } while (0)
 
-static inline int __bch2_err_trace(struct bch_fs *c, int err)
-{
-	trace_error_throw(c, err, _THIS_IP_);
-	return err;
-}
-
-#define bch_err_throw(_c, _err) __bch2_err_trace(_c, -BCH_ERR_##_err)
-
 /* Parameters that are useful for debugging, but should always be compiled in: */
 #define BCH_DEBUG_PARAMS_ALWAYS()					\
 	BCH_DEBUG_PARAM(key_merging_disabled,				\
@@ -1153,6 +1145,15 @@ struct bch_fs {
 	struct mutex		fsck_error_counts_lock;
 };
 
+static inline int __bch2_err_trace(struct bch_fs *c, int err)
+{
+	this_cpu_inc(c->counters[BCH_COUNTER_error_throw]);
+	trace_error_throw(c, err, _THIS_IP_);
+	return err;
+}
+
+#define bch_err_throw(_c, _err) __bch2_err_trace(_c, -BCH_ERR_##_err)
+
 extern struct wait_queue_head bch2_read_only_wait;
 
 static inline bool bch2_ro_ref_tryget(struct bch_fs *c)
diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index f3ea53a55384..740859c7bbae 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -101,7 +101,8 @@ enum counters_flags {
 	x(trans_restart_write_buffer_flush,		75,	TYPE_COUNTER)	\
 	x(trans_restart_split_race,			76,	TYPE_COUNTER)	\
 	x(write_buffer_flush_slowpath,			77,	TYPE_COUNTER)	\
-	x(write_buffer_flush_sync,			78,	TYPE_COUNTER)
+	x(write_buffer_flush_sync,			78,	TYPE_COUNTER)	\
+	x(error_throw,					93,	TYPE_COUNTER)
 
 enum bch_persistent_counters {
 #define x(t, n, ...) BCH_COUNTER_##t,
-- 
2.51.0


From 071b0ea811c4139689663c264b6082747b8c65d3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 20:01:03 -0400
Subject: [PATCH 238/309] bcachefs: 'bcachefs data drop_extra_replicas' can now
 drop ec
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Reported-by: Marcin Mirosaw <marcin@mejor.pl>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/data_update.c |  9 +++++++++
 fs/bcachefs/data_update.h |  1 +
 fs/bcachefs/extents.c     | 17 +++++++++++++++++
 fs/bcachefs/extents.h     |  1 +
 fs/bcachefs/move.c        | 14 ++++++++++++--
 5 files changed, 40 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index 01838a3a189d..0bd4dd06fd25 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -693,6 +693,15 @@ int bch2_extent_drop_ptrs(struct btree_trans *trans,
 	if (ret)
 		return ret;
 
+	const union bch_extent_entry *entry;
+	struct extent_ptr_decoded p;
+	unsigned i = 0;
+	bkey_for_each_ptr_decode(k.k, bch2_bkey_ptrs_c(k), p, entry) {
+		if (data_opts->kill_ec_ptrs & BIT(i))
+			bch2_bkey_drop_ec(n, p.ptr.dev);
+		i++;
+	}
+
 	while (data_opts->kill_ptrs) {
 		unsigned i = 0, drop = __fls(data_opts->kill_ptrs);
 
diff --git a/fs/bcachefs/data_update.h b/fs/bcachefs/data_update.h
index 5e14d13568de..fc12aa65366f 100644
--- a/fs/bcachefs/data_update.h
+++ b/fs/bcachefs/data_update.h
@@ -12,6 +12,7 @@ struct moving_context;
 struct data_update_opts {
 	unsigned	rewrite_ptrs;
 	unsigned	kill_ptrs;
+	unsigned	kill_ec_ptrs;
 	u16		target;
 	u8		extra_replicas;
 	unsigned	btree_insert_flags;
diff --git a/fs/bcachefs/extents.c b/fs/bcachefs/extents.c
index b879a586b7f6..7ab0398707d8 100644
--- a/fs/bcachefs/extents.c
+++ b/fs/bcachefs/extents.c
@@ -995,6 +995,22 @@ void bch2_bkey_drop_device_noerror(struct bkey_s k, unsigned dev)
 	bch2_bkey_drop_ptrs_noerror(k, ptr, ptr->dev == dev);
 }
 
+void bch2_bkey_drop_ec(struct bkey_i *k, unsigned dev)
+{
+	struct bkey_ptrs ptrs = bch2_bkey_ptrs(bkey_i_to_s(k));
+	union bch_extent_entry *entry, *ec = NULL;
+
+	bkey_extent_entry_for_each(ptrs, entry) {
+		if (extent_entry_type(entry) == BCH_EXTENT_ENTRY_stripe_ptr)
+			ec = entry;
+		else if (extent_entry_type(entry) == BCH_EXTENT_ENTRY_ptr &&
+			 entry->ptr.dev == dev) {
+			bch2_bkey_extent_entry_drop(k, ec);
+			return;
+		}
+	}
+}
+
 const struct bch_extent_ptr *bch2_bkey_has_device_c(struct bkey_s_c k, unsigned dev)
 {
 	struct bkey_ptrs_c ptrs = bch2_bkey_ptrs_c(k);
@@ -1757,3 +1773,4 @@ int bch2_cut_back_s(struct bpos where, struct bkey_s k)
 	memset(bkey_val_end(k), 0, val_u64s_delta * sizeof(u64));
 	return -val_u64s_delta;
 }
+
diff --git a/fs/bcachefs/extents.h b/fs/bcachefs/extents.h
index 35ee03cd5065..f6dcb17108cd 100644
--- a/fs/bcachefs/extents.h
+++ b/fs/bcachefs/extents.h
@@ -650,6 +650,7 @@ void bch2_bkey_drop_ptr(struct bkey_s, struct bch_extent_ptr *);
 
 void bch2_bkey_drop_device_noerror(struct bkey_s, unsigned);
 void bch2_bkey_drop_device(struct bkey_s, unsigned);
+void bch2_bkey_drop_ec(struct bkey_i *k, unsigned);
 
 #define bch2_bkey_drop_ptrs_noerror(_k, _ptr, _cond)			\
 do {									\
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 8457dd6b35ac..932b62a921cc 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -344,7 +344,7 @@ int bch2_move_extent(struct moving_context *ctxt,
 	if (!data_opts.rewrite_ptrs &&
 	    !data_opts.extra_replicas &&
 	    !data_opts.scrub) {
-		if (data_opts.kill_ptrs) {
+		if (data_opts.kill_ptrs|data_opts.kill_ec_ptrs) {
 			this_cpu_add(c->counters[BCH_COUNTER_io_move_drop_only], k.k->size);
 			return bch2_extent_drop_ptrs(trans, iter, k, &io_opts, &data_opts);
 		} else {
@@ -1280,7 +1280,17 @@ static bool drop_extra_replicas_pred(struct bch_fs *c, void *arg,
 		i++;
 	}
 
-	return data_opts->kill_ptrs != 0;
+	i = 0;
+	bkey_for_each_ptr_decode(k.k, bch2_bkey_ptrs_c(k), p, entry) {
+		if (p.has_ec && durability - p.ec.redundancy >= replicas) {
+			data_opts->kill_ec_ptrs |= BIT(i);
+			durability -= p.ec.redundancy;
+		}
+
+		i++;
+	}
+
+	return (data_opts->kill_ptrs|data_opts->kill_ec_ptrs) != 0;
 }
 
 static bool scrub_pred(struct bch_fs *c, void *_arg,
-- 
2.51.0


From c00de93c5ec65ae11f881d373906c15412ebe6ea Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 22:49:43 -0400
Subject: [PATCH 239/309] bcachefs: accounting_key_to_wb_slowpath tracepoint,
 counter

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_write_buffer.c | 10 +++++++++-
 fs/bcachefs/data_update.c        |  2 +-
 fs/bcachefs/move.c               |  2 +-
 fs/bcachefs/sb-counters_format.h |  1 +
 fs/bcachefs/trace.h              |  5 +++++
 5 files changed, 17 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/btree_write_buffer.c b/fs/bcachefs/btree_write_buffer.c
index afad11831e1d..755fb25a8eba 100644
--- a/fs/bcachefs/btree_write_buffer.c
+++ b/fs/bcachefs/btree_write_buffer.c
@@ -701,8 +701,16 @@ int bch2_accounting_key_to_wb_slowpath(struct bch_fs *c, enum btree_id btree,
 				       struct bkey_i_accounting *k)
 {
 	struct btree_write_buffer *wb = &c->btree_write_buffer;
-	struct btree_write_buffered_key new = { .btree = btree };
 
+	if (trace_accounting_key_to_wb_slowpath_enabled()) {
+		CLASS(printbuf, buf)();
+		prt_printf(&buf, "have: %zu\n", wb->accounting.nr);
+		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(&k->k_i));
+		trace_accounting_key_to_wb_slowpath(c, buf.buf);
+	}
+	count_event(c, accounting_key_to_wb_slowpath);
+
+	struct btree_write_buffered_key new = { .btree = btree };
 	bkey_copy(&new.k, &k->k_i);
 
 	int ret = darray_push(&wb->accounting, new);
diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index 0bd4dd06fd25..a314d70c6b8e 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -225,7 +225,7 @@ static void trace_io_move_created_rebalance2(struct data_update *m,
 
 	trace_io_move_created_rebalance(c, buf.buf);
 
-	this_cpu_inc(c->counters[BCH_COUNTER_io_move_created_rebalance]);
+	count_event(c, io_move_created_rebalance);
 }
 
 noinline_for_stack
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index 932b62a921cc..df6833416855 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -150,7 +150,7 @@ static void move_write_done(struct bch_write_op *op)
 			bch2_write_op_to_text(&buf, op);
 			trace_io_move_write_fail(c, buf.buf);
 		}
-		this_cpu_inc(c->counters[BCH_COUNTER_io_move_write_fail]);
+		count_event(c, io_move_write_fail);
 
 		ctxt->write_error = true;
 	}
diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index 740859c7bbae..44bc12573a0c 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -102,6 +102,7 @@ enum counters_flags {
 	x(trans_restart_split_race,			76,	TYPE_COUNTER)	\
 	x(write_buffer_flush_slowpath,			77,	TYPE_COUNTER)	\
 	x(write_buffer_flush_sync,			78,	TYPE_COUNTER)	\
+	x(accounting_key_to_wb_slowpath,		94,	TYPE_COUNTER)	\
 	x(error_throw,					93,	TYPE_COUNTER)
 
 enum bch_persistent_counters {
diff --git a/fs/bcachefs/trace.h b/fs/bcachefs/trace.h
index 3776a1403104..269cdf1a87a4 100644
--- a/fs/bcachefs/trace.h
+++ b/fs/bcachefs/trace.h
@@ -1179,6 +1179,11 @@ DEFINE_EVENT(transaction_event,	trans_restart_write_buffer_flush,
 	TP_ARGS(trans, caller_ip)
 );
 
+DEFINE_EVENT(fs_str, accounting_key_to_wb_slowpath,
+	TP_PROTO(struct bch_fs *c, const char *str),
+	TP_ARGS(c, str)
+);
+
 TRACE_EVENT(path_downgrade,
 	TP_PROTO(struct btree_trans *trans,
 		 unsigned long caller_ip,
-- 
2.51.0


From 951990d53ac483633068ea7d5a272c4843d68802 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 3 Aug 2025 23:12:23 -0400
Subject: [PATCH 240/309] bcachefs: btree write buffer accounting fastpath now
 only for in-mem keys

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_write_buffer.h |  2 +-
 fs/bcachefs/disk_accounting.h    | 10 ++++++++++
 2 files changed, 11 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_write_buffer.h b/fs/bcachefs/btree_write_buffer.h
index e484cd6b90b0..b862bdf67f58 100644
--- a/fs/bcachefs/btree_write_buffer.h
+++ b/fs/bcachefs/btree_write_buffer.h
@@ -95,7 +95,7 @@ static inline int bch2_journal_key_to_wb(struct bch_fs *c,
 
 	EBUG_ON(!dst->seq);
 
-	return k->k.type == KEY_TYPE_accounting
+	return bch2_bkey_is_accounting_mem(&k->k)
 		? bch2_accounting_key_to_wb(c, btree, bkey_i_to_accounting(k))
 		: __bch2_journal_key_to_wb(c, dst, btree, k);
 }
diff --git a/fs/bcachefs/disk_accounting.h b/fs/bcachefs/disk_accounting.h
index 43f4b21d0aab..cc73cce98a44 100644
--- a/fs/bcachefs/disk_accounting.h
+++ b/fs/bcachefs/disk_accounting.h
@@ -145,6 +145,16 @@ static inline bool bch2_accounting_is_mem(struct disk_accounting_pos *acc)
 		acc->type != BCH_DISK_ACCOUNTING_inum;
 }
 
+static inline bool bch2_bkey_is_accounting_mem(struct bkey *k)
+{
+	if (k->type != KEY_TYPE_accounting)
+		return false;
+
+	struct disk_accounting_pos acc_k;
+	bpos_to_disk_accounting_pos(&acc_k, k->p);
+	return bch2_accounting_is_mem(&acc_k);
+}
+
 /*
  * Update in memory counters so they match the btree update we're doing; called
  * from transaction commit path
-- 
2.51.0


From 28101b125273dd840cd29b073416c18871e85468 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Tue, 5 Aug 2025 00:41:05 +0800
Subject: [PATCH 241/309] bcachefs: Ignore accounting key type larger than
 BCH_DISK_ACCOUNTING_TYPE_NR

Reported-by: syzbot+cd063f869beedf5b9cd7@syzkaller.appspotmail.com
Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/disk_accounting.c | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index f96530c70262..5944ad6d0f8d 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -184,6 +184,9 @@ int bch2_accounting_validate(struct bch_fs *c, struct bkey_s_c k,
 	void *end = &acc_k + 1;
 	int ret = 0;
 
+	if (acc_k.type >= BCH_DISK_ACCOUNTING_TYPE_NR)
+		return 0;
+
 	bkey_fsck_err_on((from.flags & BCH_VALIDATE_commit) &&
 			 bversion_zero(k.k->bversion),
 			 c, accounting_key_version_0,
-- 
2.51.0


From 51625a1976d7544bd9add1e33d3434b95b2389b8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 4 Aug 2025 13:09:01 -0400
Subject: [PATCH 242/309] bcachefs: btree_id_can_reconstruct(),
 btree_id_recovers_from_scan()

Add new helpers to clarify (and fix) repair strategies for different
btrees, and kill incorrect btree_id_is_alloc() use - it's not for
deciding how to repair.

btree node scan was incorrectly skipping BTREE_ID_alloc: while we can
reconstruct this one from scratch, it will fail by OOM on huge
filesystems, it's better to try btree node scan first

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_format.h | 31 +++++++++++++++++++++++++++++--
 fs/bcachefs/btree_gc.c        | 23 +----------------------
 fs/bcachefs/btree_node_scan.c |  4 ++--
 fs/bcachefs/recovery.c        |  2 +-
 4 files changed, 33 insertions(+), 27 deletions(-)

diff --git a/fs/bcachefs/bcachefs_format.h b/fs/bcachefs/bcachefs_format.h
index a8f59522e258..7a0b602c1b27 100644
--- a/fs/bcachefs/bcachefs_format.h
+++ b/fs/bcachefs/bcachefs_format.h
@@ -1438,9 +1438,9 @@ enum btree_id {
  */
 #define BTREE_ID_NR_MAX		63
 
-static inline bool btree_id_is_alloc(enum btree_id id)
+static inline bool btree_id_is_alloc(enum btree_id btree)
 {
-	switch (id) {
+	switch (btree) {
 	case BTREE_ID_alloc:
 	case BTREE_ID_backpointers:
 	case BTREE_ID_need_discard:
@@ -1454,6 +1454,33 @@ static inline bool btree_id_is_alloc(enum btree_id id)
 	}
 }
 
+/* We can reconstruct these btrees from information in other btrees */
+static inline bool btree_id_can_reconstruct(enum btree_id btree)
+{
+	if (btree_id_is_alloc(btree))
+		return true;
+
+	switch (btree) {
+	case BTREE_ID_snapshot_trees:
+	case BTREE_ID_deleted_inodes:
+	case BTREE_ID_rebalance_work:
+	case BTREE_ID_subvolume_children:
+		return true;
+	default:
+		return false;
+	}
+}
+
+/*
+ * We can reconstruct BTREE_ID_alloc, but reconstucting it from scratch is not
+ * so cheap and OOMs on huge filesystems (until we have online
+ * check_allocations)
+ */
+static inline bool btree_id_recovers_from_scan(enum btree_id btree)
+{
+	return btree == BTREE_ID_alloc || !btree_id_can_reconstruct(btree);
+}
+
 #define BTREE_MAX_DEPTH		4U
 
 /* Btree nodes */
diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index 6b91649688da..cbf567679a85 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -44,27 +44,6 @@
 #include <linux/rcupdate.h>
 #include <linux/sched/task.h>
 
-/*
- * Returns true if it's a btree we can easily reconstruct, or otherwise won't
- * cause data loss if it's missing:
- */
-static bool btree_id_important(enum btree_id btree)
-{
-	if (btree_id_is_alloc(btree))
-		return false;
-
-	switch (btree) {
-	case BTREE_ID_quotas:
-	case BTREE_ID_snapshot_trees:
-	case BTREE_ID_logged_ops:
-	case BTREE_ID_rebalance_work:
-	case BTREE_ID_subvolume_children:
-		return false;
-	default:
-		return true;
-	}
-}
-
 static const char * const bch2_gc_phase_strs[] = {
 #define x(n)	#n,
 	GC_PHASES()
@@ -576,7 +555,7 @@ static int bch2_check_root(struct btree_trans *trans, enum btree_id btree,
 
 		if (!ret) {
 			__fsck_err(trans,
-				   FSCK_CAN_FIX|(!btree_id_important(btree) ? FSCK_AUTOFIX : 0),
+				   FSCK_CAN_FIX|(btree_id_can_reconstruct(btree) ? FSCK_AUTOFIX : 0),
 				   btree_root_unreadable_and_scan_found_nothing,
 				   "no nodes found for btree %s, continue?", buf.buf);
 
diff --git a/fs/bcachefs/btree_node_scan.c b/fs/bcachefs/btree_node_scan.c
index 4b7b5ca74ba1..b618a0bd1186 100644
--- a/fs/bcachefs/btree_node_scan.c
+++ b/fs/bcachefs/btree_node_scan.c
@@ -149,7 +149,7 @@ static void try_read_btree_node(struct find_btree_nodes *f, struct bch_dev *ca,
 		bch2_encrypt(c, BSET_CSUM_TYPE(&bn->keys), nonce, &bn->flags, bytes);
 	}
 
-	if (btree_id_is_alloc(BTREE_NODE_ID(bn)))
+	if (btree_id_can_reconstruct(BTREE_NODE_ID(bn)))
 		return;
 
 	if (BTREE_NODE_LEVEL(bn) >= BTREE_MAX_DEPTH)
@@ -534,7 +534,7 @@ int bch2_btree_has_scanned_nodes(struct bch_fs *c, enum btree_id btree)
 int bch2_get_scanned_nodes(struct bch_fs *c, enum btree_id btree,
 			   unsigned level, struct bpos node_min, struct bpos node_max)
 {
-	if (btree_id_is_alloc(btree))
+	if (!btree_id_recovers_from_scan(btree))
 		return 0;
 
 	struct find_btree_nodes *f = &c->found_btree_nodes;
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 21aa2edb13ac..29e81f96db0f 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -607,7 +607,7 @@ static int read_btree_roots(struct bch_fs *c)
 					c, btree_root_read_error,
 					"error reading btree root %s: %s",
 					buf.buf, bch2_err_str(ret))) {
-			if (btree_id_is_alloc(i))
+			if (btree_id_can_reconstruct(i))
 				r->error = 0;
 			ret = 0;
 		}
-- 
2.51.0


From e8c902b8b73860f9d2bb49015cc398548395b54e Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Tue, 5 Aug 2025 01:01:27 +0800
Subject: [PATCH 243/309] bcachefs: Add missing else statement

The if condition was broken, ret was always assigned to BCH_ERR_fsck_delete_bkey

Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/error.h | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/error.h b/fs/bcachefs/error.h
index 0c3c3a24fc6f..213814787dd6 100644
--- a/fs/bcachefs/error.h
+++ b/fs/bcachefs/error.h
@@ -173,7 +173,8 @@ do {									\
 	if (!bch2_err_matches(_ret, BCH_ERR_fsck_fix) &&		\
 	    !bch2_err_matches(_ret, BCH_ERR_fsck_ignore))		\
 		ret = _ret;						\
-	ret = bch_err_throw(c, fsck_delete_bkey);			\
+	else								\
+		ret = bch_err_throw(c, fsck_delete_bkey);		\
 	goto fsck_err;							\
 } while (0)
 
-- 
2.51.0


From 0384b4701bb1908ed04efa8622dc9fce1d3a7799 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 4 Aug 2025 18:01:48 -0400
Subject: [PATCH 244/309] bcachefs: Update bch2_extent_trim_atomic() for
 KEY_TYPE_extent_whiteout

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c    |  4 ++-
 fs/bcachefs/btree_update.c  | 16 ----------
 fs/bcachefs/btree_update.h  | 17 ++++++++++
 fs/bcachefs/extent_update.c | 62 ++++++++++++++++++++++++-------------
 fs/bcachefs/extent_update.h |  2 --
 5 files changed, 61 insertions(+), 40 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 8962c481e310..546b559fe3ce 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -2366,7 +2366,9 @@ struct bkey_s_c bch2_btree_iter_peek_max(struct btree_iter *iter, struct bpos en
 
 	bch2_trans_verify_not_unlocked_or_in_restart(trans);
 	bch2_btree_iter_verify_entry_exit(iter);
-	EBUG_ON((iter->flags & BTREE_ITER_filter_snapshots) && bkey_eq(end, POS_MAX));
+	EBUG_ON((iter->flags & BTREE_ITER_filter_snapshots) &&
+		!(iter->flags & BTREE_ITER_nofilter_whiteouts) &&
+		bkey_eq(end, POS_MAX));
 
 	ret = trans_maybe_inject_restart(trans, _RET_IP_);
 	if (unlikely(ret)) {
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index f59f018fe0d8..053a837cf241 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -12,7 +12,6 @@
 #include "extents.h"
 #include "keylist.h"
 #include "snapshot.h"
-#include "super-io.h"
 #include "trace.h"
 
 #include <linux/string_helpers.h>
@@ -159,21 +158,6 @@ int __bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 	return ret;
 }
 
-static inline enum bch_bkey_type extent_whiteout_type(struct bch_fs *c, enum btree_id btree, const struct bkey *k)
-{
-	/*
-	 * KEY_TYPE_extent_whiteout indicates that there isn't a real extent
-	 * present at that position: key start positions inclusive of
-	 * KEY_TYPE_extent_whiteout (but not KEY_TYPE_whiteout) are
-	 * monotonically increasing
-	 */
-	return btree_id_is_extents_snapshots(btree) &&
-		bkey_deleted(k) &&
-		!bch2_request_incompat_feature(c, bcachefs_metadata_version_extent_snapshot_whiteouts)
-		? KEY_TYPE_extent_whiteout
-		: KEY_TYPE_whiteout;
-}
-
 int bch2_trans_update_extent_overwrite(struct btree_trans *trans,
 				       struct btree_iter *iter,
 				       enum btree_iter_update_trigger_flags flags,
diff --git a/fs/bcachefs/btree_update.h b/fs/bcachefs/btree_update.h
index 663739db82b1..18560ca80057 100644
--- a/fs/bcachefs/btree_update.h
+++ b/fs/bcachefs/btree_update.h
@@ -5,6 +5,7 @@
 #include "btree_iter.h"
 #include "journal.h"
 #include "snapshot.h"
+#include "super-io.h"
 
 struct bch_fs;
 struct btree;
@@ -110,6 +111,22 @@ static inline int bch2_insert_snapshot_whiteouts(struct btree_trans *trans,
 		: 0;
 }
 
+static inline enum bch_bkey_type extent_whiteout_type(struct bch_fs *c, enum btree_id btree,
+						      const struct bkey *k)
+{
+	/*
+	 * KEY_TYPE_extent_whiteout indicates that there isn't a real extent
+	 * present at that position: key start positions inclusive of
+	 * KEY_TYPE_extent_whiteout (but not KEY_TYPE_whiteout) are
+	 * monotonically increasing
+	 */
+	return btree_id_is_extents_snapshots(btree) &&
+		bkey_deleted(k) &&
+		!bch2_request_incompat_feature(c, bcachefs_metadata_version_extent_snapshot_whiteouts)
+		? KEY_TYPE_extent_whiteout
+		: KEY_TYPE_whiteout;
+}
+
 int bch2_trans_update_extent_overwrite(struct btree_trans *, struct btree_iter *,
 				       enum btree_iter_update_trigger_flags,
 				       struct bkey_s_c, struct bkey_s_c);
diff --git a/fs/bcachefs/extent_update.c b/fs/bcachefs/extent_update.c
index c4b0ea1adaa8..73eb28090bc7 100644
--- a/fs/bcachefs/extent_update.c
+++ b/fs/bcachefs/extent_update.c
@@ -98,11 +98,13 @@ static int count_iters_for_insert(struct btree_trans *trans,
 	return ret2 ?: ret;
 }
 
-int bch2_extent_atomic_end(struct btree_trans *trans,
-			   struct btree_iter *iter,
-			   struct bpos *end)
+int bch2_extent_trim_atomic(struct btree_trans *trans,
+			    struct btree_iter *iter,
+			    struct bkey_i *insert)
 {
-	unsigned nr_iters = 0;
+	enum bch_bkey_type whiteout_type =
+		extent_whiteout_type(trans->c, iter->btree_id, &insert->k);
+	struct bpos end = insert->k.p;
 
 	struct btree_iter copy;
 	bch2_trans_copy_iter(&copy, iter);
@@ -111,42 +113,60 @@ int bch2_extent_atomic_end(struct btree_trans *trans,
 	if (ret)
 		goto err;
 
+	copy.flags |= BTREE_ITER_nofilter_whiteouts;
+
+	/*
+	 * We're doing our own whiteout filtering, but we still need to pass a
+	 * max key to avoid popping an assert in bch2_snapshot_is_ancestor():
+	 */
 	struct bkey_s_c k;
-	for_each_btree_key_max_continue_norestart(copy, *end, 0, k, ret) {
+	unsigned nr_iters = 0;
+	for_each_btree_key_max_continue_norestart(copy,
+						  POS(insert->k.p.inode, U64_MAX),
+						  0, k, ret) {
 		unsigned offset = 0;
 
 		if (bkey_gt(iter->pos, bkey_start_pos(k.k)))
 			offset = iter->pos.offset - bkey_start_offset(k.k);
 
-		ret = count_iters_for_insert(trans, k, offset, end, &nr_iters);
-		if (ret)
-			break;
+		if (bkey_extent_whiteout(k.k)) {
+			if (bpos_gt(k.k->p, insert->k.p)) {
+				if (k.k->type == KEY_TYPE_extent_whiteout)
+					break;
+				else
+					continue;
+			} else if (k.k->type != whiteout_type) {
+				nr_iters += 1;
+				if (nr_iters >= EXTENT_ITERS_MAX) {
+					end = bpos_min(end, k.k->p);
+					break;
+				}
+			}
+		} else {
+			if (bpos_ge(bkey_start_pos(k.k), end))
+				break;
+
+			ret = count_iters_for_insert(trans, k, offset, &end, &nr_iters);
+			if (ret)
+				break;
+		}
 	}
 err:
 	bch2_trans_iter_exit(&copy);
-	return ret < 0 ? ret : 0;
-}
-
-int bch2_extent_trim_atomic(struct btree_trans *trans,
-			    struct btree_iter *iter,
-			    struct bkey_i *k)
-{
-	struct bpos end = k->k.p;
-	int ret = bch2_extent_atomic_end(trans, iter, &end);
-	if (ret)
+	if (ret < 0)
 		return ret;
 
 	/* tracepoint */
 
-	if (bpos_lt(end, k->k.p)) {
+	if (bpos_lt(end, insert->k.p)) {
 		if (trace_extent_trim_atomic_enabled()) {
 			CLASS(printbuf, buf)();
 			bch2_bpos_to_text(&buf, end);
 			prt_newline(&buf);
-			bch2_bkey_val_to_text(&buf, trans->c, bkey_i_to_s_c(k));
+			bch2_bkey_val_to_text(&buf, trans->c, bkey_i_to_s_c(insert));
 			trace_extent_trim_atomic(trans->c, buf.buf);
 		}
-		bch2_cut_back(end, k);
+		bch2_cut_back(end, insert);
 	}
 	return 0;
 }
diff --git a/fs/bcachefs/extent_update.h b/fs/bcachefs/extent_update.h
index 34467db53f45..2d956d971b11 100644
--- a/fs/bcachefs/extent_update.h
+++ b/fs/bcachefs/extent_update.h
@@ -4,8 +4,6 @@
 
 #include "bcachefs.h"
 
-int bch2_extent_atomic_end(struct btree_trans *, struct btree_iter *,
-			   struct bpos *);
 int bch2_extent_trim_atomic(struct btree_trans *, struct btree_iter *,
 			    struct bkey_i *);
 
-- 
2.51.0


From d7e89f840edfd9868f0b688891fba48189b99cf5 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 4 Aug 2025 13:32:25 -0400
Subject: [PATCH 245/309] bcachefs: Improve bch2_check_topology_root()

Make the control flow less magic - handle explicitly btrees that we
don't recover from scan and always reconstruct.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_gc.c | 68 ++++++++++++++++++++++++------------------
 1 file changed, 39 insertions(+), 29 deletions(-)

diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index cbf567679a85..ae7d260589d8 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -536,45 +536,55 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 	return ret;
 }
 
-static int bch2_check_root(struct btree_trans *trans, enum btree_id btree,
+static int bch2_topology_check_root(struct btree_trans *trans, enum btree_id btree,
 			   bool *reconstructed_root)
 {
 	struct bch_fs *c = trans->c;
 	struct btree_root *r = bch2_btree_id_root(c, btree);
-	CLASS(printbuf, buf)();
-	int ret = 0;
-
-	bch2_btree_id_to_text(&buf, btree);
 
-	if (r->error) {
-		bch_info(c, "btree root %s unreadable, must recover from scan", buf.buf);
+	if (!r->error)
+		return 0;
 
-		ret = bch2_btree_has_scanned_nodes(c, btree);
-		if (ret < 0)
-			goto err;
+	CLASS(printbuf, buf)();
+	int ret = 0;
 
-		if (!ret) {
-			__fsck_err(trans,
-				   FSCK_CAN_FIX|(btree_id_can_reconstruct(btree) ? FSCK_AUTOFIX : 0),
-				   btree_root_unreadable_and_scan_found_nothing,
-				   "no nodes found for btree %s, continue?", buf.buf);
+	if (!btree_id_recovers_from_scan(btree)) {
+		r->alive = false;
+		r->error = 0;
+		bch2_btree_root_alloc_fake_trans(trans, btree, 0);
+		ret = bch2_btree_lost_data(c, &buf, btree);
+		bch2_print_str(c, KERN_NOTICE, buf.buf);
+		goto out;
+	}
 
-			r->alive = false;
-			r->error = 0;
-			bch2_btree_root_alloc_fake_trans(trans, btree, 0);
-		} else {
-			r->alive = false;
-			r->error = 0;
-			bch2_btree_root_alloc_fake_trans(trans, btree, 1);
+	bch2_btree_id_to_text(&buf, btree);
+	bch_info(c, "btree root %s unreadable, must recover from scan", buf.buf);
 
-			bch2_shoot_down_journal_keys(c, btree, 1, BTREE_MAX_DEPTH, POS_MIN, SPOS_MAX);
-			ret = bch2_get_scanned_nodes(c, btree, 0, POS_MIN, SPOS_MAX);
-			if (ret)
-				return ret;
-		}
+	ret = bch2_btree_has_scanned_nodes(c, btree);
+	if (ret < 0)
+		goto err;
 
-		*reconstructed_root = true;
+	if (!ret) {
+		__fsck_err(trans,
+			   FSCK_CAN_FIX|(btree_id_can_reconstruct(btree) ? FSCK_AUTOFIX : 0),
+			   btree_root_unreadable_and_scan_found_nothing,
+			   "no nodes found for btree %s, continue?", buf.buf);
+
+		r->alive = false;
+		r->error = 0;
+		bch2_btree_root_alloc_fake_trans(trans, btree, 0);
+	} else {
+		r->alive = false;
+		r->error = 0;
+		bch2_btree_root_alloc_fake_trans(trans, btree, 1);
+
+		bch2_shoot_down_journal_keys(c, btree, 1, BTREE_MAX_DEPTH, POS_MIN, SPOS_MAX);
+		ret = bch2_get_scanned_nodes(c, btree, 0, POS_MIN, SPOS_MAX);
+		if (ret)
+			return ret;
 	}
+out:
+	*reconstructed_root = true;
 err:
 fsck_err:
 	bch_err_fn(c, ret);
@@ -592,7 +602,7 @@ int bch2_check_topology(struct bch_fs *c)
 	for (unsigned i = 0; i < btree_id_nr_alive(c) && !ret; i++) {
 		bool reconstructed_root = false;
 recover:
-		ret = lockrestart_do(trans, bch2_check_root(trans, i, &reconstructed_root));
+		ret = lockrestart_do(trans, bch2_topology_check_root(trans, i, &reconstructed_root));
 		if (ret)
 			break;
 
-- 
2.51.0


From f532855106755f95eb734b9740275eb8d88714f0 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Tue, 5 Aug 2025 01:32:54 +0800
Subject: [PATCH 246/309] bcachefs: Don't lock inode around page_symlink

The new inode is not visible before __bch2_link successfully return,
no need to lock it.

Reported-by: syzbot+7836a68852a10ec3d790@syzkaller.appspotmail.com
Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 1 -
 fs/bcachefs/fs.c             | 2 --
 2 files changed, 3 deletions(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index 0005569ecace..c5ed62a11f23 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -759,7 +759,6 @@ int bch2_write_end(struct file *file, struct address_space *mapping,
 	struct bch2_folio_reservation *res = fsdata;
 	unsigned offset = pos - folio_pos(folio);
 
-	lockdep_assert_held(&inode->v.i_rwsem);
 	BUG_ON(offset + copied > folio_size(folio));
 
 	if (unlikely(copied < len && !folio_test_uptodate(folio))) {
diff --git a/fs/bcachefs/fs.c b/fs/bcachefs/fs.c
index 52722a5e8526..0425238a83ee 100644
--- a/fs/bcachefs/fs.c
+++ b/fs/bcachefs/fs.c
@@ -857,9 +857,7 @@ static int bch2_symlink(struct mnt_idmap *idmap,
 	if (IS_ERR(inode))
 		return bch2_err_class(PTR_ERR(inode));
 
-	inode_lock(&inode->v);
 	ret = page_symlink(&inode->v, symname, strlen(symname) + 1);
-	inode_unlock(&inode->v);
 
 	if (unlikely(ret))
 		goto err;
-- 
2.51.0


From 67821e5d3ecb31bdbe849eb8b71e4b0b1d7a65c1 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Wed, 6 Aug 2025 14:25:56 +0800
Subject: [PATCH 247/309] bcachefs: Fix readahead involved deadlock

readahead first lock the folio, then invokes aops->readahead, which
locks the two state lock to block subsequent direct I/O. However,
direct IO or bchfs_fpunch first lock the two state lock to block
subsequent buffered I/O, and then lock the folio to invalidate or
truncate it. Therefore, there is a deadlock:

thread1			thread2
lock folio		bch2_pagecache_block_get
bch2_pagecache_add_get 	lock folio

Reported-by: syzbot+23e4a7772eb9a9715b85@syzkaller.appspotmail.com
Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 17 ++++++++++++++++-
 1 file changed, 16 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index c5ed62a11f23..9f6f9f0f21ff 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -64,6 +64,17 @@ static int readpages_iter_init(struct readpages_iter *iter,
 	return 0;
 }
 
+static void readpages_iter_exit(struct readpages_iter *iter,
+			        struct readahead_control *ractl)
+{
+	darray_for_each_reverse(iter->folios, folio) {
+		bch2_folio_release(*folio);
+		ractl->_nr_pages += folio_nr_pages(*folio);
+		ractl->_index -= folio_nr_pages(*folio);
+		folio_get(*folio);
+	}
+}
+
 static inline struct folio *readpage_iter_peek(struct readpages_iter *iter)
 {
 	if (iter->idx >= iter->folios.nr)
@@ -290,7 +301,10 @@ void bch2_readahead(struct readahead_control *ractl)
 	 * scheduling.
 	 */
 	blk_start_plug(&plug);
-	bch2_pagecache_add_get(inode);
+	if (!bch2_pagecache_add_tryget(inode)) {
+		readpages_iter_exit(&readpages_iter, ractl);
+		goto out;
+	}
 
 	struct btree_trans *trans = bch2_trans_get(c);
 	while ((folio = readpage_iter_peek(&readpages_iter))) {
@@ -317,6 +331,7 @@ void bch2_readahead(struct readahead_control *ractl)
 	bch2_trans_put(trans);
 
 	bch2_pagecache_add_put(inode);
+out:
 	blk_finish_plug(&plug);
 	darray_exit(&readpages_iter.folios);
 }
-- 
2.51.0


From ede4002f566da960dcf93c9cbae37cb076b71f87 Mon Sep 17 00:00:00 2001
From: Alan Huang <mmpgouride@gmail.com>
Date: Wed, 6 Aug 2025 14:25:57 +0800
Subject: [PATCH 248/309] bcachefs: Factor out readpages_iter_folio_revert

Signed-off-by: Alan Huang <mmpgouride@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 16 ++++++++++------
 1 file changed, 10 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index 9f6f9f0f21ff..fd8beb5167ee 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -42,6 +42,14 @@ struct readpages_iter {
 	folios			folios;
 };
 
+static inline void readpages_iter_folio_revert(struct readahead_control *ractl,
+					       struct folio *folio)
+{
+	bch2_folio_release(folio);
+	ractl->_nr_pages += folio_nr_pages(folio);
+	ractl->_index -= folio_nr_pages(folio);
+}
+
 static int readpages_iter_init(struct readpages_iter *iter,
 			       struct readahead_control *ractl)
 {
@@ -52,9 +60,7 @@ static int readpages_iter_init(struct readpages_iter *iter,
 	while ((folio = __readahead_folio(ractl))) {
 		if (!bch2_folio_create(folio, GFP_KERNEL) ||
 		    darray_push(&iter->folios, folio)) {
-			bch2_folio_release(folio);
-			ractl->_nr_pages += folio_nr_pages(folio);
-			ractl->_index -= folio_nr_pages(folio);
+			readpages_iter_folio_revert(ractl, folio);
 			return iter->folios.nr ? 0 : -ENOMEM;
 		}
 
@@ -68,9 +74,7 @@ static void readpages_iter_exit(struct readpages_iter *iter,
 			        struct readahead_control *ractl)
 {
 	darray_for_each_reverse(iter->folios, folio) {
-		bch2_folio_release(*folio);
-		ractl->_nr_pages += folio_nr_pages(*folio);
-		ractl->_index -= folio_nr_pages(*folio);
+		readpages_iter_folio_revert(ractl, *folio);
 		folio_get(*folio);
 	}
 }
-- 
2.51.0


From 0c8034cdd4776d8a7dbc9b4d93fa1ff0c4dddd4c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 6 Aug 2025 13:43:19 -0400
Subject: [PATCH 249/309] bcachefs: btree_type_has_ptrs() now includes
 BTREE_ID_stripes

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_format.h | 3 ++-
 fs/bcachefs/migrate.c         | 4 ++++
 fs/bcachefs/move.c            | 4 +++-
 3 files changed, 9 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/bcachefs_format.h b/fs/bcachefs/bcachefs_format.h
index 7a0b602c1b27..80a48548ddd5 100644
--- a/fs/bcachefs/bcachefs_format.h
+++ b/fs/bcachefs/bcachefs_format.h
@@ -1378,7 +1378,8 @@ enum btree_id_flags {
 	  BIT_ULL(KEY_TYPE_alloc_v4))						\
 	x(quotas,		5,	0,					\
 	  BIT_ULL(KEY_TYPE_quota))						\
-	x(stripes,		6,	0,					\
+	x(stripes,		6,						\
+	  BTREE_IS_data,							\
 	  BIT_ULL(KEY_TYPE_stripe))						\
 	x(reflink,		7,						\
 	  BTREE_IS_extents|							\
diff --git a/fs/bcachefs/migrate.c b/fs/bcachefs/migrate.c
index a66d01d04e57..892990b4a6a6 100644
--- a/fs/bcachefs/migrate.c
+++ b/fs/bcachefs/migrate.c
@@ -125,6 +125,10 @@ static int bch2_dev_usrdata_drop(struct bch_fs *c,
 		if (!btree_type_has_ptrs(id))
 			continue;
 
+		/* Stripe keys have pointers, but are handled separately */
+		if (id == BTREE_ID_stripes)
+			continue;
+
 		int ret = for_each_btree_key_commit(trans, iter, id, POS_MIN,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k,
 				NULL, NULL, BCH_TRANS_COMMIT_no_enospc, ({
diff --git a/fs/bcachefs/move.c b/fs/bcachefs/move.c
index df6833416855..4f41f1f6ec6c 100644
--- a/fs/bcachefs/move.c
+++ b/fs/bcachefs/move.c
@@ -819,7 +819,9 @@ static int bch2_move_data(struct bch_fs *c,
 
 		unsigned min_depth_this_btree = min_depth;
 
-		if (!btree_type_has_ptrs(id))
+		/* Stripe keys have pointers, but are handled separately */
+		if (!btree_type_has_ptrs(id) ||
+		    id == BTREE_ID_stripes)
 			min_depth_this_btree = max(min_depth_this_btree, 1);
 
 		for (unsigned level = min_depth_this_btree;
-- 
2.51.0


From 0b7d4b736fd1dfa9cf1e9582388dd0063aae64ba Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 6 Aug 2025 14:26:10 -0400
Subject: [PATCH 250/309] bcachefs: Fix log message in
 bch2_set_version_incompat

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super-io.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index be7ed612d28f..369465a4de77 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -89,7 +89,7 @@ int bch2_set_version_incompat(struct bch_fs *c, enum bcachefs_metadata_version v
 			prt_str(&buf, "requested incompat feature ");
 			bch2_version_to_text(&buf, version);
 			prt_str(&buf, " currently not enabled, allowed up to ");
-			bch2_version_to_text(&buf, version);
+			bch2_version_to_text(&buf, c->sb.version_incompat_allowed);
 			prt_printf(&buf, "\n  set version_upgrade=incompat to enable");
 
 			bch_notice(c, "%s", buf.buf);
-- 
2.51.0


From 6b5969244169b411ac3250cc8f732874a763739a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 6 Aug 2025 14:33:34 -0400
Subject: [PATCH 251/309] bcachefs: Add extra debug asserts for is_ancestor()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/snapshot.c |  3 ++-
 fs/bcachefs/snapshot.h | 15 +++++++++++++++
 2 files changed, 17 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/snapshot.c b/fs/bcachefs/snapshot.c
index 84f987d3a02a..eab0c1e3ff56 100644
--- a/fs/bcachefs/snapshot.c
+++ b/fs/bcachefs/snapshot.c
@@ -1673,7 +1673,8 @@ static int bch2_fix_child_of_deleted_snapshot(struct btree_trans *trans,
 		return ret;
 
 	darray_for_each(*deleted, i)
-		nr_deleted_ancestors += bch2_snapshot_is_ancestor(c, s->k.p.offset, i->id);
+		nr_deleted_ancestors += bch2_snapshots_same_tree(c, s->k.p.offset, i->id) &&
+		bch2_snapshot_is_ancestor(c, s->k.p.offset, i->id);
 
 	if (!nr_deleted_ancestors)
 		return 0;
diff --git a/fs/bcachefs/snapshot.h b/fs/bcachefs/snapshot.h
index fef32a0118c4..28d9a29a1fd0 100644
--- a/fs/bcachefs/snapshot.h
+++ b/fs/bcachefs/snapshot.h
@@ -51,6 +51,17 @@ static inline u32 bch2_snapshot_tree(struct bch_fs *c, u32 id)
 	return s ? s->tree : 0;
 }
 
+static inline bool bch2_snapshots_same_tree(struct bch_fs *c, u32 id1, u32 id2)
+{
+	if (id1 == id2)
+		return true;
+
+	guard(rcu)();
+	const struct snapshot_t *s1 = snapshot_t(c, id1);
+	const struct snapshot_t *s2 = snapshot_t(c, id2);
+	return s1 && s2 && s1->tree == s2->tree;
+}
+
 static inline u32 __bch2_snapshot_parent_early(struct bch_fs *c, u32 id)
 {
 	const struct snapshot_t *s = snapshot_t(c, id);
@@ -157,6 +168,10 @@ bool __bch2_snapshot_is_ancestor(struct bch_fs *, u32, u32);
 
 static inline bool bch2_snapshot_is_ancestor(struct bch_fs *c, u32 id, u32 ancestor)
 {
+	EBUG_ON(!id);
+	EBUG_ON(!ancestor);
+	EBUG_ON(!bch2_snapshots_same_tree(c, id, ancestor));
+
 	return id == ancestor
 		? true
 		: __bch2_snapshot_is_ancestor(c, id, ancestor);
-- 
2.51.0


From cb8a3079307d98aa65efc80961329ca509e4a64f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 5 Aug 2025 09:54:52 -0400
Subject: [PATCH 252/309] bcachefs:
 bcachefs_metadata_version_31bit_dirent_offset

32 bit programs need 31 bit readdir offsets. This extends the behaviour
of the inodes_32bit option - when enabled, dirent hashes are masked to
31 bits.

Closes: https://github.com/koverstreet/bcachefs/issues/928
Reviewed-by: Nikita Ofitserov <himikof@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_format.h |  3 ++-
 fs/bcachefs/dirent.c          |  2 +-
 fs/bcachefs/inode_format.h    |  3 ++-
 fs/bcachefs/str_hash.h        | 14 ++++++++++++--
 fs/bcachefs/xattr.c           | 19 ++++++++++++++++++-
 5 files changed, 35 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/bcachefs_format.h b/fs/bcachefs/bcachefs_format.h
index 80a48548ddd5..b2de993d802b 100644
--- a/fs/bcachefs/bcachefs_format.h
+++ b/fs/bcachefs/bcachefs_format.h
@@ -706,7 +706,8 @@ struct bch_sb_field_ext {
 	x(snapshot_deletion_v2,		BCH_VERSION(1, 26))		\
 	x(fast_device_removal,		BCH_VERSION(1, 27))		\
 	x(inode_has_case_insensitive,	BCH_VERSION(1, 28))		\
-	x(extent_snapshot_whiteouts,	BCH_VERSION(1, 29))
+	x(extent_snapshot_whiteouts,	BCH_VERSION(1, 29))		\
+	x(31bit_dirent_offset,		BCH_VERSION(1, 30))
 
 enum bcachefs_metadata_version {
 	bcachefs_metadata_version_min = 9,
diff --git a/fs/bcachefs/dirent.c b/fs/bcachefs/dirent.c
index cb44b35e0f1d..fe6f3d874a47 100644
--- a/fs/bcachefs/dirent.c
+++ b/fs/bcachefs/dirent.c
@@ -95,7 +95,7 @@ static u64 bch2_dirent_hash(const struct bch_hash_info *info,
 	bch2_str_hash_update(&ctx, info, name->name, name->len);
 
 	/* [0,2) reserved for dots */
-	return max_t(u64, bch2_str_hash_end(&ctx, info), 2);
+	return max_t(u64, bch2_str_hash_end(&ctx, info, true), 2);
 }
 
 static u64 dirent_hash_key(const struct bch_hash_info *info, const void *key)
diff --git a/fs/bcachefs/inode_format.h b/fs/bcachefs/inode_format.h
index 1f00938b1bdc..e07fa6cc99bd 100644
--- a/fs/bcachefs/inode_format.h
+++ b/fs/bcachefs/inode_format.h
@@ -144,7 +144,8 @@ enum inode_opt_id {
 	x(unlinked,			7)	\
 	x(backptr_untrusted,		8)	\
 	x(has_child_snapshot,		9)	\
-	x(has_case_insensitive,		10)
+	x(has_case_insensitive,		10)	\
+	x(31bit_dirent_offset,		11)
 
 /* bits 20+ reserved for packed fields below: */
 
diff --git a/fs/bcachefs/str_hash.h b/fs/bcachefs/str_hash.h
index 8c0fb44929cc..2a61cc36ddbf 100644
--- a/fs/bcachefs/str_hash.h
+++ b/fs/bcachefs/str_hash.h
@@ -34,6 +34,7 @@ bch2_str_hash_opt_to_type(struct bch_fs *c, enum bch_str_hash_opts opt)
 struct bch_hash_info {
 	u32			inum_snapshot;
 	u8			type;
+	bool			is_31bit;
 	struct unicode_map	*cf_encoding;
 	/*
 	 * For crc32 or crc64 string hashes the first key value of
@@ -48,6 +49,7 @@ bch2_hash_info_init(struct bch_fs *c, const struct bch_inode_unpacked *bi)
 	struct bch_hash_info info = {
 		.inum_snapshot	= bi->bi_snapshot,
 		.type		= INODE_STR_HASH(bi),
+		.is_31bit	= bi->bi_flags & BCH_INODE_31bit_dirent_offset,
 		.cf_encoding	= bch2_inode_casefold(c, bi) ? c->cf_encoding : NULL,
 		.siphash_key	= { .k0 = bi->bi_hash_seed }
 	};
@@ -112,8 +114,8 @@ static inline void bch2_str_hash_update(struct bch_str_hash_ctx *ctx,
 	}
 }
 
-static inline u64 bch2_str_hash_end(struct bch_str_hash_ctx *ctx,
-				   const struct bch_hash_info *info)
+static inline u64 __bch2_str_hash_end(struct bch_str_hash_ctx *ctx,
+				      const struct bch_hash_info *info)
 {
 	switch (info->type) {
 	case BCH_STR_HASH_crc32c:
@@ -128,6 +130,14 @@ static inline u64 bch2_str_hash_end(struct bch_str_hash_ctx *ctx,
 	}
 }
 
+static inline u64 bch2_str_hash_end(struct bch_str_hash_ctx *ctx,
+				    const struct bch_hash_info *info,
+				    bool maybe_31bit)
+{
+	return __bch2_str_hash_end(ctx, info) &
+		(maybe_31bit && info->is_31bit ? INT_MAX : U64_MAX);
+}
+
 struct bch_hash_desc {
 	enum btree_id	btree_id;
 	u8		key_type;
diff --git a/fs/bcachefs/xattr.c b/fs/bcachefs/xattr.c
index 6094b568dd33..6d7303008b19 100644
--- a/fs/bcachefs/xattr.c
+++ b/fs/bcachefs/xattr.c
@@ -4,6 +4,7 @@
 #include "acl.h"
 #include "bkey_methods.h"
 #include "btree_update.h"
+#include "dirent.h"
 #include "extents.h"
 #include "fs.h"
 #include "rebalance.h"
@@ -25,7 +26,7 @@ static u64 bch2_xattr_hash(const struct bch_hash_info *info,
 	bch2_str_hash_update(&ctx, info, &key->type, sizeof(key->type));
 	bch2_str_hash_update(&ctx, info, key->name.name, key->name.len);
 
-	return bch2_str_hash_end(&ctx, info);
+	return bch2_str_hash_end(&ctx, info, false);
 }
 
 static u64 xattr_hash_key(const struct bch_hash_info *info, const void *key)
@@ -484,6 +485,22 @@ static int inode_opt_set_fn(struct btree_trans *trans,
 			return ret;
 	}
 
+	if (s->id == Inode_opt_inodes_32bit &&
+	    !bch2_request_incompat_feature(trans->c, bcachefs_metadata_version_31bit_dirent_offset)) {
+		/*
+		 * Make sure the dir is empty, as otherwise we'd need to
+		 * rehash everything and update the dirent keys.
+		 */
+		int ret = bch2_empty_dir_trans(trans, inode_inum(inode));
+		if (ret < 0)
+			return ret;
+
+		if (s->defined)
+			bi->bi_flags |= BCH_INODE_31bit_dirent_offset;
+		else
+			bi->bi_flags &= ~BCH_INODE_31bit_dirent_offset;
+	}
+
 	if (s->defined)
 		bi->bi_fields_set |= 1U << s->id;
 	else
-- 
2.51.0


From 698e0437bc46e863ed9632e519b7d6a25985cad0 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 6 Aug 2025 18:31:22 -0400
Subject: [PATCH 253/309] bcachefs: Correctly plumb inodes_32bit option for
 directories

Reviewed-by: Nikita Ofitserov <himikof@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fsck.c  |  5 +++--
 fs/bcachefs/inode.c | 11 ++++++-----
 fs/bcachefs/inode.h |  2 +-
 fs/bcachefs/namei.c |  3 ++-
 4 files changed, 12 insertions(+), 9 deletions(-)

diff --git a/fs/bcachefs/fsck.c b/fs/bcachefs/fsck.c
index 01c1c6372229..ccc44b1fc178 100644
--- a/fs/bcachefs/fsck.c
+++ b/fs/bcachefs/fsck.c
@@ -266,7 +266,8 @@ static int lookup_lostfound(struct btree_trans *trans, u32 snapshot,
 
 	root_inode.bi_nlink++;
 
-	ret = bch2_inode_create(trans, &lostfound_iter, lostfound, snapshot, cpu);
+	ret = bch2_inode_create(trans, &lostfound_iter, lostfound, snapshot, cpu,
+				inode_opt_get(c, &root_inode, inodes_32bit));
 	if (ret)
 		goto err;
 
@@ -573,7 +574,7 @@ static int reconstruct_subvol(struct btree_trans *trans, u32 snapshotid, u32 sub
 
 		new_inode.bi_subvol = subvolid;
 
-		int ret = bch2_inode_create(trans, &inode_iter, &new_inode, snapshotid, cpu) ?:
+		int ret = bch2_inode_create(trans, &inode_iter, &new_inode, snapshotid, cpu, false) ?:
 			  bch2_btree_iter_traverse(&inode_iter) ?:
 			  bch2_inode_write(trans, &inode_iter, &new_inode);
 		bch2_trans_iter_exit(&inode_iter);
diff --git a/fs/bcachefs/inode.c b/fs/bcachefs/inode.c
index d5e5190f0663..4aa130ff7cf6 100644
--- a/fs/bcachefs/inode.c
+++ b/fs/bcachefs/inode.c
@@ -944,11 +944,12 @@ void bch2_inode_init(struct bch_fs *c, struct bch_inode_unpacked *inode_u,
 }
 
 static struct bkey_i_inode_alloc_cursor *
-bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *max)
+bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *max,
+			    bool is_32bit)
 {
 	struct bch_fs *c = trans->c;
 
-	u64 cursor_idx = c->opts.inodes_32bit ? 0 : cpu + 1;
+	u64 cursor_idx = is_32bit ? 0 : cpu + 1;
 
 	cursor_idx &= ~(~0ULL << c->opts.shard_inode_numbers_bits);
 
@@ -967,7 +968,7 @@ bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *m
 	if (IS_ERR(cursor))
 		return cursor;
 
-	if (c->opts.inodes_32bit) {
+	if (is_32bit) {
 		*min = BLOCKDEV_INODE_MAX;
 		*max = INT_MAX;
 	} else {
@@ -996,11 +997,11 @@ bch2_inode_alloc_cursor_get(struct btree_trans *trans, u64 cpu, u64 *min, u64 *m
 int bch2_inode_create(struct btree_trans *trans,
 		      struct btree_iter *iter,
 		      struct bch_inode_unpacked *inode_u,
-		      u32 snapshot, u64 cpu)
+		      u32 snapshot, u64 cpu, bool is_32bit)
 {
 	u64 min, max;
 	struct bkey_i_inode_alloc_cursor *cursor =
-		bch2_inode_alloc_cursor_get(trans, cpu, &min, &max);
+		bch2_inode_alloc_cursor_get(trans, cpu, &min, &max, is_32bit);
 	int ret = PTR_ERR_OR_ZERO(cursor);
 	if (ret)
 		return ret;
diff --git a/fs/bcachefs/inode.h b/fs/bcachefs/inode.h
index b8ec3e628d90..79092ea74844 100644
--- a/fs/bcachefs/inode.h
+++ b/fs/bcachefs/inode.h
@@ -172,7 +172,7 @@ void bch2_inode_init(struct bch_fs *, struct bch_inode_unpacked *,
 		     struct bch_inode_unpacked *);
 
 int bch2_inode_create(struct btree_trans *, struct btree_iter *,
-		      struct bch_inode_unpacked *, u32, u64);
+		      struct bch_inode_unpacked *, u32, u64, bool);
 
 int bch2_inode_rm(struct bch_fs *, subvol_inum);
 
diff --git a/fs/bcachefs/namei.c b/fs/bcachefs/namei.c
index d1019052f182..5c321a0d1f89 100644
--- a/fs/bcachefs/namei.c
+++ b/fs/bcachefs/namei.c
@@ -62,7 +62,8 @@ int bch2_create_trans(struct btree_trans *trans,
 		if (flags & BCH_CREATE_TMPFILE)
 			new_inode->bi_flags |= BCH_INODE_unlinked;
 
-		ret = bch2_inode_create(trans, &inode_iter, new_inode, snapshot, cpu);
+		ret = bch2_inode_create(trans, &inode_iter, new_inode, snapshot, cpu,
+					inode_opt_get(c, dir_u, inodes_32bit));
 		if (ret)
 			goto err;
 
-- 
2.51.0


From 516b345d042a6ea8b963551088722984a569ce1d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 6 Aug 2025 23:34:06 -0400
Subject: [PATCH 254/309] bcachefs: inodes_32bit off by default

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/opts.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/opts.h b/fs/bcachefs/opts.h
index 84ce69a7f131..03e22fb83d17 100644
--- a/fs/bcachefs/opts.h
+++ b/fs/bcachefs/opts.h
@@ -242,7 +242,7 @@ enum fsck_err_opts {
 	x(inodes_32bit,			u8,				\
 	  OPT_FS|OPT_INODE|OPT_FORMAT|OPT_MOUNT|OPT_RUNTIME,		\
 	  OPT_BOOL(),							\
-	  BCH_SB_INODE_32BIT,		true,				\
+	  BCH_SB_INODE_32BIT,		false,				\
 	  NULL,		"Constrain inode numbers to 32 bits")		\
 	x(shard_inode_numbers_bits,	u8,				\
 	  OPT_FS|OPT_FORMAT,						\
-- 
2.51.0


From 60094571eea7ab8f95de0047091acb1cf7210354 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 7 Aug 2025 20:07:11 -0400
Subject: [PATCH 255/309] bcachefs: Never run check_backpointers_to_extents by
 default anymore

It's not needed anymore, we check backpointers as we use them, and the
performance overhead is too high for modern filesystems.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery.c               | 1 -
 fs/bcachefs/recovery_passes_format.h | 2 +-
 2 files changed, 1 insertion(+), 2 deletions(-)

diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 29e81f96db0f..8280ca333f5b 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -64,7 +64,6 @@ int bch2_btree_lost_data(struct bch_fs *c,
 	 * but in debug mode we want the next fsck run to be clean:
 	 */
 	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_lrus, 0, &write_sb) ?: ret;
-	ret = __bch2_run_explicit_recovery_pass(c, msg, BCH_RECOVERY_PASS_check_backpointers_to_extents, 0, &write_sb) ?: ret;
 #endif
 
 	write_sb |= !__test_and_set_bit_le64(BCH_FSCK_ERR_lru_entry_bad, ext->errors_silent);
diff --git a/fs/bcachefs/recovery_passes_format.h b/fs/bcachefs/recovery_passes_format.h
index b63c20558d3d..2696eee00345 100644
--- a/fs/bcachefs/recovery_passes_format.h
+++ b/fs/bcachefs/recovery_passes_format.h
@@ -37,7 +37,7 @@
 	x(check_alloc_info,			10, PASS_ONLINE|PASS_FSCK_ALLOC)	\
 	x(check_lrus,				11, PASS_ONLINE|PASS_FSCK_ALLOC)	\
 	x(check_btree_backpointers,		12, PASS_ONLINE|PASS_FSCK_ALLOC)	\
-	x(check_backpointers_to_extents,	13, PASS_ONLINE|PASS_FSCK_DEBUG)	\
+	x(check_backpointers_to_extents,	13, PASS_ONLINE)			\
 	x(check_extents_to_backpointers,	14, PASS_ONLINE|PASS_FSCK_ALLOC)	\
 	x(check_alloc_to_lru_refs,		15, PASS_ONLINE|PASS_FSCK_ALLOC)	\
 	x(fs_freespace_init,			16, PASS_ALWAYS|PASS_SILENT)		\
-- 
2.51.0


From 09e119b223468b97a48ee8ff2855b3c793480e20 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 7 Aug 2025 22:35:38 -0400
Subject: [PATCH 256/309] bcachefs: Ensure btree node read errors get printed

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index 276cf088539e..32dbe21a740c 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -1470,7 +1470,7 @@ static void btree_node_read_work(struct work_struct *work)
 	}
 	prt_newline(&buf);
 
-	if (failed.nr)
+	if (ret || failed.nr)
 		bch2_print_str_ratelimited(c, KERN_ERR, buf.buf);
 
 	async_object_list_del(c, btree_read_bio, rb->list_idx);
-- 
2.51.0


From 194e5eb9b4becf54de624bc24e1f576492a50524 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 7 Aug 2025 22:44:36 -0400
Subject: [PATCH 257/309] bcachefs: Log btrees_lost_data in startup message

If we have repair to do due to btree damage - log that.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/super.c | 6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 09e7f8ae9922..ee3b30b1c2b5 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1021,6 +1021,12 @@ static int bch2_fs_opt_version_init(struct bch_fs *c)
 			prt_bitflags(&p, bch2_recovery_passes, sb_passes);
 		}
 
+		u64 btrees_lost_data = le64_to_cpu(ext->btrees_lost_data);
+		if (btrees_lost_data) {
+			prt_str(&p, "\nsuperblock indicates damage to following btrees:\n  ");
+			prt_bitflags(&p, __bch2_btree_ids, btrees_lost_data);
+		}
+
 		if (bch2_check_version_downgrade(c)) {
 			prt_str(&p, "\nVersion downgrade required:");
 
-- 
2.51.0


From e455d22921e6bb32ea331c5f8dec4ec01590a3a2 Mon Sep 17 00:00:00 2001
From: Francis Rossi <francisdrossi@gmail.com>
Date: Wed, 6 Aug 2025 19:37:45 -0400
Subject: [PATCH 258/309] bcachefs: Update io_read_fail_and_poison to new
 counter

io_read_fail_and_poison shared counter 82 with io_move_write_fail, moving to its own counter

Signed-off-by: Francis Rossi <francisdrossi@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-counters_format.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index 44bc12573a0c..82d2eb3576c3 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -22,7 +22,7 @@ enum counters_flags {
 	x(io_read_split,				33,	TYPE_COUNTER)	\
 	x(io_read_reuse_race,				34,	TYPE_COUNTER)	\
 	x(io_read_retry,				32,	TYPE_COUNTER)	\
-	x(io_read_fail_and_poison,			82,	TYPE_COUNTER)	\
+	x(io_read_fail_and_poison,			95,	TYPE_COUNTER)	\
 	x(io_write,					1,	TYPE_SECTORS)	\
 	x(io_move,					2,	TYPE_SECTORS)	\
 	x(io_move_read,					35,	TYPE_SECTORS)	\
-- 
2.51.0


From 38de8638343667e94e924ac4f54c37947d0fa725 Mon Sep 17 00:00:00 2001
From: Francis Rossi <francisdrossi@gmail.com>
Date: Wed, 6 Aug 2025 23:54:00 -0400
Subject: [PATCH 259/309] bcachefs: Switch statement evaluate ids and confirm
 they are unique going forward

Signed-off-by: Francis Rossi <francisdrossi@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-counters_format.h | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index 82d2eb3576c3..bfeb713dd210 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -124,4 +124,12 @@ struct bch_sb_field_counters {
 	__le64			d[];
 };
 
+static inline void __maybe_unused check_bch_counter_ids_unique(void) {
+	switch(0){
+#define x(t, n, ...) case (n):
+        BCH_PERSISTENT_COUNTERS()
+#undef x
+	}
+}
+
 #endif /* _BCACHEFS_SB_COUNTERS_FORMAT_H */
-- 
2.51.0


From 554348a9da7b7fc0b8f85c221095040d67f84e64 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 14:58:35 -0400
Subject: [PATCH 260/309] bcachefs: Btree nodes are
 __GFP_ACCOUNT|__GFP_RECLAIMABLE

Allocations done in btree_cache.c were marked correctly, but bounce
allocations in btree_io.c typically become long lived allocations - they
need to be marked as well.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index 32dbe21a740c..b1f58fb31ed1 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -131,10 +131,10 @@ static void *btree_bounce_alloc(struct bch_fs *c, size_t size,
 	BUG_ON(size > c->opts.btree_node_size);
 
 	*used_mempool = false;
-	p = kvmalloc(size, GFP_NOWAIT);
+	p = kvmalloc(size, GFP_NOWAIT|__GFP_ACCOUNT|__GFP_RECLAIMABLE);
 	if (!p) {
 		*used_mempool = true;
-		p = mempool_alloc(&c->btree_bounce_pool, GFP_NOFS);
+		p = mempool_alloc(&c->btree_bounce_pool, GFP_NOFS|__GFP_ACCOUNT|__GFP_RECLAIMABLE);
 	}
 	memalloc_nofs_restore(flags);
 	return p;
-- 
2.51.0


From c67b2d3f60894b422b60d1a5b9aa320c01712ff5 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 17:59:51 -0400
Subject: [PATCH 261/309] bcachefs: Fix journal stuck message

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index 07869436a964..d56959f12210 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -737,9 +737,9 @@ int bch2_journal_res_get_slowpath(struct journal *j, struct journal_res *res,
 		return ret;
 
 	CLASS(printbuf, buf)();
+	prt_printf(&buf, bch2_fmt(c, "Journal stuck? Waited for 10 seconds, err %s"), bch2_err_str(ret));
 	bch2_journal_debug_to_text(&buf, j);
 	bch2_print_str(c, KERN_ERR, buf.buf);
-	prt_printf(&buf, bch2_fmt(c, "Journal stuck? Waited for 10 seconds, err %s"), bch2_err_str(ret));
 
 	closure_wait_event(&j->async_wait,
 		   !bch2_err_matches(ret = __journal_res_get(j, res, flags), BCH_ERR_operation_blocked) ||
-- 
2.51.0


From 6fe8ea254d2b6c762d1ed532c23458cf22796521 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 20:03:06 -0400
Subject: [PATCH 262/309] bcachefs: bch_opts.no_version_check

Add a hidden option for disabling the version check in sb_validate, to
be used by userspace tools (device scan, show_super).

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/opts.h     |  5 +++++
 fs/bcachefs/super-io.c | 51 ++++++++++++++++++++++--------------------
 fs/bcachefs/super-io.h |  3 ++-
 3 files changed, 34 insertions(+), 25 deletions(-)

diff --git a/fs/bcachefs/opts.h b/fs/bcachefs/opts.h
index 03e22fb83d17..31a3abcbd83e 100644
--- a/fs/bcachefs/opts.h
+++ b/fs/bcachefs/opts.h
@@ -321,6 +321,11 @@ enum fsck_err_opts {
 	  OPT_BOOL(),							\
 	  BCH2_NO_SB_OPT,		false,				\
 	  NULL,		"Don't kick drives out when splitbrain detected")\
+	x(no_version_check,		u8,				\
+	  OPT_HIDDEN,							\
+	  OPT_BOOL(),							\
+	  BCH2_NO_SB_OPT,		false,				\
+	  NULL,		"Don't fail reading the superblock due to incompatible version")\
 	x(verbose,			u8,				\
 	  OPT_FS|OPT_MOUNT|OPT_RUNTIME,					\
 	  OPT_BOOL(),							\
diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index 369465a4de77..5897380c4c08 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -379,7 +379,7 @@ static int bch2_sb_compatible(struct bch_sb *sb, struct printbuf *out)
 	return 0;
 }
 
-int bch2_sb_validate(struct bch_sb *sb, u64 read_offset,
+int bch2_sb_validate(struct bch_sb *sb, struct bch_opts *opts, u64 read_offset,
 		     enum bch_validate_flags flags, struct printbuf *out)
 {
 	enum bch_opt_id opt_id;
@@ -389,28 +389,30 @@ int bch2_sb_validate(struct bch_sb *sb, u64 read_offset,
 	if (ret)
 		return ret;
 
-	u64 incompat = le64_to_cpu(sb->features[0]) & (~0ULL << BCH_FEATURE_NR);
-	unsigned incompat_bit = 0;
-	if (incompat)
-		incompat_bit = __ffs64(incompat);
-	else if (sb->features[1])
-		incompat_bit = 64 + __ffs64(le64_to_cpu(sb->features[1]));
-
-	if (incompat_bit) {
-		prt_printf(out, "Filesystem has incompatible feature bit %u, highest supported %s (%u)",
-			   incompat_bit,
-			   bch2_sb_features[BCH_FEATURE_NR - 1],
-			   BCH_FEATURE_NR - 1);
-		return -BCH_ERR_invalid_sb_features;
-	}
+	if (!opts->no_version_check) {
+		u64 incompat = le64_to_cpu(sb->features[0]) & (~0ULL << BCH_FEATURE_NR);
+		unsigned incompat_bit = 0;
+		if (incompat)
+			incompat_bit = __ffs64(incompat);
+		else if (sb->features[1])
+			incompat_bit = 64 + __ffs64(le64_to_cpu(sb->features[1]));
+
+		if (incompat_bit) {
+			prt_printf(out, "Filesystem has incompatible feature bit %u, highest supported %s (%u)",
+				   incompat_bit,
+				   bch2_sb_features[BCH_FEATURE_NR - 1],
+				   BCH_FEATURE_NR - 1);
+			return -BCH_ERR_invalid_sb_features;
+		}
 
-	if (BCH_VERSION_MAJOR(le16_to_cpu(sb->version)) > BCH_VERSION_MAJOR(bcachefs_metadata_version_current) ||
-	    BCH_SB_VERSION_INCOMPAT(sb) > bcachefs_metadata_version_current) {
-		prt_str(out, "Filesystem has incompatible version ");
-		bch2_version_to_text(out, le16_to_cpu(sb->version));
-		prt_str(out, ", current version ");
-		bch2_version_to_text(out, bcachefs_metadata_version_current);
-		return -BCH_ERR_invalid_sb_features;
+		if (BCH_VERSION_MAJOR(le16_to_cpu(sb->version)) > BCH_VERSION_MAJOR(bcachefs_metadata_version_current) ||
+		    BCH_SB_VERSION_INCOMPAT(sb) > bcachefs_metadata_version_current) {
+			prt_str(out, "Filesystem has incompatible version ");
+			bch2_version_to_text(out, le16_to_cpu(sb->version));
+			prt_str(out, ", current version ");
+			bch2_version_to_text(out, bcachefs_metadata_version_current);
+			return -BCH_ERR_invalid_sb_features;
+		}
 	}
 
 	if (bch2_is_zero(sb->user_uuid.b, sizeof(sb->user_uuid))) {
@@ -915,7 +917,7 @@ static int __bch2_read_super(const char *path, struct bch_opts *opts,
 
 	sb->have_layout = true;
 
-	ret = bch2_sb_validate(sb->sb, offset, 0, &err);
+	ret = bch2_sb_validate(sb->sb, opts, offset, 0, &err);
 	if (ret) {
 		bch2_print_opts(opts, KERN_ERR "bcachefs (%s): error validating superblock: %s\n",
 				path, err.buf);
@@ -1081,9 +1083,10 @@ int bch2_write_super(struct bch_fs *c)
 		bch2_sb_from_fs(c, (*ca));
 
 	darray_for_each(online_devices, ca) {
+		struct bch_opts opts = bch2_opts_empty();
 		printbuf_reset(&err);
 
-		ret = bch2_sb_validate((*ca)->disk_sb.sb, 0, BCH_VALIDATE_write, &err);
+		ret = bch2_sb_validate((*ca)->disk_sb.sb, &opts, 0, BCH_VALIDATE_write, &err);
 		if (ret) {
 			bch2_fs_inconsistent(c, "sb invalid before write: %s", err.buf);
 			goto out;
diff --git a/fs/bcachefs/super-io.h b/fs/bcachefs/super-io.h
index a3b7a90f2533..82cb3a3ceeae 100644
--- a/fs/bcachefs/super-io.h
+++ b/fs/bcachefs/super-io.h
@@ -92,7 +92,8 @@ int bch2_sb_from_fs(struct bch_fs *, struct bch_dev *);
 void bch2_free_super(struct bch_sb_handle *);
 int bch2_sb_realloc(struct bch_sb_handle *, unsigned);
 
-int bch2_sb_validate(struct bch_sb *, u64, enum bch_validate_flags, struct printbuf *);
+int bch2_sb_validate(struct bch_sb *, struct bch_opts *, u64,
+		     enum bch_validate_flags, struct printbuf *);
 
 int bch2_read_super(const char *, struct bch_opts *, struct bch_sb_handle *);
 int bch2_read_super_silent(const char *, struct bch_opts *, struct bch_sb_handle *);
-- 
2.51.0


From 012e1e25105b8c936f802ec67e240a6b34ad9e1e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 19:41:59 -0400
Subject: [PATCH 263/309] bcachefs: Fix backpointers 1.14 upgrade

When upgrading from before on disk format version 1.14, we want to
aggressively delete probably-wrong backpoitners so that we don't have
to walk to the extent they point to later.

The version check was wrong - it should have been "if upgrade_complete <
1.14".

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 45d3db41225a..e6812a4a2493 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -897,7 +897,7 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 
 		struct bkey_s_c_backpointer bp = bkey_s_c_to_backpointer(bp_k);
 
-		if (c->sb.version_upgrade_complete >= bcachefs_metadata_version_backpointer_bucket_gen &&
+		if (c->sb.version_upgrade_complete < bcachefs_metadata_version_backpointer_bucket_gen &&
 		    (bp.v->bucket_gen != a->gen ||
 		     bp.v->pad)) {
 			ret = bch2_backpointer_del(trans, bp_k.k->p);
-- 
2.51.0


From 044695a17ad1ecbd4f976c2af9b86e50e7bd355e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 19:50:51 -0400
Subject: [PATCH 264/309] bcachefs: Fix backpointer_node_has_missing()

At some point the mismatches and empty bitmaps changed: mismatches now
includes empty, but backpointer_node_has_missing() wasn't changed to
take that into account - we don't need to pin nodes that point to
buckets where we'll be recreating, not checking backpointers in those
buckets.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 22 ++++++++++++++++------
 1 file changed, 16 insertions(+), 6 deletions(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index e6812a4a2493..e046f1acf5dc 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -976,12 +976,22 @@ static bool backpointer_node_has_missing(struct bch_fs *c, struct bkey_s_c k)
 				goto next;
 
 			struct bpos bucket = bp_pos_to_bucket(ca, pos);
-			u64 next = ca->mi.nbuckets;
-
-			unsigned long *bitmap = READ_ONCE(ca->bucket_backpointer_mismatch.buckets);
-			if (bitmap)
-				next = min_t(u64, next,
-					     find_next_bit(bitmap, ca->mi.nbuckets, bucket.offset));
+			u64 next = min(bucket.offset, ca->mi.nbuckets);
+
+			unsigned long *mismatch = READ_ONCE(ca->bucket_backpointer_mismatch.buckets);
+			unsigned long *empty = READ_ONCE(ca->bucket_backpointer_empty.buckets);
+			/*
+			 * Find the first bucket with mismatches - but
+			 * not empty buckets; we don't need to pin those
+			 * because we just recreate all backpointers in
+			 * those buckets
+			 */
+			if (mismatch && empty)
+				next = find_next_andnot_bit(mismatch, empty, ca->mi.nbuckets, next);
+			else if (mismatch)
+				next = find_next_bit(mismatch, ca->mi.nbuckets, next);
+			else
+				next = ca->mi.nbuckets;
 
 			bucket.offset = next;
 			if (bucket.offset == ca->mi.nbuckets)
-- 
2.51.0


From 95968bc1abfbf4361df6fec6869ccac4b28ffa6f Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 19:53:36 -0400
Subject: [PATCH 265/309] bcachefs: Improve
 bch2_check_extents_to_backpointers() log message

For 6.14 upgrades, it's important to know how many buckets had
backpointer mismatches vs. were empty of backpointers - the latter are
much more efficient to process.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index e046f1acf5dc..3f829440a639 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -1118,17 +1118,18 @@ int bch2_check_extents_to_backpointers(struct bch_fs *c)
 	if (ret)
 		goto err;
 
-	u64 nr_buckets = 0, nr_mismatches = 0;
+	u64 nr_buckets = 0, nr_mismatches = 0, nr_empty = 0;
 	for_each_member_device(c, ca) {
 		nr_buckets	+= ca->mi.nbuckets;
 		nr_mismatches	+= ca->bucket_backpointer_mismatch.nr;
+		nr_empty	+= ca->bucket_backpointer_empty.nr;
 	}
 
 	if (!nr_mismatches)
 		goto err;
 
-	bch_info(c, "scanning for missing backpointers in %llu/%llu buckets",
-		 nr_mismatches, nr_buckets);
+	bch_info(c, "scanning for missing backpointers in %llu/%llu buckets, %llu buckets with no backpointers",
+		 nr_mismatches - nr_empty, nr_buckets, nr_empty);
 
 	while (1) {
 		ret = bch2_pin_backpointer_nodes_with_missing(trans, s.bp_start, &s.bp_end);
-- 
2.51.0


From 7b63cde2ad8be9994039ae1a5abe4d38268e9fb3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 19:58:34 -0400
Subject: [PATCH 266/309] bcachefs: add comment to
 check_bucket_backpointer_mismatch()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 3f829440a639..01f548751891 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -929,6 +929,14 @@ static int check_bucket_backpointer_mismatch(struct btree_trans *trans, struct b
 	if (sectors[ALLOC_dirty]  != a->dirty_sectors ||
 	    sectors[ALLOC_cached] != a->cached_sectors ||
 	    sectors[ALLOC_stripe] != a->stripe_sectors) {
+		/*
+		 * Post 1.14 upgrade, we assume that backpointers are mostly
+		 * correct and a sector count mismatch is probably due to a
+		 * write buffer race
+		 *
+		 * Pre upgrade, we expect all the buckets to be wrong, a write
+		 * buffer flush is pointless:
+		 */
 		if (c->sb.version_upgrade_complete >= bcachefs_metadata_version_backpointer_bucket_gen) {
 			ret = bch2_backpointers_maybe_flush(trans, alloc_k, last_flushed);
 			if (ret)
-- 
2.51.0


From 65c604dba89a86d3dae0bd98b7b0b6c077ac930c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 20:35:10 -0400
Subject: [PATCH 267/309] bcachefs: Lift multi-pass range check out of
 check_bp_exists()

Fix a performance bug when we have lots of buckets devoid of
backpointers, and are running in multiple passes.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/backpointers.c | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/fs/bcachefs/backpointers.c b/fs/bcachefs/backpointers.c
index 01f548751891..cb25cddb759b 100644
--- a/fs/bcachefs/backpointers.c
+++ b/fs/bcachefs/backpointers.c
@@ -532,10 +532,6 @@ static int check_bp_exists(struct btree_trans *trans,
 	struct btree_iter other_extent_iter = {};
 	CLASS(printbuf, buf)();
 
-	if (bpos_lt(bp->k.p, s->bp_start) ||
-	    bpos_gt(bp->k.p, s->bp_end))
-		return 0;
-
 	CLASS(btree_iter, bp_iter)(trans, BTREE_ID_backpointers, bp->k.p, 0);
 	struct bkey_s_c bp_k = bch2_btree_iter_peek_slot(&bp_iter);
 	int ret = bkey_err(bp_k);
@@ -690,6 +686,10 @@ static int check_extent_to_backpointers(struct btree_trans *trans,
 		struct bkey_i_backpointer bp;
 		bch2_extent_ptr_to_bp(c, btree, level, k, p, entry, &bp);
 
+		if (bpos_lt(bp.k.p, s->bp_start) ||
+		    bpos_gt(bp.k.p, s->bp_end))
+			continue;
+
 		int ret = !empty
 			? check_bp_exists(trans, s, &bp, k)
 			: bch2_bucket_backpointer_mod(trans, k, &bp, true);
-- 
2.51.0


From 6fa7d8fea8b79e345df19b77848d503b33bedeee Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 10 Aug 2025 17:42:00 -0400
Subject: [PATCH 268/309] bcachefs: Fix spurious error in validate_bset_keys

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_io.c | 1 +
 1 file changed, 1 insertion(+)

diff --git a/fs/bcachefs/btree_io.c b/fs/bcachefs/btree_io.c
index b1f58fb31ed1..2e3dd9bacac5 100644
--- a/fs/bcachefs/btree_io.c
+++ b/fs/bcachefs/btree_io.c
@@ -1014,6 +1014,7 @@ static int validate_bset_keys(struct bch_fs *c, struct btree *b,
 		k = bkey_p_next(k);
 		continue;
 drop_this_key:
+		ret = 0;
 		next_good_key = k->u64s;
 
 		if (!next_good_key ||
-- 
2.51.0


From 64e16fd8eddeb5b0eb09a2ca0f6535d3fb44064a Mon Sep 17 00:00:00 2001
From: Gopi Krishna Menon <krishnagopi487@gmail.com>
Date: Sun, 10 Aug 2025 16:16:48 +0530
Subject: [PATCH 269/309] docs: filesystems: bcachefs: Fix spelling mistake in
 idle_work page

Specifically, fix spelling mistake of "hierarchy"

Signed-off-by: Gopi Krishna Menon <krishnagopi487@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 Documentation/filesystems/bcachefs/future/idle_work.rst | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/Documentation/filesystems/bcachefs/future/idle_work.rst b/Documentation/filesystems/bcachefs/future/idle_work.rst
index 59a332509dcd..f1202113dde0 100644
--- a/Documentation/filesystems/bcachefs/future/idle_work.rst
+++ b/Documentation/filesystems/bcachefs/future/idle_work.rst
@@ -11,10 +11,10 @@ idle" so the system can go to sleep. We don't want to be dribbling out
 background work while the system should be idle.
 
 The complicating factor is that there are a number of background tasks, which
-form a heirarchy (or a digraph, depending on how you divide it up) - one
+form a hierarchy (or a digraph, depending on how you divide it up) - one
 background task may generate work for another.
 
-Thus proper idle detection needs to model this heirarchy.
+Thus proper idle detection needs to model this hierarchy.
 
 - Foreground writes
 - Page cache writeback
@@ -51,7 +51,7 @@ IDLE REGIME
 When the system becomes idle, we should start flushing our pending work
 quicker so the system can go to sleep.
 
-Note that the definition of "idle" depends on where in the heirarchy a task
+Note that the definition of "idle" depends on where in the hierarchy a task
 is - a task should start flushing work more quickly when the task above it has
 stopped generating new work.
 
-- 
2.51.0


From 2b96d222bb473039e79892a4f81ee758166b8fba Mon Sep 17 00:00:00 2001
From: Nathan Chancellor <nathan@kernel.org>
Date: Tue, 12 Aug 2025 11:02:11 -0700
Subject: [PATCH 270/309] bcachefs: Add statement to switch in
 check_bch_counter_ids_unique()

Clang warns (or errors with CONFIG_WERROR=y):

  fs/bcachefs/sb-counters_format.h:132:2: error: label at end of compound statement is a C23 extension [-Werror,-Wc23-extensions]
    132 |         }
        |         ^

In older versions of clang, this is an unconditional hard error:

  fs/bcachefs/sb-counters_format.h:130:34: error: label at end of compound statement: expected statement
          BCH_PERSISTENT_COUNTERS()
                                   ^
                                    ;

Add an empty statement to resolve the error/warning.

Fixes: 38de86383436 ("bcachefs: Switch statement evaluate ids and confirm they are unique going forward")
Signed-off-by: Nathan Chancellor <nathan@kernel.org>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-counters_format.h | 1 +
 1 file changed, 1 insertion(+)

diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index bfeb713dd210..96ad64920810 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -129,6 +129,7 @@ static inline void __maybe_unused check_bch_counter_ids_unique(void) {
 #define x(t, n, ...) case (n):
         BCH_PERSISTENT_COUNTERS()
 #undef x
+		;
 	}
 }
 
-- 
2.51.0


From 8118d12629a6ef0b6afc5c458a3e548d8235fd8d Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 12:27:23 -0400
Subject: [PATCH 271/309] bcachefs: Add tracking for size of dirty journal
 entries

Prep work for limiting the size of dirty journal entries, to make sure
journal replay works.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal.c         |  6 ++++++
 fs/bcachefs/journal_reclaim.c | 10 +++++++++-
 fs/bcachefs/journal_types.h   |  2 ++
 3 files changed, 17 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/journal.c b/fs/bcachefs/journal.c
index d56959f12210..93ac0faedf7d 100644
--- a/fs/bcachefs/journal.c
+++ b/fs/bcachefs/journal.c
@@ -120,6 +120,7 @@ static void journal_pin_list_init(struct journal_entry_pin_list *p, int count)
 		INIT_LIST_HEAD(&p->flushed[i]);
 	atomic_set(&p->count, count);
 	p->devs.nr = 0;
+	p->bytes = 0;
 }
 
 /*
@@ -264,6 +265,11 @@ static void __journal_entry_close(struct journal *j, unsigned closed_val, bool t
 	/* Close out old buffer: */
 	buf->data->u64s		= cpu_to_le32(old.cur_entry_offset);
 
+	struct journal_entry_pin_list *pin_list =
+		journal_seq_pin(j, journal_cur_seq(j));
+	pin_list->bytes = roundup_pow_of_two(vstruct_bytes(buf->data));
+	j->dirty_entry_bytes += pin_list->bytes;
+
 	if (trace_journal_entry_close_enabled() && trace) {
 		CLASS(printbuf, err)();
 		guard(printbuf_atomic)(&err);
diff --git a/fs/bcachefs/journal_reclaim.c b/fs/bcachefs/journal_reclaim.c
index f23e5ee9ad75..0b348b7ea3de 100644
--- a/fs/bcachefs/journal_reclaim.c
+++ b/fs/bcachefs/journal_reclaim.c
@@ -328,9 +328,17 @@ void bch2_journal_reclaim_fast(struct journal *j)
 	 * Unpin journal entries whose reference counts reached zero, meaning
 	 * all btree nodes got written out
 	 */
+	struct journal_entry_pin_list *pin_list;
 	while (!fifo_empty(&j->pin) &&
 	       j->pin.front <= j->seq_ondisk &&
-	       !atomic_read(&fifo_peek_front(&j->pin).count)) {
+	       !atomic_read(&(pin_list = &fifo_peek_front(&j->pin))->count)) {
+
+		if (WARN_ON(j->dirty_entry_bytes < pin_list->bytes))
+			pin_list->bytes = j->dirty_entry_bytes;
+
+		j->dirty_entry_bytes -= pin_list->bytes;
+		pin_list->bytes = 0;
+
 		j->pin.front++;
 		popped = true;
 	}
diff --git a/fs/bcachefs/journal_types.h b/fs/bcachefs/journal_types.h
index 51104bbb99da..7c9273bd0e15 100644
--- a/fs/bcachefs/journal_types.h
+++ b/fs/bcachefs/journal_types.h
@@ -71,6 +71,7 @@ struct journal_entry_pin_list {
 	struct list_head		flushed[JOURNAL_PIN_TYPE_NR];
 	atomic_t			count;
 	struct bch_devs_list		devs;
+	size_t				bytes;
 };
 
 struct journal;
@@ -253,6 +254,7 @@ struct journal {
 		u64 front, back, size, mask;
 		struct journal_entry_pin_list *data;
 	}			pin;
+	size_t			dirty_entry_bytes;
 
 	struct journal_space	space[journal_space_nr];
 
-- 
2.51.0


From e1d3555413d636a2a4ef18d1ed1e18de0ed05d33 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 12:48:07 -0400
Subject: [PATCH 272/309] bcachefs: Limit dirty journal entries to total ram /
 4

Avoid journal replay failures due to -ENOMEM.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_reclaim.c | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/fs/bcachefs/journal_reclaim.c b/fs/bcachefs/journal_reclaim.c
index 0b348b7ea3de..bd1885607d3e 100644
--- a/fs/bcachefs/journal_reclaim.c
+++ b/fs/bcachefs/journal_reclaim.c
@@ -148,6 +148,9 @@ static struct journal_space __journal_space_available(struct journal *j, unsigne
 
 	BUG_ON(nr_devs_want > ARRAY_SIZE(dev_space));
 
+	size_t mem_limit = max_t(ssize_t, 0,
+			(totalram_pages() * PAGE_SIZE) / 4 - j->dirty_entry_bytes);
+
 	for_each_member_device_rcu(c, ca, &c->rw_devs[BCH_DATA_journal]) {
 		if (!ca->journal.nr ||
 		    !ca->mi.durability)
@@ -180,6 +183,7 @@ static struct journal_space __journal_space_available(struct journal *j, unsigne
 	 * @nr_devs_want largest devices:
 	 */
 	space = dev_space[nr_devs_want - 1];
+	space.total = min(space.total, mem_limit >> 9);
 	space.next_entry = min(space.next_entry, min_bucket_size);
 	return space;
 }
-- 
2.51.0


From bcb3260832896ac8a3a6bcd2c73aaa015fc3ecca Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 15:12:32 -0400
Subject: [PATCH 273/309] bcachefs: Const correctness for btree_journal_iter

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c         | 24 ++++++++++++------------
 fs/bcachefs/btree_journal_iter.c | 18 +++++++++---------
 fs/bcachefs/btree_journal_iter.h |  6 +++---
 fs/bcachefs/btree_trans_commit.c |  2 +-
 fs/bcachefs/btree_update.c       |  2 +-
 5 files changed, 26 insertions(+), 26 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 546b559fe3ce..488639c87d1a 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -650,7 +650,7 @@ static void bch2_trans_revalidate_updates_in_node(struct btree_trans *trans, str
 			i->old_v = bch2_btree_path_peek_slot(trans->paths + i->path, &i->old_k).v;
 
 			if (unlikely(trans->journal_replay_not_finished)) {
-				struct bkey_i *j_k =
+				const struct bkey_i *j_k =
 					bch2_journal_keys_peek_slot(c, i->btree_id, i->level,
 								    i->k->k.p);
 
@@ -2120,10 +2120,10 @@ void bch2_btree_trans_peek_slot_updates(struct btree_trans *trans, struct btree_
 		}
 }
 
-static struct bkey_i *bch2_btree_journal_peek(struct btree_trans *trans,
-					      struct btree_iter *iter,
-					      struct bpos search_pos,
-					      struct bpos end_pos)
+static const struct bkey_i *bch2_btree_journal_peek(struct btree_trans *trans,
+						    struct btree_iter *iter,
+						    struct bpos search_pos,
+						    struct bpos end_pos)
 {
 	struct btree_path *path = btree_iter_path(trans, iter);
 
@@ -2139,7 +2139,7 @@ struct bkey_s_c btree_trans_peek_slot_journal(struct btree_trans *trans,
 					      struct btree_iter *iter)
 {
 	struct btree_path *path = btree_iter_path(trans, iter);
-	struct bkey_i *k = bch2_btree_journal_peek(trans, iter, path->pos, path->pos);
+	const struct bkey_i *k = bch2_btree_journal_peek(trans, iter, path->pos, path->pos);
 
 	if (k) {
 		iter->k = k->k;
@@ -2156,7 +2156,7 @@ void btree_trans_peek_journal(struct btree_trans *trans,
 			      struct bkey_s_c *k)
 {
 	struct btree_path *path = btree_iter_path(trans, iter);
-	struct bkey_i *next_journal =
+	const struct bkey_i *next_journal =
 		bch2_btree_journal_peek(trans, iter, search_key,
 				k->k ? k->k->p : path_l(path)->b->key.k.p);
 	if (next_journal) {
@@ -2165,10 +2165,10 @@ void btree_trans_peek_journal(struct btree_trans *trans,
 	}
 }
 
-static struct bkey_i *bch2_btree_journal_peek_prev(struct btree_trans *trans,
-					      struct btree_iter *iter,
-					      struct bpos search_key,
-					      struct bpos end_pos)
+static const struct bkey_i *bch2_btree_journal_peek_prev(struct btree_trans *trans,
+							 struct btree_iter *iter,
+							 struct bpos search_key,
+							 struct bpos end_pos)
 {
 	struct btree_path *path = btree_iter_path(trans, iter);
 
@@ -2186,7 +2186,7 @@ void btree_trans_peek_prev_journal(struct btree_trans *trans,
 				   struct bkey_s_c *k)
 {
 	struct btree_path *path = btree_iter_path(trans, iter);
-	struct bkey_i *next_journal =
+	const struct bkey_i *next_journal =
 		bch2_btree_journal_peek_prev(trans, iter, search_key,
 				k->k ? k->k->p : path_l(path)->b->data->min_key);
 
diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index 24f2fbe84ad7..a91c5f61568f 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -73,9 +73,9 @@ static size_t bch2_journal_key_search(struct journal_keys *keys,
 }
 
 /* Returns first non-overwritten key >= search key: */
-struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id btree_id,
-					   unsigned level, struct bpos pos,
-					   struct bpos end_pos, size_t *idx)
+const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id btree_id,
+						unsigned level, struct bpos pos,
+						struct bpos end_pos, size_t *idx)
 {
 	struct journal_keys *keys = &c->journal_keys;
 	unsigned iters = 0;
@@ -96,7 +96,7 @@ struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id btree_
 		}
 	}
 
-	struct bkey_i *ret = NULL;
+	const struct bkey_i *ret = NULL;
 	rcu_read_lock(); /* for overwritten_ranges */
 
 	while ((k = *idx < keys->nr ? idx_to_key(keys, *idx) : NULL)) {
@@ -129,9 +129,9 @@ struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id btree_
 	return ret;
 }
 
-struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btree_id btree_id,
-					   unsigned level, struct bpos pos,
-					   struct bpos end_pos, size_t *idx)
+const struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btree_id btree_id,
+						     unsigned level, struct bpos pos,
+						     struct bpos end_pos, size_t *idx)
 {
 	struct journal_keys *keys = &c->journal_keys;
 	unsigned iters = 0;
@@ -194,8 +194,8 @@ struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btree_id b
 	return ret;
 }
 
-struct bkey_i *bch2_journal_keys_peek_slot(struct bch_fs *c, enum btree_id btree_id,
-					   unsigned level, struct bpos pos)
+const struct bkey_i *bch2_journal_keys_peek_slot(struct bch_fs *c, enum btree_id btree_id,
+						 unsigned level, struct bpos pos)
 {
 	size_t idx = 0;
 
diff --git a/fs/bcachefs/btree_journal_iter.h b/fs/bcachefs/btree_journal_iter.h
index 2a3082919b8d..52ef672d8d79 100644
--- a/fs/bcachefs/btree_journal_iter.h
+++ b/fs/bcachefs/btree_journal_iter.h
@@ -51,11 +51,11 @@ static inline int journal_key_cmp(const struct journal_key *l, const struct jour
 	return __journal_key_cmp(l->btree_id, l->level, l->k->k.p, r);
 }
 
-struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *, enum btree_id,
+const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *, enum btree_id,
 				unsigned, struct bpos, struct bpos, size_t *);
-struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *, enum btree_id,
+const struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *, enum btree_id,
 				unsigned, struct bpos, struct bpos, size_t *);
-struct bkey_i *bch2_journal_keys_peek_slot(struct bch_fs *, enum btree_id,
+const struct bkey_i *bch2_journal_keys_peek_slot(struct bch_fs *, enum btree_id,
 					   unsigned, struct bpos);
 
 int bch2_btree_and_journal_iter_prefetch(struct btree_trans *, struct btree_path *,
diff --git a/fs/bcachefs/btree_trans_commit.c b/fs/bcachefs/btree_trans_commit.c
index 4d58bdb233e9..5fa7f2f9f1e9 100644
--- a/fs/bcachefs/btree_trans_commit.c
+++ b/fs/bcachefs/btree_trans_commit.c
@@ -54,7 +54,7 @@ static void verify_update_old_key(struct btree_trans *trans, struct btree_insert
 	struct bkey_s_c k = bch2_btree_path_peek_slot_exact(trans->paths + i->path, &u);
 
 	if (unlikely(trans->journal_replay_not_finished)) {
-		struct bkey_i *j_k =
+		const struct bkey_i *j_k =
 			bch2_journal_keys_peek_slot(c, i->btree_id, i->level, i->k->k.p);
 
 		if (j_k)
diff --git a/fs/bcachefs/btree_update.c b/fs/bcachefs/btree_update.c
index 053a837cf241..b70eb095a37e 100644
--- a/fs/bcachefs/btree_update.c
+++ b/fs/bcachefs/btree_update.c
@@ -403,7 +403,7 @@ __btree_trans_update_by_path(struct btree_trans *trans,
 		i->old_btree_u64s = !bkey_deleted(&i->old_k) ? i->old_k.u64s : 0;
 
 		if (unlikely(trans->journal_replay_not_finished)) {
-			struct bkey_i *j_k =
+			const struct bkey_i *j_k =
 				bch2_journal_keys_peek_slot(c, n.btree_id, n.level, k->k.p);
 
 			if (j_k) {
-- 
2.51.0


From 8b5968e92d377db9b0f7d704993de04f77c1241a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 15:18:50 -0400
Subject: [PATCH 274/309] bcachefs: journal_key_k()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_gc.c                 |   4 +-
 fs/bcachefs/btree_iter.c               |   4 +-
 fs/bcachefs/btree_journal_iter.c       | 107 +++++++++++++++----------
 fs/bcachefs/btree_journal_iter.h       |  19 +++--
 fs/bcachefs/btree_journal_iter_types.h |  23 ++++++
 fs/bcachefs/btree_update_interior.c    |   2 +-
 fs/bcachefs/disk_accounting.c          |  17 ++--
 fs/bcachefs/journal_io.h               |  23 ------
 fs/bcachefs/recovery.c                 |  38 +++++----
 9 files changed, 138 insertions(+), 99 deletions(-)

diff --git a/fs/bcachefs/btree_gc.c b/fs/bcachefs/btree_gc.c
index ae7d260589d8..43f294284d57 100644
--- a/fs/bcachefs/btree_gc.c
+++ b/fs/bcachefs/btree_gc.c
@@ -356,7 +356,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 	bch2_btree_and_journal_iter_init_node_iter(trans, &iter, b);
 	iter.prefetch = true;
 
-	while ((k = bch2_btree_and_journal_iter_peek(&iter)).k) {
+	while ((k = bch2_btree_and_journal_iter_peek(c, &iter)).k) {
 		BUG_ON(bpos_lt(k.k->p, b->data->min_key));
 		BUG_ON(bpos_gt(k.k->p, b->data->max_key));
 
@@ -470,7 +470,7 @@ static int bch2_btree_repair_topology_recurse(struct btree_trans *trans, struct
 	bch2_btree_and_journal_iter_init_node_iter(trans, &iter, b);
 	iter.prefetch = true;
 
-	while ((k = bch2_btree_and_journal_iter_peek(&iter)).k) {
+	while ((k = bch2_btree_and_journal_iter_peek(c, &iter)).k) {
 		bch2_bkey_buf_reassemble(&cur_k, c, k);
 		bch2_btree_and_journal_iter_advance(&iter);
 
diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 488639c87d1a..76f430f93dc1 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -848,7 +848,7 @@ static int btree_path_prefetch_j(struct btree_trans *trans, struct btree_path *p
 			break;
 
 		bch2_btree_and_journal_iter_advance(jiter);
-		k = bch2_btree_and_journal_iter_peek(jiter);
+		k = bch2_btree_and_journal_iter_peek(c, jiter);
 		if (!k.k)
 			break;
 
@@ -898,7 +898,7 @@ static noinline int btree_node_iter_and_journal_peek(struct btree_trans *trans,
 
 	__bch2_btree_and_journal_iter_init_node_iter(trans, &jiter, l->b, l->iter, path->pos);
 
-	k = bch2_btree_and_journal_iter_peek(&jiter);
+	k = bch2_btree_and_journal_iter_peek(c, &jiter);
 	if (!k.k) {
 		CLASS(printbuf, buf)();
 
diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index a91c5f61568f..2e9078b5f538 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -46,21 +46,22 @@ static size_t __bch2_journal_key_search(struct journal_keys *keys,
 					enum btree_id id, unsigned level,
 					struct bpos pos)
 {
+	struct bch_fs *c = container_of(keys, struct bch_fs, journal_keys);
 	size_t l = 0, r = keys->nr, m;
 
 	while (l < r) {
 		m = l + ((r - l) >> 1);
-		if (__journal_key_cmp(id, level, pos, idx_to_key(keys, m)) > 0)
+		if (__journal_key_cmp(c, id, level, pos, idx_to_key(keys, m)) > 0)
 			l = m + 1;
 		else
 			r = m;
 	}
 
 	BUG_ON(l < keys->nr &&
-	       __journal_key_cmp(id, level, pos, idx_to_key(keys, l)) > 0);
+	       __journal_key_cmp(c, id, level, pos, idx_to_key(keys, l)) > 0);
 
 	BUG_ON(l &&
-	       __journal_key_cmp(id, level, pos, idx_to_key(keys, l - 1)) <= 0);
+	       __journal_key_cmp(c, id, level, pos, idx_to_key(keys, l - 1)) <= 0);
 
 	return l;
 }
@@ -87,7 +88,7 @@ const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id
 		*idx = __bch2_journal_key_search(keys, btree_id, level, pos);
 
 	while (*idx &&
-	       __journal_key_cmp(btree_id, level, end_pos, idx_to_key(keys, *idx - 1)) <= 0) {
+	       __journal_key_cmp(c, btree_id, level, end_pos, idx_to_key(keys, *idx - 1)) <= 0) {
 		--(*idx);
 		iters++;
 		if (iters == 10) {
@@ -100,7 +101,7 @@ const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id
 	rcu_read_lock(); /* for overwritten_ranges */
 
 	while ((k = *idx < keys->nr ? idx_to_key(keys, *idx) : NULL)) {
-		if (__journal_key_cmp(btree_id, level, end_pos, k) < 0)
+		if (__journal_key_cmp(c, btree_id, level, end_pos, k) < 0)
 			break;
 
 		if (k->overwritten) {
@@ -111,8 +112,8 @@ const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id
 			continue;
 		}
 
-		if (__journal_key_cmp(btree_id, level, pos, k) <= 0) {
-			ret = k->k;
+		if (__journal_key_cmp(c, btree_id, level, pos, k) <= 0) {
+			ret = journal_key_k(c, k);
 			break;
 		}
 
@@ -146,7 +147,7 @@ const struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btre
 		*idx = __bch2_journal_key_search(keys, btree_id, level, pos);
 
 	while (*idx < keys->nr &&
-	       __journal_key_cmp(btree_id, level, end_pos, idx_to_key(keys, *idx)) >= 0) {
+	       __journal_key_cmp(c, btree_id, level, end_pos, idx_to_key(keys, *idx)) >= 0) {
 		(*idx)++;
 		iters++;
 		if (iters == 10) {
@@ -158,12 +159,12 @@ const struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btre
 	if (*idx == keys->nr)
 		--(*idx);
 
-	struct bkey_i *ret = NULL;
+	const struct bkey_i *ret = NULL;
 	rcu_read_lock(); /* for overwritten_ranges */
 
 	while (true) {
 		k = idx_to_key(keys, *idx);
-		if (__journal_key_cmp(btree_id, level, end_pos, k) > 0)
+		if (__journal_key_cmp(c, btree_id, level, end_pos, k) > 0)
 			break;
 
 		if (k->overwritten) {
@@ -175,8 +176,8 @@ const struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btre
 			continue;
 		}
 
-		if (__journal_key_cmp(btree_id, level, pos, k) >= 0) {
-			ret = k->k;
+		if (__journal_key_cmp(c, btree_id, level, pos, k) >= 0) {
+			ret = journal_key_k(c, k);
 			break;
 		}
 
@@ -278,8 +279,8 @@ int bch2_journal_key_insert_take(struct bch_fs *c, enum btree_id id,
 	BUG_ON(test_bit(BCH_FS_rw, &c->flags));
 
 	if (idx < keys->size &&
-	    journal_key_cmp(&n, &keys->data[idx]) == 0) {
-		struct bkey_i *o = keys->data[idx].k;
+	    journal_key_cmp(c, &n, &keys->data[idx]) == 0) {
+		struct bkey_i *o = journal_key_k(c, &keys->data[idx]);
 
 		if (k->k.type == KEY_TYPE_accounting &&
 		    o->k.type == KEY_TYPE_accounting) {
@@ -376,17 +377,20 @@ int bch2_journal_key_delete(struct bch_fs *c, enum btree_id id,
 bool bch2_key_deleted_in_journal(struct btree_trans *trans, enum btree_id btree,
 				 unsigned level, struct bpos pos)
 {
-	struct journal_keys *keys = &trans->c->journal_keys;
+	if (!trans->journal_replay_not_finished)
+		return false;
+
+	struct bch_fs *c = trans->c;
+	struct journal_keys *keys = &c->journal_keys;
 	size_t idx = bch2_journal_key_search(keys, btree, level, pos);
 
-	if (!trans->journal_replay_not_finished)
+	if (idx >= keys->size ||
+	    keys->data[idx].btree_id	!= btree ||
+	    keys->data[idx].level	!= level)
 		return false;
 
-	return (idx < keys->size &&
-		keys->data[idx].btree_id	== btree &&
-		keys->data[idx].level		== level &&
-		bpos_eq(keys->data[idx].k->k.p, pos) &&
-		bkey_deleted(&keys->data[idx].k->k));
+	struct bkey_i *k = journal_key_k(c, &keys->data[idx]);
+	return bpos_eq(k->k.p, pos) && bkey_deleted(&k->k);
 }
 
 static void __bch2_journal_key_overwritten(struct journal_keys *keys, size_t pos)
@@ -457,11 +461,15 @@ void bch2_journal_key_overwritten(struct bch_fs *c, enum btree_id btree,
 	struct journal_keys *keys = &c->journal_keys;
 	size_t idx = bch2_journal_key_search(keys, btree, level, pos);
 
-	if (idx < keys->size &&
-	    keys->data[idx].btree_id	== btree &&
-	    keys->data[idx].level	== level &&
-	    bpos_eq(keys->data[idx].k->k.p, pos) &&
-	    !keys->data[idx].overwritten) {
+	if (idx >= keys->size ||
+	    keys->data[idx].btree_id	!= btree ||
+	    keys->data[idx].level	!= level ||
+	    keys->data[idx].overwritten)
+		return;
+
+	struct bkey_i *k = journal_key_k(c, &keys->data[idx]);
+
+	if (bpos_eq(k->k.p, pos)) {
 		guard(mutex)(&keys->overwrite_lock);
 		__bch2_journal_key_overwritten(keys, idx);
 	}
@@ -476,7 +484,7 @@ static void bch2_journal_iter_advance(struct journal_iter *iter)
 	}
 }
 
-static struct bkey_s_c bch2_journal_iter_peek(struct journal_iter *iter)
+static struct bkey_s_c bch2_journal_iter_peek(struct bch_fs *c, struct journal_iter *iter)
 {
 	journal_iter_verify(iter);
 
@@ -490,7 +498,7 @@ static struct bkey_s_c bch2_journal_iter_peek(struct journal_iter *iter)
 		BUG_ON(cmp);
 
 		if (!k->overwritten)
-			return bkey_i_to_s_c(k->k);
+			return bkey_i_to_s_c(journal_key_k(c, k));
 
 		if (k->overwritten_range)
 			iter->idx = idx_to_pos(iter->keys, rcu_dereference(k->overwritten_range)->end);
@@ -554,7 +562,7 @@ static void btree_and_journal_iter_prefetch(struct btree_and_journal_iter *_iter
 
 	while (nr--) {
 		bch2_btree_and_journal_iter_advance(&iter);
-		struct bkey_s_c k = bch2_btree_and_journal_iter_peek(&iter);
+		struct bkey_s_c k = bch2_btree_and_journal_iter_peek(c, &iter);
 		if (!k.k)
 			break;
 
@@ -565,7 +573,7 @@ static void btree_and_journal_iter_prefetch(struct btree_and_journal_iter *_iter
 	bch2_bkey_buf_exit(&tmp, c);
 }
 
-struct bkey_s_c bch2_btree_and_journal_iter_peek(struct btree_and_journal_iter *iter)
+struct bkey_s_c bch2_btree_and_journal_iter_peek(struct bch_fs *c, struct btree_and_journal_iter *iter)
 {
 	struct bkey_s_c btree_k, journal_k = bkey_s_c_null, ret;
 	size_t iters = 0;
@@ -586,7 +594,7 @@ struct bkey_s_c bch2_btree_and_journal_iter_peek(struct btree_and_journal_iter *
 		bch2_journal_iter_advance_btree(iter);
 
 	if (iter->trans->journal_replay_not_finished)
-		while ((journal_k = bch2_journal_iter_peek(&iter->journal)).k &&
+		while ((journal_k = bch2_journal_iter_peek(c, &iter->journal)).k &&
 		       bpos_lt(journal_k.k->p, iter->pos))
 			bch2_journal_iter_advance(&iter->journal);
 
@@ -658,15 +666,22 @@ void bch2_btree_and_journal_iter_init_node_iter(struct btree_trans *trans,
 /*
  * When keys compare equal, oldest compares first:
  */
-static int journal_sort_key_cmp(const void *_l, const void *_r)
+static int journal_sort_key_cmp(const void *_l, const void *_r, const void *priv)
 {
+	struct bch_fs *c = (void *) priv;
 	const struct journal_key *l = _l;
 	const struct journal_key *r = _r;
 	int rewind = l->rewind && r->rewind ? -1 : 1;
 
-	return  journal_key_cmp(l, r) ?:
-		((cmp_int(l->journal_seq, r->journal_seq) ?:
-		  cmp_int(l->journal_offset, r->journal_offset)) * rewind);
+	int cmp = journal_key_cmp(c, l, r);
+	if (cmp)
+		return cmp;
+
+	if (l->allocated || r->allocated)
+		return cmp_int(l->allocated, r->allocated);
+
+	return ((cmp_int(l->journal_seq, r->journal_seq) ?:
+		 cmp_int(l->journal_offset, r->journal_offset)) * rewind);
 }
 
 void bch2_journal_keys_put(struct bch_fs *c)
@@ -704,8 +719,10 @@ void bch2_journal_keys_put(struct bch_fs *c)
 
 static void __journal_keys_sort(struct journal_keys *keys)
 {
-	sort_nonatomic(keys->data, keys->nr, sizeof(keys->data[0]),
-		       journal_sort_key_cmp, NULL);
+	struct bch_fs *c = container_of(keys, struct bch_fs, journal_keys);
+
+	sort_r_nonatomic(keys->data, keys->nr, sizeof(keys->data[0]),
+			 journal_sort_key_cmp, NULL, c);
 
 	cond_resched();
 
@@ -717,9 +734,10 @@ static void __journal_keys_sort(struct journal_keys *keys)
 		 * compare each individual accounting key against the version in
 		 * the btree during replay:
 		 */
-		if (src->k->k.type != KEY_TYPE_accounting &&
+		struct bkey_i *k = journal_key_k(c, src);
+		if (k->k.type != KEY_TYPE_accounting &&
 		    src + 1 < &darray_top(*keys) &&
-		    !journal_key_cmp(src, src + 1))
+		    !journal_key_cmp(c, src, src + 1))
 			continue;
 
 		*dst++ = *src;
@@ -801,13 +819,16 @@ void bch2_shoot_down_journal_keys(struct bch_fs *c, enum btree_id btree,
 
 	move_gap(keys, keys->nr);
 
-	darray_for_each(*keys, i)
+	darray_for_each(*keys, i) {
+		struct bkey_i *k = journal_key_k(c, i);
+
 		if (!(i->btree_id == btree &&
 		      i->level >= level_min &&
 		      i->level <= level_max &&
-		      bpos_ge(i->k->k.p, start) &&
-		      bpos_le(i->k->k.p, end)))
+		      bpos_ge(k->k.p, start) &&
+		      bpos_le(k->k.p, end)))
 			keys->data[dst++] = *i;
+	}
 	keys->nr = keys->gap = dst;
 }
 
@@ -825,7 +846,7 @@ void bch2_journal_keys_dump(struct bch_fs *c)
 		prt_printf(&buf, "btree=");
 		bch2_btree_id_to_text(&buf, i->btree_id);
 		prt_printf(&buf, " l=%u ", i->level);
-		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(i->k));
+		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(journal_key_k(c, i)));
 		pr_err("%s", buf.buf);
 	}
 }
diff --git a/fs/bcachefs/btree_journal_iter.h b/fs/bcachefs/btree_journal_iter.h
index 52ef672d8d79..a1b26832869f 100644
--- a/fs/bcachefs/btree_journal_iter.h
+++ b/fs/bcachefs/btree_journal_iter.h
@@ -29,6 +29,12 @@ struct btree_and_journal_iter {
 	bool			fail_if_too_many_whiteouts;
 };
 
+static inline struct bkey_i *journal_key_k(struct bch_fs *c,
+					   const struct journal_key *k)
+{
+	return k->k;
+}
+
 static inline int __journal_key_btree_cmp(enum btree_id	l_btree_id,
 					  unsigned	l_level,
 					  const struct journal_key *r)
@@ -37,18 +43,21 @@ static inline int __journal_key_btree_cmp(enum btree_id	l_btree_id,
 		cmp_int(l_btree_id,	r->btree_id);
 }
 
-static inline int __journal_key_cmp(enum btree_id	l_btree_id,
+static inline int __journal_key_cmp(struct bch_fs *c,
+				    enum btree_id	l_btree_id,
 				    unsigned		l_level,
 				    struct bpos	l_pos,
 				    const struct journal_key *r)
 {
 	return __journal_key_btree_cmp(l_btree_id, l_level, r) ?:
-		bpos_cmp(l_pos,	r->k->k.p);
+		bpos_cmp(l_pos, journal_key_k(c, r)->k.p);
 }
 
-static inline int journal_key_cmp(const struct journal_key *l, const struct journal_key *r)
+static inline int journal_key_cmp(struct bch_fs *c,
+				  const struct journal_key *l, const struct journal_key *r)
 {
-	return __journal_key_cmp(l->btree_id, l->level, l->k->k.p, r);
+	return __journal_key_cmp(c, l->btree_id, l->level,
+				 journal_key_k(c, l)->k.p, r);
 }
 
 const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *, enum btree_id,
@@ -71,7 +80,7 @@ bool bch2_key_deleted_in_journal(struct btree_trans *, enum btree_id, unsigned,
 void bch2_journal_key_overwritten(struct bch_fs *, enum btree_id, unsigned, struct bpos);
 
 void bch2_btree_and_journal_iter_advance(struct btree_and_journal_iter *);
-struct bkey_s_c bch2_btree_and_journal_iter_peek(struct btree_and_journal_iter *);
+struct bkey_s_c bch2_btree_and_journal_iter_peek(struct bch_fs *, struct btree_and_journal_iter *);
 
 void bch2_btree_and_journal_iter_exit(struct btree_and_journal_iter *);
 void __bch2_btree_and_journal_iter_init_node_iter(struct btree_trans *,
diff --git a/fs/bcachefs/btree_journal_iter_types.h b/fs/bcachefs/btree_journal_iter_types.h
index 86aacb254fb2..0b4f6c1cb183 100644
--- a/fs/bcachefs/btree_journal_iter_types.h
+++ b/fs/bcachefs/btree_journal_iter_types.h
@@ -2,6 +2,29 @@
 #ifndef _BCACHEFS_BTREE_JOURNAL_ITER_TYPES_H
 #define _BCACHEFS_BTREE_JOURNAL_ITER_TYPES_H
 
+struct journal_ptr {
+	bool		csum_good;
+	struct bch_csum	csum;
+	u8		dev;
+	u32		bucket;
+	u32		bucket_offset;
+	u64		sector;
+};
+
+/*
+ * Only used for holding the journal entries we read in btree_journal_read()
+ * during cache_registration
+ */
+struct journal_replay {
+	DARRAY_PREALLOCATED(struct journal_ptr, 8) ptrs;
+
+	bool			csum_good;
+	bool			ignore_blacklisted;
+	bool			ignore_not_dirty;
+	/* must be last: */
+	struct jset		j;
+};
+
 struct journal_key_range_overwritten {
 	size_t			start, end;
 };
diff --git a/fs/bcachefs/btree_update_interior.c b/fs/bcachefs/btree_update_interior.c
index 65ca54c5b0ff..a9877a47bfc6 100644
--- a/fs/bcachefs/btree_update_interior.c
+++ b/fs/bcachefs/btree_update_interior.c
@@ -95,7 +95,7 @@ int bch2_btree_node_check_topology(struct btree_trans *trans, struct btree *b)
 	if (!b->c.level)
 		goto out;
 
-	while ((k = bch2_btree_and_journal_iter_peek(&iter)).k) {
+	while ((k = bch2_btree_and_journal_iter_peek(c, &iter)).k) {
 		if (k.k->type != KEY_TYPE_btree_ptr_v2)
 			goto out;
 
diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 5944ad6d0f8d..2ed4546bd923 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -796,14 +796,15 @@ int bch2_accounting_read(struct bch_fs *c)
 	move_gap(keys, keys->nr);
 
 	darray_for_each(*keys, i) {
-		if (i->k->k.type == KEY_TYPE_accounting) {
+		struct bkey_s_c k = bkey_i_to_s_c(journal_key_k(c, i));
+
+		if (k.k->type == KEY_TYPE_accounting) {
 			struct disk_accounting_pos acc_k;
-			bpos_to_disk_accounting_pos(&acc_k, i->k->k.p);
+			bpos_to_disk_accounting_pos(&acc_k, k.k->p);
 
 			if (!bch2_accounting_is_mem(&acc_k))
 				continue;
 
-			struct bkey_s_c k = bkey_i_to_s_c(i->k);
 			unsigned idx = eytzinger0_find(acc->k.data, acc->k.nr,
 						sizeof(acc->k.data[0]),
 						accounting_pos_cmp, &k.k->p);
@@ -815,13 +816,15 @@ int bch2_accounting_read(struct bch_fs *c)
 				continue;
 
 			if (i + 1 < &darray_top(*keys) &&
-			    i[1].k->k.type == KEY_TYPE_accounting &&
-			    !journal_key_cmp(i, i + 1)) {
-				WARN_ON(bversion_cmp(i[0].k->k.bversion, i[1].k->k.bversion) >= 0);
+			    journal_key_k(c, &i[1])->k.type == KEY_TYPE_accounting &&
+			    !journal_key_cmp(c, i, i + 1)) {
+				struct bkey_i *n = journal_key_k(c, &i[1]);
+
+				WARN_ON(bversion_cmp(k.k->bversion, n->k.bversion) >= 0);
 
 				i[1].journal_seq = i[0].journal_seq;
 
-				bch2_accounting_accumulate(bkey_i_to_accounting(i[1].k),
+				bch2_accounting_accumulate(bkey_i_to_accounting(n),
 							   bkey_s_c_to_accounting(k));
 				continue;
 			}
diff --git a/fs/bcachefs/journal_io.h b/fs/bcachefs/journal_io.h
index f53c5c81d137..f8754bf71264 100644
--- a/fs/bcachefs/journal_io.h
+++ b/fs/bcachefs/journal_io.h
@@ -7,29 +7,6 @@
 void bch2_journal_pos_from_member_info_set(struct bch_fs *);
 void bch2_journal_pos_from_member_info_resume(struct bch_fs *);
 
-struct journal_ptr {
-	bool		csum_good;
-	struct bch_csum	csum;
-	u8		dev;
-	u32		bucket;
-	u32		bucket_offset;
-	u64		sector;
-};
-
-/*
- * Only used for holding the journal entries we read in btree_journal_read()
- * during cache_registration
- */
-struct journal_replay {
-	DARRAY_PREALLOCATED(struct journal_ptr, 8) ptrs;
-
-	bool			csum_good;
-	bool			ignore_blacklisted;
-	bool			ignore_not_dirty;
-	/* must be last: */
-	struct jset		j;
-};
-
 static inline bool journal_replay_ignore(struct journal_replay *i)
 {
 	return !i || i->ignore_blacklisted || i->ignore_not_dirty;
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 8280ca333f5b..0117405e51ef 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -181,9 +181,12 @@ void bch2_reconstruct_alloc(struct bch_fs *c)
  */
 static void zero_out_btree_mem_ptr(struct journal_keys *keys)
 {
-	darray_for_each(*keys, i)
-		if (i->k->k.type == KEY_TYPE_btree_ptr_v2)
-			bkey_i_to_btree_ptr_v2(i->k)->v.mem_ptr = 0;
+	struct bch_fs *c = container_of(keys, struct bch_fs, journal_keys);
+	darray_for_each(*keys, i) {
+		struct bkey_i *k = journal_key_k(c, i);
+		if (k->k.type == KEY_TYPE_btree_ptr_v2)
+			bkey_i_to_btree_ptr_v2(k)->v.mem_ptr = 0;
+	}
 }
 
 /* journal replay: */
@@ -201,8 +204,9 @@ static void replay_now_at(struct journal *j, u64 seq)
 static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 					      struct journal_key *k)
 {
+	struct bkey_i *bk = journal_key_k(trans->c, k);
 	struct btree_iter iter;
-	bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
+	bch2_trans_node_iter_init(trans, &iter, k->btree_id, bk->k.p,
 				  BTREE_MAX_DEPTH, k->level,
 				  BTREE_ITER_intent);
 	int ret = bch2_btree_iter_traverse(&iter);
@@ -213,14 +217,14 @@ static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 	struct bkey_s_c old = bch2_btree_path_peek_slot(btree_iter_path(trans, &iter), &u);
 
 	/* Has this delta already been applied to the btree? */
-	if (bversion_cmp(old.k->bversion, k->k->k.bversion) >= 0) {
+	if (bversion_cmp(old.k->bversion, bk->k.bversion) >= 0) {
 		ret = 0;
 		goto out;
 	}
 
-	struct bkey_i *new = k->k;
+	struct bkey_i *new = bk;
 	if (old.k->type == KEY_TYPE_accounting) {
-		new = bch2_bkey_make_mut_noupdate(trans, bkey_i_to_s_c(k->k));
+		new = bch2_bkey_make_mut_noupdate(trans, bkey_i_to_s_c(bk));
 		ret = PTR_ERR_OR_ZERO(new);
 		if (ret)
 			goto out;
@@ -265,7 +269,8 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 	else
 		update_flags |= BTREE_UPDATE_key_cache_reclaim;
 
-	bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
+	struct bkey_i *bk = journal_key_k(trans->c, k);
+	bch2_trans_node_iter_init(trans, &iter, k->btree_id, bk->k.p,
 				  BTREE_MAX_DEPTH, k->level,
 				  iter_flags);
 	ret = bch2_btree_iter_traverse(&iter);
@@ -280,7 +285,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 		prt_str(&buf, "btree=");
 		bch2_btree_id_to_text(&buf, k->btree_id);
 		prt_printf(&buf, " level=%u ", k->level);
-		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(k->k));
+		bch2_bkey_val_to_text(&buf, c, bkey_i_to_s_c(bk));
 
 		if (!(c->recovery.passes_complete & (BIT_ULL(BCH_RECOVERY_PASS_scan_for_btree_nodes)|
 						     BIT_ULL(BCH_RECOVERY_PASS_check_topology)))) {
@@ -297,7 +302,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 		}
 
 		bch2_trans_iter_exit(&iter);
-		bch2_trans_node_iter_init(trans, &iter, k->btree_id, k->k->k.p,
+		bch2_trans_node_iter_init(trans, &iter, k->btree_id, bk->k.p,
 					  BTREE_MAX_DEPTH, 0, iter_flags);
 		ret =   bch2_btree_iter_traverse(&iter) ?:
 			bch2_btree_increase_depth(trans, iter.path, 0) ?:
@@ -309,17 +314,17 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 	if (k->overwritten)
 		goto out;
 
-	if (k->k->k.type == KEY_TYPE_accounting) {
-		struct bkey_i *n = bch2_trans_subbuf_alloc(trans, &trans->accounting, k->k->k.u64s);
+	if (bk->k.type == KEY_TYPE_accounting) {
+		struct bkey_i *n = bch2_trans_subbuf_alloc(trans, &trans->accounting, bk->k.u64s);
 		ret = PTR_ERR_OR_ZERO(n);
 		if (ret)
 			goto out;
 
-		bkey_copy(n, k->k);
+		bkey_copy(n, bk);
 		goto out;
 	}
 
-	ret = bch2_trans_update(trans, &iter, k->k, update_flags);
+	ret = bch2_trans_update(trans, &iter, bk, update_flags);
 out:
 	bch2_trans_iter_exit(&iter);
 	return ret;
@@ -368,7 +373,9 @@ int bch2_journal_replay(struct bch_fs *c)
 	 * flush accounting keys until we're done
 	 */
 	darray_for_each(*keys, k) {
-		if (!(k->k->k.type == KEY_TYPE_accounting && !k->allocated))
+		struct bkey_i *bk = journal_key_k(trans->c, k);
+
+		if (!(bk->k.type == KEY_TYPE_accounting && !k->allocated))
 			continue;
 
 		cond_resched();
@@ -411,7 +418,6 @@ int bch2_journal_replay(struct bch_fs *c)
 				  BCH_TRANS_COMMIT_skip_accounting_apply|
 				  (!k->allocated ? BCH_TRANS_COMMIT_no_journal_res : 0),
 			     bch2_journal_replay_key(trans, k));
-		BUG_ON(!ret && !k->overwritten && k->k->k.type != KEY_TYPE_accounting);
 		if (ret) {
 			ret = darray_push(&keys_sorted, k);
 			if (ret)
-- 
2.51.0


From e84bcc582073727cd2517566ec60a9280df5cd37 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 21:04:17 -0400
Subject: [PATCH 275/309] bcachefs: Change bch2_accounting_read() accumulation

In order to kill journal_key.k, we'll be using journal_key.journal_seq
to refer to the key pointed to, which means we can't change it when
accumulating accounting keys in accounting read.

To avoid this, accumulate into the oldest accounting key.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/darray.h          |  5 ++-
 fs/bcachefs/disk_accounting.c | 73 +++++++++++++++++------------------
 2 files changed, 40 insertions(+), 38 deletions(-)

diff --git a/fs/bcachefs/darray.h b/fs/bcachefs/darray.h
index 4080ee99aadd..14c7fc7c8061 100644
--- a/fs/bcachefs/darray.h
+++ b/fs/bcachefs/darray.h
@@ -107,8 +107,11 @@ int __bch2_darray_resize_noprof(darray_char *, size_t, size_t, gfp_t);
 #define __darray_for_each(_d, _i)					\
 	for ((_i) = (_d).data; _i < (_d).data + (_d).nr; _i++)
 
+#define darray_for_each_from(_d, _i, _start)					\
+	for (typeof(&(_d).data[0]) _i = _start; _i < (_d).data + (_d).nr; _i++)
+
 #define darray_for_each(_d, _i)						\
-	for (typeof(&(_d).data[0]) _i = (_d).data; _i < (_d).data + (_d).nr; _i++)
+	darray_for_each_from(_d, _i, (_d).data)
 
 #define darray_for_each_reverse(_d, _i)					\
 	for (typeof(&(_d).data[0]) _i = (_d).data + (_d).nr - 1; _i >= (_d).data && (_d).nr; --_i)
diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 2ed4546bd923..5ec57b710501 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -765,78 +765,77 @@ int bch2_accounting_read(struct bch_fs *c)
 	iter.flags &= ~BTREE_ITER_with_journal;
 	int ret = for_each_btree_key_continue(trans, iter,
 				BTREE_ITER_prefetch|BTREE_ITER_all_snapshots, k, ({
-			struct bkey u;
-			struct bkey_s_c k = bch2_btree_path_peek_slot_exact(btree_iter_path(trans, &iter), &u);
+		struct bkey u;
+		struct bkey_s_c k = bch2_btree_path_peek_slot_exact(btree_iter_path(trans, &iter), &u);
 
-			if (k.k->type != KEY_TYPE_accounting)
-				continue;
+		if (k.k->type != KEY_TYPE_accounting)
+			continue;
 
-			struct disk_accounting_pos acc_k;
-			bpos_to_disk_accounting_pos(&acc_k, k.k->p);
+		struct disk_accounting_pos acc_k;
+		bpos_to_disk_accounting_pos(&acc_k, k.k->p);
 
-			if (acc_k.type >= BCH_DISK_ACCOUNTING_TYPE_NR)
-				break;
+		if (acc_k.type >= BCH_DISK_ACCOUNTING_TYPE_NR)
+			break;
 
-			if (!bch2_accounting_is_mem(&acc_k)) {
-				struct disk_accounting_pos next;
-				memset(&next, 0, sizeof(next));
-				next.type = acc_k.type + 1;
-				bch2_btree_iter_set_pos(&iter, disk_accounting_pos_to_bpos(&next));
-				continue;
-			}
+		if (!bch2_accounting_is_mem(&acc_k)) {
+			struct disk_accounting_pos next;
+			memset(&next, 0, sizeof(next));
+			next.type = acc_k.type + 1;
+			bch2_btree_iter_set_pos(&iter, disk_accounting_pos_to_bpos(&next));
+			continue;
+		}
 
-			accounting_read_key(trans, k);
-		}));
+		accounting_read_key(trans, k);
+	}));
 	bch2_trans_iter_exit(&iter);
 	if (ret)
 		return ret;
 
 	struct journal_keys *keys = &c->journal_keys;
-	struct journal_key *dst = keys->data;
 	move_gap(keys, keys->nr);
 
 	darray_for_each(*keys, i) {
-		struct bkey_s_c k = bkey_i_to_s_c(journal_key_k(c, i));
+		if (i->overwritten)
+			continue;
+
+		struct bkey_i *k = journal_key_k(c, i);
 
-		if (k.k->type == KEY_TYPE_accounting) {
+		if (k->k.type == KEY_TYPE_accounting) {
 			struct disk_accounting_pos acc_k;
-			bpos_to_disk_accounting_pos(&acc_k, k.k->p);
+			bpos_to_disk_accounting_pos(&acc_k, k->k.p);
 
 			if (!bch2_accounting_is_mem(&acc_k))
 				continue;
 
 			unsigned idx = eytzinger0_find(acc->k.data, acc->k.nr,
 						sizeof(acc->k.data[0]),
-						accounting_pos_cmp, &k.k->p);
+						accounting_pos_cmp, &k->k.p);
 
 			bool applied = idx < acc->k.nr &&
-				bversion_cmp(acc->k.data[idx].bversion, k.k->bversion) >= 0;
+				bversion_cmp(acc->k.data[idx].bversion, k->k.bversion) >= 0;
 
 			if (applied)
 				continue;
 
-			if (i + 1 < &darray_top(*keys) &&
-			    journal_key_k(c, &i[1])->k.type == KEY_TYPE_accounting &&
-			    !journal_key_cmp(c, i, i + 1)) {
-				struct bkey_i *n = journal_key_k(c, &i[1]);
-
-				WARN_ON(bversion_cmp(k.k->bversion, n->k.bversion) >= 0);
+			darray_for_each_from(*keys, j, i + 1) {
+				if (journal_key_cmp(c, i, j))
+					break;
 
-				i[1].journal_seq = i[0].journal_seq;
+				struct bkey_i *n = journal_key_k(c, j);
+				if (n->k.type == KEY_TYPE_accounting) {
+					WARN_ON(bversion_cmp(k->k.bversion, n->k.bversion) >= 0);
 
-				bch2_accounting_accumulate(bkey_i_to_accounting(n),
-							   bkey_s_c_to_accounting(k));
-				continue;
+					bch2_accounting_accumulate(bkey_i_to_accounting(k),
+								   bkey_i_to_s_c_accounting(n));
+					j->overwritten = true;
+				}
 			}
 
-			ret = accounting_read_key(trans, k);
+			ret = accounting_read_key(trans, bkey_i_to_s_c(k));
 			if (ret)
 				return ret;
 		}
-
-		*dst++ = *i;
 	}
-	keys->gap = keys->nr = dst - keys->data;
 
 	guard(percpu_write)(&c->mark_lock);
 
-- 
2.51.0


From e4747a06dcaaba224e8e58c70b9f736f29437f8b Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 14:18:02 -0400
Subject: [PATCH 276/309] bcachefs: Kill journal_key.k

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_journal_iter.c       | 14 +++++---------
 fs/bcachefs/btree_journal_iter.h       | 13 ++++++++++++-
 fs/bcachefs/btree_journal_iter_types.h |  6 ++++--
 fs/bcachefs/journal_io.c               |  6 +-----
 4 files changed, 22 insertions(+), 17 deletions(-)

diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index 2e9078b5f538..f63c349e09da 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -265,13 +265,8 @@ int bch2_journal_key_insert_take(struct bch_fs *c, enum btree_id id,
 	struct journal_key n = {
 		.btree_id	= id,
 		.level		= level,
-		.k		= k,
 		.allocated	= true,
-		/*
-		 * Ensure these keys are done last by journal replay, to unblock
-		 * journal reclaim:
-		 */
-		.journal_seq	= U64_MAX,
+		.allocated_k	= k,
 	};
 	struct journal_keys *keys = &c->journal_keys;
 	size_t idx = bch2_journal_key_search(keys, id, level, k->k.p);
@@ -292,7 +287,7 @@ int bch2_journal_key_insert_take(struct bch_fs *c, enum btree_id id,
 		}
 
 		if (keys->data[idx].allocated)
-			kfree(keys->data[idx].k);
+			kfree(keys->data[idx].allocated_k);
 		keys->data[idx] = n;
 		return 0;
 	}
@@ -702,7 +697,7 @@ void bch2_journal_keys_put(struct bch_fs *c)
 			kfree(i->overwritten_range);
 
 		if (i->allocated)
-			kfree(i->k);
+			kfree(i->allocated_k);
 	}
 
 	kvfree(keys->data);
@@ -781,7 +776,6 @@ int bch2_journal_keys_sort(struct bch_fs *c)
 					.btree_id	= entry->btree_id,
 					.level		= entry->level,
 					.rewind		= rewind,
-					.k		= k,
 					.journal_seq	= le64_to_cpu(i->j.seq),
 					.journal_offset	= k->_data - i->j._data,
 				};
@@ -828,6 +822,8 @@ void bch2_shoot_down_journal_keys(struct bch_fs *c, enum btree_id btree,
 		      bpos_ge(k->k.p, start) &&
 		      bpos_le(k->k.p, end)))
 			keys->data[dst++] = *i;
+		else if (i->allocated)
+			kfree(i->allocated_k);
 	}
 	keys->nr = keys->gap = dst;
 }
diff --git a/fs/bcachefs/btree_journal_iter.h b/fs/bcachefs/btree_journal_iter.h
index a1b26832869f..cfd2061bc966 100644
--- a/fs/bcachefs/btree_journal_iter.h
+++ b/fs/bcachefs/btree_journal_iter.h
@@ -29,10 +29,21 @@ struct btree_and_journal_iter {
 	bool			fail_if_too_many_whiteouts;
 };
 
+static inline u32 journal_entry_radix_idx(struct bch_fs *c, u64 seq)
+{
+	return (seq - c->journal_entries_base_seq) & (~0U >> 1);
+}
+
 static inline struct bkey_i *journal_key_k(struct bch_fs *c,
 					   const struct journal_key *k)
 {
-	return k->k;
+	if (k->allocated)
+		return k->allocated_k;
+
+	struct journal_replay *i =
+		*genradix_ptr(&c->journal_entries, journal_entry_radix_idx(c, k->journal_seq));
+
+	return (struct bkey_i *) (i->j._data + k->journal_offset);
 }
 
 static inline int __journal_key_btree_cmp(enum btree_id	l_btree_id,
diff --git a/fs/bcachefs/btree_journal_iter_types.h b/fs/bcachefs/btree_journal_iter_types.h
index 0b4f6c1cb183..e9d8628edec6 100644
--- a/fs/bcachefs/btree_journal_iter_types.h
+++ b/fs/bcachefs/btree_journal_iter_types.h
@@ -30,7 +30,10 @@ struct journal_key_range_overwritten {
 };
 
 struct journal_key {
-	u64			journal_seq;
+	union {
+		u64		journal_seq;
+		struct bkey_i	*allocated_k;
+	};
 	u32			journal_offset;
 	enum btree_id		btree_id:8;
 	unsigned		level:8;
@@ -39,7 +42,6 @@ struct journal_key {
 	bool			rewind:1;
 	struct journal_key_range_overwritten __rcu *
 				overwritten_range;
-	struct bkey_i		*k;
 };
 
 struct journal_keys {
diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 093e4acad085..6e8a89a0f244 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -3,6 +3,7 @@
 #include "alloc_background.h"
 #include "alloc_foreground.h"
 #include "btree_io.h"
+#include "btree_journal_iter.h"
 #include "btree_update_interior.h"
 #include "btree_write_buffer.h"
 #include "buckets.h"
@@ -106,11 +107,6 @@ static bool jset_csum_good(struct bch_fs *c, struct jset *j, struct bch_csum *cs
 	return !bch2_crc_cmp(j->csum, *csum);
 }
 
-static inline u32 journal_entry_radix_idx(struct bch_fs *c, u64 seq)
-{
-	return (seq - c->journal_entries_base_seq) & (~0U >> 1);
-}
-
 static void __journal_replay_free(struct bch_fs *c,
 				  struct journal_replay *i)
 {
-- 
2.51.0


From 570444b6385d1ff8a673fdc828239ddc6cdee916 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 21:27:18 -0400
Subject: [PATCH 277/309] bcachefs: journal_key.journal_seq_base_offset

Shrink journal_key some more.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_journal_iter.c       |  4 ++--
 fs/bcachefs/btree_journal_iter.h       |  3 +--
 fs/bcachefs/btree_journal_iter_types.h |  6 ++++--
 fs/bcachefs/recovery.c                 | 28 ++++++++++++--------------
 4 files changed, 20 insertions(+), 21 deletions(-)

diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index f63c349e09da..4213af39eb02 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -675,7 +675,7 @@ static int journal_sort_key_cmp(const void *_l, const void *_r, const void *priv
 	if (l->allocated || r->allocated)
 		return cmp_int(l->allocated, r->allocated);
 
-	return ((cmp_int(l->journal_seq, r->journal_seq) ?:
+	return ((cmp_int(l->journal_seq_offset, r->journal_seq_offset) ?:
 		 cmp_int(l->journal_offset, r->journal_offset)) * rewind);
 }
 
@@ -776,7 +776,7 @@ int bch2_journal_keys_sort(struct bch_fs *c)
 					.btree_id	= entry->btree_id,
 					.level		= entry->level,
 					.rewind		= rewind,
-					.journal_seq	= le64_to_cpu(i->j.seq),
+					.journal_seq_offset = journal_entry_radix_idx(c, le64_to_cpu(i->j.seq)),
 					.journal_offset	= k->_data - i->j._data,
 				};
 
diff --git a/fs/bcachefs/btree_journal_iter.h b/fs/bcachefs/btree_journal_iter.h
index cfd2061bc966..8dc8e778be6c 100644
--- a/fs/bcachefs/btree_journal_iter.h
+++ b/fs/bcachefs/btree_journal_iter.h
@@ -40,8 +40,7 @@ static inline struct bkey_i *journal_key_k(struct bch_fs *c,
 	if (k->allocated)
 		return k->allocated_k;
 
-	struct journal_replay *i =
-		*genradix_ptr(&c->journal_entries, journal_entry_radix_idx(c, k->journal_seq));
+	struct journal_replay *i = *genradix_ptr(&c->journal_entries, k->journal_seq_offset);
 
 	return (struct bkey_i *) (i->j._data + k->journal_offset);
 }
diff --git a/fs/bcachefs/btree_journal_iter_types.h b/fs/bcachefs/btree_journal_iter_types.h
index e9d8628edec6..53d866acda25 100644
--- a/fs/bcachefs/btree_journal_iter_types.h
+++ b/fs/bcachefs/btree_journal_iter_types.h
@@ -31,10 +31,12 @@ struct journal_key_range_overwritten {
 
 struct journal_key {
 	union {
-		u64		journal_seq;
+	struct {
+		u32		journal_seq_offset;
+		u32		journal_offset;
+	};
 		struct bkey_i	*allocated_k;
 	};
-	u32			journal_offset;
 	enum btree_id		btree_id:8;
 	unsigned		level:8;
 	bool			allocated:1;
diff --git a/fs/bcachefs/recovery.c b/fs/bcachefs/recovery.c
index 0117405e51ef..6319144a440c 100644
--- a/fs/bcachefs/recovery.c
+++ b/fs/bcachefs/recovery.c
@@ -204,7 +204,8 @@ static void replay_now_at(struct journal *j, u64 seq)
 static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 					      struct journal_key *k)
 {
-	struct bkey_i *bk = journal_key_k(trans->c, k);
+	struct bch_fs *c = trans->c;
+	struct bkey_i *bk = journal_key_k(c, k);
 	struct btree_iter iter;
 	bch2_trans_node_iter_init(trans, &iter, k->btree_id, bk->k.p,
 				  BTREE_MAX_DEPTH, k->level,
@@ -233,7 +234,8 @@ static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 					   bkey_s_c_to_accounting(old));
 	}
 
-	trans->journal_res.seq = k->journal_seq;
+	if (!k->allocated)
+		trans->journal_res.seq = c->journal_entries_base_seq + k->journal_seq_offset;
 
 	ret = bch2_trans_update(trans, &iter, new, BTREE_TRIGGER_norun);
 out:
@@ -244,6 +246,7 @@ static int bch2_journal_replay_accounting_key(struct btree_trans *trans,
 static int bch2_journal_replay_key(struct btree_trans *trans,
 				   struct journal_key *k)
 {
+	struct bch_fs *c = trans->c;
 	struct btree_iter iter;
 	unsigned iter_flags =
 		BTREE_ITER_intent|
@@ -254,7 +257,8 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 	if (k->overwritten)
 		return 0;
 
-	trans->journal_res.seq = k->journal_seq;
+	if (!k->allocated)
+		trans->journal_res.seq = c->journal_entries_base_seq + k->journal_seq_offset;
 
 	/*
 	 * BTREE_UPDATE_key_cache_reclaim disables key cache lookup/update to
@@ -269,7 +273,7 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 	else
 		update_flags |= BTREE_UPDATE_key_cache_reclaim;
 
-	struct bkey_i *bk = journal_key_k(trans->c, k);
+	struct bkey_i *bk = journal_key_k(c, k);
 	bch2_trans_node_iter_init(trans, &iter, k->btree_id, bk->k.p,
 				  BTREE_MAX_DEPTH, k->level,
 				  iter_flags);
@@ -279,8 +283,6 @@ static int bch2_journal_replay_key(struct btree_trans *trans,
 
 	struct btree_path *path = btree_iter_path(trans, &iter);
 	if (unlikely(!btree_path_node(path, k->level))) {
-		struct bch_fs *c = trans->c;
-
 		CLASS(printbuf, buf)();
 		prt_str(&buf, "btree=");
 		bch2_btree_id_to_text(&buf, k->btree_id);
@@ -335,13 +337,9 @@ static int journal_sort_seq_cmp(const void *_l, const void *_r)
 	const struct journal_key *l = *((const struct journal_key **)_l);
 	const struct journal_key *r = *((const struct journal_key **)_r);
 
-	/*
-	 * Map 0 to U64_MAX, so that keys with journal_seq === 0 come last
-	 *
-	 * journal_seq == 0 means that the key comes from early repair, and
-	 * should be inserted last so as to avoid overflowing the journal
-	 */
-	return cmp_int(l->journal_seq - 1, r->journal_seq - 1);
+	return !l->allocated && !r->allocated
+		? cmp_int(l->journal_seq_offset, r->journal_seq_offset)
+		: cmp_int(l->allocated, r->allocated);
 }
 
 DEFINE_DARRAY_NAMED(darray_journal_keys, struct journal_key *)
@@ -439,8 +437,8 @@ int bch2_journal_replay(struct bch_fs *c)
 
 		struct journal_key *k = *kp;
 
-		if (k->journal_seq)
-			replay_now_at(j, k->journal_seq);
+		if (!k->allocated)
+			replay_now_at(j, c->journal_entries_base_seq + k->journal_seq_offset);
 		else
 			replay_now_at(j, j->replay_journal_seq_end);
 
-- 
2.51.0


From 808708fe9da0c0bf953fe04fbf08803b8d90d8f2 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 21:56:30 -0400
Subject: [PATCH 278/309] bcachefs: darray_make_room_rcu()

RCU-freeing helper for darrays.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/darray.c | 23 ++++++++++++++++-------
 fs/bcachefs/darray.h | 14 ++++++++++----
 2 files changed, 26 insertions(+), 11 deletions(-)

diff --git a/fs/bcachefs/darray.c b/fs/bcachefs/darray.c
index e86d36d23e9e..6940037bd19e 100644
--- a/fs/bcachefs/darray.c
+++ b/fs/bcachefs/darray.c
@@ -1,11 +1,13 @@
 // SPDX-License-Identifier: GPL-2.0
 
 #include <linux/log2.h>
+#include <linux/rcupdate.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 #include "darray.h"
 
-int __bch2_darray_resize_noprof(darray_char *d, size_t element_size, size_t new_size, gfp_t gfp)
+int __bch2_darray_resize_noprof(darray_char *d, size_t element_size, size_t new_size, gfp_t gfp,
+				bool rcu)
 {
 	if (new_size > d->size) {
 		new_size = roundup_pow_of_two(new_size);
@@ -20,18 +22,25 @@ int __bch2_darray_resize_noprof(darray_char *d, size_t element_size, size_t new_
 		if (unlikely(check_mul_overflow(new_size, element_size, &bytes)))
 			return -ENOMEM;
 
-		void *data = likely(bytes < INT_MAX)
+		void *old = d->data;
+		void *new = likely(bytes < INT_MAX)
 			? kvmalloc_noprof(bytes, gfp)
 			: vmalloc_noprof(bytes);
-		if (!data)
+		if (!new)
 			return -ENOMEM;
 
 		if (d->size)
-			memcpy(data, d->data, d->size * element_size);
-		if (d->data != d->preallocated)
-			kvfree(d->data);
-		d->data	= data;
+			memcpy(new, old, d->size * element_size);
+
+		rcu_assign_pointer(d->data, new);
 		d->size = new_size;
+
+		if (old != d->preallocated) {
+			if (!rcu)
+				kvfree(old);
+			else
+				kvfree_rcu_mightsleep(old);
+		}
 	}
 
 	return 0;
diff --git a/fs/bcachefs/darray.h b/fs/bcachefs/darray.h
index 14c7fc7c8061..b4f284fe9652 100644
--- a/fs/bcachefs/darray.h
+++ b/fs/bcachefs/darray.h
@@ -34,17 +34,17 @@ typedef DARRAY(s16)	darray_s16;
 typedef DARRAY(s32)	darray_s32;
 typedef DARRAY(s64)	darray_s64;
 
-int __bch2_darray_resize_noprof(darray_char *, size_t, size_t, gfp_t);
+int __bch2_darray_resize_noprof(darray_char *, size_t, size_t, gfp_t, bool);
 
 #define __bch2_darray_resize(...)	alloc_hooks(__bch2_darray_resize_noprof(__VA_ARGS__))
 
-#define __darray_resize(_d, _element_size, _new_size, _gfp)		\
+#define __darray_resize(_d, _element_size, _new_size, _gfp, _rcu)	\
 	(unlikely((_new_size) > (_d)->size)				\
-	 ? __bch2_darray_resize((_d), (_element_size), (_new_size), (_gfp))\
+	 ? __bch2_darray_resize((_d), (_element_size), (_new_size), (_gfp), _rcu)\
 	 : 0)
 
 #define darray_resize_gfp(_d, _new_size, _gfp)				\
-	__darray_resize((darray_char *) (_d), sizeof((_d)->data[0]), (_new_size), _gfp)
+	__darray_resize((darray_char *) (_d), sizeof((_d)->data[0]), (_new_size), _gfp, false)
 
 #define darray_resize(_d, _new_size)					\
 	darray_resize_gfp(_d, _new_size, GFP_KERNEL)
@@ -55,6 +55,12 @@ int __bch2_darray_resize_noprof(darray_char *, size_t, size_t, gfp_t);
 #define darray_make_room(_d, _more)					\
 	darray_make_room_gfp(_d, _more, GFP_KERNEL)
 
+#define darray_resize_rcu(_d, _new_size)				\
+	__darray_resize((darray_char *) (_d), sizeof((_d)->data[0]), (_new_size), GFP_KERNEL, true)
+
+#define darray_make_room_rcu(_d, _more)				\
+	darray_resize_rcu((_d), (_d)->nr + (_more))
+
 #define darray_room(_d)		((_d).size - (_d).nr)
 
 #define darray_top(_d)		((_d).data[(_d).nr])
-- 
2.51.0


From 3b2c7467ab088f5fae10522aeed80d5157e640f9 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 13 Aug 2025 21:56:53 -0400
Subject: [PATCH 279/309] bcachefs: pointer compression for
 journal_key_range_overwritten

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_journal_iter.c       | 70 ++++++++++++++++----------
 fs/bcachefs/btree_journal_iter_types.h |  5 +-
 2 files changed, 46 insertions(+), 29 deletions(-)

diff --git a/fs/bcachefs/btree_journal_iter.c b/fs/bcachefs/btree_journal_iter.c
index 4213af39eb02..a6f344faf751 100644
--- a/fs/bcachefs/btree_journal_iter.c
+++ b/fs/bcachefs/btree_journal_iter.c
@@ -73,6 +73,16 @@ static size_t bch2_journal_key_search(struct journal_keys *keys,
 	return idx_to_pos(keys, __bch2_journal_key_search(keys, id, level, pos));
 }
 
+static inline struct journal_key_range_overwritten *__overwrite_range(struct journal_keys *keys, u32 idx)
+{
+	return idx ? keys->overwrites.data + idx : NULL;
+}
+
+static inline struct journal_key_range_overwritten *overwrite_range(struct journal_keys *keys, u32 idx)
+{
+	return idx ? rcu_dereference(keys->overwrites.data) + idx : NULL;
+}
+
 /* Returns first non-overwritten key >= search key: */
 const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id btree_id,
 						unsigned level, struct bpos pos,
@@ -106,7 +116,7 @@ const struct bkey_i *bch2_journal_keys_peek_max(struct bch_fs *c, enum btree_id
 
 		if (k->overwritten) {
 			if (k->overwritten_range)
-				*idx = rcu_dereference(k->overwritten_range)->end;
+				*idx = overwrite_range(keys, k->overwritten_range)->end;
 			else
 				*idx += 1;
 			continue;
@@ -169,7 +179,7 @@ const struct bkey_i *bch2_journal_keys_peek_prev_min(struct bch_fs *c, enum btre
 
 		if (k->overwritten) {
 			if (k->overwritten_range)
-				*idx = rcu_dereference(k->overwritten_range)->start;
+				*idx = overwrite_range(keys, k->overwritten_range)->start;
 			if (!*idx)
 				break;
 			--(*idx);
@@ -402,9 +412,9 @@ static void __bch2_journal_key_overwritten(struct journal_keys *keys, size_t pos
 	bool next_overwritten = next && next->overwritten;
 
 	struct journal_key_range_overwritten *prev_range =
-		prev_overwritten ? prev->overwritten_range : NULL;
+		prev_overwritten ? __overwrite_range(keys, prev->overwritten_range) : NULL;
 	struct journal_key_range_overwritten *next_range =
-		next_overwritten ? next->overwritten_range : NULL;
+		next_overwritten ? __overwrite_range(keys, next->overwritten_range) : NULL;
 
 	BUG_ON(prev_range && prev_range->end != idx);
 	BUG_ON(next_range && next_range->start != idx + 1);
@@ -412,37 +422,47 @@ static void __bch2_journal_key_overwritten(struct journal_keys *keys, size_t pos
 	if (prev_range && next_range) {
 		prev_range->end = next_range->end;
 
-		keys->data[pos].overwritten_range = prev_range;
+		keys->data[pos].overwritten_range = prev->overwritten_range;
+
+		u32 old = next->overwritten_range;
+
 		for (size_t i = next_range->start; i < next_range->end; i++) {
 			struct journal_key *ip = keys->data + idx_to_pos(keys, i);
-			BUG_ON(ip->overwritten_range != next_range);
-			ip->overwritten_range = prev_range;
+			BUG_ON(ip->overwritten_range != old);
+			ip->overwritten_range = prev->overwritten_range;
 		}
-
-		kfree_rcu_mightsleep(next_range);
 	} else if (prev_range) {
 		prev_range->end++;
-		k->overwritten_range = prev_range;
+		k->overwritten_range = prev->overwritten_range;
 		if (next_overwritten) {
 			prev_range->end++;
-			next->overwritten_range = prev_range;
+			next->overwritten_range = prev->overwritten_range;
 		}
 	} else if (next_range) {
 		next_range->start--;
-		k->overwritten_range = next_range;
+		k->overwritten_range = next->overwritten_range;
 		if (prev_overwritten) {
 			next_range->start--;
-			prev->overwritten_range = next_range;
+			prev->overwritten_range = next->overwritten_range;
 		}
 	} else if (prev_overwritten || next_overwritten) {
-		struct journal_key_range_overwritten *r = kmalloc(sizeof(*r), GFP_KERNEL);
-		if (!r)
+		/* 0 is a sentinel value */
+		if (darray_resize_rcu(&keys->overwrites, max(keys->overwrites.nr + 1, 2)))
 			return;
 
-		r->start = idx - (size_t) prev_overwritten;
-		r->end = idx + 1 + (size_t) next_overwritten;
+		if (!keys->overwrites.nr)
+			darray_push(&keys->overwrites, (struct journal_key_range_overwritten) {});
+
+		darray_push(&keys->overwrites, ((struct journal_key_range_overwritten) {
+			.start	= idx - (size_t) prev_overwritten,
+			.end	= idx + 1 + (size_t) next_overwritten,
+		}));
+
+		smp_wmb();
+		u32 r = keys->overwrites.nr - 1;
+
+		k->overwritten_range = r;
 
-		rcu_assign_pointer(k->overwritten_range, r);
 		if (prev_overwritten)
 			prev->overwritten_range = r;
 		if (next_overwritten)
@@ -456,7 +476,7 @@ void bch2_journal_key_overwritten(struct bch_fs *c, enum btree_id btree,
 	struct journal_keys *keys = &c->journal_keys;
 	size_t idx = bch2_journal_key_search(keys, btree, level, pos);
 
-	if (idx >= keys->size ||
+	if (idx				>= keys->size ||
 	    keys->data[idx].btree_id	!= btree ||
 	    keys->data[idx].level	!= level ||
 	    keys->data[idx].overwritten)
@@ -496,7 +516,7 @@ static struct bkey_s_c bch2_journal_iter_peek(struct bch_fs *c, struct journal_i
 			return bkey_i_to_s_c(journal_key_k(c, k));
 
 		if (k->overwritten_range)
-			iter->idx = idx_to_pos(iter->keys, rcu_dereference(k->overwritten_range)->end);
+			iter->idx = idx_to_pos(iter->keys, overwrite_range(iter->keys, k->overwritten_range)->end);
 		else
 			bch2_journal_iter_advance(iter);
 	}
@@ -690,20 +710,16 @@ void bch2_journal_keys_put(struct bch_fs *c)
 
 	move_gap(keys, keys->nr);
 
-	darray_for_each(*keys, i) {
-		if (i->overwritten_range &&
-		    (i == &darray_last(*keys) ||
-		     i->overwritten_range != i[1].overwritten_range))
-			kfree(i->overwritten_range);
-
+	darray_for_each(*keys, i)
 		if (i->allocated)
 			kfree(i->allocated_k);
-	}
 
 	kvfree(keys->data);
 	keys->data = NULL;
 	keys->nr = keys->gap = keys->size = 0;
 
+	darray_exit(&keys->overwrites);
+
 	struct journal_replay **i;
 	struct genradix_iter iter;
 
diff --git a/fs/bcachefs/btree_journal_iter_types.h b/fs/bcachefs/btree_journal_iter_types.h
index 53d866acda25..4495fc92f848 100644
--- a/fs/bcachefs/btree_journal_iter_types.h
+++ b/fs/bcachefs/btree_journal_iter_types.h
@@ -42,8 +42,7 @@ struct journal_key {
 	bool			allocated:1;
 	bool			overwritten:1;
 	bool			rewind:1;
-	struct journal_key_range_overwritten __rcu *
-				overwritten_range;
+	u32			overwritten_range;
 };
 
 struct journal_keys {
@@ -58,7 +57,9 @@ struct journal_keys {
 	size_t			gap;
 	atomic_t		ref;
 	bool			initial_ref_held;
+
 	struct mutex		overwrite_lock;
+	DARRAY(struct journal_key_range_overwritten) overwrites;
 };
 
 #endif /* _BCACHEFS_BTREE_JOURNAL_ITER_TYPES_H */
-- 
2.51.0


From 6feff1e0066e805ba6f3aeebd0d07b13be2f1d6e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 15 Aug 2025 00:02:28 -0400
Subject: [PATCH 280/309] bcachefs: Memory allocation profiling support for
 bkey_bufs

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bkey_buf.h | 44 ++++++++++++++++++++++++++----------------
 1 file changed, 27 insertions(+), 17 deletions(-)

diff --git a/fs/bcachefs/bkey_buf.h b/fs/bcachefs/bkey_buf.h
index a30c4ae8eb36..05a01bf86039 100644
--- a/fs/bcachefs/bkey_buf.h
+++ b/fs/bcachefs/bkey_buf.h
@@ -2,6 +2,8 @@
 #ifndef _BCACHEFS_BKEY_BUF_H
 #define _BCACHEFS_BKEY_BUF_H
 
+#include <linux/mempool.h>
+
 #include "bcachefs.h"
 #include "bkey.h"
 
@@ -10,41 +12,49 @@ struct bkey_buf {
 	u64		onstack[12];
 };
 
-static inline void bch2_bkey_buf_realloc(struct bkey_buf *s,
-					 struct bch_fs *c, unsigned u64s)
+static inline int bch2_bkey_buf_realloc_noprof(struct bkey_buf *s,
+						struct bch_fs *c, unsigned u64s)
 {
 	if (s->k == (void *) s->onstack &&
 	    u64s > ARRAY_SIZE(s->onstack)) {
-		s->k = mempool_alloc(&c->large_bkey_pool, GFP_NOFS);
+		s->k = mempool_alloc_noprof(&c->large_bkey_pool, GFP_NOFS);
 		memcpy(s->k, s->onstack, sizeof(s->onstack));
 	}
+
+	return 0; /* for alloc_hooks() macro */
 }
+#define bch2_bkey_buf_realloc(...)	alloc_hooks(bch2_bkey_buf_realloc_noprof(__VA_ARGS__))
 
-static inline void bch2_bkey_buf_reassemble(struct bkey_buf *s,
-					    struct bch_fs *c,
-					    struct bkey_s_c k)
+static inline int bch2_bkey_buf_reassemble_noprof(struct bkey_buf *s,
+						  struct bch_fs *c,
+						  struct bkey_s_c k)
 {
-	bch2_bkey_buf_realloc(s, c, k.k->u64s);
+	bch2_bkey_buf_realloc_noprof(s, c, k.k->u64s);
 	bkey_reassemble(s->k, k);
+	return 0;
 }
+#define bch2_bkey_buf_reassemble(...)	alloc_hooks(bch2_bkey_buf_reassemble_noprof(__VA_ARGS__))
 
-static inline void bch2_bkey_buf_copy(struct bkey_buf *s,
-				      struct bch_fs *c,
-				      struct bkey_i *src)
+static inline int bch2_bkey_buf_copy_noprof(struct bkey_buf *s,
+					    struct bch_fs *c,
+					    struct bkey_i *src)
 {
-	bch2_bkey_buf_realloc(s, c, src->k.u64s);
+	bch2_bkey_buf_realloc_noprof(s, c, src->k.u64s);
 	bkey_copy(s->k, src);
+	return 0;
 }
+#define bch2_bkey_buf_copy(...)	alloc_hooks(bch2_bkey_buf_copy_noprof(__VA_ARGS__))
 
-static inline void bch2_bkey_buf_unpack(struct bkey_buf *s,
-					struct bch_fs *c,
-					struct btree *b,
-					struct bkey_packed *src)
+static inline int bch2_bkey_buf_unpack_noprof(struct bkey_buf *s,
+					      struct bch_fs *c,
+					      struct btree *b,
+					      struct bkey_packed *src)
 {
-	bch2_bkey_buf_realloc(s, c, BKEY_U64s +
-			      bkeyp_val_u64s(&b->format, src));
+	bch2_bkey_buf_realloc_noprof(s, c, BKEY_U64s + bkeyp_val_u64s(&b->format, src));
 	bch2_bkey_unpack(b, s->k, src);
+	return 0;
 }
+#define bch2_bkey_buf_unpack(...)	alloc_hooks(bch2_bkey_buf_unpack_noprof(__VA_ARGS__))
 
 static inline void bch2_bkey_buf_init(struct bkey_buf *s)
 {
-- 
2.51.0


From aecfff73c6c0ef4d697aa17d752d45f60230a649 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Thu, 14 Aug 2025 10:28:41 -0400
Subject: [PATCH 281/309] bcachefs: accounting_read() improvemnts

Compact all accounting keys in the journal, not just in-mem ones, so
that we can be called incrementally by journal_keys_sort() if low on
memory.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/disk_accounting.c | 121 ++++++++++++++++++++--------------
 1 file changed, 73 insertions(+), 48 deletions(-)

diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 5ec57b710501..809c76b68ba8 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -734,6 +734,37 @@ static int bch2_disk_accounting_validate_late(struct btree_trans *trans,
 	goto fsck_err;
 }
 
+static struct journal_key *accumulate_newer_accounting_keys(struct bch_fs *c, struct journal_key *i)
+{
+	struct journal_keys *keys = &c->journal_keys;
+	struct bkey_i *k = journal_key_k(c, i);
+
+	darray_for_each_from(*keys, j, i + 1) {
+		if (journal_key_cmp(c, i, j))
+			return j;
+
+		struct bkey_i *n = journal_key_k(c, j);
+		if (n->k.type == KEY_TYPE_accounting) {
+			WARN_ON(bversion_cmp(k->k.bversion, n->k.bversion) >= 0);
+
+			bch2_accounting_accumulate(bkey_i_to_accounting(k),
+						   bkey_i_to_s_c_accounting(n));
+			j->overwritten = true;
+		}
+	}
+
+	return &darray_top(*keys);
+}
+
+static struct journal_key *accumulate_and_read_journal_accounting(struct btree_trans *trans, struct journal_key *i)
+{
+	struct bch_fs *c = trans->c;
+	struct journal_key *next = accumulate_newer_accounting_keys(c, i);
+
+	int ret = accounting_read_key(trans, bkey_i_to_s_c(journal_key_k(c, i)));
+	return ret ? ERR_PTR(ret) : next;
+}
+
 /*
  * At startup time, initialize the in memory accounting from the btree (and
  * journal)
@@ -759,6 +790,18 @@ int bch2_accounting_read(struct bch_fs *c)
 		percpu_memset(c->usage, 0, sizeof(*c->usage));
 	}
 
+	struct journal_keys *keys = &c->journal_keys;
+	struct journal_key *jk = keys->data;
+
+	while (jk < &darray_top(*keys) &&
+	       __journal_key_cmp(c, BTREE_ID_accounting, 0, POS_MIN, jk) > 0)
+		jk++;
+
+	struct journal_key *end = jk;
+	while (end < &darray_top(*keys) &&
+	       __journal_key_cmp(c, BTREE_ID_accounting, 0, SPOS_MAX, end) > 0)
+		end++;
+
 	struct btree_iter iter;
 	bch2_trans_iter_init(trans, &iter, BTREE_ID_accounting, POS_MIN,
 			     BTREE_ITER_prefetch|BTREE_ITER_all_snapshots);
@@ -771,6 +814,21 @@ int bch2_accounting_read(struct bch_fs *c)
 		if (k.k->type != KEY_TYPE_accounting)
 			continue;
 
+		while (jk < end &&
+		       __journal_key_cmp(c, BTREE_ID_accounting, 0, k.k->p, jk) > 0)
+			jk = accumulate_and_read_journal_accounting(trans, jk);
+
+		while (jk < end &&
+		       __journal_key_cmp(c, BTREE_ID_accounting, 0, k.k->p, jk) == 0 &&
+		       bversion_cmp(journal_key_k(c, jk)->k.bversion, k.k->bversion) <= 0) {
+			jk->overwritten = true;
+			jk++;
+		}
+
+		if (jk < end &&
+		    __journal_key_cmp(c, BTREE_ID_accounting, 0, k.k->p, jk) == 0)
+			jk = accumulate_and_read_journal_accounting(trans, jk);
+
 		struct disk_accounting_pos acc_k;
 		bpos_to_disk_accounting_pos(&acc_k, k.k->p);
 
@@ -778,10 +836,14 @@ int bch2_accounting_read(struct bch_fs *c)
 			break;
 
 		if (!bch2_accounting_is_mem(&acc_k)) {
-			struct disk_accounting_pos next;
-			memset(&next, 0, sizeof(next));
-			next.type = acc_k.type + 1;
-			bch2_btree_iter_set_pos(&iter, disk_accounting_pos_to_bpos(&next));
+			struct disk_accounting_pos next_acc;
+			memset(&next_acc, 0, sizeof(next_acc));
+			next_acc.type = acc_k.type + 1;
+			struct bpos next = disk_accounting_pos_to_bpos(&next_acc);
+			if (jk < end)
+				next = bpos_min(next, journal_key_k(c, jk)->k.p);
+
+			bch2_btree_iter_set_pos(&iter, next);
 			continue;
 		}
 
@@ -791,51 +853,14 @@ int bch2_accounting_read(struct bch_fs *c)
 	if (ret)
 		return ret;
 
-	struct journal_keys *keys = &c->journal_keys;
-	move_gap(keys, keys->nr);
-
-	darray_for_each(*keys, i) {
-		if (i->overwritten)
-			continue;
-
-		struct bkey_i *k = journal_key_k(c, i);
-
-		if (k->k.type == KEY_TYPE_accounting) {
-			struct disk_accounting_pos acc_k;
-			bpos_to_disk_accounting_pos(&acc_k, k->k.p);
-
-			if (!bch2_accounting_is_mem(&acc_k))
-				continue;
+	while (jk < end)
+		jk = accumulate_and_read_journal_accounting(trans, jk);
 
-			unsigned idx = eytzinger0_find(acc->k.data, acc->k.nr,
-						sizeof(acc->k.data[0]),
-						accounting_pos_cmp, &k->k.p);
-
-			bool applied = idx < acc->k.nr &&
-				bversion_cmp(acc->k.data[idx].bversion, k->k.bversion) >= 0;
-
-			if (applied)
-				continue;
-
-			darray_for_each_from(*keys, j, i + 1) {
-				if (journal_key_cmp(c, i, j))
-					break;
-
-				struct bkey_i *n = journal_key_k(c, j);
-				if (n->k.type == KEY_TYPE_accounting) {
-					WARN_ON(bversion_cmp(k->k.bversion, n->k.bversion) >= 0);
-
-					bch2_accounting_accumulate(bkey_i_to_accounting(k),
-								   bkey_i_to_s_c_accounting(n));
-					j->overwritten = true;
-				}
-			}
-
-			ret = accounting_read_key(trans, bkey_i_to_s_c(k));
-			if (ret)
-				return ret;
-		}
-	}
+	struct journal_key *dst = keys->data;
+	darray_for_each(*keys, i)
+		if (!i->overwritten)
+			*dst++ = *i;
+	keys->gap = keys->nr = dst - keys->data;
 
 	guard(percpu_write)(&c->mark_lock);
 
-- 
2.51.0


From 53e0054a48906155fe3d156f08e2b28457521417 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 17 Aug 2025 17:05:04 -0400
Subject: [PATCH 282/309] bcachefs: dump_stack() in bch2_dev_missing_atomic()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sb-members.c | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/sb-members.c b/fs/bcachefs/sb-members.c
index e3c73d903898..d26a0ca4a59d 100644
--- a/fs/bcachefs/sb-members.c
+++ b/fs/bcachefs/sb-members.c
@@ -36,10 +36,12 @@ int bch2_dev_missing_bkey(struct bch_fs *c, struct bkey_s_c k, unsigned dev)
 
 void bch2_dev_missing_atomic(struct bch_fs *c, unsigned dev)
 {
-	if (dev != BCH_SB_MEMBER_INVALID)
+	if (dev != BCH_SB_MEMBER_INVALID) {
 		bch2_fs_inconsistent(c, "pointer to %s device %u",
 				     test_bit(dev, c->devs_removed.d)
 				     ? "removed" : "nonexistent", dev);
+		dump_stack();
+	}
 }
 
 void bch2_dev_bucket_missing(struct bch_dev *ca, u64 bucket)
-- 
2.51.0


From 120ee9b857b90683f436288c9cfa86152f09e9bb Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 17 Aug 2025 19:10:11 -0400
Subject: [PATCH 283/309] bcachefs: check_fix_ptr() should use
 bch2_dev_tryget_noerror()

If the device is missing, that's what we're supposed to be fixing.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/buckets.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/fs/bcachefs/buckets.c b/fs/bcachefs/buckets.c
index 87a6f4dce296..280b169efb62 100644
--- a/fs/bcachefs/buckets.c
+++ b/fs/bcachefs/buckets.c
@@ -111,7 +111,7 @@ static int bch2_check_fix_ptr(struct btree_trans *trans,
 	CLASS(printbuf, buf)();
 	int ret = 0;
 
-	CLASS(bch2_dev_tryget, ca)(c, p.ptr.dev);
+	CLASS(bch2_dev_tryget_noerror, ca)(c, p.ptr.dev);
 	if (!ca) {
 		if (fsck_err_on(p.ptr.dev != BCH_SB_MEMBER_INVALID,
 				trans, ptr_to_invalid_device,
-- 
2.51.0


From 6a0ee14f9e70baaf600691406de636388f77a1cf Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 17 Aug 2025 19:49:31 -0400
Subject: [PATCH 284/309] bcachefs: Plumb printbuf through device_set_state

To be used for improving ioctl error messages.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/chardev.c  |  3 ++-
 fs/bcachefs/error.c    | 12 +++++++-----
 fs/bcachefs/opts.c     |  2 +-
 fs/bcachefs/replicas.c | 14 ++++++--------
 fs/bcachefs/replicas.h |  2 +-
 fs/bcachefs/super-io.c |  4 ++--
 fs/bcachefs/super.c    | 40 +++++++++++++++++++++++-----------------
 fs/bcachefs/super.h    |  9 ++++++---
 8 files changed, 48 insertions(+), 38 deletions(-)

diff --git a/fs/bcachefs/chardev.c b/fs/bcachefs/chardev.c
index 467fc45e84fe..e6ed64dc11b7 100644
--- a/fs/bcachefs/chardev.c
+++ b/fs/bcachefs/chardev.c
@@ -287,7 +287,8 @@ static long bch2_ioctl_disk_set_state(struct bch_fs *c,
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	int ret = bch2_dev_set_state(c, ca, arg.new_state, arg.flags);
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_set_state(c, ca, arg.new_state, arg.flags, &err);
 	bch_err_msg(ca, ret, "setting device state");
 	return ret;
 }
diff --git a/fs/bcachefs/error.c b/fs/bcachefs/error.c
index 32a286b3a74e..e33f3166c48a 100644
--- a/fs/bcachefs/error.c
+++ b/fs/bcachefs/error.c
@@ -141,14 +141,16 @@ void bch2_io_error_work(struct work_struct *work)
 		if (ca->mi.state >= BCH_MEMBER_STATE_ro)
 			return;
 
-		bool dev = !__bch2_dev_set_state(c, ca, BCH_MEMBER_STATE_ro,
-						 BCH_FORCE_IF_DEGRADED);
 		CLASS(printbuf, buf)();
 		__bch2_log_msg_start(ca->name, &buf);
 
-		prt_printf(&buf, "writes erroring for %u seconds, setting %s ro",
-			c->opts.write_error_timeout,
-			dev ? "device" : "filesystem");
+		prt_printf(&buf, "writes erroring for %u seconds\n",
+			c->opts.write_error_timeout);
+
+		bool dev = !__bch2_dev_set_state(c, ca, BCH_MEMBER_STATE_ro,
+						 BCH_FORCE_IF_DEGRADED, &buf);
+
+		prt_printf(&buf, "setting %s ro", dev ? "device" : "filesystem");
 		if (!dev)
 			bch2_fs_emergency_read_only2(c, &buf);
 
diff --git a/fs/bcachefs/opts.c b/fs/bcachefs/opts.c
index 921f9049912d..c3ef35dc01e2 100644
--- a/fs/bcachefs/opts.c
+++ b/fs/bcachefs/opts.c
@@ -525,7 +525,7 @@ int bch2_opt_hook_pre_set(struct bch_fs *c, struct bch_dev *ca, enum bch_opt_id
 	switch (id) {
 	case Opt_state:
 		if (ca)
-			return bch2_dev_set_state(c, ca, v, BCH_FORCE_IF_DEGRADED);
+			return bch2_dev_set_state(c, ca, v, BCH_FORCE_IF_DEGRADED, NULL);
 		break;
 
 	case Opt_compression:
diff --git a/fs/bcachefs/replicas.c b/fs/bcachefs/replicas.c
index 0784283ce78c..3ffd68d2608d 100644
--- a/fs/bcachefs/replicas.c
+++ b/fs/bcachefs/replicas.c
@@ -784,7 +784,7 @@ const struct bch_sb_field_ops bch_sb_field_ops_replicas_v0 = {
 /* Query replicas: */
 
 bool bch2_have_enough_devs(struct bch_fs *c, struct bch_devs_mask devs,
-			   unsigned flags, bool print)
+			   unsigned flags, struct printbuf *err)
 {
 	struct bch_replicas_entry_v1 *e;
 
@@ -823,16 +823,14 @@ bool bch2_have_enough_devs(struct bch_fs *c, struct bch_devs_mask devs,
 				: BCH_FORCE_IF_DATA_DEGRADED;
 
 		if (dflags & ~flags) {
-			if (print) {
-				CLASS(printbuf, buf)();
-
-				bch2_replicas_entry_to_text(&buf, e);
-				bch_err(c, "insufficient devices online (%u) for replicas entry %s",
-					nr_online, buf.buf);
+			if (err) {
+				prt_printf(err, "insufficient devices online (%u) for replicas entry ",
+					   nr_online);
+				bch2_replicas_entry_to_text(err, e);
+				prt_newline(err);
 			}
 			return false;
 		}
-
 	}
 
 	return true;
diff --git a/fs/bcachefs/replicas.h b/fs/bcachefs/replicas.h
index 5aba2c1ce133..15023a9b0b1e 100644
--- a/fs/bcachefs/replicas.h
+++ b/fs/bcachefs/replicas.h
@@ -44,7 +44,7 @@ static inline void bch2_replicas_entry_cached(struct bch_replicas_entry_v1 *e,
 }
 
 bool bch2_have_enough_devs(struct bch_fs *, struct bch_devs_mask,
-			   unsigned, bool);
+			   unsigned, struct printbuf *);
 
 unsigned bch2_sb_dev_has_data(struct bch_sb *, unsigned);
 unsigned bch2_dev_has_data(struct bch_fs *, struct bch_dev *);
diff --git a/fs/bcachefs/super-io.c b/fs/bcachefs/super-io.c
index 5897380c4c08..61eeac671283 100644
--- a/fs/bcachefs/super-io.c
+++ b/fs/bcachefs/super-io.c
@@ -1189,13 +1189,13 @@ int bch2_write_super(struct bch_fs *c)
 	nr_wrote = dev_mask_nr(&sb_written);
 
 	can_mount_with_written =
-		bch2_have_enough_devs(c, sb_written, degraded_flags, false);
+		bch2_have_enough_devs(c, sb_written, degraded_flags, NULL);
 
 	for (unsigned i = 0; i < ARRAY_SIZE(sb_written.d); i++)
 		sb_written.d[i] = ~sb_written.d[i];
 
 	can_mount_without_written =
-		bch2_have_enough_devs(c, sb_written, degraded_flags, false);
+		bch2_have_enough_devs(c, sb_written, degraded_flags, NULL);
 
 	/*
 	 * If we would be able to mount _without_ the devices we successfully
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index ee3b30b1c2b5..4281a20f7856 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1368,10 +1368,14 @@ static bool bch2_fs_may_start(struct bch_fs *c)
 				return false;
 		}
 		break;
-	 }
+	}
 	}
 
-	return bch2_have_enough_devs(c, c->online_devs, flags, true);
+	CLASS(printbuf, err)();
+	bool ret = bch2_have_enough_devs(c, c->online_devs, flags, &err);
+	if (!ret)
+		bch2_print_str(c, KERN_ERR, err.buf);
+	return ret;
 }
 
 int bch2_fs_start(struct bch_fs *c)
@@ -1833,7 +1837,8 @@ static int bch2_dev_attach_bdev(struct bch_fs *c, struct bch_sb_handle *sb)
  * because we got an error or what have you?
  */
 bool bch2_dev_state_allowed(struct bch_fs *c, struct bch_dev *ca,
-			    enum bch_member_state new_state, int flags)
+			    enum bch_member_state new_state, int flags,
+			    struct printbuf *err)
 {
 	struct bch_devs_mask new_online_devs;
 	int nr_rw = 0, required;
@@ -1870,7 +1875,7 @@ bool bch2_dev_state_allowed(struct bch_fs *c, struct bch_dev *ca,
 		new_online_devs = c->online_devs;
 		__clear_bit(ca->dev_idx, new_online_devs.d);
 
-		return bch2_have_enough_devs(c, new_online_devs, flags, false);
+		return bch2_have_enough_devs(c, new_online_devs, flags, err);
 	default:
 		BUG();
 	}
@@ -1904,14 +1909,15 @@ static void __bch2_dev_read_write(struct bch_fs *c, struct bch_dev *ca)
 }
 
 int __bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
-			 enum bch_member_state new_state, int flags)
+			 enum bch_member_state new_state, int flags,
+			 struct printbuf *err)
 {
 	int ret = 0;
 
 	if (ca->mi.state == new_state)
 		return 0;
 
-	if (!bch2_dev_state_allowed(c, ca, new_state, flags))
+	if (!bch2_dev_state_allowed(c, ca, new_state, flags, err))
 		return bch_err_throw(c, device_state_not_allowed);
 
 	if (new_state != BCH_MEMBER_STATE_rw)
@@ -1934,10 +1940,11 @@ int __bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
 }
 
 int bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
-		       enum bch_member_state new_state, int flags)
+		       enum bch_member_state new_state, int flags,
+		       struct printbuf *err)
 {
 	guard(rwsem_write)(&c->state_lock);
-	return __bch2_dev_set_state(c, ca, new_state, flags);
+	return __bch2_dev_set_state(c, ca, new_state, flags, err);
 }
 
 /* Device add/removal: */
@@ -1957,7 +1964,7 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 	 */
 	bch2_dev_put(ca);
 
-	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags)) {
+	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags, NULL)) {
 		bch_err(ca, "Cannot remove without losing data");
 		ret = bch_err_throw(c, device_state_not_allowed);
 		goto err;
@@ -2278,7 +2285,7 @@ int bch2_dev_offline(struct bch_fs *c, struct bch_dev *ca, int flags)
 		return 0;
 	}
 
-	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags)) {
+	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags, NULL)) {
 		bch_err(ca, "Cannot offline required disk");
 		return bch_err_throw(c, device_state_not_allowed);
 	}
@@ -2455,10 +2462,14 @@ static void bch2_fs_bdev_mark_dead(struct block_device *bdev, bool surprise)
 
 	struct bch_dev *ca = bdev_to_bch_dev(c, bdev);
 	if (ca) {
+		CLASS(printbuf, buf)();
+		__bch2_log_msg_start(ca->name, &buf);
+		prt_printf(&buf, "offline from block layer\n");
+
 		bool dev = bch2_dev_state_allowed(c, ca,
 						  BCH_MEMBER_STATE_failed,
-						  BCH_FORCE_IF_DEGRADED);
-
+						  BCH_FORCE_IF_DEGRADED,
+						  &buf);
 		if (!dev && sb) {
 			if (!surprise)
 				sync_filesystem(sb);
@@ -2466,11 +2477,6 @@ static void bch2_fs_bdev_mark_dead(struct block_device *bdev, bool surprise)
 			evict_inodes(sb);
 		}
 
-		CLASS(printbuf, buf)();
-		__bch2_log_msg_start(ca->name, &buf);
-
-		prt_printf(&buf, "offline from block layer");
-
 		if (dev) {
 			__bch2_dev_offline(c, ca);
 		} else {
diff --git a/fs/bcachefs/super.h b/fs/bcachefs/super.h
index e90bab9afe78..de2c4430b8f7 100644
--- a/fs/bcachefs/super.h
+++ b/fs/bcachefs/super.h
@@ -17,11 +17,14 @@ struct bch_fs *bch2_dev_to_fs(dev_t);
 struct bch_fs *bch2_uuid_to_fs(__uuid_t);
 
 bool bch2_dev_state_allowed(struct bch_fs *, struct bch_dev *,
-			   enum bch_member_state, int);
+			    enum bch_member_state, int,
+			    struct printbuf *);
 int __bch2_dev_set_state(struct bch_fs *, struct bch_dev *,
-			enum bch_member_state, int);
+			 enum bch_member_state, int,
+			 struct printbuf *);
 int bch2_dev_set_state(struct bch_fs *, struct bch_dev *,
-		      enum bch_member_state, int);
+		       enum bch_member_state, int,
+		       struct printbuf *);
 
 int bch2_dev_fail(struct bch_dev *, int);
 int bch2_dev_remove(struct bch_fs *, struct bch_dev *, int);
-- 
2.51.0


From bdebdc54146b9d4c8face0674d615ba7a5dfba20 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 17 Aug 2025 20:09:48 -0400
Subject: [PATCH 285/309] bcachefs: BCH_IOCTL_DISK_SET_STATE_v2

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_ioctl.h | 15 +++++++++++++++
 fs/bcachefs/chardev.c        | 36 ++++++++++++++++++++++++++++++++++++
 2 files changed, 51 insertions(+)

diff --git a/fs/bcachefs/bcachefs_ioctl.h b/fs/bcachefs/bcachefs_ioctl.h
index 52594e925eb7..42e2cb5d7b4d 100644
--- a/fs/bcachefs/bcachefs_ioctl.h
+++ b/fs/bcachefs/bcachefs_ioctl.h
@@ -71,6 +71,7 @@ struct bch_ioctl_incremental {
 #define BCH_IOCTL_DISK_ONLINE	_IOW(0xbc,	6,  struct bch_ioctl_disk)
 #define BCH_IOCTL_DISK_OFFLINE	_IOW(0xbc,	7,  struct bch_ioctl_disk)
 #define BCH_IOCTL_DISK_SET_STATE _IOW(0xbc,	8,  struct bch_ioctl_disk_set_state)
+#define BCH_IOCTL_DISK_SET_STATE_v2 _IOW(0xbc,	22,  struct bch_ioctl_disk_set_state_v2)
 #define BCH_IOCTL_DATA		_IOW(0xbc,	10, struct bch_ioctl_data)
 #define BCH_IOCTL_FS_USAGE	_IOWR(0xbc,	11, struct bch_ioctl_fs_usage)
 #define BCH_IOCTL_DEV_USAGE	_IOWR(0xbc,	11, struct bch_ioctl_dev_usage)
@@ -93,6 +94,12 @@ struct bch_ioctl_incremental {
 
 #define BCHFS_IOC_REINHERIT_ATTRS	_IOR(0xbc, 64, const char __user *)
 
+struct bch_ioctl_err_msg {
+	__u64			msg_ptr;
+	__u32			msg_len;
+	__u32			pad;
+};
+
 /*
  * BCH_IOCTL_QUERY_UUID: get filesystem UUID
  *
@@ -181,6 +188,14 @@ struct bch_ioctl_disk_set_state {
 	__u64			dev;
 };
 
+struct bch_ioctl_disk_set_state_v2 {
+	__u32				flags;
+	__u8				new_state;
+	__u8				pad[3];
+	__u64				dev;
+	struct bch_ioctl_err_msg	err;
+};
+
 #define BCH_DATA_OPS()			\
 	x(scrub,		0)	\
 	x(rereplicate,		1)	\
diff --git a/fs/bcachefs/chardev.c b/fs/bcachefs/chardev.c
index e6ed64dc11b7..24442bc9f808 100644
--- a/fs/bcachefs/chardev.c
+++ b/fs/bcachefs/chardev.c
@@ -293,6 +293,40 @@ static long bch2_ioctl_disk_set_state(struct bch_fs *c,
 	return ret;
 }
 
+static long bch2_ioctl_disk_set_state_v2(struct bch_fs *c,
+			struct bch_ioctl_disk_set_state_v2 arg)
+{
+	CLASS(printbuf, err)();
+
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if ((arg.flags & ~(BCH_FORCE_IF_DATA_LOST|
+			   BCH_FORCE_IF_METADATA_LOST|
+			   BCH_FORCE_IF_DEGRADED|
+			   BCH_BY_INDEX)) ||
+	    arg.pad[0] || arg.pad[1] || arg.pad[2] ||
+	    arg.new_state >= BCH_MEMBER_STATE_NR)
+		return -EINVAL;
+
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
+	int ret = PTR_ERR_OR_ZERO(ca);
+	if (ret) {
+		prt_printf(&err, "device %llu not found\n", arg.dev);
+		goto err;
+	}
+
+	ret = bch2_dev_set_state(c, ca, arg.new_state, arg.flags, &err);
+err:
+	if (ret) {
+		prt_printf(&err, "error=%s", bch2_err_str(ret));
+		ret = copy_to_user_errcode((void __user *)(ulong)arg.err.msg_ptr,
+					   err.buf,
+					   min(err.pos, arg.err.msg_len)) ?: ret;
+	}
+	return ret;
+}
+
 struct bch_data_ctx {
 	struct thread_with_file		thr;
 
@@ -693,6 +727,8 @@ long bch2_fs_ioctl(struct bch_fs *c, unsigned cmd, void __user *arg)
 		BCH_IOCTL(disk_offline, struct bch_ioctl_disk);
 	case BCH_IOCTL_DISK_SET_STATE:
 		BCH_IOCTL(disk_set_state, struct bch_ioctl_disk_set_state);
+	case BCH_IOCTL_DISK_SET_STATE_v2:
+		BCH_IOCTL(disk_set_state_v2, struct bch_ioctl_disk_set_state_v2);
 	case BCH_IOCTL_DATA:
 		BCH_IOCTL(data, struct bch_ioctl_data);
 	case BCH_IOCTL_DISK_RESIZE:
-- 
2.51.0


From c32669b6c62023ab02cedc593073436183b93012 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 18 Aug 2025 12:06:33 -0400
Subject: [PATCH 286/309] bcachefs: Plumb a printbuf for error strings through
 ioctls

Convert:
- bch2_dev_online()
- bch2_dev_offline()
- bch2_dev_add()
- bch2_dev_remove()
- bch2_dev_resize()

Next patch will add v2 ioctls to return error strings to userspace.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_ioctl.h |   7 --
 fs/bcachefs/chardev.c        |  31 ++++++--
 fs/bcachefs/super.c          | 150 +++++++++++++++++++++--------------
 fs/bcachefs/super.h          |  11 ++-
 4 files changed, 118 insertions(+), 81 deletions(-)

diff --git a/fs/bcachefs/bcachefs_ioctl.h b/fs/bcachefs/bcachefs_ioctl.h
index 42e2cb5d7b4d..08fa1636dde2 100644
--- a/fs/bcachefs/bcachefs_ioctl.h
+++ b/fs/bcachefs/bcachefs_ioctl.h
@@ -111,13 +111,6 @@ struct bch_ioctl_query_uuid {
 	__uuid_t		uuid;
 };
 
-#if 0
-struct bch_ioctl_start {
-	__u32			flags;
-	__u32			pad;
-};
-#endif
-
 /*
  * BCH_IOCTL_DISK_ADD: add a new device to an existing filesystem
  *
diff --git a/fs/bcachefs/chardev.c b/fs/bcachefs/chardev.c
index 24442bc9f808..2370c15e28b6 100644
--- a/fs/bcachefs/chardev.c
+++ b/fs/bcachefs/chardev.c
@@ -203,10 +203,12 @@ static long bch2_ioctl_disk_add(struct bch_fs *c, struct bch_ioctl_disk arg)
 	if (ret)
 		return ret;
 
-	ret = bch2_dev_add(c, path);
-	if (!IS_ERR(path))
-		kfree(path);
+	CLASS(printbuf, err)();
+	ret = bch2_dev_add(c, path, &err);
+	if (ret)
+		bch_err(c, "%s", err.buf);
 
+	kfree(path);
 	return ret;
 }
 
@@ -226,7 +228,11 @@ static long bch2_ioctl_disk_remove(struct bch_fs *c, struct bch_ioctl_disk arg)
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	return bch2_dev_remove(c, ca, arg.flags);
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_remove(c, ca, arg.flags, &err);
+	if (ret)
+		bch_err(ca, "%s", err.buf);
+	return ret;
 }
 
 static long bch2_ioctl_disk_online(struct bch_fs *c, struct bch_ioctl_disk arg)
@@ -245,7 +251,10 @@ static long bch2_ioctl_disk_online(struct bch_fs *c, struct bch_ioctl_disk arg)
 	if (ret)
 		return ret;
 
-	ret = bch2_dev_online(c, path);
+	CLASS(printbuf, err)();
+	ret = bch2_dev_online(c, path, &err);
+	if (ret)
+		bch_err(c, "%s", err.buf);
 	kfree(path);
 	return ret;
 }
@@ -266,7 +275,11 @@ static long bch2_ioctl_disk_offline(struct bch_fs *c, struct bch_ioctl_disk arg)
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	return bch2_dev_offline(c, ca, arg.flags);
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_offline(c, ca, arg.flags, &err);
+	if (ret)
+		bch_err(ca, "%s", err.buf);
+	return ret;
 }
 
 static long bch2_ioctl_disk_set_state(struct bch_fs *c,
@@ -655,7 +668,11 @@ static long bch2_ioctl_disk_resize(struct bch_fs *c,
 	if (IS_ERR(ca))
 		return PTR_ERR(ca);
 
-	return bch2_dev_resize(c, ca, arg.nbuckets);
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_resize(c, ca, arg.nbuckets, &err);
+	if (ret)
+		bch_err(ca, "%s", err.buf);
+	return ret;
 }
 
 static long bch2_ioctl_disk_resize_journal(struct bch_fs *c,
diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index 4281a20f7856..cc9d00e1afd5 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -1750,19 +1750,20 @@ static int bch2_dev_alloc(struct bch_fs *c, unsigned dev_idx)
 	return 0;
 }
 
-static int __bch2_dev_attach_bdev(struct bch_dev *ca, struct bch_sb_handle *sb)
+static int __bch2_dev_attach_bdev(struct bch_dev *ca, struct bch_sb_handle *sb,
+				  struct printbuf *err)
 {
 	unsigned ret;
 
 	if (bch2_dev_is_online(ca)) {
-		bch_err(ca, "already have device online in slot %u",
-			sb->sb->dev_idx);
+		prt_printf(err, "already have device online in slot %u\n",
+			   sb->sb->dev_idx);
 		return bch_err_throw(ca->fs, device_already_online);
 	}
 
 	if (get_capacity(sb->bdev->bd_disk) <
 	    ca->mi.bucket_size * ca->mi.nbuckets) {
-		bch_err(ca, "cannot online: device too small (capacity %llu filesystem size %llu nbuckets %llu)",
+		prt_printf(err, "cannot online: device too small (capacity %llu filesystem size %llu nbuckets %llu)\n",
 			get_capacity(sb->bdev->bd_disk),
 			ca->mi.bucket_size * ca->mi.nbuckets,
 			ca->mi.nbuckets);
@@ -1798,7 +1799,8 @@ static int __bch2_dev_attach_bdev(struct bch_dev *ca, struct bch_sb_handle *sb)
 	return 0;
 }
 
-static int bch2_dev_attach_bdev(struct bch_fs *c, struct bch_sb_handle *sb)
+static int bch2_dev_attach_bdev(struct bch_fs *c, struct bch_sb_handle *sb,
+				struct printbuf *err)
 {
 	struct bch_dev *ca;
 	int ret;
@@ -1813,7 +1815,7 @@ static int bch2_dev_attach_bdev(struct bch_fs *c, struct bch_sb_handle *sb)
 
 	ca = bch2_dev_locked(c, sb->sb->dev_idx);
 
-	ret = __bch2_dev_attach_bdev(ca, sb);
+	ret = __bch2_dev_attach_bdev(ca, sb, err);
 	if (ret)
 		return ret;
 
@@ -1949,7 +1951,8 @@ int bch2_dev_set_state(struct bch_fs *c, struct bch_dev *ca,
 
 /* Device add/removal: */
 
-int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
+int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags,
+		    struct printbuf *err)
 {
 	unsigned dev_idx = ca->dev_idx, data;
 	bool fast_device_removal = !bch2_request_incompat_feature(c,
@@ -1965,7 +1968,7 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 	bch2_dev_put(ca);
 
 	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags, NULL)) {
-		bch_err(ca, "Cannot remove without losing data");
+		prt_printf(err, "Cannot remove without losing data\n");
 		ret = bch_err_throw(c, device_state_not_allowed);
 		goto err;
 	}
@@ -1985,16 +1988,17 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 		if (!data_type_is_empty(i) &&
 		    !data_type_is_hidden(i) &&
 		    usage.buckets[i]) {
-			bch_err(ca, "Remove failed: still has data (%s, %llu buckets)",
-				__bch2_data_types[i], usage.buckets[i]);
+			prt_printf(err, "Remove failed: still has data (%s, %llu buckets)\n",
+				   __bch2_data_types[i], usage.buckets[i]);
 			ret = -EBUSY;
 			goto err;
 		}
 
 	ret = bch2_dev_remove_alloc(c, ca);
-	bch_err_msg(ca, ret, "bch2_dev_remove_alloc()");
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_dev_remove_alloc() error: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
 	/*
 	 * We need to flush the entire journal to get rid of keys that reference
@@ -2007,25 +2011,28 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 	 * calls, and could be cleaned up:
 	 */
 	ret = bch2_journal_flush_device_pins(&c->journal, ca->dev_idx);
-	bch_err_msg(ca, ret, "bch2_journal_flush_device_pins()");
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_journal_flush_device_pins() error: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
 	ret = bch2_journal_flush(&c->journal);
-	bch_err_msg(ca, ret, "bch2_journal_flush()");
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_journal_flush() error: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
 	ret = bch2_replicas_gc2(c);
-	bch_err_msg(ca, ret, "bch2_replicas_gc2()");
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_replicas_gc2() error: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
 	data = bch2_dev_has_data(c, ca);
 	if (data) {
-		CLASS(printbuf, data_has)();
-		prt_bitflags(&data_has, __bch2_data_types, data);
-		bch_err(ca, "Remove failed, still has data (%s)", data_has.buf);
+		prt_str(err, "Remove failed, still has data (");
+		prt_bitflags(err, __bch2_data_types, data);
+		prt_str(err, ")\n");
 		ret = -EBUSY;
 		goto err;
 	}
@@ -2070,7 +2077,7 @@ int bch2_dev_remove(struct bch_fs *c, struct bch_dev *ca, int flags)
 }
 
 /* Add new device to running filesystem: */
-int bch2_dev_add(struct bch_fs *c, const char *path)
+int bch2_dev_add(struct bch_fs *c, const char *path, struct printbuf *err)
 {
 	struct bch_opts opts = bch2_opts_empty();
 	struct bch_sb_handle sb = {};
@@ -2079,9 +2086,10 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 	int ret = 0;
 
 	ret = bch2_read_super(path, &opts, &sb);
-	bch_err_msg(c, ret, "reading super");
-	if (ret)
+	if (ret) {
+		prt_printf(err, "error reading superblock: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
 	struct bch_member dev_mi = bch2_sb_member_get(sb.sb, sb.sb->dev_idx);
 
@@ -2102,7 +2110,7 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 		}
 
 		if (ret) {
-			bch_err(c, "filesystem UUID already open");
+			prt_printf(err, "cannot go multidevice: filesystem UUID already open\n");
 			goto err;
 		}
 	}
@@ -2117,7 +2125,7 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 		goto err;
 	}
 
-	ret = __bch2_dev_attach_bdev(ca, &sb);
+	ret = __bch2_dev_attach_bdev(ca, &sb, err);
 	if (ret)
 		goto err;
 
@@ -2126,16 +2134,17 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 			SET_BCH_SB_MULTI_DEVICE(c->disk_sb.sb, true);
 
 			ret = bch2_sb_from_fs(c, ca);
-			bch_err_msg(c, ret, "setting up new superblock");
-			if (ret)
+			if (ret) {
+				prt_printf(err, "error setting up new superblock: %s\n", bch2_err_str(ret));
 				goto err;
+			}
 
 			if (dynamic_fault("bcachefs:add:no_slot"))
 				goto err;
 
 			ret = bch2_sb_member_alloc(c);
 			if (ret < 0) {
-				bch_err_msg(c, ret, "setting up new superblock");
+				prt_printf(err, "error allocating superblock member slot: %s\n", bch2_err_str(ret));
 				goto err;
 			}
 			unsigned dev_idx = ret;
@@ -2153,7 +2162,7 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 
 			if (BCH_MEMBER_GROUP(&dev_mi)) {
 				ret = __bch2_dev_group_set(c, ca, label.buf);
-				bch_err_msg(c, ret, "creating new label");
+				prt_printf(err, "error creating new label: %s\n", bch2_err_str(ret));
 				if (ret)
 					goto err_late;
 			}
@@ -2167,22 +2176,25 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 
 		if (test_bit(BCH_FS_started, &c->flags)) {
 			ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
-			bch_err_msg(ca, ret, "marking new superblock");
-			if (ret)
+			if (ret) {
+				prt_printf(err, "error marking new superblock: %s\n", bch2_err_str(ret));
 				goto err_late;
+			}
 
 			ret = bch2_fs_freespace_init(c);
-			bch_err_msg(ca, ret, "initializing free space");
-			if (ret)
+			if (ret) {
+				prt_printf(err, "error initializing free space: %s\n", bch2_err_str(ret));
 				goto err_late;
+			}
 
 			if (ca->mi.state == BCH_MEMBER_STATE_rw)
 				__bch2_dev_read_write(c, ca);
 
 			ret = bch2_dev_journal_alloc(ca, false);
-			bch_err_msg(c, ret, "allocating journal");
-			if (ret)
+			if (ret) {
+				prt_printf(err, "error allocating journal: %s\n", bch2_err_str(ret));
 				goto err_late;
+			}
 		}
 
 		/*
@@ -2215,7 +2227,7 @@ int bch2_dev_add(struct bch_fs *c, const char *path)
 }
 
 /* Hot add existing device to running filesystem: */
-int bch2_dev_online(struct bch_fs *c, const char *path)
+int bch2_dev_online(struct bch_fs *c, const char *path, struct printbuf *err)
 {
 	struct bch_opts opts = bch2_opts_empty();
 	struct bch_sb_handle sb = { NULL };
@@ -2226,42 +2238,48 @@ int bch2_dev_online(struct bch_fs *c, const char *path)
 	guard(rwsem_write)(&c->state_lock);
 
 	ret = bch2_read_super(path, &opts, &sb);
-	if (ret)
+	if (ret) {
+		prt_printf(err, "error reading superblock: %s\n", bch2_err_str(ret));
 		return ret;
+	}
 
 	dev_idx = sb.sb->dev_idx;
 
 	ret = bch2_dev_in_fs(&c->disk_sb, &sb, &c->opts);
-	bch_err_msg(c, ret, "bringing %s online", path);
-	if (ret)
+	if (ret) {
+		prt_printf(err, "device not a member of fs: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
-	ret = bch2_dev_attach_bdev(c, &sb);
+	ret = bch2_dev_attach_bdev(c, &sb, err);
 	if (ret)
 		goto err;
 
 	ca = bch2_dev_locked(c, dev_idx);
 
 	ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
-	bch_err_msg(c, ret, "bringing %s online: error from bch2_trans_mark_dev_sb", path);
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_trans_mark_dev_sb() error: %s\n", bch2_err_str(ret));
 		goto err;
+	}
 
 	if (ca->mi.state == BCH_MEMBER_STATE_rw)
 		__bch2_dev_read_write(c, ca);
 
 	if (!ca->mi.freespace_initialized) {
 		ret = bch2_dev_freespace_init(c, ca, 0, ca->mi.nbuckets);
-		bch_err_msg(ca, ret, "initializing free space");
-		if (ret)
+		if (ret) {
+			prt_printf(err, "bch2_dev_freespace_init() error: %s\n", bch2_err_str(ret));
 			goto err;
+		}
 	}
 
 	if (!ca->journal.nr) {
 		ret = bch2_dev_journal_alloc(ca, false);
-		bch_err_msg(ca, ret, "allocating journal");
-		if (ret)
+		if (ret) {
+			prt_printf(err, "bch2_dev_journal_alloc() error: %s\n", bch2_err_str(ret));
 			goto err;
+		}
 	}
 
 	scoped_guard(mutex, &c->sb_lock) {
@@ -2276,17 +2294,17 @@ int bch2_dev_online(struct bch_fs *c, const char *path)
 	return ret;
 }
 
-int bch2_dev_offline(struct bch_fs *c, struct bch_dev *ca, int flags)
+int bch2_dev_offline(struct bch_fs *c, struct bch_dev *ca, int flags, struct printbuf *err)
 {
 	guard(rwsem_write)(&c->state_lock);
 
 	if (!bch2_dev_is_online(ca)) {
-		bch_err(ca, "Already offline");
+		prt_printf(err, "Already offline\n");
 		return 0;
 	}
 
 	if (!bch2_dev_state_allowed(c, ca, BCH_MEMBER_STATE_failed, flags, NULL)) {
-		bch_err(ca, "Cannot offline required disk");
+		prt_printf(err, "Cannot offline required disk\n");
 		return bch_err_throw(c, device_state_not_allowed);
 	}
 
@@ -2306,7 +2324,7 @@ static int __bch2_dev_resize_alloc(struct bch_dev *ca, u64 old_nbuckets, u64 new
 		bch2_dev_freespace_init(c, ca, old_nbuckets, new_nbuckets);
 }
 
-int bch2_dev_resize(struct bch_fs *c, struct bch_dev *ca, u64 nbuckets)
+int bch2_dev_resize(struct bch_fs *c, struct bch_dev *ca, u64 nbuckets, struct printbuf *err)
 {
 	u64 old_nbuckets;
 	int ret = 0;
@@ -2315,31 +2333,36 @@ int bch2_dev_resize(struct bch_fs *c, struct bch_dev *ca, u64 nbuckets)
 	old_nbuckets = ca->mi.nbuckets;
 
 	if (nbuckets < ca->mi.nbuckets) {
-		bch_err(ca, "Cannot shrink yet");
+		prt_printf(err, "Cannot shrink yet\n");
 		return -EINVAL;
 	}
 
 	if (nbuckets > BCH_MEMBER_NBUCKETS_MAX) {
-		bch_err(ca, "New device size too big (%llu greater than max %u)",
-			nbuckets, BCH_MEMBER_NBUCKETS_MAX);
+		prt_printf(err, "New device size too big (%llu greater than max %u)\n",
+			   nbuckets, BCH_MEMBER_NBUCKETS_MAX);
 		return bch_err_throw(c, device_size_too_big);
 	}
 
 	if (bch2_dev_is_online(ca) &&
 	    get_capacity(ca->disk_sb.bdev->bd_disk) <
 	    ca->mi.bucket_size * nbuckets) {
-		bch_err(ca, "New size larger than device");
+		prt_printf(err, "New size %llu larger than device size %llu\n",
+			   ca->mi.bucket_size * nbuckets,
+			   get_capacity(ca->disk_sb.bdev->bd_disk));
 		return bch_err_throw(c, device_size_too_small);
 	}
 
 	ret = bch2_dev_buckets_resize(c, ca, nbuckets);
-	bch_err_msg(ca, ret, "resizing buckets");
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_dev_buckets_resize() error: %s\n", bch2_err_str(ret));
 		return ret;
+	}
 
 	ret = bch2_trans_mark_dev_sb(c, ca, BTREE_TRIGGER_transactional);
-	if (ret)
+	if (ret) {
+		prt_printf(err, "bch2_trans_mark_dev_sb() error: %s\n", bch2_err_str(ret));
 		return ret;
+	}
 
 	scoped_guard(mutex, &c->sb_lock) {
 		struct bch_member *m = bch2_members_v2_get_mut(c->disk_sb.sb, ca->dev_idx);
@@ -2350,8 +2373,10 @@ int bch2_dev_resize(struct bch_fs *c, struct bch_dev *ca, u64 nbuckets)
 
 	if (ca->mi.freespace_initialized) {
 		ret = __bch2_dev_resize_alloc(ca, old_nbuckets, nbuckets);
-		if (ret)
+		if (ret) {
+			prt_printf(err, "__bch2_dev_resize_alloc() error: %s\n", bch2_err_str(ret));
 			return ret;
+		}
 	}
 
 	bch2_recalc_capacity(c);
@@ -2581,9 +2606,12 @@ struct bch_fs *bch2_fs_open(darray_const_str *devices,
 
 	scoped_guard(rwsem_write, &c->state_lock)
 		darray_for_each(sbs, sb) {
-			ret = bch2_dev_attach_bdev(c, sb);
-			if (ret)
+			CLASS(printbuf, err)();
+			ret = bch2_dev_attach_bdev(c, sb, &err);
+			if (ret) {
+				bch_err(bch2_dev_locked(c, sb->sb->dev_idx), "%s", err.buf);
 				goto err;
+			}
 		}
 
 	if (!c->opts.nostart) {
diff --git a/fs/bcachefs/super.h b/fs/bcachefs/super.h
index de2c4430b8f7..d13dbf2b8227 100644
--- a/fs/bcachefs/super.h
+++ b/fs/bcachefs/super.h
@@ -26,12 +26,11 @@ int bch2_dev_set_state(struct bch_fs *, struct bch_dev *,
 		       enum bch_member_state, int,
 		       struct printbuf *);
 
-int bch2_dev_fail(struct bch_dev *, int);
-int bch2_dev_remove(struct bch_fs *, struct bch_dev *, int);
-int bch2_dev_add(struct bch_fs *, const char *);
-int bch2_dev_online(struct bch_fs *, const char *);
-int bch2_dev_offline(struct bch_fs *, struct bch_dev *, int);
-int bch2_dev_resize(struct bch_fs *, struct bch_dev *, u64);
+int bch2_dev_remove(struct bch_fs *, struct bch_dev *, int, struct printbuf *);
+int bch2_dev_add(struct bch_fs *, const char *, struct printbuf *);
+int bch2_dev_online(struct bch_fs *, const char *, struct printbuf *);
+int bch2_dev_offline(struct bch_fs *, struct bch_dev *, int, struct printbuf *);
+int bch2_dev_resize(struct bch_fs *, struct bch_dev *, u64, struct printbuf *);
 struct bch_dev *bch2_dev_lookup(struct bch_fs *, const char *);
 
 bool bch2_fs_emergency_read_only(struct bch_fs *);
-- 
2.51.0


From e4530982feb952491d2e7333049381a03c73c154 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 18 Aug 2025 12:45:32 -0400
Subject: [PATCH 287/309] bcachefs: Add v2 ioctls that return error strings

Like BCH_IOCTL_DISK_SET_STATE_v2, implement v2 of other device ioctls
that return error messages via 'struct bch_ioctl_err_msg'.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/bcachefs_ioctl.h |  75 ++++++++++++-----
 fs/bcachefs/chardev.c        | 159 +++++++++++++++++++++++++++++++++--
 2 files changed, 204 insertions(+), 30 deletions(-)

diff --git a/fs/bcachefs/bcachefs_ioctl.h b/fs/bcachefs/bcachefs_ioctl.h
index 08fa1636dde2..5dc562f2a881 100644
--- a/fs/bcachefs/bcachefs_ioctl.h
+++ b/fs/bcachefs/bcachefs_ioctl.h
@@ -66,29 +66,35 @@ struct bch_ioctl_incremental {
 #define BCH_IOCTL_STOP		_IO(0xbc,	3)
 #endif
 
-#define BCH_IOCTL_DISK_ADD	_IOW(0xbc,	4,  struct bch_ioctl_disk)
-#define BCH_IOCTL_DISK_REMOVE	_IOW(0xbc,	5,  struct bch_ioctl_disk)
-#define BCH_IOCTL_DISK_ONLINE	_IOW(0xbc,	6,  struct bch_ioctl_disk)
-#define BCH_IOCTL_DISK_OFFLINE	_IOW(0xbc,	7,  struct bch_ioctl_disk)
-#define BCH_IOCTL_DISK_SET_STATE _IOW(0xbc,	8,  struct bch_ioctl_disk_set_state)
-#define BCH_IOCTL_DISK_SET_STATE_v2 _IOW(0xbc,	22,  struct bch_ioctl_disk_set_state_v2)
-#define BCH_IOCTL_DATA		_IOW(0xbc,	10, struct bch_ioctl_data)
-#define BCH_IOCTL_FS_USAGE	_IOWR(0xbc,	11, struct bch_ioctl_fs_usage)
-#define BCH_IOCTL_DEV_USAGE	_IOWR(0xbc,	11, struct bch_ioctl_dev_usage)
-#define BCH_IOCTL_READ_SUPER	_IOW(0xbc,	12, struct bch_ioctl_read_super)
-#define BCH_IOCTL_DISK_GET_IDX	_IOW(0xbc,	13,  struct bch_ioctl_disk_get_idx)
-#define BCH_IOCTL_DISK_RESIZE	_IOW(0xbc,	14,  struct bch_ioctl_disk_resize)
-#define BCH_IOCTL_DISK_RESIZE_JOURNAL _IOW(0xbc,15,  struct bch_ioctl_disk_resize_journal)
-
-#define BCH_IOCTL_SUBVOLUME_CREATE _IOW(0xbc,	16,  struct bch_ioctl_subvolume)
-#define BCH_IOCTL_SUBVOLUME_DESTROY _IOW(0xbc,	17,  struct bch_ioctl_subvolume)
-
-#define BCH_IOCTL_DEV_USAGE_V2	_IOWR(0xbc,	18, struct bch_ioctl_dev_usage_v2)
-
-#define BCH_IOCTL_FSCK_OFFLINE	_IOW(0xbc,	19,  struct bch_ioctl_fsck_offline)
-#define BCH_IOCTL_FSCK_ONLINE	_IOW(0xbc,	20,  struct bch_ioctl_fsck_online)
-#define BCH_IOCTL_QUERY_ACCOUNTING _IOW(0xbc,	21,  struct bch_ioctl_query_accounting)
-#define BCH_IOCTL_QUERY_COUNTERS _IOW(0xbc,	21,  struct bch_ioctl_query_counters)
+#define BCH_IOCTL_DISK_ADD		_IOW(0xbc,	4,  struct bch_ioctl_disk)
+#define BCH_IOCTL_DISK_ADD_v2		_IOW(0xbc,	23, struct bch_ioctl_disk_v2)
+#define BCH_IOCTL_DISK_REMOVE		_IOW(0xbc,	5,  struct bch_ioctl_disk)
+#define BCH_IOCTL_DISK_REMOVE_v2	_IOW(0xbc,	24, struct bch_ioctl_disk_v2)
+#define BCH_IOCTL_DISK_ONLINE		_IOW(0xbc,	6,  struct bch_ioctl_disk)
+#define BCH_IOCTL_DISK_ONLINE_v2	_IOW(0xbc,	25, struct bch_ioctl_disk_v2)
+#define BCH_IOCTL_DISK_OFFLINE		_IOW(0xbc,	7,  struct bch_ioctl_disk)
+#define BCH_IOCTL_DISK_OFFLINE_v2	_IOW(0xbc,	26, struct bch_ioctl_disk_v2)
+#define BCH_IOCTL_DISK_SET_STATE	_IOW(0xbc,	8,  struct bch_ioctl_disk_set_state)
+#define BCH_IOCTL_DISK_SET_STATE_v2	_IOW(0xbc,	22, struct bch_ioctl_disk_set_state_v2)
+#define BCH_IOCTL_DATA			_IOW(0xbc,	10, struct bch_ioctl_data)
+#define BCH_IOCTL_FS_USAGE		_IOWR(0xbc,	11, struct bch_ioctl_fs_usage)
+#define BCH_IOCTL_DEV_USAGE		_IOWR(0xbc,	11, struct bch_ioctl_dev_usage)
+#define BCH_IOCTL_READ_SUPER		_IOW(0xbc,	12, struct bch_ioctl_read_super)
+#define BCH_IOCTL_DISK_GET_IDX		_IOW(0xbc,	13, struct bch_ioctl_disk_get_idx)
+#define BCH_IOCTL_DISK_RESIZE		_IOW(0xbc,	14, struct bch_ioctl_disk_resize)
+#define BCH_IOCTL_DISK_RESIZE_v2	_IOW(0xbc,	27, struct bch_ioctl_disk_resize_v2)
+#define BCH_IOCTL_DISK_RESIZE_JOURNAL	_IOW(0xbc,	15, struct bch_ioctl_disk_resize_journal)
+#define BCH_IOCTL_DISK_RESIZE_JOURNAL_v2 _IOW(0xbc,	28, struct bch_ioctl_disk_resize_journal_v2)
+
+#define BCH_IOCTL_SUBVOLUME_CREATE	_IOW(0xbc,	16, struct bch_ioctl_subvolume)
+#define BCH_IOCTL_SUBVOLUME_DESTROY	_IOW(0xbc,	17, struct bch_ioctl_subvolume)
+
+#define BCH_IOCTL_DEV_USAGE_V2		_IOWR(0xbc,	18, struct bch_ioctl_dev_usage_v2)
+
+#define BCH_IOCTL_FSCK_OFFLINE		_IOW(0xbc,	19, struct bch_ioctl_fsck_offline)
+#define BCH_IOCTL_FSCK_ONLINE		_IOW(0xbc,	20, struct bch_ioctl_fsck_online)
+#define BCH_IOCTL_QUERY_ACCOUNTING	_IOW(0xbc,	21, struct bch_ioctl_query_accounting)
+#define BCH_IOCTL_QUERY_COUNTERS	_IOW(0xbc,	21, struct bch_ioctl_query_counters)
 
 /* ioctl below act on a particular file, not the filesystem as a whole: */
 
@@ -164,6 +170,13 @@ struct bch_ioctl_disk {
 	__u64			dev;
 };
 
+struct bch_ioctl_disk_v2 {
+	__u32				flags;
+	__u32				pad;
+	__u64				dev;
+	struct bch_ioctl_err_msg	err;
+};
+
 /*
  * BCH_IOCTL_DISK_SET_STATE: modify state of a member device of a filesystem
  *
@@ -400,6 +413,14 @@ struct bch_ioctl_disk_resize {
 	__u64			nbuckets;
 };
 
+struct bch_ioctl_disk_resize_v2 {
+	__u32				flags;
+	__u32				pad;
+	__u64				dev;
+	__u64				nbuckets;
+	struct bch_ioctl_err_msg	err;
+};
+
 /*
  * BCH_IOCTL_DISK_RESIZE_JOURNAL: resize journal on a device
  *
@@ -413,6 +434,14 @@ struct bch_ioctl_disk_resize_journal {
 	__u64			nbuckets;
 };
 
+struct bch_ioctl_disk_resize_journal_v2 {
+	__u32				flags;
+	__u32				pad;
+	__u64				dev;
+	__u64				nbuckets;
+	struct bch_ioctl_err_msg	err;
+};
+
 struct bch_ioctl_subvolume {
 	__u32			flags;
 	__u32			dirfd;
diff --git a/fs/bcachefs/chardev.c b/fs/bcachefs/chardev.c
index 2370c15e28b6..f6f90d421f27 100644
--- a/fs/bcachefs/chardev.c
+++ b/fs/bcachefs/chardev.c
@@ -187,6 +187,18 @@ static long bch2_ioctl_stop(struct bch_fs *c)
 }
 #endif
 
+static int copy_ioctl_err_msg(struct bch_ioctl_err_msg *dst, struct printbuf *src, int ret)
+{
+	if (ret) {
+		prt_printf(src, "error=%s", bch2_err_str(ret));
+		ret = copy_to_user_errcode((void __user *)(ulong)dst->msg_ptr,
+					   src->buf,
+					   min(src->pos, dst->msg_len)) ?: ret;
+	}
+
+	return ret;
+}
+
 static long bch2_ioctl_disk_add(struct bch_fs *c, struct bch_ioctl_disk arg)
 {
 	char *path;
@@ -212,6 +224,28 @@ static long bch2_ioctl_disk_add(struct bch_fs *c, struct bch_ioctl_disk arg)
 	return ret;
 }
 
+static long bch2_ioctl_disk_add_v2(struct bch_fs *c, struct bch_ioctl_disk_v2 arg)
+{
+	char *path = NULL;
+	int ret;
+
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if (arg.flags || arg.pad)
+		return -EINVAL;
+
+	path = strndup_user((const char __user *)(unsigned long) arg.dev, PATH_MAX);
+	ret = PTR_ERR_OR_ZERO(path);
+	if (ret)
+		return ret;
+
+	CLASS(printbuf, err)();
+	ret = bch2_dev_add(c, path, &err);
+	kfree(path);
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
+}
+
 static long bch2_ioctl_disk_remove(struct bch_fs *c, struct bch_ioctl_disk arg)
 {
 	if (!capable(CAP_SYS_ADMIN))
@@ -235,6 +269,27 @@ static long bch2_ioctl_disk_remove(struct bch_fs *c, struct bch_ioctl_disk arg)
 	return ret;
 }
 
+static long bch2_ioctl_disk_remove_v2(struct bch_fs *c, struct bch_ioctl_disk_v2 arg)
+{
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if ((arg.flags & ~(BCH_FORCE_IF_DATA_LOST|
+			   BCH_FORCE_IF_METADATA_LOST|
+			   BCH_FORCE_IF_DEGRADED|
+			   BCH_BY_INDEX)) ||
+	    arg.pad)
+		return -EINVAL;
+
+	struct bch_dev *ca = bch2_device_lookup(c, arg.dev, arg.flags);
+	if (IS_ERR(ca))
+		return PTR_ERR(ca);
+
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_remove(c, ca, arg.flags, &err);
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
+}
+
 static long bch2_ioctl_disk_online(struct bch_fs *c, struct bch_ioctl_disk arg)
 {
 	char *path;
@@ -259,6 +314,28 @@ static long bch2_ioctl_disk_online(struct bch_fs *c, struct bch_ioctl_disk arg)
 	return ret;
 }
 
+static long bch2_ioctl_disk_online_v2(struct bch_fs *c, struct bch_ioctl_disk_v2 arg)
+{
+	char *path;
+	int ret;
+
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if (arg.flags || arg.pad)
+		return -EINVAL;
+
+	path = strndup_user((const char __user *)(unsigned long) arg.dev, PATH_MAX);
+	ret = PTR_ERR_OR_ZERO(path);
+	if (ret)
+		return ret;
+
+	CLASS(printbuf, err)();
+	ret = bch2_dev_online(c, path, &err);
+	kfree(path);
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
+}
+
 static long bch2_ioctl_disk_offline(struct bch_fs *c, struct bch_ioctl_disk arg)
 {
 	if (!capable(CAP_SYS_ADMIN))
@@ -282,6 +359,27 @@ static long bch2_ioctl_disk_offline(struct bch_fs *c, struct bch_ioctl_disk arg)
 	return ret;
 }
 
+static long bch2_ioctl_disk_offline_v2(struct bch_fs *c, struct bch_ioctl_disk_v2 arg)
+{
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if ((arg.flags & ~(BCH_FORCE_IF_DATA_LOST|
+			   BCH_FORCE_IF_METADATA_LOST|
+			   BCH_FORCE_IF_DEGRADED|
+			   BCH_BY_INDEX)) ||
+	    arg.pad)
+		return -EINVAL;
+
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
+	if (IS_ERR(ca))
+		return PTR_ERR(ca);
+
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_offline(c, ca, arg.flags, &err);
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
+}
+
 static long bch2_ioctl_disk_set_state(struct bch_fs *c,
 			struct bch_ioctl_disk_set_state arg)
 {
@@ -331,13 +429,7 @@ static long bch2_ioctl_disk_set_state_v2(struct bch_fs *c,
 
 	ret = bch2_dev_set_state(c, ca, arg.new_state, arg.flags, &err);
 err:
-	if (ret) {
-		prt_printf(&err, "error=%s", bch2_err_str(ret));
-		ret = copy_to_user_errcode((void __user *)(ulong)arg.err.msg_ptr,
-					   err.buf,
-					   min(err.pos, arg.err.msg_len)) ?: ret;
-	}
-	return ret;
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
 }
 
 struct bch_data_ctx {
@@ -675,6 +767,25 @@ static long bch2_ioctl_disk_resize(struct bch_fs *c,
 	return ret;
 }
 
+static long bch2_ioctl_disk_resize_v2(struct bch_fs *c,
+				      struct bch_ioctl_disk_resize_v2 arg)
+{
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if ((arg.flags & ~BCH_BY_INDEX) ||
+	    arg.pad)
+		return -EINVAL;
+
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
+	if (IS_ERR(ca))
+		return PTR_ERR(ca);
+
+	CLASS(printbuf, err)();
+	int ret = bch2_dev_resize(c, ca, arg.nbuckets, &err);
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
+}
+
 static long bch2_ioctl_disk_resize_journal(struct bch_fs *c,
 				   struct bch_ioctl_disk_resize_journal arg)
 {
@@ -695,6 +806,28 @@ static long bch2_ioctl_disk_resize_journal(struct bch_fs *c,
 	return bch2_set_nr_journal_buckets(c, ca, arg.nbuckets);
 }
 
+static long bch2_ioctl_disk_resize_journal_v2(struct bch_fs *c,
+				   struct bch_ioctl_disk_resize_journal_v2 arg)
+{
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if ((arg.flags & ~BCH_BY_INDEX) ||
+	    arg.pad)
+		return -EINVAL;
+
+	if (arg.nbuckets > U32_MAX)
+		return -EINVAL;
+
+	CLASS(bch2_device_lookup, ca)(c, arg.dev, arg.flags);
+	if (IS_ERR(ca))
+		return PTR_ERR(ca);
+
+	CLASS(printbuf, err)();
+	int ret = bch2_set_nr_journal_buckets(c, ca, arg.nbuckets);
+	return copy_ioctl_err_msg(&arg.err, &err, ret);
+}
+
 #define BCH_IOCTL(_name, _argtype)					\
 do {									\
 	_argtype i;							\
@@ -736,12 +869,20 @@ long bch2_fs_ioctl(struct bch_fs *c, unsigned cmd, void __user *arg)
 	switch (cmd) {
 	case BCH_IOCTL_DISK_ADD:
 		BCH_IOCTL(disk_add, struct bch_ioctl_disk);
+	case BCH_IOCTL_DISK_ADD_v2:
+		BCH_IOCTL(disk_add_v2, struct bch_ioctl_disk_v2);
 	case BCH_IOCTL_DISK_REMOVE:
 		BCH_IOCTL(disk_remove, struct bch_ioctl_disk);
+	case BCH_IOCTL_DISK_REMOVE_v2:
+		BCH_IOCTL(disk_remove_v2, struct bch_ioctl_disk_v2);
 	case BCH_IOCTL_DISK_ONLINE:
 		BCH_IOCTL(disk_online, struct bch_ioctl_disk);
+	case BCH_IOCTL_DISK_ONLINE_v2:
+		BCH_IOCTL(disk_online_v2, struct bch_ioctl_disk_v2);
 	case BCH_IOCTL_DISK_OFFLINE:
 		BCH_IOCTL(disk_offline, struct bch_ioctl_disk);
+	case BCH_IOCTL_DISK_OFFLINE_v2:
+		BCH_IOCTL(disk_offline_v2, struct bch_ioctl_disk_v2);
 	case BCH_IOCTL_DISK_SET_STATE:
 		BCH_IOCTL(disk_set_state, struct bch_ioctl_disk_set_state);
 	case BCH_IOCTL_DISK_SET_STATE_v2:
@@ -750,8 +891,12 @@ long bch2_fs_ioctl(struct bch_fs *c, unsigned cmd, void __user *arg)
 		BCH_IOCTL(data, struct bch_ioctl_data);
 	case BCH_IOCTL_DISK_RESIZE:
 		BCH_IOCTL(disk_resize, struct bch_ioctl_disk_resize);
+	case BCH_IOCTL_DISK_RESIZE_v2:
+		BCH_IOCTL(disk_resize_v2, struct bch_ioctl_disk_resize_v2);
 	case BCH_IOCTL_DISK_RESIZE_JOURNAL:
 		BCH_IOCTL(disk_resize_journal, struct bch_ioctl_disk_resize_journal);
+	case BCH_IOCTL_DISK_RESIZE_JOURNAL_v2:
+		BCH_IOCTL(disk_resize_journal_v2, struct bch_ioctl_disk_resize_journal_v2);
 	case BCH_IOCTL_FSCK_ONLINE:
 		BCH_IOCTL(fsck_online, struct bch_ioctl_fsck_online);
 	case BCH_IOCTL_QUERY_ACCOUNTING:
-- 
2.51.0


From 8e9bd2a6953eeaa00d79ed675f87faed2db69400 Mon Sep 17 00:00:00 2001
From: Christoph Hellwig <hch@lst.de>
Date: Mon, 18 Aug 2025 08:10:09 +0200
Subject: [PATCH 288/309] bcachefs: stop using write_cache_pages

Stop using the obsolete write_cache_pages and use writeback_iter
directly.  This basically just open codes write_cache_pages
without the indirect call, but there's probably ways to structure
the code even nicer as a follow on.

Signed-off-by: Christoph Hellwig <hch@lst.de>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/fs-io-buffered.c | 13 ++++++++++++-
 1 file changed, 12 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/fs-io-buffered.c b/fs/bcachefs/fs-io-buffered.c
index fd8beb5167ee..9532f1a73053 100644
--- a/fs/bcachefs/fs-io-buffered.c
+++ b/fs/bcachefs/fs-io-buffered.c
@@ -667,6 +667,17 @@ static int __bch2_writepage(struct folio *folio,
 	return 0;
 }
 
+static int bch2_write_cache_pages(struct address_space *mapping,
+		      struct writeback_control *wbc, void *data)
+{
+	struct folio *folio = NULL;
+	int error;
+
+	while ((folio = writeback_iter(mapping, wbc, folio, &error)))
+		error = __bch2_writepage(folio, wbc, data);
+	return error;
+}
+
 int bch2_writepages(struct address_space *mapping, struct writeback_control *wbc)
 {
 	struct bch_fs *c = mapping->host->i_sb->s_fs_info;
@@ -675,7 +686,7 @@ int bch2_writepages(struct address_space *mapping, struct writeback_control *wbc
 	bch2_inode_opts_get(&w->opts, c, &to_bch_ei(mapping->host)->ei_inode);
 
 	blk_start_plug(&w->plug);
-	int ret = write_cache_pages(mapping, wbc, __bch2_writepage, w);
+	int ret = bch2_write_cache_pages(mapping, wbc, w);
 	if (w->io)
 		bch2_writepage_do_io(w);
 	blk_finish_plug(&w->plug);
-- 
2.51.0


From 338ce95363138ecb1f15809aef0a912fd2e39d95 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 18 Aug 2025 18:27:29 -0400
Subject: [PATCH 289/309] bcachefs: Add missing BCH_COUNTER_rebalance_extent

Tracepoints should generally have corresponding counters, and vice
versa.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/rebalance.c          | 1 +
 fs/bcachefs/sb-counters_format.h | 1 +
 2 files changed, 2 insertions(+)

diff --git a/fs/bcachefs/rebalance.c b/fs/bcachefs/rebalance.c
index e1db63d75a99..d1e064be1b9f 100644
--- a/fs/bcachefs/rebalance.c
+++ b/fs/bcachefs/rebalance.c
@@ -421,6 +421,7 @@ static struct bkey_s_c next_rebalance_extent(struct btree_trans *trans,
 
 		trace_rebalance_extent(c, buf.buf);
 	}
+	count_event(c, rebalance_extent);
 
 	return k;
 }
diff --git a/fs/bcachefs/sb-counters_format.h b/fs/bcachefs/sb-counters_format.h
index 96ad64920810..f65fe61b3432 100644
--- a/fs/bcachefs/sb-counters_format.h
+++ b/fs/bcachefs/sb-counters_format.h
@@ -35,6 +35,7 @@ enum counters_flags {
 	x(io_move_noop,					92,	TYPE_COUNTER)	\
 	x(io_move_created_rebalance,			83,	TYPE_COUNTER)	\
 	x(io_move_evacuate_bucket,			84,	TYPE_COUNTER)	\
+	x(rebalance_extent,				96,	TYPE_COUNTER)	\
 	x(bucket_invalidate,				3,	TYPE_COUNTER)	\
 	x(bucket_discard,				4,	TYPE_COUNTER)	\
 	x(bucket_discard_fast,				79,	TYPE_COUNTER)	\
-- 
2.51.0


From c544816b018aa15b986d22b31c97db8c0fa156a7 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 18 Aug 2025 18:35:41 -0400
Subject: [PATCH 290/309] bcachefs: improve trace_data_update_done_no_rw_devs

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/data_update.c | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

diff --git a/fs/bcachefs/data_update.c b/fs/bcachefs/data_update.c
index a314d70c6b8e..2c997fddefb3 100644
--- a/fs/bcachefs/data_update.c
+++ b/fs/bcachefs/data_update.c
@@ -812,10 +812,14 @@ static int can_write_extent(struct bch_fs *c, struct data_update *m)
 			break;
 	}
 
-	if (!nr_replicas) {
+	if (nr_replicas < m->op.nr_replicas) {
+		prt_printf(&buf, "\nnr_replicas %u < %u", nr_replicas, m->op.nr_replicas);
 		trace_data_update_done_no_rw_devs(c, buf.buf);
-		return bch_err_throw(c, data_update_done_no_rw_devs);
 	}
+
+	if (!nr_replicas)
+		return bch_err_throw(c, data_update_done_no_rw_devs);
+
 	if (nr_replicas < m->op.nr_replicas)
 		return bch_err_throw(c, insufficient_devices);
 	return 0;
-- 
2.51.0


From dc5f8b16c0e65d8ea77c422dda9c437395a8dc83 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 19 Aug 2025 13:21:20 -0400
Subject: [PATCH 291/309] bcachefs: Run check_snapshots before going RW

Snapshots have to be consistent before starting copygc or doing data
move operations, since fragmenting extents requires maintaining the same
visibility in descendent snapshots - so we have to be able to walk
snapshot trees.

It's possible to deadlock on free space if we have to run journal replay
without copygc running, as a user just discovered.

Closes: https://github.com/koverstreet/bcachefs/issues/938
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/recovery_passes_format.h | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/recovery_passes_format.h b/fs/bcachefs/recovery_passes_format.h
index 2696eee00345..05f1c09955b4 100644
--- a/fs/bcachefs/recovery_passes_format.h
+++ b/fs/bcachefs/recovery_passes_format.h
@@ -32,6 +32,9 @@
 	x(check_allocations,			 5, PASS_FSCK_ALLOC)			\
 	x(trans_mark_dev_sbs,			 6, PASS_ALWAYS|PASS_SILENT|PASS_ALLOC)	\
 	x(fs_journal_alloc,			 7, PASS_ALWAYS|PASS_SILENT|PASS_ALLOC)	\
+	x(reconstruct_snapshots,		38, 0)					\
+	x(check_snapshot_trees,			18, PASS_ONLINE|PASS_FSCK)		\
+	x(check_snapshots,			19, PASS_ONLINE|PASS_FSCK)		\
 	x(set_may_go_rw,			 8, PASS_ALWAYS|PASS_SILENT)		\
 	x(journal_replay,			 9, PASS_ALWAYS)			\
 	x(check_alloc_info,			10, PASS_ONLINE|PASS_FSCK_ALLOC)	\
@@ -42,9 +45,6 @@
 	x(check_alloc_to_lru_refs,		15, PASS_ONLINE|PASS_FSCK_ALLOC)	\
 	x(fs_freespace_init,			16, PASS_ALWAYS|PASS_SILENT)		\
 	x(bucket_gens_init,			17, 0)					\
-	x(reconstruct_snapshots,		38, 0)					\
-	x(check_snapshot_trees,			18, PASS_ONLINE|PASS_FSCK)		\
-	x(check_snapshots,			19, PASS_ONLINE|PASS_FSCK)		\
 	x(check_subvols,			20, PASS_ONLINE|PASS_FSCK)		\
 	x(check_subvol_children,		35, PASS_ONLINE|PASS_FSCK)		\
 	x(delete_dead_snapshots,		21, PASS_ONLINE|PASS_FSCK)		\
-- 
2.51.0


From 4137703af81b56b842fd1cf8f8ad77826164f4d3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 19 Aug 2025 16:01:11 -0400
Subject: [PATCH 292/309] bcachefs: Check for accounting underflow at mount
 time

We've had a bug report where accounting is clearly screwed up, and
counters have underflowed: we can repair this automatically, we just
need to check for it.

Link: https://github.com/koverstreet/bcachefs/issues/938
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/disk_accounting.c  | 35 ++++++++++++++++++++++++++++++++++
 fs/bcachefs/sb-errors_format.h |  3 ++-
 2 files changed, 37 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/disk_accounting.c b/fs/bcachefs/disk_accounting.c
index 809c76b68ba8..5863b5a30b61 100644
--- a/fs/bcachefs/disk_accounting.c
+++ b/fs/bcachefs/disk_accounting.c
@@ -11,6 +11,7 @@
 #include "disk_accounting.h"
 #include "error.h"
 #include "journal_io.h"
+#include "recovery_passes.h"
 #include "replicas.h"
 
 /*
@@ -910,6 +911,40 @@ int bch2_accounting_read(struct bch_fs *c)
 			u64 v[BCH_ACCOUNTING_MAX_COUNTERS];
 			bch2_accounting_mem_read_counters(acc, i, v, ARRAY_SIZE(v), false);
 
+			/*
+			 * Check for underflow, schedule check_allocations
+			 * necessary:
+			 *
+			 * XXX - see if we can factor this out to run on a bkey
+			 * so we can check everything lazily, right now we don't
+			 * check the non in-mem counters at all
+			 */
+			bool underflow = false;
+			for (unsigned j = 0; j < acc->k.data[i].nr_counters; j++)
+				underflow |= (s64) v[j] < 0;
+
+			if (underflow) {
+				CLASS(printbuf, buf)();
+				bch2_log_msg_start(c, &buf);
+
+				prt_printf(&buf, "Accounting underflow for\n");
+				bch2_accounting_key_to_text(&buf, &k);
+
+				for (unsigned j = 0; j < acc->k.data[i].nr_counters; j++)
+					prt_printf(&buf, " %lli", v[j]);
+
+				bool print = bch2_count_fsck_err(c, accounting_key_underflow, &buf);
+				unsigned pos = buf.pos;
+				ret = bch2_run_explicit_recovery_pass(c, &buf,
+						BCH_RECOVERY_PASS_check_allocations, 0);
+				print |= buf.pos != pos;
+
+				if (print)
+					bch2_print_str(c, KERN_ERR, buf.buf);
+				if (ret)
+					return ret;
+			}
+
 			switch (k.type) {
 			case BCH_DISK_ACCOUNTING_persistent_reserved:
 				usage->reserved += v[0] * k.persistent_reserved.nr_replicas;
diff --git a/fs/bcachefs/sb-errors_format.h b/fs/bcachefs/sb-errors_format.h
index 5317b1bfe2e5..aa0ea1ec9f10 100644
--- a/fs/bcachefs/sb-errors_format.h
+++ b/fs/bcachefs/sb-errors_format.h
@@ -328,6 +328,7 @@ enum bch_fsck_flags {
 	x(accounting_key_replicas_devs_unsorted,		280,	FSCK_AUTOFIX)	\
 	x(accounting_key_version_0,				282,	FSCK_AUTOFIX)	\
 	x(accounting_key_nr_counters_wrong,			307,	FSCK_AUTOFIX)	\
+	x(accounting_key_underflow,				325,	FSCK_AUTOFIX)	\
 	x(logged_op_but_clean,					283,	FSCK_AUTOFIX)	\
 	x(compression_opt_not_marked_in_sb,			295,	FSCK_AUTOFIX)	\
 	x(compression_type_not_marked_in_sb,			296,	FSCK_AUTOFIX)	\
@@ -336,7 +337,7 @@ enum bch_fsck_flags {
 	x(dirent_stray_data_after_cf_name,			305,	0)		\
 	x(rebalance_work_incorrectly_set,			309,	FSCK_AUTOFIX)	\
 	x(rebalance_work_incorrectly_unset,			310,	FSCK_AUTOFIX)	\
-	x(MAX,							325,	0)
+	x(MAX,							326,	0)
 
 enum bch_sb_error_id {
 #define x(t, n, ...) BCH_FSCK_ERR_##t = n,
-- 
2.51.0


From c317ce1ac0d1a3f59f5c6c695051f8ce30f973f6 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 19 Aug 2025 16:37:40 -0400
Subject: [PATCH 293/309] bcachefs: Allocate btree_trans bump allocator with
 GFP_NOWARN
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This is mempool backed later; we don't need to warn on allocation
failure.

Reported-by: Marcin Mirosaw <marcin@mejor.pl>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_iter.c | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/btree_iter.c b/fs/bcachefs/btree_iter.c
index 76f430f93dc1..99d6866b33d0 100644
--- a/fs/bcachefs/btree_iter.c
+++ b/fs/bcachefs/btree_iter.c
@@ -3271,9 +3271,10 @@ void *__bch2_trans_kmalloc(struct btree_trans *trans, size_t size, unsigned long
 	EBUG_ON(trans->mem_bytes);
 	EBUG_ON(trans->mem_top);
 	EBUG_ON(new_bytes > BTREE_TRANS_MEM_MAX);
-	
+
 	bool lock_dropped = false;
-	new_mem = allocate_dropping_locks_norelock(trans, lock_dropped, kmalloc(new_bytes, _gfp));
+	new_mem = allocate_dropping_locks_norelock(trans, lock_dropped,
+					kmalloc(new_bytes, _gfp|__GFP_NOWARN));
 	if (!new_mem) {
 		new_mem = mempool_alloc(&c->btree_trans_mem_pool, GFP_KERNEL);
 		new_bytes = BTREE_TRANS_MEM_MAX;
@@ -3525,7 +3526,7 @@ struct btree_trans *__bch2_trans_get(struct bch_fs *c, unsigned fn_idx)
 		if (s->max_mem) {
 			unsigned expected_mem_bytes = roundup_pow_of_two(s->max_mem);
 
-			trans->mem = kmalloc(expected_mem_bytes, GFP_KERNEL);
+			trans->mem = kmalloc(expected_mem_bytes, GFP_KERNEL|__GFP_NOWARN);
 			if (likely(trans->mem))
 				trans->mem_bytes = expected_mem_bytes;
 		}
-- 
2.51.0


From fe726eb6af0400006aae30af44c6e206918956fd Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 19 Aug 2025 10:54:52 -0400
Subject: [PATCH 294/309] fixup! bcachefs: bch2_fs_opt_version_init()

---
 fs/bcachefs/super.c | 14 +++++++++-----
 1 file changed, 9 insertions(+), 5 deletions(-)

diff --git a/fs/bcachefs/super.c b/fs/bcachefs/super.c
index cc9d00e1afd5..6df782024052 100644
--- a/fs/bcachefs/super.c
+++ b/fs/bcachefs/super.c
@@ -988,11 +988,7 @@ static int bch2_fs_opt_version_init(struct bch_fs *c)
 		}
 	}
 
-	if (c->cf_encoding)
-		prt_printf(&p, "\nUsing encoding defined by superblock: utf8-%u.%u.%u",
-			   unicode_major(BCH_FS_DEFAULT_UTF8_ENCODING),
-			   unicode_minor(BCH_FS_DEFAULT_UTF8_ENCODING),
-			   unicode_rev(BCH_FS_DEFAULT_UTF8_ENCODING));
+	/* cf_encoding log message should be here, but it breaks xfstests - sigh */
 
 	if (c->opts.journal_rewind)
 		prt_printf(&p, "\nrewinding journal, fsck required");
@@ -1060,6 +1056,14 @@ static int bch2_fs_opt_version_init(struct bch_fs *c)
 
 	bch2_print_str(c, KERN_INFO, p.buf);
 
+	/* this really should be part of our one multi line mount message, but -
+	 * xfstests... */
+	if (c->cf_encoding)
+		bch_info(c, "Using encoding defined by superblock: utf8-%u.%u.%u",
+			   unicode_major(BCH_FS_DEFAULT_UTF8_ENCODING),
+			   unicode_minor(BCH_FS_DEFAULT_UTF8_ENCODING),
+			   unicode_rev(BCH_FS_DEFAULT_UTF8_ENCODING));
+
 	if (BCH_SB_INITIALIZED(c->disk_sb.sb)) {
 		if (!(c->sb.features & (1ULL << BCH_FEATURE_new_extent_overwrite))) {
 			bch_err(c, "feature new_extent_overwrite not set, filesystem no longer supported");
-- 
2.51.0


From 52f206a728b3e57539f145dd5b7608648663a88e Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 19 Aug 2025 11:04:55 -0400
Subject: [PATCH 295/309] bcachefs: journal_entry_add() refactoring

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/journal_io.c | 14 ++++++--------
 1 file changed, 6 insertions(+), 8 deletions(-)

diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index 6e8a89a0f244..af0e614dbaeb 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -152,6 +152,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 	struct journal_replay **_i, *i, *dup;
 	size_t bytes = vstruct_bytes(j);
 	u64 last_seq = !JSET_NO_FLUSH(j) ? le64_to_cpu(j->last_seq) : 0;
+	u64 seq = le64_to_cpu(j->seq);
 	CLASS(printbuf, buf)();
 	int ret = JOURNAL_ENTRY_ADD_OK;
 
@@ -159,12 +160,11 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 		last_seq = min(last_seq, c->opts.journal_rewind);
 
 	if (!c->journal.oldest_seq_found_ondisk ||
-	    le64_to_cpu(j->seq) < c->journal.oldest_seq_found_ondisk)
-		c->journal.oldest_seq_found_ondisk = le64_to_cpu(j->seq);
+	    seq < c->journal.oldest_seq_found_ondisk)
+		c->journal.oldest_seq_found_ondisk = seq;
 
 	/* Is this entry older than the range we need? */
-	if (!c->opts.read_entire_journal &&
-	    le64_to_cpu(j->seq) < jlist->last_seq)
+	if (!c->opts.read_entire_journal && seq < jlist->last_seq)
 		return JOURNAL_ENTRY_ADD_OUT_OF_RANGE;
 
 	/*
@@ -173,7 +173,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 	 * within the range of +-2billion of the filrst one we find.
 	 */
 	if (!c->journal_entries_base_seq)
-		c->journal_entries_base_seq = max_t(s64, 1, le64_to_cpu(j->seq) - S32_MAX);
+		c->journal_entries_base_seq = max_t(s64, 1, seq - S32_MAX);
 
 	/* Drop entries we don't need anymore */
 	if (last_seq > jlist->last_seq && !c->opts.read_entire_journal) {
@@ -193,9 +193,7 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 
 	jlist->last_seq = max(jlist->last_seq, last_seq);
 
-	_i = genradix_ptr_alloc(&c->journal_entries,
-				journal_entry_radix_idx(c, le64_to_cpu(j->seq)),
-				GFP_KERNEL);
+	_i = genradix_ptr_alloc(&c->journal_entries, journal_entry_radix_idx(c, seq), GFP_KERNEL);
 	if (!_i)
 		return bch_err_throw(c, ENOMEM_journal_entry_add);
 
-- 
2.51.0


From efc5e0fd59ee60f56cd18549ac49dfd6acab9829 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Tue, 19 Aug 2025 11:09:53 -0400
Subject: [PATCH 296/309] bcachefs: fix journal_entry_radix_idx()

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_journal_iter.h | 2 +-
 fs/bcachefs/journal_io.c         | 6 ++++++
 2 files changed, 7 insertions(+), 1 deletion(-)

diff --git a/fs/bcachefs/btree_journal_iter.h b/fs/bcachefs/btree_journal_iter.h
index 8dc8e778be6c..85d6969fa9b1 100644
--- a/fs/bcachefs/btree_journal_iter.h
+++ b/fs/bcachefs/btree_journal_iter.h
@@ -31,7 +31,7 @@ struct btree_and_journal_iter {
 
 static inline u32 journal_entry_radix_idx(struct bch_fs *c, u64 seq)
 {
-	return (seq - c->journal_entries_base_seq) & (~0U >> 1);
+	return seq - c->journal_entries_base_seq;
 }
 
 static inline struct bkey_i *journal_key_k(struct bch_fs *c,
diff --git a/fs/bcachefs/journal_io.c b/fs/bcachefs/journal_io.c
index af0e614dbaeb..f33b2c2d13c0 100644
--- a/fs/bcachefs/journal_io.c
+++ b/fs/bcachefs/journal_io.c
@@ -193,6 +193,12 @@ static int journal_entry_add(struct bch_fs *c, struct bch_dev *ca,
 
 	jlist->last_seq = max(jlist->last_seq, last_seq);
 
+	if (seq <  c->journal_entries_base_seq ||
+	    seq >= c->journal_entries_base_seq + U32_MAX) {
+		bch_err(c, "journal entry sequence numbers span too large a range: cannot reply, contact developers");
+		return bch_err_throw(c, ENOMEM_journal_entry_add);
+	}
+
 	_i = genradix_ptr_alloc(&c->journal_entries, journal_entry_radix_idx(c, seq), GFP_KERNEL);
 	if (!_i)
 		return bch_err_throw(c, ENOMEM_journal_entry_add);
-- 
2.51.0


From 22575715f9f94fe3f4539ee8842b9909affa34b4 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 11 Jun 2025 15:09:30 -0400
Subject: [PATCH 297/309] dm-flakey: Fix corrupt_bio_byte setup checks

Fix the error_reads mode - it's incompatible with corrupt_bio_byte, but
that's only enabled if corrupt_bio_byte is nonzero.

Cc: Benjamin Marzinski <bmarzins@redhat.com>
Cc: Mikulas Patocka <mpatocka@redhat.com>
Cc: Mike Snitzer <snitzer@kernel.org>
Cc: dm-devel@lists.linux.dev
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 drivers/md/dm-flakey.c | 9 ++++++---
 1 file changed, 6 insertions(+), 3 deletions(-)

diff --git a/drivers/md/dm-flakey.c b/drivers/md/dm-flakey.c
index c711db6f8f5c..cf17fd46e255 100644
--- a/drivers/md/dm-flakey.c
+++ b/drivers/md/dm-flakey.c
@@ -215,16 +215,19 @@ static int parse_features(struct dm_arg_set *as, struct flakey_c *fc,
 	}
 
 	if (test_bit(DROP_WRITES, &fc->flags) &&
-	    (fc->corrupt_bio_rw == WRITE || fc->random_write_corrupt)) {
+	    ((fc->corrupt_bio_byte && fc->corrupt_bio_rw == WRITE) ||
+	     fc->random_write_corrupt)) {
 		ti->error = "drop_writes is incompatible with random_write_corrupt or corrupt_bio_byte with the WRITE flag set";
 		return -EINVAL;
 
 	} else if (test_bit(ERROR_WRITES, &fc->flags) &&
-		   (fc->corrupt_bio_rw == WRITE || fc->random_write_corrupt)) {
+		   ((fc->corrupt_bio_byte && fc->corrupt_bio_rw == WRITE) ||
+		    fc->random_write_corrupt)) {
 		ti->error = "error_writes is incompatible with random_write_corrupt or corrupt_bio_byte with the WRITE flag set";
 		return -EINVAL;
 	} else if (test_bit(ERROR_READS, &fc->flags) &&
-		   (fc->corrupt_bio_rw == READ || fc->random_read_corrupt)) {
+		   ((fc->corrupt_bio_byte && fc->corrupt_bio_rw == READ) ||
+		    fc->random_read_corrupt)) {
 		ti->error = "error_reads is incompatible with random_read_corrupt or corrupt_bio_byte with the READ flag set";
 		return -EINVAL;
 	}
-- 
2.51.0


From 95f98c980aa393407ca1e1369837919fd9abcd5c Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 6 Feb 2023 20:05:36 -0500
Subject: [PATCH 298/309] seq_buf: seq_buf_human_readable_u64()

This adds a seq_buf wrapper for string_get_size().

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 include/linux/seq_buf.h |  4 ++++
 lib/seq_buf.c           | 10 ++++++++++
 2 files changed, 14 insertions(+)

diff --git a/include/linux/seq_buf.h b/include/linux/seq_buf.h
index 52791e070506..c055243ec206 100644
--- a/include/linux/seq_buf.h
+++ b/include/linux/seq_buf.h
@@ -173,4 +173,8 @@ int seq_buf_bprintf(struct seq_buf *s, const char *fmt, const u32 *binary);
 
 void seq_buf_do_printk(struct seq_buf *s, const char *lvl);
 
+enum string_size_units;
+void seq_buf_human_readable_u64(struct seq_buf *s, u64 v,
+				const enum string_size_units units);
+
 #endif /* _LINUX_SEQ_BUF_H */
diff --git a/lib/seq_buf.c b/lib/seq_buf.c
index f3f3436d60a9..3c41ca83a0c3 100644
--- a/lib/seq_buf.c
+++ b/lib/seq_buf.c
@@ -436,3 +436,13 @@ int seq_buf_hex_dump(struct seq_buf *s, const char *prefix_str, int prefix_type,
 	}
 	return 0;
 }
+
+void seq_buf_human_readable_u64(struct seq_buf *s, u64 v, const enum string_size_units units)
+{
+	char *buf;
+	size_t size = seq_buf_get_buf(s, &buf);
+	int wrote = string_get_size(v, 1, units, buf, size);
+
+	seq_buf_commit(s, wrote);
+}
+EXPORT_SYMBOL(seq_buf_human_readable_u64);
-- 
2.51.0


From ccf6bc42cecad19bc2a0ee598ce24d502bf28758 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 22 Nov 2023 18:15:33 -0500
Subject: [PATCH 299/309] mm: shrinker: Add a .to_text() method for shrinkers

This adds a new callback method to shrinkers which they can use to
describe anything relevant to memory reclaim about their internal state,
for example object dirtyness.

This patch also adds shrinkers_to_text(), which reports on the top 10
shrinkers - by object count - in sorted order, to be used in OOM
reporting.

Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Qi Zheng <zhengqi.arch@bytedance.com>
Cc: Roman Gushchin <roman.gushchin@linux.dev>
Cc: linux-mm@kvack.org
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>

From david@fromorbit.com Tue Aug 27 23:32:26 2024
> > +	if (!mutex_trylock(&shrinker_mutex)) {
> > +		seq_buf_puts(out, "(couldn't take shrinker lock)");
> > +		return;
> > +	}
>
> Please don't use the shrinker_mutex like this. There can be tens of
> thousands of entries in the shrinker list (because memcgs) and
> holding the shrinker_mutex for long running traversals like this is
> known to cause latency problems for memcg reaping. If we are at
> ENOMEM, the last thing we want to be doing is preventing memcgs from
> being reaped.
>
> > +	list_for_each_entry(shrinker, &shrinker_list, list) {
> > +		struct shrink_control sc = { .gfp_mask = GFP_KERNEL, };
>
> This iteration and counting setup is neither node or memcg aware.
> For node aware shrinkers, this will only count the items freeable
> on node 0, and ignore all the other memory in the system. For memcg
> systems, it will also only scan the root memcg and so miss counting
> any memory in memcg owned caches.
>
> IOWs, the shrinker iteration mechanism needs to iterate both by NUMA
> node and by memcg. On large machines with multiple nodes and hosting
> thousands of memcgs, a total shrinker state iteration is has to walk
> a -lot- of structures.
>
> And example of this is drop_slab() - called from
> /proc/sys/vm/drop_caches(). It does this to iterate all the
> shrinkers for all the nodes and memcgs in the system:
>
> static unsigned long drop_slab_node(int nid)
> {
>         unsigned long freed = 0;
>         struct mem_cgroup *memcg = NULL;
>
>         memcg = mem_cgroup_iter(NULL, NULL, NULL);
>         do {
>                 freed += shrink_slab(GFP_KERNEL, nid, memcg, 0);
>         } while ((memcg = mem_cgroup_iter(NULL, memcg, NULL)) != NULL);
>
>         return freed;
> }
>
> void drop_slab(void)
> {
>         int nid;
>         int shift = 0;
>         unsigned long freed;
>
>         do {
>                 freed = 0;
>                 for_each_online_node(nid) {
>                         if (fatal_signal_pending(current))
>                                 return;
>
>                         freed += drop_slab_node(nid);
>                 }
>         } while ((freed >> shift++) > 1);
> }
>
> Hence any iteration for finding the 10 largest shrinkable caches in
> the system needs to do something similar. Only, it needs to iterate
> memcgs first and then aggregate object counts across all nodes for
> shrinkers that are NUMA aware.
>
> Because it needs direct access to the shrinkers, it will need to use
> the RCU lock + refcount method of traversal because that's the only
> safe way to go from memcg to shrinker instance. IOWs, it
> needs to mirror the code in shrink_slab/shrink_slab_memcg to obtain
> a safe reference to the relevant shrinker so it can call
> ->count_objects() and store a refcounted pointer to the shrinker(s)
> that will get printed out after the scan is done....
>
> Once the shrinker iteration is sorted out, I'll look further at the
> rest of the code in this patch...
>
> -Dave.
---
 include/linux/shrinker.h |  7 +++-
 mm/shrinker.c            | 78 +++++++++++++++++++++++++++++++++++++++-
 2 files changed, 83 insertions(+), 2 deletions(-)

diff --git a/include/linux/shrinker.h b/include/linux/shrinker.h
index 1a00be90d93a..6193612617a1 100644
--- a/include/linux/shrinker.h
+++ b/include/linux/shrinker.h
@@ -24,6 +24,8 @@ struct shrinker_info {
 	struct shrinker_info_unit *unit[];
 };
 
+struct seq_buf;
+
 /*
  * This struct is used to pass information from page reclaim to the shrinkers.
  * We consolidate the values for easier extension later.
@@ -80,10 +82,12 @@ struct shrink_control {
  * @flags determine the shrinker abilities, like numa awareness
  */
 struct shrinker {
+	const char *name;
 	unsigned long (*count_objects)(struct shrinker *,
 				       struct shrink_control *sc);
 	unsigned long (*scan_objects)(struct shrinker *,
 				      struct shrink_control *sc);
+	void (*to_text)(struct seq_buf *, struct shrinker *);
 
 	long batch;	/* reclaim batch size, 0 = default */
 	int seeks;	/* seeks to recreate an obj */
@@ -110,7 +114,6 @@ struct shrinker {
 #endif
 #ifdef CONFIG_SHRINKER_DEBUG
 	int debugfs_id;
-	const char *name;
 	struct dentry *debugfs_entry;
 #endif
 	/* objs pending delete, per node */
@@ -135,6 +138,8 @@ __printf(2, 3)
 struct shrinker *shrinker_alloc(unsigned int flags, const char *fmt, ...);
 void shrinker_register(struct shrinker *shrinker);
 void shrinker_free(struct shrinker *shrinker);
+void shrinker_to_text(struct seq_buf *, struct shrinker *);
+void shrinkers_to_text(struct seq_buf *);
 
 static inline bool shrinker_try_get(struct shrinker *shrinker)
 {
diff --git a/mm/shrinker.c b/mm/shrinker.c
index 4a93fd433689..beb6ef0cb3c3 100644
--- a/mm/shrinker.c
+++ b/mm/shrinker.c
@@ -1,8 +1,9 @@
 // SPDX-License-Identifier: GPL-2.0
 #include <linux/memcontrol.h>
+#include <linux/rculist.h>
 #include <linux/rwsem.h>
+#include <linux/seq_buf.h>
 #include <linux/shrinker.h>
-#include <linux/rculist.h>
 #include <trace/events/vmscan.h>
 
 #include "internal.h"
@@ -809,3 +810,78 @@ void shrinker_free(struct shrinker *shrinker)
 	call_rcu(&shrinker->rcu, shrinker_free_rcu_cb);
 }
 EXPORT_SYMBOL_GPL(shrinker_free);
+
+void shrinker_to_text(struct seq_buf *out, struct shrinker *shrinker)
+{
+	seq_buf_printf(out, "%ps", shrinker->scan_objects);
+	if (shrinker->name)
+		seq_buf_printf(out, ": %s", shrinker->name);
+	seq_buf_putc(out, '\n');
+
+	if (shrinker->to_text) {
+		shrinker->to_text(out, shrinker);
+		seq_buf_puts(out, "\n");
+	}
+}
+
+/**
+ * shrinkers_to_text - Report on shrinkers with highest usage
+ *
+ * This reports on the top 10 shrinkers, by object counts, in sorted order:
+ * intended to be used for OOM reporting.
+ */
+void shrinkers_to_text(struct seq_buf *out)
+{
+	struct shrinker *shrinker;
+	struct shrinker_by_mem {
+		struct shrinker	*shrinker;
+		unsigned long	mem;
+	} shrinkers_by_mem[4];
+	int i, nr = 0;
+
+	if (!mutex_trylock(&shrinker_mutex)) {
+		seq_buf_puts(out, "(couldn't take shrinker lock)");
+		return;
+	}
+
+	list_for_each_entry(shrinker, &shrinker_list, list) {
+		struct shrink_control sc = {
+			.gfp_mask = GFP_KERNEL,
+#ifdef CONFIG_MEMCG
+			.memcg = root_mem_cgroup,
+#endif
+		};
+		unsigned long mem = shrinker->count_objects(shrinker, &sc);
+
+		if (!mem || mem == SHRINK_STOP || mem == SHRINK_EMPTY)
+			continue;
+
+		for (i = 0; i < nr; i++)
+			if (mem < shrinkers_by_mem[i].mem)
+				break;
+
+		if (nr < ARRAY_SIZE(shrinkers_by_mem)) {
+			memmove(&shrinkers_by_mem[i + 1],
+				&shrinkers_by_mem[i],
+				sizeof(shrinkers_by_mem[0]) * (nr - i));
+			nr++;
+		} else if (i) {
+			i--;
+			memmove(&shrinkers_by_mem[0],
+				&shrinkers_by_mem[1],
+				sizeof(shrinkers_by_mem[0]) * i);
+		} else {
+			continue;
+		}
+
+		shrinkers_by_mem[i] = (struct shrinker_by_mem) {
+			.shrinker = shrinker,
+			.mem = mem,
+		};
+	}
+
+	for (i = nr - 1; i >= 0; --i)
+		shrinker_to_text(out, shrinkers_by_mem[i].shrinker);
+
+	mutex_unlock(&shrinker_mutex);
+}
-- 
2.51.0


From c016944d143e764021eaf68bde794222a3cb67ca Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 22 Nov 2023 18:17:06 -0500
Subject: [PATCH 300/309] mm: shrinker: Add new stats for .to_text()

Add a few new shrinker stats.

number of objects requested to free, number of objects freed:

Shrinkers won't necessarily free all objects requested for a variety of
reasons, but if the two counts are wildly different something is likely
amiss.

.scan_objects runtime:

If one shrinker is taking an excessive amount of time to free
objects that will block kswapd from running other shrinkers.

Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Qi Zheng <zhengqi.arch@bytedance.com>
Cc: Roman Gushchin <roman.gushchin@linux.dev>
Cc: linux-mm@kvack.org
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 include/linux/shrinker.h |  6 ++++++
 mm/shrinker.c            | 29 +++++++++++++++++++++++++++++
 2 files changed, 35 insertions(+)

diff --git a/include/linux/shrinker.h b/include/linux/shrinker.h
index 6193612617a1..106622ddac77 100644
--- a/include/linux/shrinker.h
+++ b/include/linux/shrinker.h
@@ -118,6 +118,12 @@ struct shrinker {
 #endif
 	/* objs pending delete, per node */
 	atomic_long_t *nr_deferred;
+
+	atomic_long_t	objects_requested_to_free;
+	atomic_long_t	objects_freed;
+	unsigned long	last_freed;	/* timestamp, in jiffies */
+	unsigned long	last_scanned;	/* timestamp, in jiffies */
+	atomic64_t	ns_run;
 };
 #define DEFAULT_SEEKS 2 /* A good number if you don't know better. */
 
diff --git a/mm/shrinker.c b/mm/shrinker.c
index beb6ef0cb3c3..4a76364d2b7e 100644
--- a/mm/shrinker.c
+++ b/mm/shrinker.c
@@ -412,6 +412,7 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,
 
 	trace_mm_shrink_slab_start(shrinker, shrinkctl, nr,
 				   freeable, delta, total_scan, priority);
+	u64 start_time = ktime_get_ns();
 
 	/*
 	 * Normally, we should not scan less than batch_size objects in one
@@ -462,6 +463,17 @@ static unsigned long do_shrink_slab(struct shrink_control *shrinkctl,
 	 */
 	new_nr = add_nr_deferred(next_deferred, shrinker, shrinkctl);
 
+	unsigned long now = jiffies;
+	if (freed) {
+		atomic_long_add(freed, &shrinker->objects_freed);
+		shrinker->last_freed = now;
+	}
+	shrinker->last_scanned = now;
+	atomic_long_add(scanned, &shrinker->objects_requested_to_free);
+
+	atomic64_add(ktime_get_ns() - start_time, &shrinker->ns_run);
+
+
 	trace_mm_shrink_slab_end(shrinker, shrinkctl->nid, freed, nr, new_nr, total_scan);
 	return freed;
 }
@@ -813,11 +825,28 @@ EXPORT_SYMBOL_GPL(shrinker_free);
 
 void shrinker_to_text(struct seq_buf *out, struct shrinker *shrinker)
 {
+	struct shrink_control sc = {
+		.gfp_mask = GFP_KERNEL,
+#ifdef CONFIG_MEMCG
+		.memcg = root_mem_cgroup,
+#endif
+	};
+	unsigned long nr_freed = atomic_long_read(&shrinker->objects_freed);
+
 	seq_buf_printf(out, "%ps", shrinker->scan_objects);
 	if (shrinker->name)
 		seq_buf_printf(out, ": %s", shrinker->name);
 	seq_buf_putc(out, '\n');
 
+	seq_buf_printf(out, "objects:             %lu\n", shrinker->count_objects(shrinker, &sc));
+	seq_buf_printf(out, "requested to free:   %lu\n", atomic_long_read(&shrinker->objects_requested_to_free));
+	seq_buf_printf(out, "objects freed:       %lu\n", nr_freed);
+	seq_buf_printf(out, "last scanned:        %li sec ago\n", (jiffies - shrinker->last_scanned) / HZ);
+	seq_buf_printf(out, "last freed:          %li sec ago\n", (jiffies - shrinker->last_freed) / HZ);
+	seq_buf_printf(out, "ns per object freed: %llu\n", nr_freed
+		       ? div64_ul(atomic64_read(&shrinker->ns_run), nr_freed)
+		       : 0);
+
 	if (shrinker->to_text) {
 		shrinker->to_text(out, shrinker);
 		seq_buf_puts(out, "\n");
-- 
2.51.0


From 3ba5bdf67d6469e8add85b5e9d697a374b8463a8 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 22 Nov 2023 18:18:00 -0500
Subject: [PATCH 301/309] mm: Centralize & improve oom reporting in show_mem.c

This patch:
 - Changes show_mem() to always report on slab usage
 - Instead of reporting on all slabs, we only report on top 10 slabs,
   and in sorted order
 - Also reports on shrinkers, with the new shrinkers_to_text().
   Shrinkers need to be included in OOM/allocation failure reporting
   because they're responsible for memory reclaim - if a shrinker isn't
   giving up its memory, we need to know which one and why.

More OOM reporting can be moved to show_mem.c and improved, this patch
is only a start.

New example output on OOM/memory allocation failure:

00177 Mem-Info:
00177 active_anon:13706 inactive_anon:32266 isolated_anon:16
00177  active_file:1653 inactive_file:1822 isolated_file:0
00177  unevictable:0 dirty:0 writeback:0
00177  slab_reclaimable:6242 slab_unreclaimable:11168
00177  mapped:3824 shmem:3 pagetables:1266 bounce:0
00177  kernel_misc_reclaimable:0
00177  free:4362 free_pcp:35 free_cma:0
00177 Node 0 active_anon:54824kB inactive_anon:129064kB active_file:6612kB inactive_file:7288kB unevictable:0kB isolated(anon):64kB isolated(file):0kB mapped:15296kB dirty:0kB writeback:0kB shmem:12kB writeback_tmp:0kB kernel_stack:3392kB pagetables:5064kB all_unreclaimable? no
00177 DMA free:2232kB boost:0kB min:88kB low:108kB high:128kB reserved_highatomic:0KB active_anon:2924kB inactive_anon:6596kB active_file:428kB inactive_file:384kB unevictable:0kB writepending:0kB present:15992kB managed:15360kB mlocked:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB
00177 lowmem_reserve[]: 0 426 426 426
00177 DMA32 free:15092kB boost:5836kB min:8432kB low:9080kB high:9728kB reserved_highatomic:0KB active_anon:52196kB inactive_anon:122392kB active_file:6176kB inactive_file:7068kB unevictable:0kB writepending:0kB present:507760kB managed:441816kB mlocked:0kB bounce:0kB free_pcp:72kB local_pcp:0kB free_cma:0kB
00177 lowmem_reserve[]: 0 0 0 0
00177 DMA: 284*4kB (UM) 53*8kB (UM) 21*16kB (U) 11*32kB (U) 0*64kB 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB = 2248kB
00177 DMA32: 2765*4kB (UME) 375*8kB (UME) 57*16kB (UM) 5*32kB (U) 0*64kB 0*128kB 0*256kB 0*512kB 0*1024kB 0*2048kB 0*4096kB = 15132kB
00177 4656 total pagecache pages
00177 1031 pages in swap cache
00177 Swap cache stats: add 6572399, delete 6572173, find 488603/3286476
00177 Free swap  = 509112kB
00177 Total swap = 2097148kB
00177 130938 pages RAM
00177 0 pages HighMem/MovableOnly
00177 16644 pages reserved
00177 Unreclaimable slab info:
00177 9p-fcall-cache    total: 8.25 MiB active: 8.25 MiB
00177 kernfs_node_cache total: 2.15 MiB active: 2.15 MiB
00177 kmalloc-64        total: 2.08 MiB active: 2.07 MiB
00177 task_struct       total: 1.95 MiB active: 1.95 MiB
00177 kmalloc-4k        total: 1.50 MiB active: 1.50 MiB
00177 signal_cache      total: 1.34 MiB active: 1.34 MiB
00177 kmalloc-2k        total: 1.16 MiB active: 1.16 MiB
00177 bch_inode_info    total: 1.02 MiB active: 922 KiB
00177 perf_event        total: 1.02 MiB active: 1.02 MiB
00177 biovec-max        total: 992 KiB active: 960 KiB
00177 Shrinkers:
00177 super_cache_scan: objects: 127
00177 super_cache_scan: objects: 106
00177 jbd2_journal_shrink_scan: objects: 32
00177 ext4_es_scan: objects: 32
00177 bch2_btree_cache_scan: objects: 8
00177   nr nodes:          24
00177   nr dirty:          0
00177   cannibalize lock:  0000000000000000
00177
00177 super_cache_scan: objects: 8
00177 super_cache_scan: objects: 1

Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Qi Zheng <zhengqi.arch@bytedance.com>
Cc: Roman Gushchin <roman.gushchin@linux.dev>
Cc: linux-mm@kvack.org
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 mm/oom_kill.c    | 23 ---------------------
 mm/show_mem.c    | 50 ++++++++++++++++++++++++++++++++++++++++++++++
 mm/slab.h        |  6 ++++--
 mm/slab_common.c | 52 +++++++++++++++++++++++++++++++++++++++---------
 4 files changed, 97 insertions(+), 34 deletions(-)

diff --git a/mm/oom_kill.c b/mm/oom_kill.c
index 25923cfec9c6..ad1ac9be0db4 100644
--- a/mm/oom_kill.c
+++ b/mm/oom_kill.c
@@ -169,27 +169,6 @@ static bool oom_unkillable_task(struct task_struct *p)
 	return false;
 }
 
-/*
- * Check whether unreclaimable slab amount is greater than
- * all user memory(LRU pages).
- * dump_unreclaimable_slab() could help in the case that
- * oom due to too much unreclaimable slab used by kernel.
-*/
-static bool should_dump_unreclaim_slab(void)
-{
-	unsigned long nr_lru;
-
-	nr_lru = global_node_page_state(NR_ACTIVE_ANON) +
-		 global_node_page_state(NR_INACTIVE_ANON) +
-		 global_node_page_state(NR_ACTIVE_FILE) +
-		 global_node_page_state(NR_INACTIVE_FILE) +
-		 global_node_page_state(NR_ISOLATED_ANON) +
-		 global_node_page_state(NR_ISOLATED_FILE) +
-		 global_node_page_state(NR_UNEVICTABLE);
-
-	return (global_node_page_state_pages(NR_SLAB_UNRECLAIMABLE_B) > nr_lru);
-}
-
 /**
  * oom_badness - heuristic function to determine which candidate task to kill
  * @p: task struct of which task we should calculate
@@ -469,8 +448,6 @@ static void dump_header(struct oom_control *oc)
 		mem_cgroup_print_oom_meminfo(oc->memcg);
 	else {
 		__show_mem(SHOW_MEM_FILTER_NODES, oc->nodemask, gfp_zone(oc->gfp_mask));
-		if (should_dump_unreclaim_slab())
-			dump_unreclaimable_slab();
 	}
 	if (sysctl_oom_dump_tasks)
 		dump_tasks(oc);
diff --git a/mm/show_mem.c b/mm/show_mem.c
index 0cf8bf5d832d..534848dd7209 100644
--- a/mm/show_mem.c
+++ b/mm/show_mem.c
@@ -7,15 +7,18 @@
 
 #include <linux/blkdev.h>
 #include <linux/cma.h>
+#include <linux/console.h>
 #include <linux/cpuset.h>
 #include <linux/highmem.h>
 #include <linux/hugetlb.h>
 #include <linux/mm.h>
 #include <linux/mmzone.h>
+#include <linux/seq_buf.h>
 #include <linux/swap.h>
 #include <linux/vmstat.h>
 
 #include "internal.h"
+#include "slab.h"
 #include "swap.h"
 
 atomic_long_t _totalram_pages __read_mostly;
@@ -394,10 +397,31 @@ static void show_free_areas(unsigned int filter, nodemask_t *nodemask, int max_z
 	show_swap_cache_info();
 }
 
+static void print_string_as_lines(const char *prefix, const char *lines)
+{
+	if (!lines) {
+		printk("%s (null)\n", prefix);
+		return;
+	}
+
+	bool locked = console_trylock();
+
+	while (1) {
+		const char *p = strchrnul(lines, '\n');
+		printk("%s%.*s\n", prefix, (int) (p - lines), lines);
+		if (!*p)
+			break;
+		lines = p + 1;
+	}
+	if (locked)
+		console_unlock();
+}
+
 void __show_mem(unsigned int filter, nodemask_t *nodemask, int max_zone_idx)
 {
 	unsigned long total = 0, reserved = 0, highmem = 0;
 	struct zone *zone;
+	char *buf;
 
 	printk("Mem-Info:\n");
 	show_free_areas(filter, nodemask, max_zone_idx);
@@ -449,4 +473,30 @@ void __show_mem(unsigned int filter, nodemask_t *nodemask, int max_zone_idx)
 		}
 	}
 #endif
+
+	const unsigned buf_size = 8192;
+	buf = kmalloc(buf_size, GFP_ATOMIC);
+	if (buf) {
+		struct seq_buf s;
+
+		printk("Unreclaimable slab info:\n");
+		seq_buf_init(&s, buf, buf_size);
+		dump_unreclaimable_slab(&s);
+		print_string_as_lines(KERN_NOTICE, seq_buf_str(&s));
+
+		static unsigned long shrinkers_last_print;
+
+		/* Ratelimit to at most once every 30 seconds */
+		if (!shrinkers_last_print ||
+		    time_after(jiffies, shrinkers_last_print + HZ * 30)) {
+			shrinkers_last_print = jiffies;
+
+			printk("Shrinkers:\n");
+			seq_buf_init(&s, buf, buf_size);
+			shrinkers_to_text(&s);
+			print_string_as_lines(KERN_NOTICE, seq_buf_str(&s));
+		}
+
+		kfree(buf);
+	}
 }
diff --git a/mm/slab.h b/mm/slab.h
index 05a21dc796e0..232f309d951b 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -611,10 +611,12 @@ static inline size_t slab_ksize(const struct kmem_cache *s)
 	return s->size;
 }
 
+struct seq_buf;
+
 #ifdef CONFIG_SLUB_DEBUG
-void dump_unreclaimable_slab(void);
+void dump_unreclaimable_slab(struct seq_buf *);
 #else
-static inline void dump_unreclaimable_slab(void)
+static inline void dump_unreclaimable_slab(struct seq_buf *out)
 {
 }
 #endif
diff --git a/mm/slab_common.c b/mm/slab_common.c
index bfe7c40eeee1..a365f146e669 100644
--- a/mm/slab_common.c
+++ b/mm/slab_common.c
@@ -27,6 +27,7 @@
 #include <asm/tlbflush.h>
 #include <asm/page.h>
 #include <linux/memcontrol.h>
+#include <linux/seq_buf.h>
 #include <linux/stackdepot.h>
 #include <trace/events/rcu.h>
 
@@ -1127,10 +1128,15 @@ static int slab_show(struct seq_file *m, void *p)
 	return 0;
 }
 
-void dump_unreclaimable_slab(void)
+void dump_unreclaimable_slab(struct seq_buf *out)
 {
 	struct kmem_cache *s;
 	struct slabinfo sinfo;
+	struct slab_by_mem {
+		struct kmem_cache *s;
+		size_t total, active;
+	} slabs_by_mem[10], n;
+	int i, nr = 0;
 
 	/*
 	 * Here acquiring slab_mutex is risky since we don't prefer to get
@@ -1140,24 +1146,52 @@ void dump_unreclaimable_slab(void)
 	 * without acquiring the mutex.
 	 */
 	if (!mutex_trylock(&slab_mutex)) {
-		pr_warn("excessive unreclaimable slab but cannot dump stats\n");
+		seq_buf_puts(out, "excessive unreclaimable slab but cannot dump stats\n");
 		return;
 	}
 
-	pr_info("Unreclaimable slab info:\n");
-	pr_info("Name                      Used          Total\n");
-
 	list_for_each_entry(s, &slab_caches, list) {
 		if (s->flags & SLAB_RECLAIM_ACCOUNT)
 			continue;
 
 		get_slabinfo(s, &sinfo);
 
-		if (sinfo.num_objs > 0)
-			pr_info("%-17s %10luKB %10luKB\n", s->name,
-				(sinfo.active_objs * s->size) / 1024,
-				(sinfo.num_objs * s->size) / 1024);
+		if (!sinfo.num_objs)
+			continue;
+
+		n.s = s;
+		n.total = sinfo.num_objs * s->size;
+		n.active = sinfo.active_objs * s->size;
+
+		for (i = 0; i < nr; i++)
+			if (n.total < slabs_by_mem[i].total)
+				break;
+
+		if (nr < ARRAY_SIZE(slabs_by_mem)) {
+			memmove(&slabs_by_mem[i + 1],
+				&slabs_by_mem[i],
+				sizeof(slabs_by_mem[0]) * (nr - i));
+			nr++;
+		} else if (i) {
+			i--;
+			memmove(&slabs_by_mem[0],
+				&slabs_by_mem[1],
+				sizeof(slabs_by_mem[0]) * i);
+		} else {
+			continue;
+		}
+
+		slabs_by_mem[i] = n;
 	}
+
+	for (i = nr - 1; i >= 0; --i) {
+		seq_buf_printf(out, "%-17s total: ", slabs_by_mem[i].s->name);
+		seq_buf_human_readable_u64(out, slabs_by_mem[i].total, STRING_UNITS_2);
+		seq_buf_printf(out, " active: ");
+		seq_buf_human_readable_u64(out, slabs_by_mem[i].active, STRING_UNITS_2);
+		seq_buf_putc(out, '\n');
+	}
+
 	mutex_unlock(&slab_mutex);
 }
 
-- 
2.51.0


From fbde8cfde9ef0e3c6922400deba5039409407455 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 20 Oct 2023 11:52:56 -0400
Subject: [PATCH 302/309] mm: shrinker: Add shrinker_to_text() to debugfs
 interface

Previously, we added shrinker_to_text() and hooked it up to the OOM
report - now, the same report is available via debugfs.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 mm/shrinker_debug.c | 18 ++++++++++++++++++
 1 file changed, 18 insertions(+)

diff --git a/mm/shrinker_debug.c b/mm/shrinker_debug.c
index 20eaee3e97f7..a16c2848d332 100644
--- a/mm/shrinker_debug.c
+++ b/mm/shrinker_debug.c
@@ -2,6 +2,7 @@
 #include <linux/idr.h>
 #include <linux/slab.h>
 #include <linux/debugfs.h>
+#include <linux/seq_buf.h>
 #include <linux/seq_file.h>
 #include <linux/shrinker.h>
 #include <linux/memcontrol.h>
@@ -159,6 +160,21 @@ static const struct file_operations shrinker_debugfs_scan_fops = {
 	.write	 = shrinker_debugfs_scan_write,
 };
 
+static int shrinker_debugfs_report_show(struct seq_file *m, void *v)
+{
+	struct shrinker *shrinker = m->private;
+	char *bufp;
+	size_t buflen = seq_get_buf(m, &bufp);
+	struct seq_buf out;
+
+	seq_buf_init(&out, bufp, buflen);
+	shrinker_to_text(&out, shrinker);
+	seq_commit(m, seq_buf_used(&out));
+
+	return 0;
+}
+DEFINE_SHOW_ATTRIBUTE(shrinker_debugfs_report);
+
 int shrinker_debugfs_add(struct shrinker *shrinker)
 {
 	struct dentry *entry;
@@ -190,6 +206,8 @@ int shrinker_debugfs_add(struct shrinker *shrinker)
 			    &shrinker_debugfs_count_fops);
 	debugfs_create_file("scan", 0220, entry, shrinker,
 			    &shrinker_debugfs_scan_fops);
+	debugfs_create_file("report", 0440, entry, shrinker,
+			    &shrinker_debugfs_report_fops);
 	return 0;
 }
 
-- 
2.51.0


From 375c960f7dd834b02e87c655824128a5e74af127 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Wed, 22 Nov 2023 18:19:02 -0500
Subject: [PATCH 303/309] bcachefs: shrinker.to_text() methods

This adds shrinker.to_text() methods for our shrinkers and hooks them up
to our existing to_text() functions.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/btree_cache.c     | 16 ++++++++++++++++
 fs/bcachefs/btree_key_cache.c | 14 ++++++++++++++
 2 files changed, 30 insertions(+)

diff --git a/fs/bcachefs/btree_cache.c b/fs/bcachefs/btree_cache.c
index 59638d09e1fd..3b1d694dcb3a 100644
--- a/fs/bcachefs/btree_cache.c
+++ b/fs/bcachefs/btree_cache.c
@@ -15,6 +15,7 @@
 
 #include <linux/prefetch.h>
 #include <linux/sched/mm.h>
+#include <linux/seq_buf.h>
 #include <linux/swap.h>
 
 const char * const bch2_btree_node_flags[] = {
@@ -565,6 +566,19 @@ static unsigned long bch2_btree_cache_count(struct shrinker *shrink,
 	return btree_cache_can_free(list);
 }
 
+static void bch2_btree_cache_shrinker_to_text(struct seq_buf *s, struct shrinker *shrink)
+{
+	struct btree_cache_list *list = shrink->private_data;
+	struct btree_cache *bc = container_of(list, struct btree_cache, live[list->idx]);
+
+	char *cbuf;
+	size_t buflen = seq_buf_get_buf(s, &cbuf);
+	struct printbuf out = PRINTBUF_EXTERN(cbuf, buflen);
+
+	bch2_btree_cache_to_text(&out, bc);
+	seq_buf_commit(s, out.pos);
+}
+
 void bch2_fs_btree_cache_exit(struct bch_fs *c)
 {
 	struct btree_cache *bc = &c->btree_cache;
@@ -659,6 +673,7 @@ int bch2_fs_btree_cache_init(struct bch_fs *c)
 	bc->live[0].shrink	= shrink;
 	shrink->count_objects	= bch2_btree_cache_count;
 	shrink->scan_objects	= bch2_btree_cache_scan;
+	shrink->to_text		= bch2_btree_cache_shrinker_to_text;
 	shrink->seeks		= 2;
 	shrink->private_data	= &bc->live[0];
 	shrinker_register(shrink);
@@ -669,6 +684,7 @@ int bch2_fs_btree_cache_init(struct bch_fs *c)
 	bc->live[1].shrink	= shrink;
 	shrink->count_objects	= bch2_btree_cache_count;
 	shrink->scan_objects	= bch2_btree_cache_scan;
+	shrink->to_text		= bch2_btree_cache_shrinker_to_text;
 	shrink->seeks		= 8;
 	shrink->private_data	= &bc->live[1];
 	shrinker_register(shrink);
diff --git a/fs/bcachefs/btree_key_cache.c b/fs/bcachefs/btree_key_cache.c
index 4890cbc88e7c..e3336ab27ccc 100644
--- a/fs/bcachefs/btree_key_cache.c
+++ b/fs/bcachefs/btree_key_cache.c
@@ -13,6 +13,7 @@
 #include "trace.h"
 
 #include <linux/sched/mm.h>
+#include <linux/seq_buf.h>
 
 static inline bool btree_uses_pcpu_readers(enum btree_id id)
 {
@@ -808,6 +809,18 @@ void bch2_fs_btree_key_cache_init_early(struct btree_key_cache *c)
 {
 }
 
+static void bch2_btree_key_cache_shrinker_to_text(struct seq_buf *s, struct shrinker *shrink)
+{
+	struct bch_fs *c = shrink->private_data;
+	struct btree_key_cache *bc = &c->btree_key_cache;
+	char *cbuf;
+	size_t buflen = seq_buf_get_buf(s, &cbuf);
+	struct printbuf out = PRINTBUF_EXTERN(cbuf, buflen);
+
+	bch2_btree_key_cache_to_text(&out, bc);
+	seq_buf_commit(s, out.pos);
+}
+
 int bch2_fs_btree_key_cache_init(struct btree_key_cache *bc)
 {
 	struct bch_fs *c = container_of(bc, struct bch_fs, btree_key_cache);
@@ -832,6 +845,7 @@ int bch2_fs_btree_key_cache_init(struct btree_key_cache *bc)
 	bc->shrink = shrink;
 	shrink->count_objects	= bch2_btree_key_cache_count;
 	shrink->scan_objects	= bch2_btree_key_cache_scan;
+	shrink->to_text		= bch2_btree_key_cache_shrinker_to_text;
 	shrink->batch		= 1 << 14;
 	shrink->seeks		= 0;
 	shrink->private_data	= c;
-- 
2.51.0


From 87544619b1f91f55ba93fcaa2429c6ae014cb991 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 10 Mar 2025 18:44:12 -0400
Subject: [PATCH 304/309] block: Allow REQ_FUA|REQ_READ

FUA is also allowed with reads, not just writes.

The specified behaviour is:
 - If the location being read from in the drive cache is dirty, it's
   flushed
 - Read is serviced from media, not cache

It's documented in the NVME specification, and the nvme driver already
passes through REQ_FUA for reads, not just writes, so there's no reason
for the block layer to be disallowing it.

To validate behaviour, a simple test was run on a variety of hardware
that checks latency of repeated reads to the same location (cached
reads), random reads (uncached), and FUA reads to the same location.

Data:
 - Samsung consumer SSDs
   Reads appear to not be cached
 - Seagate SCSI hard drives (ST20000NM002D)
   Reads are cached, and FUA reads appear to work correctly

Link: https://lore.kernel.org/linux-block/20250311133517.3095878-1-kent.overstreet@linux.dev/
Link: https://lore.kernel.org/linux-bcachefs/26585.34711.506258.318405@quad.stoffel.home/T/#m5fffbc0e1c68cf0479c94b9f4ac1bef297333782
Cc: Jens Axboe <axboe@kernel.dk>
Cc: linux-block@vger.kernel.org
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 block/blk-core.c | 19 ++++++++++---------
 1 file changed, 10 insertions(+), 9 deletions(-)

diff --git a/block/blk-core.c b/block/blk-core.c
index fdac48aec5ef..75fd237ce76c 100644
--- a/block/blk-core.c
+++ b/block/blk-core.c
@@ -800,20 +800,21 @@ void submit_bio_noacct(struct bio *bio)
 			goto end_io;
 	}
 
+	if (WARN_ON_ONCE((bio->bi_opf & REQ_PREFLUSH) &&
+			 bio_op(bio) != REQ_OP_WRITE &&
+			 bio_op(bio) != REQ_OP_ZONE_APPEND))
+		goto end_io;
+
 	/*
 	 * Filter flush bio's early so that bio based drivers without flush
 	 * support don't have to worry about them.
 	 */
-	if (op_is_flush(bio->bi_opf)) {
-		if (WARN_ON_ONCE(bio_op(bio) != REQ_OP_WRITE &&
-				 bio_op(bio) != REQ_OP_ZONE_APPEND))
+	if (op_is_flush(bio->bi_opf) &&
+	    !bdev_write_cache(bdev)) {
+		bio->bi_opf &= ~(REQ_PREFLUSH | REQ_FUA);
+		if (!bio_sectors(bio)) {
+			status = BLK_STS_OK;
 			goto end_io;
-		if (!bdev_write_cache(bdev)) {
-			bio->bi_opf &= ~(REQ_PREFLUSH | REQ_FUA);
-			if (!bio_sectors(bio)) {
-				status = BLK_STS_OK;
-				goto end_io;
-			}
 		}
 	}
 
-- 
2.51.0


From b1b00ab04d3436e3e9716ff552abb959c2aedf1a Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 17 Mar 2025 15:08:43 -0400
Subject: [PATCH 305/309] bcachefs: read_fua_test

Add a sysfs attribute for checking whether read fua appears to behave
properly on a device.

Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/sysfs.c | 117 ++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 117 insertions(+)

diff --git a/fs/bcachefs/sysfs.c b/fs/bcachefs/sysfs.c
index cf97c9ab2a5c..bd3fa9c3372d 100644
--- a/fs/bcachefs/sysfs.c
+++ b/fs/bcachefs/sysfs.c
@@ -45,6 +45,7 @@
 
 #include <linux/blkdev.h>
 #include <linux/sort.h>
+#include <linux/string_choices.h>
 #include <linux/sched/clock.h>
 
 #include "util.h"
@@ -157,6 +158,7 @@ write_attribute(trigger_recalc_capacity);
 write_attribute(trigger_delete_dead_snapshots);
 write_attribute(trigger_emergency_read_only);
 read_attribute(gc_gens_pos);
+__sysfs_attribute(read_fua_test, 0400);
 
 read_attribute(uuid);
 read_attribute(minor);
@@ -305,6 +307,116 @@ static void bch2_fs_usage_base_to_text(struct printbuf *out, struct bch_fs *c)
 	prt_printf(out, "nr_inodes:\t%llu\n",	b.nr_inodes);
 }
 
+static int bch2_read_fua_test(struct printbuf *out, struct bch_dev *ca)
+{
+	struct bch_fs *c = ca->fs;
+	struct bio *bio = NULL;
+	void *buf = NULL;
+	unsigned bs = c->opts.block_size, iters;
+	u64 end, test_duration = NSEC_PER_SEC * 2;
+	struct bch2_time_stats stats_nofua, stats_fua, stats_random;
+	int ret = 0;
+
+	bch2_time_stats_init_no_pcpu(&stats_nofua);
+	bch2_time_stats_init_no_pcpu(&stats_fua);
+	bch2_time_stats_init_no_pcpu(&stats_random);
+
+	if (!bch2_dev_get_ioref(c, ca->dev_idx, READ, BCH_DEV_READ_REF_read_fua_test)) {
+		prt_str(out, "offline\n");
+		return 0;
+	}
+
+	struct block_device *bdev = ca->disk_sb.bdev;
+
+	bio = bio_kmalloc(1, GFP_KERNEL);
+	if (!bio) {
+		ret = -ENOMEM;
+		goto err;
+	}
+
+	buf = kmalloc(bs, GFP_KERNEL);
+	if (!buf)
+		goto err;
+
+	end = ktime_get_ns() + test_duration;
+	for (iters = 0; iters < 1000 && time_before64(ktime_get_ns(), end); iters++) {
+		bio_init(bio, bdev, bio->bi_inline_vecs, 1, READ);
+		bch2_bio_map(bio, buf, bs);
+
+		u64 submit_time = ktime_get_ns();
+		ret = submit_bio_wait(bio);
+		bch2_time_stats_update(&stats_nofua, submit_time);
+
+		if (ret)
+			goto err;
+	}
+
+	end = ktime_get_ns() + test_duration;
+	for (iters = 0; iters < 1000 && time_before64(ktime_get_ns(), end); iters++) {
+		bio_init(bio, bdev, bio->bi_inline_vecs, 1, REQ_FUA|READ);
+		bch2_bio_map(bio, buf, bs);
+
+		u64 submit_time = ktime_get_ns();
+		ret = submit_bio_wait(bio);
+		bch2_time_stats_update(&stats_fua, submit_time);
+
+		if (ret)
+			goto err;
+	}
+
+	u64 dev_size = ca->mi.nbuckets * bucket_bytes(ca);
+
+	end = ktime_get_ns() + test_duration;
+	for (iters = 0; iters < 1000 && time_before64(ktime_get_ns(), end); iters++) {
+		bio_init(bio, bdev, bio->bi_inline_vecs, 1, READ);
+		bio->bi_iter.bi_sector = (bch2_get_random_u64_below(dev_size) & ~((u64) bs - 1)) >> 9;
+		bch2_bio_map(bio, buf, bs);
+
+		u64 submit_time = ktime_get_ns();
+		ret = submit_bio_wait(bio);
+		bch2_time_stats_update(&stats_random, submit_time);
+
+		if (ret)
+			goto err;
+	}
+
+	u64 ns_nofua		= mean_and_variance_get_mean(stats_nofua.duration_stats);
+	u64 ns_fua		= mean_and_variance_get_mean(stats_fua.duration_stats);
+	u64 ns_rand		= mean_and_variance_get_mean(stats_random.duration_stats);
+
+	u64 stddev_nofua	= mean_and_variance_get_stddev(stats_nofua.duration_stats);
+	u64 stddev_fua		= mean_and_variance_get_stddev(stats_fua.duration_stats);
+	u64 stddev_rand		= mean_and_variance_get_stddev(stats_random.duration_stats);
+
+	printbuf_tabstop_push(out, 8);
+	printbuf_tabstop_push(out, 12);
+	printbuf_tabstop_push(out, 12);
+	prt_printf(out, "This test must be run on an idle drive for accurate results\n");
+	prt_printf(out, "%s\n", dev_name(&ca->disk_sb.bdev->bd_device));
+	prt_printf(out, "fua support advertized: %s\n", str_yes_no(bdev_fua(bdev)));
+	prt_newline(out);
+	prt_printf(out, "ns:\tlatency\rstddev\r\n");
+	prt_printf(out, "nofua\t%llu\r%llu\r\n",	ns_nofua,	stddev_nofua);
+	prt_printf(out, "fua\t%llu\r%llu\r\n",		ns_fua,		stddev_fua);
+	prt_printf(out, "random\t%llu\r%llu\r\n",	ns_rand,	stddev_rand);
+
+	bool read_cache = ns_nofua * 2 < ns_rand;
+	bool fua_cached	= read_cache && ns_fua < (ns_nofua + ns_rand) / 2;
+
+	if (!read_cache)
+		prt_str(out, "reads don't appear to be cached - safe\n");
+	else if (!fua_cached)
+		prt_str(out, "fua reads don't appear to be cached - safe\n");
+	else
+		prt_str(out, "fua reads appear to be cached - unsafe\n");
+err:
+	kfree(buf);
+	kfree(bio);
+	enumerated_ref_put(&ca->io_ref[READ], BCH_DEV_READ_REF_read_fua_test);
+	bch_err_fn(c, ret);
+	return ret;
+}
+
 SHOW(bch2_fs)
 {
 	struct bch_fs *c = container_of(kobj, struct bch_fs, kobj);
@@ -848,6 +960,9 @@ SHOW(bch2_dev)
 	if (attr == &sysfs_open_buckets)
 		bch2_open_buckets_to_text(out, c, ca);
 
+	if (attr == &sysfs_read_fua_test)
+		return bch2_read_fua_test(out, ca);
+
 	int opt_id = bch2_opt_lookup(attr->name);
 	if (opt_id >= 0)
 		return sysfs_opt_show(c, ca, opt_id, out);
@@ -912,6 +1027,8 @@ struct attribute *bch2_dev_files[] = {
 	&sysfs_congested,
 #endif
 
+	&sysfs_read_fua_test,
+
 	/* debug: */
 	&sysfs_alloc_debug,
 	&sysfs_open_buckets,
-- 
2.51.0


From 8921c2790c0ff07fe8a347657c580e2f17ea17ed Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Mon, 10 Mar 2025 15:40:04 -0400
Subject: [PATCH 306/309] bcachefs: Read retries are after checksum errors now
 REQ_FUA

REQ_FUA means "skip the drive cache", and it can be used with reads to.
If there was a checksum error, we want to retry the whole read path, not
read it from cache again.

Suggested-by: Benjamin LaHaise <bcrl@kvack.org>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/bcachefs/io_read.c | 13 ++++---------
 1 file changed, 4 insertions(+), 9 deletions(-)

diff --git a/fs/bcachefs/io_read.c b/fs/bcachefs/io_read.c
index c4f0f9d8f959..e7d53ab1cf55 100644
--- a/fs/bcachefs/io_read.c
+++ b/fs/bcachefs/io_read.c
@@ -37,12 +37,6 @@ module_param_named(read_corrupt_ratio, bch2_read_corrupt_ratio, uint, 0644);
 MODULE_PARM_DESC(read_corrupt_ratio, "");
 #endif
 
-static bool bch2_poison_extents_on_checksum_error;
-module_param_named(poison_extents_on_checksum_error,
-		   bch2_poison_extents_on_checksum_error, bool, 0644);
-MODULE_PARM_DESC(poison_extents_on_checksum_error,
-		 "Extents with checksum errors are marked as poisoned - unsafe without read fua support");
-
 #ifndef CONFIG_BCACHEFS_NO_LATENCY_ACCT
 
 static inline u32 bch2_dev_congested_read(struct bch_dev *ca, u64 now)
@@ -546,9 +540,6 @@ static void get_rbio_extent(struct btree_trans *trans,
 static noinline int maybe_poison_extent(struct btree_trans *trans, struct bch_read_bio *rbio,
 					enum btree_id btree, struct bkey_s_c read_k)
 {
-	if (!bch2_poison_extents_on_checksum_error)
-		return 0;
-
 	struct bch_fs *c = trans->c;
 
 	struct data_update *u = rbio_data_update(rbio);
@@ -1273,6 +1264,10 @@ int __bch2_read_extent(struct btree_trans *trans, struct bch_read_bio *orig,
 
 	async_object_list_add(c, rbio, rbio, &rbio->list_idx);
 
+	/* XXX: also nvme read recovery level */
+	if (unlikely(failed && bch2_dev_io_failures(failed, pick.ptr.dev)))
+		rbio->bio.bi_opf |= REQ_FUA;
+
 	if (rbio->bounce)
 		trace_and_count(c, io_read_bounce, &rbio->bio);
 
-- 
2.51.0


From 14e98386b7efaebef8b763e74c67b16986e25593 Mon Sep 17 00:00:00 2001
From: Amir Goldstein <amir73il@gmail.com>
Date: Mon, 2 Jun 2025 19:17:02 +0200
Subject: [PATCH 307/309] ovl: support layers on case-folding capable
 filesystems

Case folding is often applied to subtrees and not on an entire
filesystem.

Disallowing layers from filesystems that support case folding is over
limiting.

Replace the rule that case-folding capable are not allowed as layers
with a rule that case folded directories are not allowed in a merged
directory stack.

Should case folding be enabled on an underlying directory while
overlayfs is mounted the outcome is generally undefined.

Specifically in ovl_lookup(), we check the base underlying directory
and fail with -ESTALE and write a warning to kmsg if an underlying
directory case folding is enabled.

Suggested-by: Kent Overstreet <kent.overstreet@linux.dev>
Link: https://lore.kernel.org/linux-fsdevel/20250520051600.1903319-1-kent.overstreet@linux.dev/
Signed-off-by: Amir Goldstein <amir73il@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 fs/overlayfs/namei.c     | 31 ++++++++++++++++++++++++++++---
 fs/overlayfs/overlayfs.h |  6 ++++++
 fs/overlayfs/params.c    | 10 ++++------
 fs/overlayfs/util.c      | 15 +++++++++++----
 4 files changed, 49 insertions(+), 13 deletions(-)

diff --git a/fs/overlayfs/namei.c b/fs/overlayfs/namei.c
index 2043f0369059..76d6248b625e 100644
--- a/fs/overlayfs/namei.c
+++ b/fs/overlayfs/namei.c
@@ -230,13 +230,26 @@ static int ovl_lookup_single(struct dentry *base, struct ovl_lookup_data *d,
 			     struct dentry **ret, bool drop_negative)
 {
 	struct ovl_fs *ofs = OVL_FS(d->sb);
-	struct dentry *this;
+	struct dentry *this = NULL;
+	const char *warn;
 	struct path path;
 	int err;
 	bool last_element = !post[0];
 	bool is_upper = d->layer->idx == 0;
 	char val;
 
+	/*
+	 * We allow filesystems that are case-folding capable but deny composing
+	 * ovl stack from case-folded directories. If someone has enabled case
+	 * folding on a directory on underlying layer, the warranty of the ovl
+	 * stack is voided.
+	 */
+	if (ovl_dentry_casefolded(base)) {
+		warn = "case folded parent";
+		err = -ESTALE;
+		goto out_warn;
+	}
+
 	this = ovl_lookup_positive_unlocked(d, name, base, namelen, drop_negative);
 	if (IS_ERR(this)) {
 		err = PTR_ERR(this);
@@ -246,10 +259,17 @@ static int ovl_lookup_single(struct dentry *base, struct ovl_lookup_data *d,
 		goto out_err;
 	}
 
+	if (ovl_dentry_casefolded(this)) {
+		warn = "case folded child";
+		err = -EREMOTE;
+		goto out_warn;
+	}
+
 	if (ovl_dentry_weird(this)) {
 		/* Don't support traversing automounts and other weirdness */
+		warn = "unsupported object type";
 		err = -EREMOTE;
-		goto out_err;
+		goto out_warn;
 	}
 
 	path.dentry = this;
@@ -283,8 +303,9 @@ static int ovl_lookup_single(struct dentry *base, struct ovl_lookup_data *d,
 	} else {
 		if (ovl_lookup_trap_inode(d->sb, this)) {
 			/* Caught in a trap of overlapping layers */
+			warn = "overlapping layers";
 			err = -ELOOP;
-			goto out_err;
+			goto out_warn;
 		}
 
 		if (last_element)
@@ -316,6 +337,10 @@ static int ovl_lookup_single(struct dentry *base, struct ovl_lookup_data *d,
 	this = NULL;
 	goto out;
 
+out_warn:
+	pr_warn_ratelimited("failed lookup in %s (%pd2, name='%.*s', err=%i): %s\n",
+			    is_upper ? "upper" : "lower", base,
+			    namelen, name, err, warn);
 out_err:
 	dput(this);
 	return err;
diff --git a/fs/overlayfs/overlayfs.h b/fs/overlayfs/overlayfs.h
index 497323128e5f..55806bd36faa 100644
--- a/fs/overlayfs/overlayfs.h
+++ b/fs/overlayfs/overlayfs.h
@@ -448,6 +448,12 @@ void ovl_dentry_init_reval(struct dentry *dentry, struct dentry *upperdentry,
 void ovl_dentry_init_flags(struct dentry *dentry, struct dentry *upperdentry,
 			   struct ovl_entry *oe, unsigned int mask);
 bool ovl_dentry_weird(struct dentry *dentry);
+
+static inline bool ovl_dentry_casefolded(struct dentry *dentry)
+{
+	return sb_has_encoding(dentry->d_sb) && IS_CASEFOLDED(d_inode(dentry));
+}
+
 enum ovl_path_type ovl_path_type(struct dentry *dentry);
 void ovl_path_upper(struct dentry *dentry, struct path *path);
 void ovl_path_lower(struct dentry *dentry, struct path *path);
diff --git a/fs/overlayfs/params.c b/fs/overlayfs/params.c
index f42488c01957..2b9b31524c38 100644
--- a/fs/overlayfs/params.c
+++ b/fs/overlayfs/params.c
@@ -282,13 +282,11 @@ static int ovl_mount_dir_check(struct fs_context *fc, const struct path *path,
 		return invalfc(fc, "%s is not a directory", name);
 
 	/*
-	 * Root dentries of case-insensitive capable filesystems might
-	 * not have the dentry operations set, but still be incompatible
-	 * with overlayfs.  Check explicitly to prevent post-mount
-	 * failures.
+	 * Allow filesystems that are case-folding capable but deny composing
+	 * ovl stack from case-folded directories.
 	 */
-	if (sb_has_encoding(path->mnt->mnt_sb))
-		return invalfc(fc, "case-insensitive capable filesystem on %s not supported", name);
+	if (ovl_dentry_casefolded(path->dentry))
+		return invalfc(fc, "case-insensitive directory on %s not supported", name);
 
 	if (ovl_dentry_weird(path->dentry))
 		return invalfc(fc, "filesystem on %s not supported", name);
diff --git a/fs/overlayfs/util.c b/fs/overlayfs/util.c
index dcccb4b4a66c..593c4da107d6 100644
--- a/fs/overlayfs/util.c
+++ b/fs/overlayfs/util.c
@@ -206,10 +206,17 @@ bool ovl_dentry_weird(struct dentry *dentry)
 	if (!d_can_lookup(dentry) && !d_is_file(dentry) && !d_is_symlink(dentry))
 		return true;
 
-	return dentry->d_flags & (DCACHE_NEED_AUTOMOUNT |
-				  DCACHE_MANAGE_TRANSIT |
-				  DCACHE_OP_HASH |
-				  DCACHE_OP_COMPARE);
+	if (dentry->d_flags & (DCACHE_NEED_AUTOMOUNT | DCACHE_MANAGE_TRANSIT))
+		return true;
+
+	/*
+	 * Allow filesystems that are case-folding capable but deny composing
+	 * ovl stack from case-folded directories.
+	 */
+	if (sb_has_encoding(dentry->d_sb))
+		return IS_CASEFOLDED(d_inode(dentry));
+
+	return dentry->d_flags & (DCACHE_OP_HASH | DCACHE_OP_COMPARE);
 }
 
 enum ovl_path_type ovl_path_type(struct dentry *dentry)
-- 
2.51.0


From e47a75865e2462dbc32dc7da95eacec79ad16f10 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Sun, 15 Jun 2025 13:11:58 -0400
Subject: [PATCH 308/309] workqueue: Basic memory allocation profiling support

Hook alloc_workqueue and alloc_workqueue_attrs() so that they're
accounted to the callsite. Since we're doing allocations on behalf of
another subsystem, this helps when using memory allocation profiling to
check for leaks.

Cc: Tejun Heo <tj@kernel.org>
Cc: Lai Jiangshan <jiangshanlai@gmail.com>
Signed-off-by: Kent Overstreet <kent.overstreet@linux.dev>
---
 include/linux/workqueue.h | 12 ++++++++----
 kernel/workqueue.c        | 14 +++++++-------
 2 files changed, 15 insertions(+), 11 deletions(-)

diff --git a/include/linux/workqueue.h b/include/linux/workqueue.h
index 6e30f275da77..e907c9bb840c 100644
--- a/include/linux/workqueue.h
+++ b/include/linux/workqueue.h
@@ -6,6 +6,7 @@
 #ifndef _LINUX_WORKQUEUE_H
 #define _LINUX_WORKQUEUE_H
 
+#include <linux/alloc_tag.h>
 #include <linux/timer.h>
 #include <linux/linkage.h>
 #include <linux/bitops.h>
@@ -505,7 +506,8 @@ void workqueue_softirq_dead(unsigned int cpu);
  * Pointer to the allocated workqueue on success, %NULL on failure.
  */
 __printf(1, 4) struct workqueue_struct *
-alloc_workqueue(const char *fmt, unsigned int flags, int max_active, ...);
+alloc_workqueue_noprof(const char *fmt, unsigned int flags, int max_active, ...);
+#define alloc_workqueue(...)	alloc_hooks(alloc_workqueue_noprof(__VA_ARGS__))
 
 #ifdef CONFIG_LOCKDEP
 /**
@@ -544,8 +546,8 @@ alloc_workqueue_lockdep_map(const char *fmt, unsigned int flags, int max_active,
  * Pointer to the allocated workqueue on success, %NULL on failure.
  */
 #define alloc_ordered_workqueue_lockdep_map(fmt, flags, lockdep_map, args...)	\
-	alloc_workqueue_lockdep_map(fmt, WQ_UNBOUND | __WQ_ORDERED | (flags),	\
-				    1, lockdep_map, ##args)
+	alloc_hooks(alloc_workqueue_lockdep_map(fmt, WQ_UNBOUND | __WQ_ORDERED | (flags),\
+						1, lockdep_map, ##args))
 #endif
 
 /**
@@ -577,7 +579,9 @@ alloc_workqueue_lockdep_map(const char *fmt, unsigned int flags, int max_active,
 
 extern void destroy_workqueue(struct workqueue_struct *wq);
 
-struct workqueue_attrs *alloc_workqueue_attrs(void);
+struct workqueue_attrs *alloc_workqueue_attrs_noprof(void);
+#define alloc_workqueue_attrs(...)	alloc_hooks(alloc_workqueue_attrs_noprof(__VA_ARGS__))
+
 void free_workqueue_attrs(struct workqueue_attrs *attrs);
 int apply_workqueue_attrs(struct workqueue_struct *wq,
 			  const struct workqueue_attrs *attrs);
diff --git a/kernel/workqueue.c b/kernel/workqueue.c
index 9f9148075828..992cb0467c21 100644
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -4629,7 +4629,7 @@ void free_workqueue_attrs(struct workqueue_attrs *attrs)
  *
  * Return: The allocated new workqueue_attr on success. %NULL on failure.
  */
-struct workqueue_attrs *alloc_workqueue_attrs(void)
+struct workqueue_attrs *alloc_workqueue_attrs_noprof(void)
 {
 	struct workqueue_attrs *attrs;
 
@@ -5682,12 +5682,12 @@ static struct workqueue_struct *__alloc_workqueue(const char *fmt,
 	else
 		wq_size = sizeof(*wq);
 
-	wq = kzalloc(wq_size, GFP_KERNEL);
+	wq = kzalloc_noprof(wq_size, GFP_KERNEL);
 	if (!wq)
 		return NULL;
 
 	if (flags & WQ_UNBOUND) {
-		wq->unbound_attrs = alloc_workqueue_attrs();
+		wq->unbound_attrs = alloc_workqueue_attrs_noprof();
 		if (!wq->unbound_attrs)
 			goto err_free_wq;
 	}
@@ -5777,9 +5777,9 @@ static struct workqueue_struct *__alloc_workqueue(const char *fmt,
 }
 
 __printf(1, 4)
-struct workqueue_struct *alloc_workqueue(const char *fmt,
-					 unsigned int flags,
-					 int max_active, ...)
+struct workqueue_struct *alloc_workqueue_noprof(const char *fmt,
+						unsigned int flags,
+						int max_active, ...)
 {
 	struct workqueue_struct *wq;
 	va_list args;
@@ -5794,7 +5794,7 @@ struct workqueue_struct *alloc_workqueue(const char *fmt,
 
 	return wq;
 }
-EXPORT_SYMBOL_GPL(alloc_workqueue);
+EXPORT_SYMBOL_GPL(alloc_workqueue_noprof);
 
 #ifdef CONFIG_LOCKDEP
 __printf(1, 5)
-- 
2.51.0


From 3594d40e8d0b46db8b602ecc377ddf65fb846ba3 Mon Sep 17 00:00:00 2001
From: Kent Overstreet <kent.overstreet@linux.dev>
Date: Fri, 8 Aug 2025 19:41:59 -0400
Subject: [PATCH 309/309] Revert "bcachefs: Run check_snapshots before going
 RW"

This reverts commit dc5f8b16c0e65d8ea77c422dda9c437395a8dc83.
---
 fs/bcachefs/recovery_passes_format.h | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/fs/bcachefs/recovery_passes_format.h b/fs/bcachefs/recovery_passes_format.h
index 05f1c09955b4..2696eee00345 100644
--- a/fs/bcachefs/recovery_passes_format.h
+++ b/fs/bcachefs/recovery_passes_format.h
@@ -32,9 +32,6 @@
 	x(check_allocations,			 5, PASS_FSCK_ALLOC)			\
 	x(trans_mark_dev_sbs,			 6, PASS_ALWAYS|PASS_SILENT|PASS_ALLOC)	\
 	x(fs_journal_alloc,			 7, PASS_ALWAYS|PASS_SILENT|PASS_ALLOC)	\
-	x(reconstruct_snapshots,		38, 0)					\
-	x(check_snapshot_trees,			18, PASS_ONLINE|PASS_FSCK)		\
-	x(check_snapshots,			19, PASS_ONLINE|PASS_FSCK)		\
 	x(set_may_go_rw,			 8, PASS_ALWAYS|PASS_SILENT)		\
 	x(journal_replay,			 9, PASS_ALWAYS)			\
 	x(check_alloc_info,			10, PASS_ONLINE|PASS_FSCK_ALLOC)	\
@@ -45,6 +42,9 @@
 	x(check_alloc_to_lru_refs,		15, PASS_ONLINE|PASS_FSCK_ALLOC)	\
 	x(fs_freespace_init,			16, PASS_ALWAYS|PASS_SILENT)		\
 	x(bucket_gens_init,			17, 0)					\
+	x(reconstruct_snapshots,		38, 0)					\
+	x(check_snapshot_trees,			18, PASS_ONLINE|PASS_FSCK)		\
+	x(check_snapshots,			19, PASS_ONLINE|PASS_FSCK)		\
 	x(check_subvols,			20, PASS_ONLINE|PASS_FSCK)		\
 	x(check_subvol_children,		35, PASS_ONLINE|PASS_FSCK)		\
 	x(delete_dead_snapshots,		21, PASS_ONLINE|PASS_FSCK)		\
-- 
2.51.0

